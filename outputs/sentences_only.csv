text
A specification of the application's functional and nonfunctional requirements.
"First, it is anticipated that the SRS will be used by the application designers."
Designers will use the information recorded here as the basis for creating the application's design.
"Second, the client for the project, the library manager in our case, is expected to review this document."
The SRS will serve to establish a basis for agreement between the client and development team about the functionality to be provided by the application.
The purpose of this software development project is to create a new application called: DLS SYSTEM.
The client for this project wishes to enter the PC-based internet environment.
"The Library Management System will be PC-base with a internet, allowing library users to search for books,seminars and library staff members to manage the book inventory and user database."
The application will be access via a internet on a PC at any place.
"Library staff will be able to manage library user accounts including remove, change, and add."
"Library staff will be able to manage the book inventory database including remove, change, and add."
The application will generate reports for administrative purposes.
"The application will provide search function on books based on ISBN, subject, title, or author."
Provide additional flexibility and convenience to the library users.
Provide better reliability and security of the library information.
Provide a more productive environment for the library staff member.
The availability of information at any time in any place.
"DLS SYSTEM is used for Library Manager, Librarian, and Library User."
"However, it is possible to exchange data with other system through external interface if required."
The high level summary of functions in DLSSYSTEM System is described in the following concept map.
Detail functional requirements will be described in section 3.
The following table describe general users characteristics that will affect the functionality of the software product.
"This system is Web based, there will be a need to provide PC Server hardware connected to the internet."
DLS System can potentially have more than hundreds of users.
It is unrealistic to provide training for everyone.
"Therefore, the system should be designed for easy to use, providing help instructions, and appropriate error messages for invalid user inputs."
Library user is allowed to use the DLSSYSTEM only for searching book records.
User should never be able to break into the system and to perform any modification.
The DLSSYSTEM should not have any unscheduled down time during library operation hours.
Any down time in operation hours has significant impact to the operation and cause inconvenience to everyone in library.
The following is a list of assumptions and dependencies that would affect Users have basic understanding to PC and Windows and internet.
There is a method to convert all book records and library user records from the existing system into the DLSSYSTEM.
"In this section, the users of ""Search Book Record"" are refereed to librarians and patrons (library users)."
Interfaces are a critical class of components within the DML that will provide the means by which users interact with the system.
"As such, all interfaces should provide easy access to help as well as clearly indicate the current state of the user’s transaction when the user isn’t idle."
Transaction and error status MUST be displayed within each interface component.
Cut and paste of text within interfaces and into and out of the interfaces MUST be supported.
Administrative interfaces will assist Library Staff in building/maintaining collections and controlling access to them.
"Because of the complexity of the data model, Library Staff will need to be able to edit multiple records simultaneously and create links between them."
Administrative MUST be able to have multiple records open for editing Administrator MUST be able to create links (references) between records without needing to type in record identifiers.
Additionally data represented in the administrative interface may be in a differentstate than that stored in the repository.
"For example, after a record has been edited, but before it has be en “saved” into the repository two versions of the record exist."
The interface should clearly indicate the state of the locally edited record relative to the version stored in the repository.
"All editors MUST clearly indicate the state of the edited record (new,saved, and modified/not yet saved)."
"The system shall display the user account information including user ID, last and first name, and user position, privilege."
"The system shall use a graphic user interface which allows librarians to choice actions including removing, changing and adding user account and account information.."
"Within the system, logging will be used to provide a trail of transactions that have taken place."
"This might either be for developer debugging purposes, administrative checks on usage, or research on the usability of interfaces."
Transaction logs MUST be kept for each service provided.
Sufficiently detailed client session logs MUST be generated to SRS-005.
The user’s password MUST never be exposed to compromise.
SRS-006 User session logs stored for usability and other research MUST be anonymous.
"SRS-008: When download the books, the system shall display the information of the e-book which is just being downloaded including: ISBN, title, location."
The system shall allow a user to enter his/her data via choose an item via a mouse.
"SRS-011: Whenever the ""date"" data is needed, it shall be entered only by choose date from a online calendar."
The system shall allow the user to enter the library card number and ISBN both by typing or scanning.
"The system shall allow the user to enter book borrowing, recalling data as frequently as required."
"The system shall allow the user to add or change information in an account including: last name, first name, user ID, user position, user privilege."
SRS-016: the system shall allow the user to delete an entire account.
"The system shall allow the user choose language option which the SRS-019: If the search result are a list of books, the system shall allow the user to choose any one of them to see the details."
"SRS-021: the system shall allow the user to put ""delete"" for a existing e- book and specify the deleting reason."
The system shall have a report feature that will allow the user to generate a report showing the information of a particular patron.
"The system shall have a report feature that will allow the user to generate a report showing the information of book purchase information in a period including the book titles, category, the author, the publisher, the price."
"It also shall give statistic data about the total number of books purchased, the money paid by category."
"The system shall be generate those reports to the display, a file or a printer which is linked to the system."
The system shall be installed in a windows-NT network.
The Patron information report shall be generated by users who have librarian account.
The book purchase report shall only be generated by managers or users with defined privileges.
SRS-7: Database update data shall be committed to the database only after the managers have approved.
The system shall be recovered within 10 minutes if it is down.
The system shall be recovered without intervention at user terminal if it is down.
The system shall show appropriate messages at terminal when system is down.
The system shall have 99% reliability during library operating hours.
SRS-012: Scheduled down time after library operating hours shall not be more than 1 hour per day.
The system shall generate error messages when the user attempts to enter invalid data.
System must be able to extend to store and deliver new content media types.
SRS-015 System must be able to extend to support synchronization of media based on shared work/item structure.
System MUST be able to extend to include music thesaurus in later versions.
System MUST be able to extend support to MMTT components built in later versions.
System MUST be able to extend to support data sharing between records.
SRS-019System MUST be able to extend to support more sophisticated bookmaking including additional context (e.g. size and configuration of viewer) and book marking of other record types.
Instructors will be using the system in collaboration with Concourse to provide access to course materials and content stored within the DML.
Library Staff will populate the repositories with both metadata records and media content.
They must necessarily be able to generate and modify metadata and content in records as well as create references between the records.
Additionally data represented in the administrative interface may be stored in a different database .
"For example, after a record has been edited, but before it has be en “saved” into main database ."
"The RDB administrator, who will be able to select an existing word or add a new one (hence it is a less controlled list than the Subjects, suggests keywords."
This document includes the system requirements jointly defined by the project partners.
"In this document, system requirements defined by the partners are presented."
System requirements are classified into two categories: funtional and non-functional system requirements.
"Non-functional system requirements are classified into various categories: accessibility; accuracy; audit, control, and reporting; availability; backup and restore; capacity, current and forecast; certification; compliance; compatibility of software, tools, standards, platform, database; concurrency; configuration management; dependency on deployment; documentation; disaster recovery; efficiency (resource consumption for given load); effectiveness (resulting performance in relation to effort); error handling; exploitability; extensibility (adding features); failure management; interoperability; legal and regulatory; localizability; maintainability; modifiability; network topology; operability; performance/response time; privacy; portability; quality; recoverability; redundancy; reliability (mean time between failures); reporting; resource constraints (processor speed, memory, disk space, network bandwidth, etc."
System requirements are defined taking into account the user requirements.
Therefore “D1.1.2 - Use Case Scenarios and Requirements” is used during this task.
This deliverable wil be used during system design phase.
The urban spaces are full of stand-alone sensor based installations of different services designed according to their own purpose and requirements.
"For example, the municipalities provide several services to the citizens: safety and security services of citizens in the streets, traffic management, etc."
"These services rely mostly on street-implemented infrastructures, such as cameras, sensors, induction loops."
"In addition, local businesses have their own illumination systems, advertising infrastructure including neon signs, public displays etc."
They also monitor customer behavior using various sensor systems.
The INSIST project proposes an integration of these sensor-based systems into a wider perspective.
"The role of WP1 is to investigate the state-of-the-art and gather the requirements on the smart systems targeted by the INSIST project, and their development flow."
"The main objective of the second activity (Activity 1.2: System requirements) of WP1 is the definition and the consistency evaluation of the generic INSIST system requirements, taking into account the use cases and user requirements which were determined in the first activity (Activity 1.1: Use case description and user requirements) of WP1 and were provided in the first deliverable (D1.1.2 - Use Case Scenarios and Requirements)."
"To achieve this objective, a set of system requirements for INSIST platform are defined and presented in this document."
These requirements will meet user requirements and platform’s general requirements.
System requirement is a requirement at the system level that describes a function or the functions which the system as a whole should fullfill to satisfy the stakeholder needs and requirements.
"System requirements are expressed in an appropriate combination of textual statements, views, and non-functional requirements."
"System requirements express the levels of safety, security, reliability which will be necessary [1]."
"Based on this definition, a set of system requirements are defined in WP1, taking into account the user requirements."
System requirements describe what the system shall do whereas the user requirements (user needs) describe what the user does with the system.
System requirements are classified as either functional or non-functional (supplemental) requirements in terms of functionality feature of the requirement.
A functional requirement specifies something that a user needs to perform their work.
"For example, collecting traffic – related data and processing them is a functional requirement for INSIST project."
"For example, a system may be required to enter and print cost estimates; this is a functional requirement."
Non-functional requirements specify all the remaining requirements not covered by the functional requirements.
The plan for implementing functional requirements will be detailed in the system design phase.
The plan for implementing non-functional requirements will be detailed in the system architecture phase.
"System requirements are classified into three categories: (i) general system requirements, (ii) security requirements, (iii) initial capacity requirements."
"General system requirements are composed of major capabilities, major system conditions, system interfaces, and system user characteristics."
Major system conditions contain of assumptions and constraints.
System interfaces describe the dependency and relationship requirements of the system to other enterprise and/or external systems.
System interfaces include any interface to a future system or one under development.
"System user characteristics identify each type of user of the system by function, location, and type of device."
Aggregated number of users should be specified and the nature of their use of the system should be explained.
Security requirements are related to the security requirements for users of the system.
Initial capacity requirements should be specified for the system.
"An initial estimation can be established using current data amounts, planned number of users, and estimated number of services."
General system acceptance criteria should be specified and agreed upon by the project partners and the potential customers who will be used to accept the final end product.
Requirement: Performance requirements should be defined.
Performance requirements should be specified and defined to measure the performance of the INSIST Platform.
A list of performance criteria of the platform should be defined.
These performance criteria will be used during the acceptance of the project output.
The performance of the platform will be measured by using simulation and instrumentation tools.
Obtained results will be included into performance analysis report of the platform.
The elapsed time between the request of traffic density at a specific location and the calculation of the value.
Quality criteria of the UIs of the INSIST Platform should be defined and quality of the UIs should be measured.
Quality of the UIs of the INSIST Platform should be measured and should meet required quality level.
"Documentation, complexity, integration, and usability criteria will be considered during the measurement of the UIs."
Requirement: Software quality attributes should be defined.
Software quality attributes should be specified and defined to measure the quality of the INSIST Platform.
The quality charactreistics of the INSIST Platform should be specified.
These characteristics are the items which can be important to either platform customers or platform developers.
"The important characteristics include adaptability, availability, reusability, robustness, testability, and usability."
Requirement: Operating environment should be described.
Operating environment in which the software will operate should be described.
"Operating environment requirements include the hardware platform, operating system and versions, and any other software components or applications."
Requirement: Limitations and contraints should be defined.
Limitations and contraints should be defined and the platform developers should be informed.
Any items or issues which will limit the options available to the platform developers should be described.
Requirement: User documentation should be prepared.
User documentation should be prepared for all types of the platform users.
"User documentations include user manuals, on-line help, and tutorials should be prepared."
All documents should be delivered along with the platform or applications.
User types of the INSIST Platform and the main characteristics of the users should be defined.
Requirement: Assumptions and dependencies should be defined.
Assumptions and dependencies can affect the development process.
Platform developers and users should be informed about them.
Assumptions and dependencies which could affect the development of the system should be defined.
"These could include third-party or commercial components, issues around the development or operating environment, and constraints."
Requirement: External interface requirements should be defined.
All interface requirements should be specified and defined.
"External interface requirements include user interfaces, hardware interfaces, software interfaces, and communication interfaces."
"User interface requirements such as sample screens, and GUI standards are the logical characteristics of each interface between the platform and the users."
The logical and physical characteristics of each interface between the platform and the hardware components should be defined.
Hardware components include the supported device types.
"Requirements of the hardware interfaces contain required data and control interactions between platform and the hardware, and the communication protocols to be used."
The connections between the platform and the other used software components should be described.
"The used software components include databases, operating systems, tools, libraries, and commercial components."
Name and the versions should be identified in the requirement document.
The requirements associated with any communications functions required by the INSIST Platform should be described.
"These communication functions include web browser, network server communications protocols, and so on."
"The communication standards (such as ftp, http) that will be used should be identified."
The initial capacity requirements should be specified.
The initial capacity requirements of the INSIST Platform should be specified.
"The initial estimation will be established using current test data amounts, planned number of users, and estimated number of transactions."
"The highest and lowest numbers of the transactions, and processing frequency expected usage will be estimated."
These will be used for capacity planning for storage and memory requirements for INSIST Platform.
Two different main user types are defined in INSIST platform.
Any kind of user type can be chose when setting up your users in the INSIST system.
"A system user is a person who interacts with the INSIST system, through an interface to define the behaviour of the system and how the end users would interact with the system."
A maintenance user who has the role of Administrator can access the maintenance console of the INSIST project.
"A maintenance user can develop applications on th INSIST platform, create / update the database and test the system."
"A database manager performs the management functionalities, such as creation and maintenance of the database."
"A database manager has also abilities to back up and restore, attach and detach, create and clone the database."
A developer can develop new applications or services for the INSIST platform.
A test user can run the test scenarios on the INSIST platform.
A data analysis user can access to the INSIST platform to analyze platform data and obtain results.
System admin user can access to all areas of the INSIST platform.
B2B users use INSIST Platform for their production and/or service process.
They need INSIST Platform's functionalities for their operational reasons.
The overall volume of B2B user's transactions is much higher than the volume of B2C user's transactions.
B2C users in INSIST Platform are all road users such as pedestrians and drivers.
A list of abbreviations used in this document is presented below.
"This chapter is an informative introductory element that gives certain information or commentaries about the purpose of the requirement specification (e.g. that the requirement specification describes services, requirements, inspection and testing conditions that the product to be developed has to fulfil)."
"The foreword must not contain any technical or functional requirements, images or tables."
Structure: level 1 and level 2 of the VDA component requirement specification structure have to be kept and must not be changed.
"Expansion of the structure: if supplements are necessary in the implementation of the VDA structure on level 1, in each case these are to be added to the last chapter with content of Module I or Module II (see Module I, chapter 12 and Module II chapter 7)."
"Expansions on level 2 of the VDA structure are to be placed at the end of a respective sub-chapter structure (see e.g. Module I, chapter 2.6)."
"Headlines that are not used may not be deleted on levels 1 and 2 of the Modules I and II, in order to guarantee the transparency and clarity of the component requirement specification contents."
When referencing an external document it has to be entered here.
Contents on level 3 are to be preferentially used and have the nature of a recommendation.
"If chapters from level 3 are not used, these may be deleted or renamed."
It consists of universal requirements for the component requirement specification (Module I) and components (Module II).
"In this chapter, roughly describe the component and/or the service scope to be developed."
"This chapter provides information about the rough objective of the product to be developed and/or delivered (e.g. clear improvements in regard to image, market leadership, expected costs, consumption, efficiency, pollutant emissions, etc)."
"In this chapter the component-specific details are to be given about product line, target markets, fields and purpose of application to which the component is to be assigned and for which it is to be developed."
"Furthermore, stipulations about variant management (at the contractor’s) and about a targeted blocking of components, parts or product lines are to be made."
"In addition, specific features and regulations (internal and external) for various target markets should be addressed if possible."
"Additionally, further requirements on the data security are to be formulated here if they have not already been defined in the chapter “Product Data Management” (Module I)."
"In this chapter the development and delivery scope is to be described, e. all services that are connected to the delivery of the component (including prototypes)."
"This also includes the proof of certification, auditing, etc., that are necessary at the time of the quotation at the latest."
"Furthermore, a reference to the performance requirement is to be stated here, if this is necessary."
"The requirements on the properties, condition and durability of the components are to be formulated in this chapter."
A component-specific development and testing schedule that deviates from the project master schedule (e.g. for long-running parts) is to be individually stipulated here.
"If available, reference is to be made to a schedule with project-wide validity, in order to avoid redundancies between the individual CRS modules (cross-component deadlines are determined in CRS Module I)."
"The participants, the contents and the possible escalation paths for certain milestones over the course of the project are to be determined here (reference is to be made to existing standards in the CRS Module I where possible)."
"Furthermore, component-specific “main milestones”, assurance levels descriptions) have to be defined in this chapter."
"Customer requirements on the contractor’s internal reviews (e.g. participation possibility, result documentation) have to be determined for different types of reviews (design, design engineering, validation, crash, etc)."
"The type, number, date and participants (function) of reviews (e.g. requirement review, design review, quality gates, project management reviews, and additional development-accompanying reviews) are to be determined here."
"Definition of prototype categories and pieces regarding the properties and condition at milestones, the deadlines and the number of individual pieces."
"Reference is to be made to existing standards, if applicable, when defining prototype statuses (the generally valid definitions should be listed in CRS Module I if they are relevant to the contractor)."
In this chapter the quantities of the individual prototype statuses are to be agreed on with the contractor.
The inspections that are to be carried out and the acceptance and release criteria for the various prototype statuses and first samples are to be defined here.
"For the proof of compliance to legal requirements, tests in consultation with the customer’s responsible department and, if necessary, in the presence of the technical monitoring service are to be carried out and documented."
"Here the type approvals and certifications to be carried out for the vehicle are to be defined that also have an effect on the development and release of the individual components (content, terms, VDA standards, DIN standards, etc)."
"If available, information about the milestones within the certification of the component and the vehicle has to be given here."
"In this chapter, requirements for quality and reliability are to be described that go beyond the legally binding as well as the general requirements in CRS Module I (e.g. early fault detection system)."
"In this chapter, requirements are to be formulated as to how the con- tractor or its sub-supplier is to conduct risk management."
"A differentiated determination of the responsibilities between customer, contractor or sub-supplier is important."
"Furthermore, component-specific details about FMEA or FTA (e.g. type [process, product] or design) as well as the tests to be conducted and deadlines are to be given."
In this chapter the evaluations for relevant parts (risk components) that are to be conducted in the framework of a preventive quality concept are to be determined.
"In the course of a CPM process, all parts of the E/E components are to be identified in this chapter whose risks regarding insufficient automotive suitability according to the above evaluation is classified as “to be critically observed”."
"In this chapter, agreements for the validation of the software quality are made."
The requirements on the SW quality management are to be defined.
"If the given content structure does not suffice to assign all requirements on level 2 to the superordinated subject on level 1, the requirements can be assigned to this chapter."
"If this chapter is not needed, you should delete it!"
The responsibilities and escalation paths in the project are to be deter- mined in this chapter.
"The component-specific requirements have to define the cooperation on various aggregation levels (design enginee- ring, system integration, diagnostics, construction of test vehicles, test drives – further detailing would be conceivable, but should not result in any redundancies to the other requirements and information [e.g. in testing])."
"A list of contact persons at the customer (and at the contractor, if known) has to be added in order to complete the information."
"Supplementary requirements regarding the distribution and fulfilment of tasks are also to be defined in this chapter (e.g. resident engineers, capacity requirements, qualification profiles of the project members, communication concept, and customer cooperation obligations in testing)."
The requirements on the conformity of the component and the pre- cautions taken by the contractor for the safeguarding of the conformity are to be requested here.
In this chapter the component and its environment (component environment) is to be described briefly and in an overview manner.
This facilitates a quick overview of the function of the component and how it communicates with other components.
In this chapter the component is to be described in connection to the relevant physical interfaces as well as to the affected components during development and/or production.
"Relevant requirements in regard to mounting, distances and collision, as well as permitted or preferred fastening systems, are also to be described."
A system circuit diagram that shows the component of this requirement specification in the intended environment is to be added here.
"Clear names and abbreviations, as well as the part number of the com- ponent are to be given here."
The described basic and partial functions of the component are to be illustrated here graphically (e.g. as function block diagram or principle depiction).
The requirements on the component regarding possible faulty operation are to be defined here.
The requirements for protective timeout as well as regarding targeted misuse of the component are to be described.
The functional specifications for ensuring emergency operation are to be described here.
"All requirements concerning operation of the component (e.g. switching, pushing, pulling, turning, or multifunction assignment of switches and push buttons) are to be established in this chapter."
"Although the operating concept for the component to be developed is the main focus in this chapter, the relevant requirements or boundary conditions of possible superordinated or affected systems also have to be addressed (where applicable with a reference to the system description)."
"Possible requirements on the displays, voice entries and responses, operation philosophy, etc."
"Furthermore, the MMI concept for output, reset or confirmation of fault states is to be specified, if applicable."
Please note that there could be cross-sections to the MMI requirement specification.
"Describe the service and/or application functions of the component (e.g. emergency call, DynAPS) here."
The diagnostics requirements on the component and the individual functions are to be defined here.
A control unit concept determines the individual systems and blocks of the component that are – in terms of software and hardware – necessary for the implementation of the complete function.
"Describe the design of the component, taking into consideration the requirements for computer and storage selection, number of plug positions, plugs, operating system, and design principles."
Pay attention to the legal regulations and the customer’s system requirements.
"The signal characteristics of all electrical connections (input and output signals, as well as bus signals) are to be described here with all signal information, load behaviour, and conditions under which the signals are positively identified or made available."
"The signal characteristics, signal types (analogue or digital), modulation, signal amplitude, frequency range, protocol, bus, signal coding etc."
"If a diagnostic interface in the component is intended, the requirements for this (if available) are to be taken from the diagnostics specifications implementation regulations."
"If this component is to be programmed in series production compliant to the customer, this requirement is to be recorded here (e.g. flashing or EEprom)."
"The physical specifications of the individual pins are to be specified here for each individual plug of the component (current load, cross-section, etc)."
"If there are customer-specified increased requirements on components whose power supplies are connected to the battery (terminal 30) even when the car is parked, they should be specified here."
Establish the general characteristics of the component here.
"Specify in a table the physical, component-specific variables such as the path of a travel sensor."
"The mechanical safety requirements on protection systems, operating and environmental safety, as well as the requirements of the active and passive safety on the component are to be described in this chapter."
"If possible, additional requirements that directly or indirectly affect the protection of persons (e.g. flammability, mechanical safeguarding of emergency operation, redundancy systems) are also to be defined here."
"The safety requirements determined by the customer on the complete vehicle or on the component in connection to the complete vehicle are to be determined here (e.g. edge protection, anti-theft protection, and fire prevention)."
Describe relevant future scenarios that could have an effect on the development or production of the component.
"These developments should be identified in terms of functional extensions, (construction) variants, design options, alternative production processes, environmental aspects and other plans."
"If necessary, the installation location is to be described more precisely (possibly with an illustration or sketch)."
"If many installation locations are scheduled, all installation locations are to be described."
"If the component is exposed to direct sunlight, this should be indicated."
"If additional environmental strains occur at the intended installation location, for example through strong heat sources, vibration sources (motors) or similar, these strains are to be described."
"Component-specific requirements on the installability, handling in the production process, permitted adjustment work, tensioning and securing concepts, etc."
"If possible, details or requirements on the contractor concerning the component-specific start-up screening are to be passed on already."
"The customer is to define the stipulations concerning geometry, dimen- sion, space requirements and packaging in this chapter."
"The permitted tolerances in the construction and joining process of the component, as well as the types of measurement, definition of source locations, tolerance chains, etc."
"Define the requirements concerning component styling (e.g. flush fit, gap widths, and radiuses)."
"In addition to the targeted quality impression of the component, the customer is to also define concrete requirements concerning surface feel of a component (e.g. pressure point or lift on the switches)."
"Furthermore, the requirements regarding the surface characteristics as well as regarding protection (e.g. anodised, or phosphatised) as well as concerning the characteristics of the component (e.g. roughness and aerodynamics) are also to be determined here."
"In principle, the acoustic requirements that the component has to fulfil are to be established here."
In this connection a differentiation of the requirements according to the different operating conditions of the com- ponent and the driving conditions of the vehicle has to be made (e.g. permitted threshold values in different driving situations).
"Specifically, the development or absorption of noise (e.g. door slamming noise, movement noises) as well as the avoidance of defined frequency ranges and types of noises (e.g. rattling) are to be determined by the requirements."
A precise as possible assignment of limit values or tole- rance ranges is to be strived for.
Information about required handling of the component is to be given in this chapter (e.g. operability of lids).
"The technically permitted or stipulated materials are to be described in this chapter (e.g. permitted processing conditions of the material, fogging, permitted alternative materials, auxiliary materials, permitted or prohibited material pairings)."
"Determine the requirements concerning the resistance to contamination here (e.g. types of possible contamination, emissions, reagents, measures to avoid contamination, permitted effects of contamination)."
"As far as possible, measures for the avoidance of unwanted effects are also to be established (e.g. screening)."
The corrosion protection requirements are to define differentiated requirements concerning the resistance of the component under specified environmental conditions.
"In this connection, the material- specific differentiation of the requirements is to be made."
"If possible or available, the specific stipulations of protection classes that the component has to fulfil in terms of certain characteristics (e.g. contact and dust protection, splash water, surface, and IP classes) are to take place."
"Determination of material prohibitions for environmental and health reasons (e.g. VDA 232-101 “List of Notifiable Substances in Automotive Production”), compatibility of the materials, requirements on the reduc- tion of the material diversity (e.g. VDA 232-101 “List of Notifiable Substances”)."
Component-specific specifications for the recycling and dismantling scheme are to be given in this chapter.
A component-specific recycling rate is to be defined in this chapter.
"Furthermore, the calculation regulation used to determine this recycling rate is to be stated (e.g. according to ISO 22628)."
The way in which the lifecycle analysis for the component is to be determined is to be established in this chapter.
Information concerning the boundary conditions for the creation of a lifecycle analysis is to be given through the type of analysis (e.g. lifecycle inventory analysis or lifecycle impact analysis) and description of the analysis scope (e.g. gate to gate).
"Consideration of all production and auxiliary materials that are used during product manufacture, consideration of the material manufacture (e.g. aluminium)."
"Define the direct load requirements on the component (maximum forces, alternating load, forces, weight-dependent loads, predetermined breaking points, acceleration) and also the indirect external mechanical requirements (effects on fastening elements, etc)."
"Define the requirements on the vibration behaviour of the component (e.g. resonance ranges while driving or in different driving conditions, natural frequencies of the component)."
"The requirements on the stiffness or torsion stiffness, as well as the cushioning characteristics of the component are to be described differentiating according to static and dynamic stiffness."
The customer is to describe the deformation requirements (e.g. permitted bending of a component in various load situations).
The crash requirements on the component have to be detailed here separately.
"Establish the pressure requirements on the component here (e.g. pressures in various operating conditions, maximum pressures, low pressure)."
All general and vehicle-specific electrical requirements are to be described here.
"Electrical requirements on the supply voltage fluctuations, electrical surge, system compatibility and electrical operational stability are to be recorded as the minimum specifications."
The requirements on the component concerning the electrostatic discharge are to be defined here.
"The thermal requirements on the component are to be defined here (e.g. heat resistance, operating temperature, storage temperature)."
"If country and/or engine-specific variants of the component are planned, these should be differentiated accordingly."
"The component-specific service requirements (e.g. service, part handling in the service garage, installability, availability of replacement parts) are to be established in this chapter."
"Furthermore, the details concerning the repair and replacement parts schemes that are to be taken into account in the development of the component (e.g. demanded to be maintenance- free or compliance to defined service intervals, service and repair times) are to be defined here."
"Furthermore, agreements for the processing of the component are to be made in this chapter."
Requirements for a technical and cost-effective processing of the component for the reuse as a replacement part are to be described here.
The customer-specific specifications about the necessary transport protection of the component are to be made here.
"In this chapter, the customer is to make component-specific stipulations for the logistic concept (series production and replacement parts)."
"In addition to a description of the required delivery concept (just in time, etc."
"Additionally, the locating requirements on the contractor or possible sub- suppliers are to be defined (e.g. selection and release of raw materials, locating single parts at the contractor’s or customer’s premises at any time, technical release(s) in the production and assembly process)."
The component-specific requirements on the product and process monitoring in the development and production of the delivery scope are to be defined in this chapter.
This especially includes 100% tests for certain quality characteristics.
"Here the customer is to define the test equipment and facilities to be used and establish the possible provision for the contractor (e.g. test mules [engines, vehicles], cable harnesses, plugs, add-on parts, wear and tear parts)."
"In this chapter, binding regulations are to be made as to which proof of compliance through tests carried out is to be provided by the contractor."
"The information given here should only define the universal requirements (minimum data scope of the test documentation, proof of compliance, deadlines, customer’s departments that are to be involved, etc)."
Specific proof of compliance (e.g. separate parameters) should be dealt with in the respective chapters.
A testing plan is to be established in which the individual tests are referenced.
A method for how the test results are to be determined should be defined for all relevant characteristics.
"Furthermore, the number of parts to be tested, the frequency of the tests and who is responsible for testing is to be established."
By means of which criteria and what the limits are for a part to be evaluated as meeting the specification are also to be established.
"Establish all relevant environmental factors (temperature, pressure, operating condition of the component to be tested, type and angle of the force effect, etc."
Define the properties and condition of the components or parts to be tested (if necessary with reference to standardised prototypes statuses in the CRS Module I).
"If the component has different operating conditions (e.g. normal operation and emergency operation), the requirements that exist for the intentional bringing about of an operating condition in order to be able to carry out certain tests at all (e.g. in a service garage) are to be listed here."
Which requirements are to be tested in which operating condition are also to be listed here.
The requirements concerning type and scope of virtual tests and simu- lations are to be defined in this chapter.
"If the customer provides the data and models which allow the contractor to, for example, represent the system environment during simulations, this is also to be stated here."
In this chapter the specific requirements on the testing of the component in the vehicle are to be defined.
"If the given content structure does not suffice to assign all requirements on level 1, the requirements can be assigned to this chapter."
The table of acronyms is to be supplemented by a standardised glossary in which the most important terms that are used within the requirement specification are uniformly defined.
For this the same terms from other VDA volumes are to be used for the same facts.
"In this connection, only the documents quoted from in the requirement specification are to be considered further applicable documents."
"Furthermore, a source (alternative: contact person) of the information for the contractor is to be named."
The further applicable documents that are valid at the CRS issue date are applicable here.
"If reference is made to regulations (laws, ordinances, etc."
The access address and modalities for the supplier are also to be named here.
The following list contains a selection of words and word combinations which should not be used in connection with requirement specifications and component requirement specifications.
They are too “weak” in the truest sense of the word and therefore unsuitable for adequately describing a requirement on a product.
"Dreher, Marion: „Konstruktive und analytische Methoden zur Qualitätssicherung von Anforderungen in der Softwareentwicklung“."
"The Co-ReSyF project will implement a dedicated data access and processing infrastructure, with automated tools, methods and standards to support research applications using Earth Observation (EO) data for monitoring of Coastal Waters, levering on the components deployed SenSyF (www.sensyf.eu)."
"The main objective is to facilitate the access to Earth Observation data and pre-processing tools to the research community, towards the future provision of future Coastal Waters services based on EO data."
"Through Co-ReSyF‘s collaborative front end, even inexperienced researchers in EO will be able to upload their applications to the system to compose and configure processing chains for easy deployment on the cloud infrastructure."
They will be able to accelerate the development of high-performing applications taking full advantage of the scalability of resources available in the cloud framework.
"The system’s facilities and tools, optimized for distributed processing, include EO data access catalogues, discovery and retrieval tools, as well as a number of pre-processing tools and toolboxes for manipulating EO data."
"Advanced users will also be able to go further and take full control of the processing chains and algorithms by having access to the cloud back-end, and to further optimize their applications for fast deployment for big data access and processing."
"The Co-ReSyF capabilities will be supported and initially demonstrated by a series of early adopters who will develop new research applications on the coastal domain, guide the definition of requirements and serve as system beta testers."
A competitive call will be issued within the project to further demonstrate and promote the usage of the Co-ReSyF release.
"These pioneering researchers in will be given access not only to the platform itself, but also to extensive training material on the system and on Coastal Waters research themes, as well as to the project's events, including the Summer School and Final Workshop."
"Define technical requirements for the system Tools, tracing the functional extent and feasibility defined in support of the Co-ReSyF Research Applications user stories."
Within the Co-ReSyF platform it can be identified two major components that support the operation of the research activities performed within the platform.
"One component is the Framework, which is composed of all the things that support the environment where the applications are defined and executed, and the other component are the Tools which are things that can be used to build an application and to analyse/visualize the results of the application."
"The Framework includes the Cloud back-end, which is the infrastructure that runs the applications in the cloud and is in charge of coordinating and creating the VMs for distributed processing and collection of input and output data."
"The other part of the framework is related to the user interaction and it is the part that directly interfaces with the user, this includes the Front- end (GUI that provides the connection to all the platform functionalities) and the Expert Centre and Knowledge Base (wiki with relevant information for newcomers of the platform to start using it)."
The Tools live within the Framework and are a set of executables or libraries that can be used by the researchers to build and manage their applications or handle the data.
It includes the Automated Orchestration which is a set of tools designed to configure and monitor the execution of the sequence of tasks that compose one application.
"The Image Inter-calibration, Atmospheric corrections, Data Co-registration and Fusion and Other tools, which are tools used to process the data commonly used by several applications and provided in a default tool-kit available to all users of the platform."
"Finally there is also a set of Visualisation tools, which are provided as default by the platform that allow the users to visualise and manipulate the data is commonly used data visualization tools (different from the main front-end data visualization provided with the platform)."
This document focuses solely on the Tools part of the Co-ReSyF platform.
The Co-ReSyF platform is envisaged to help researchers analysing EO data.
"One of the biggest advantages of using Co-ReSyF is when the data to be analyzed has a significant size, where the researcher will be able to access the cloud assets in order to process the data."
This means that the data is not being processed locally and it can also take some time before the processing is complete.
It then becomes important to have mechanisms that can provide feedback to the user of the current status of the processing and that also ensure that the processing is correctly executed.
ARGANS background in remote sensing image inter-comparison and inter-calibration derives from involvement in radiometric calibration of medium resolution optical multi-spectral sensors (DIMITRI (https://dimitri.argans.co.uk)) and involvement with MERIS match-up in-situ database (MERMAID (http://mermaid.acri.fr/home/home.php)).
Inter-calibration provide a practical means of identifying and correcting relative biases in radiometric calibration between instruments.
One approach to inter-calibration is to use a well-characterized instrument as a reference to compare with other instruments viewing the same target under near-simultaneous conditions.
"But there are problems for coastal Type II waters since PICS tend to be land sites, e.g. desert, salt lakes, snow; and both Rayleigh and glint procedures requires low chlorophyl and low aerosol."
The coastal zone is dynamic and the marine signal measures by satellite sensors strongly affected by land contamination effects.
"Another approach is vicarious ground-based calibration in which surface measurements and radiative transfer models are used to estimate theoretical at-sensor radiance and correct biases in measured Top-of-Atmosphere (TOA) radiances, provides absolute calibration enabling direct inter-calibration of sensor images with relatively high accuracy."
For this in-situ data is needed (http://mermaid.acri.fr/home/home.php)) it is expensive and labour intensive to acquire.
It also requires inversion of Radiative Transfer Models (RTMs) which is sensitive to climatological and atmospheric parameters.
"A possible approximate solution would be to perform relative calibration between sensors based on a set of invariant sites: PICS, Rayleigh and sun glint; and generalise that the bias and coastal test site."
For Sentinel-2 Multi-spectral Imager (MSI) (https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi) these correction coefficients are not provided with the image metadata and would need to be generated within the framework.
This may result in significant uncertainty since the spectral signature at the coast is not invariant.
A better approach would be to directly compare sensors by matching up images of the AOI based on viewing angle and illumination and normalise the images based on the sensor spectral response function (SRF).
But this requires a long time series so that sufficient match-ups between images are available.
And it does not consider that cross-sensor wavelength variations in SRF that can lead to measurement discrepencies between sensors.
"A compensation for differences in SRF can be made by integrating the SRF of the sensor with the spectral signature of the target, the Spectral Band Adjustment Factor (SBAF) but as stated before the dynamic nature of the coastal spectral signature complicates the characterisation of the reference sensor simulated TOA reflectance."
In the wider context of the strategic fit to the framework it is important to be able to combine data from multiple satellite sensors and data from the same satellite sensor acquired over a period of time.
"It is possible to create a composite image simply by normalising the image set using an image manipulation package but if the aim is to derive geophysical measurements care is needed to ensure inter-calibration considers the differing spectral response of the sensors, the observing and environmental conditions, and the spectral signature of the target."
In dynamic and heterogenous coastal zones absolute calibration and sensor inter-comparison is a challenging problem.
"Inter-calibration, e.g. normalizing multiple images to a common radiometric scale, is distinct from sensor calibration, a process performed during Ground Segment processing and monitoring to ensure baseline data quality requirements are met."
Implicitly that quantifying and correcting relative bias between monitored and reference sensors for collocated data can be generalised to measurements by the same pair of satellites even when they are not being directly compared.
Geometrical calibration will have been performed on data retrieved from repositories.
Atmospheric correction will be provided by the framework [see CORESYF-TOOL-ATCORR].
"A reference standard has been identified i.e. a stable well-calibrated satellite instrument that provide temporal, spatial, spectral and geometric collocation with the sensors to be inter-calibrated or an appropriate stable pseudo-invariant calibration site (PICS) or a well- characterised instrumented in situ site."
From a series of data from a reference sensor and target sensor(s) derive calibration coefficients to align the radiometry of the target sensors with the reference sensor.
"By re-scaling all sensors to the same radiometric scale a consistent set of acquisitions over a given site, covering a broad range of geometries, is generated."
Absolute calibration of images is probably out-of-scope considering the resources allocated to this tool (5 months) and the requirement for a reasonably long time series of Sentinel-2 data to ensure there are a significant number of matchup images sharing geometrical and temporal viewing and illumination characteristics.
If there is a necessity for inter-calibration of SAR images input is required from another partner with the relevant knowledge.
Detection using remote sensing is based on geometry and radiometry.
"Using radiometry often requires to apply a solid atmospheric correction algorithm, especially regarding water colour as the signal is quite low."
"Indeed, up to 90% of the signal sensed by the satellite can be related to the atmosphere so it is primordial to correct that in order to clear any noise affecting the water colour."
For the second version of the Co-ReSyF platform it is envisaged to explore the potential of synergies between the different applications.
"In order to be able to exploit these synergies, the applications that will combine the data from other applications, will need generic tools for co- registration and fusion of the data."
For the development of the Co-ReSyF applications several tools are identified as needed for the data processing that are useful to many other applications and are generic enough to be applied to a certain type of data in many use cases.
"When analysing the data, either output or input data, the users may need some tools for data visualization and manipulation that are generic enough to consider them as useful to all users of the platform."
These tools are then identified as being tools for visualization that should be included in the Co-ReSyF default tool-kit.
"The USDA and Agricultural Research Service (ARS) have supported hydrologic research since the managed and made available independently at each research location, greatly reducing the accessibility and utility of these data for policy-relevant, multi-site analyses."
"The ARS is developing and implementing a data system to organize, document, manipulate and compile water, soil, management, and economic data for assessment of conservation practices."
"While primary responsibility for data will continue to reside at individual watersheds, the new data system will provide one-point access to data from the sites in well-documented, and standardized formats."
"The purpose of this document is to describe the technical and operation requirements that meet the needs of the CEAP Watershed Assessment Studies, as well as additional needs of researchers at the watershed sites and diverse outside users, in adequate detail to provide the basis for the system design."
The system will be called STEWARDS: Sustaining the Earth's Watersheds – Agricultural Research Data System.
"The system requirements specification document describes what the system is to do, and how the system will perform each function."
The audiences for this document include the system developers and the users.
The system developer uses this document as the authority on designing and building system capabilities.
The users review the document to ensure the documentation completely and accurately describes the intended functionality.
This version – version 1.0 - provides general descriptions of the system.
The system developer should review the document to ensure there is adequate information for defining an initial design of the system.
"The users should review the document to affirm the features described are needed, to clarify features, and to identify additional features needed within the system."
The next version – version 2.0 – will be the result of more detailed requirements analysis.
"When version 2.0 is written, the system developer and users will be asked to review this document."
The document is structured to follow IEEE 830-1998 standards for recording system requirements.
"As part of the Conservation Effects Assessment Project (CEAP), twelve ARS Benchmark Watersheds will support watershed-scale assessment of environmental effects of USDA conservation program implementation."
"The ARS Benchmark Watersheds represent primarily rainfed cropland, although some of the watersheds also contain irrigated cropland, grazingland, wetlands, and confined animal feeding operations."
Three additional ARS watersheds may be added in the future to represent additional land uses.
"Conservation practices to be emphasized will include NRCS CORE 4 practices for croplands (conservation buffers, nutrient management, pest management, and tillage management), drainage management systems, and manure management practices."
"Environmental effects and benefits will be estimated primarily for water and soil resources, with some assessment of wildlife habitat and air quality benefits in some watersheds."
"The goal for the watershed-scale research is to provide detailed assessments of conservation practices and programs in a selected watershed, provide a framework for improving the performance of the national assessment models, and support coordinated research on the effects of conservation practices across a range of resource characteristics (such as climate, terrain, land use, and soils)."
"The basic requirement for STEWARDS is to deliver consistent high quality data in support of the CEAP watershed-scale assessment from a one-stop data portal to the CEAP clients and, in time, the public at large."
"The data system consists two main parts -- a central database management system for the storage and management of data, and a client application to allow users access and interact with the data."
The data stored in the database can be viewed and downloaded using graphical and tabular interface tools.
"The data system will serve as a repository where diverse end-users can access, search, analyze, visualize, and report various types of integrated watershed data contributed from the multiple locations."
"Types of data will be diverse, including biophysical data (i.e., point-based in time and/or space, spatially variable data, time series), data about land use, management, and conservation practices; and economic data."
"Where applicable, data from the NRCS, Economics Research Service (ERS) Agricultural Resources and Environmental Indicators database, other ERS sources of data on costs of conservation practices, and land use and management data of NASS or other agencies will be utilized."
The intention of the team is that ARS researchers at watershed locations retain primary responsibility for data collection and management.
Sites may chose to retain existing data management protocols or change location protocols to those of STEWARDS.
"However, STEWARDS must have the capability to translate data from location-specific formats into the standardized STEWARDS formats."
Data on STEWARDS will not be available to the public in real time.
Access to real-time data will remain at the discretion of each location research team.
"Instead, annual or more frequent updates from location databases to STEWARDS will be made by the watersheds’ staffs after the locations have completed their quality assurance procedures."
"Source data for this system are the long-term ARS watersheds, with those participating in the CEAP project expected to participate in this data system first."
"The data system consists two main parts -- a central database management system for the uploading, storage, and management of data, and a client application to allow users access and interact with the data."
"Diverse end-users can access, search, analyze, visualize, download, and report various types of integrated watershed data contributed from the multiple locations."
"Types of data will include biophysical data (i.e., point-based in time and/or space, spatially variable data, time series), data about land use, management, and conservation practices; and economic data."
This includes the role commonly thought of as a Database Administrator (DBA).
"UCC-4: ARS users: ARS scientists, engineers, and support staff who require ARS watershed data for research purposes."
"These would likely be conversant with the general characteristics of the data content, and to a lesser extent have abilities manipulating views of the data using database tools such as envisioned for this database system."
These users will need user/password authentication to enable user settings management and to have access to data protected through the confidentiality agreements among agencies participating in CEAP.
"These would have similar characteristics and needs as ARS users, but because of the agency-level confidentiality issues, could not access the password-protected sensitive data."
These users would have access to the public data without need for authentication.
"The rule for selecting hardware and software is that the components/application must be functionally efficient, capable of interfacing with other software, and easy to maintain."
"The Data Management portion of the system shall permit user access from the corporate Intranet and, if a user is authorized for outside access through the corporate firewall, from an Internet connection at the user’s home."
The goal of the web application is to be platform independent on the client side wherever possible.
"Therefore, the web applications will be implemented to run on the server side as much as possible."
"Also, it is required to test the application using different platforms, connection speeds, screen settings, colors/graphics, and browsers."
CO-3: Data uploading and management will likely be done as infrequently as once a year.
This fact greatly limits the complexity of the user interface and the learning curve needed for completing this task.
"The testing plan will be based on user roles, modules or use cases, required tasks and expected outcomes."
"User documentation will consist of the several components usually expected of a modern web-based software application, including a tutorial, help pages, FAQ’s with an online request form, and a complete user’s manual."
Frequently asked questions will be screened for the FAQ pages.
"It is anticipated that each watershed location will provide human and fiscal resources required to prepare metadata files, data files, work with the data team on initial import of data, perform subsequent data uploads, and provide site-specific support to users of the system."
"If a location has inadequate resources, the minimal data required for CEAP analyses will be identified and the data team will provide additional support to that location."
This may result in a location’s data coming into the system later than scheduled.
Team leaders anticipate availability of the operational platform at the ARS OCIO level.
"Pilot and, as a contingency, operational data systems may be developed and maintained at El Reno or other research locations."
It is anticipated that funding from NRCS will partially support this activity through FY07.
"If that funding were not available or insufficient in future years, base funds at the locations and/or discretionary funds from the Area and Headquarters funds would support the activity but the timelines would be adjusted."
Help desk funding will be determined from staffing needs identified during the design phase and a proposal will then be made to NPS.
"The standardized data structure will facilitate database development, storage, and maintenance; metadata development, storage, and maintenance; and support database functionality, including tabular and spatial data queries, evaluation, visualization, and transfer (downloading) to off-site locations."
"The database management system should be stable and secured, have high performance (in terms of speed and efficiency/effectiveness), and be easy to maintain."
This component is central to the effort and is thus of highest priority.
The team will elicit user requirements from a cross-section of user class members (see section 2.3) to accurately and completely describe the expected uses and functionality of the system.
"To elicit requirements, the user class members will be asked via conferencing, interviews, and email, to provide a detailed description of the user actions and system responses that will take place during execution of the use case under normal, expected conditions."
The summation of responses will lead to an accurate and complete inventory of user requirements.
Establish a database in support of CEAP that will house the collective data assembled or generated during research activities.
"The database will support a variety of data types and formats, including but not limited to: spatial data - vector, raster, imagery, and tabular; tabular data – static and time-series; spreadsheets; documents; reports; photographs; and URL links."
"The use of agricultural models (SWAT, AnnAGNPS) is a core element of the CEAP effort."
"Several modeling-related database topics will need to be addressed: Maintenance and reporting of uncertainty or error in measured data, in spatial components of GIS data, and in modeling output."
"Reporting of uncertainty may take place on an individual sample basis, on a method or procedural basis, or on an entire database."
"Models will require specific input data and will generate output data during the calibration and validation phases, sensitivity analyses, and exploratory scenarios."
The current scope of the STEWARDS system is to provide measured data for input to the model and for comparison to output.
FR-2.1: View entire universe of watersheds from top-level screen for selection Design tools to navigate the individual watershed sites and their data.
"Summary descriptions of research watersheds, stations, and instruments that are useful in describing the research activities should be accessible."
This information would not be considered ‘formal’ metadata.
"Provide access to the data via browsing of sites, stations, and instruments; allow for simple queries to individual datasets; provide a metadata search tool to query dataset parameters; and allow for downloading of datasets (full or partial)."
"Users may wish to examine time-series data, e.g. stream discharge data, over a user-specified time frame in order to select only those data desired for download."
Charting tools in association with the query engine are desirable.
"Provide access to CEAP-related reports, tables, and project documents."
Agricultural research data are inherently spatial in nature.
STEWARDS will provide web-based geographic information tools to allow site-specific data to be viewed within their spatial context.
These tools will provide browse and query functionality and support links to download spatial data and their associated tabular data.
"Much of the initial effort in CEAP will focus on the use of agricultural models (e.g. SWAT, AnnAGNPS) in the CEAP watersheds."
"Users will be able to examine the data used in the modeling effort, visualize the results in their spatial context, and download the model input data and results."
Develop and maintain a metadata database that provides browse and query access to formal descriptions of the database elements.
Provide tools for database contributors to create and upload metadata compatible with the STEWARDS metadata database.
"Develop search tools that query watershed, station, and instrument metadata across the STEWARDS database."
"Metadata query tools will support query by location, theme, and keyword."
The STEWARDS database will maintain a metadata report for each database in STEWARDS.
The metadata of individual datasets should be created at the local watershed sites for local use and for populating a CEAP metadata database.
Adopt a metadata standard that is compliant with Federal regulations.
"The current Federal standards for spatial data are the Content Standard for Digital Geospatial Metadata (version 2.0), (http://www.fgdc.gov/metadata/contstan.html), FGDC-STD-001-1998."
There are some indications that the Federal government may implement the ISO 19115 geographic information/metadata standard in the future.
"If this occurs, the CEAP database team will evaluate conversion of metadata."
Implement a metadata input tool that supports creating and editing of metadata in the chosen format.
The metadata tool will allow for local and web-based input and editing.
"A likely scenario involves a web-based wizard which allows users to specify particulars of a data set, and then save those answers and relate them to a particular project, so that these selections can be re-used in future uploading operations."
Implement a web-based browse-and-query tool for searching STEWARDS metadata.
"Queries by location, theme, and keyword will be supported."
A likely scenario involves a web-based wizard which allows users to specify particular querying parameters and then save them for reference later such that time-based comparisons are facilitated with minimal user training.
Implement a database of STEWARDS metadata elements.
The database will provide browse and query functionality.
"To make data electronically available any place and any time through a web server-client service, the web service will be platform independent as much as possible."
"Where there is an exception, the software/hardware requirement should be specified for a particular application."
"Users whose computing environment precludes downloading the data via the internet will have the opportunity to acquire data, reports, model results and other STEWARDS information via alternative media."
The system needs to be able to store hundreds of megabytes of data on demand.
The potential for needing Gigabytes of data storage capacity is also in the realm of possibilities.
Further requirements gathering is needed to get real-world estimates of such data storage needs.
HR-1.2: Near-line Storage – All User and Application data as well as software installation and configuration files must be fully backed up week-nightly.
"Further, secure, off-site storage will be performed on a weekly basis with 24-hour retrieval times."
HR-2.1: Load Balancing - Application Servers and Database servers must be load balanced at the application level to ensure maximum stability and availability.
"Specific scenarios, such as fail-over versus session-managed load balancing need to be addressed in the functional requirements specification."
"The system requires a “back-end” private network environment in order to ensure that end-user operations (on the front-end) are not impeded by database backups, index propagations, or other large back-end data transfers."
"The system will use, where appropriate, the standard hardware and data communications resources provided by the ARS OCIO at the ARS George Washington Carver Center in Beltsville, MD."
"This includes, but is not limited to, the general Ethernet network/T1 connection at the server/hosting site, network servers, and network management tools."
"SR-2: HTTP and GIS Server Applications – As the Web will be the primary delivery protocol for the application, HTTP and related GIS server applications will be required to support system functionality."
The use of Browser plug-ins will be judiciously restricted on an as-needed basis.
"The system will use, where appropriate, the standard software resources provided by the ARS OCIO."
"This includes, but is not limited to, MS ASP/Java Scripts, C++/C#, MS SQL server and IIS, or the use of PHP/Perl, JB scripts, C++/C#, MySQL server, and Apache server."
Data will be subject to quality assurance prior to either initial or recurring uploading to STEWARDS.
Initial population of STEWARDS will require that transition filters be developed jointly between the STEWARDS team and the individual watersheds.
"These filters will provide the same function for recurring, probably annual, uploads."
Local watershed staff will be responsible for performing necessary quality assurance/quality control (QA/QC) procedures prior to data being uploaded to the STEWARDS database.
Measurement methods and QA/QC procedures established by the CEAP Quality Assurance Team will be used by local data producers and recorded in the data provided to STEWARDS.
The purpose of quality assurance is intended to provide added assurance of data integrity.
Quality assurance checking will be carried out at two different levels – local site level and central site level.
"First, the guidelines for quality assurance, including parameter-specific ranges, threshold values, quality flags etc., will be determined."
Quality assurance checking at the local sites may be performed before or during the standard exchange file conversion phase.
"A general quality assurance checking, not as specific as at the local sites, will be carried out during the data uploading stage."
"Note that a) the primary responsibility for data quality assurance rests with the individual sites and b) the quality assurance ranges, criteria, etc., used here should be consistent with the quality assurance information specified in metadata (and may be a component of the data dictionary)."
Basic information regarding individual watersheds will be made available to STEWARDS by local watershed sites.
"Basic information may include spatial data in a GIS-compatible format; descriptive data about stations, instruments, methods, or procedures; reports; modeling results; and other data."
Data will be reformatted to be compatible with the STEWARDS data schema and CEAP modeling requirements.
Watershed data to be used in modeling that does not conform to model requirements will be processed in STEWARDS for inclusion in the STEWARDS databases.
"As part of the initial population of the database, time-series data (measurement data, annual land use information, weather/climate data) that has been collected by local watershed staff will be processed through local and CEAP QA/QC procedures and uploaded to the STEWARDS database by watershed staff per obligations to CEAP Objective 1."
Protocols for data imports from local sites via input files with different formats will be developed and implemented jointly between the STEWARDS team and the local watersheds.
The standard exchange file format will have been jointly determined first.
A single import filter will be written to parse the standard formatted (e.g. tab-delimited) files from the local watershed sites.
"In this manner, all the data files from the local sites will have consistent formats when they are stored in the central site."
The filter developed for the intial population of the database will be available for use in later periodic uploads.
"Time-series data (measurement data, annual land use information, weather/climate data) and other data (spatial data, metadata) will be collected by local watershed staff, processed through local and CEAP QA/QC procedures, and uploaded to the STEWARDS database on an annual basis using the filter developed during the initial population of the database."
Requests will initiate from the central system per schedule negotiated with individual watersheds.
Compliance by watershed staff is understood to be expected per obligations under CEAP watershed project plans revised to accommodate the CEAP project plan objective 1.
"The central database will allow users to access the data of individual watersheds, sub-watersheds on a station-by-station basis, or a collection of stations if the entire dataset is desired."
"Multiple levels of data aggregation of time-series data (daily, monthly, or yearly) will be supported."
"A great flexibility of export data should be also available in terms of data volume (the number of data entity and time coverage) and output format [for example, for tabular data – comma separated values (csv) or database format (dbf); for spatial data – shape files (shp) or ascii grid files (grd); for reports – Adobe page definition format (pdf)]."
"The user interface will be simple and consistent, using terminology commonly understood by the intended users of the system."
"The system will have a simple interface, consistent with industry standard interfaces, to eliminate the need for user training of infrequent users."
The STEWARDS team will evaluate the user interface of similar systems and apply appropriately.
"For additional details see Appendix E. User testing will be used to ensure the user interface is clear (simple, commonly understood vocabulary, intuitive to use without training), complete (users can perform all functions from the interface), and consistent (buttons and wording are the same throughout the system)."
"The system will use the standard hardware and data communications resources provided by the ARS OCIO at the ARS George Washington Carver Center in Beltsville, MD."
"This system will include a warning message when a low transmission speed is detected, and a non-graphical interface option will be available."
The system will use the standard software resources provided by the ARS OCIO.
The system will use the communications resources provided by the ARS OCIO.
"This includes, but is not limited to, HTTP protocol for communication with the web browser and the web server and TCP/IP network protocol with HTTP protocol."
Response times seen by end users for querying metadata should be on the order of a few seconds or less.
"Response times seen by end users for retrieving the actual images may take much longer, anywhere from a few minutes to several hours."
"If the user requests a large image with a short response time, it is acceptable for the ARS data system to advise the user that the target response time cannot be met."
"In that case, the person would be referred to an alternate method of getting the data."
Data on the server should be protected from power loss but data in transit from server to requester could be lost.
"Given that these data will also remain on the watershed site system, rather than expend resources to prevent this loss, such failures will be monitored and the uploading process will be repeated."
"STEWARDS will have reasonable controls consistent with ARS OCIO practices, in compliance with agency, Dept and Govt regulations."
STEWARDS security requirements will have four primary components.
"They are authentication, confidentiality, integrity, and availability."
"STEWARDS will follow industry best practices for authentication, using single-sign-on systems like Microsoft Active Directory to perform authentication."
Authentication addresses security requirements to ensure those using system are who they say they are.
This is of greatest concern when data are being changed or updated.
This is primarily done through userids and passwords.
Confidentiality security requirements describe the need to protect the data appropriately.
STEWARDS will use the user classes described in section 2.3 above to define boundaries of information sharing to ensure confidentiality as appropriate.
Any data that should be viewed by a restricted audience must be protected with appropriate security features.
The integrity of STEWARDS data will be critical to its success as a product.
Scientific research and publications will be based on the data obtained through the system.
"Therefore, extensive data validation and review will be performed both before data are uploaded to the system and as part of the upload process."
"The system will need policy and procedures protecting the data from intentional or unintentional modifications, and to ensure accurate data are made available."
The fourth consideration for security requirements is availability.
"The system must be available to the intended audience 24 hours per day, 7 days a week with, 99% availability and a tolerance of -5% (not less than 50% of working hours in any week)."
"For this system, availability will be concerned with the reliability of the software and network components."
Intentional “denial of service attacks” is not foreseen as a significant concern.
This database will be built for a particular system and may not be portable but results to queries will be portable between many environments.
Implementation of the application software/code and design of database structure should be flexible enough for the necessary change in the later phase.
Availability is defined here to mean the ability to use the system during its intended period of operation as defined in SCR-4 above.
ArcGIS - ArcGIS is an integrated collection of GIS software products for building a complete GIS developed by ESRI.
The procedure (essentially approval) used by the approval authority in verifying that specification content is acceptable.
Authentication does not imply acceptance or responsibility for the specified item to perform successfully.
Benchmark watersheds - is used to differentiate the larger scale ARS watersheds from field scale ARS research activity or from other non-ARS watersheds.
"C++ - ""C plus plus"" is a programming language that was built off the C language."
Core 4 - NRCS's Core 4 is a common-sense approach to improving farm profitability while addressing environmental concerns.
The approach is easily adaptable to virtually any farming situation and can be fine tuned to meet your unique needs.
"The net result is better soil, cleaner water, greater on-farm profits, and a brighter future for all of us."
Database - A collection of related data stored in one or more computerized files in a manner that can be accessed by users or computer programs via a database management system.
"Database management system - An integrated set of computer programs that provide the capabilities needed to establish, modify, make available, and maintain the integrity of a database."
"Data dictionary - A collection of data definitions, each identified by the name of a piece of data, describing the meaning and purpose of that piece of data in the system, the type of the data, its components and any other relevant attributes (range, precision, storage size and so on)."
"Data Schema - A data schema is a grammar that describes elements and their types, attributes and possible relations."
Functional requirement: A statement of a piece of required functionality or a behavior that a system will exhibit under specific conditions.
"These include inputs, outputs, calculations, external interfaces, communications, and special management information needs."
Functional requirements are also called behavioral requirements because they address what the system does.
"Intranet - An intranet is an internal or private Internet used strictly within the confines of a company, university, or organization."
"JavaScript - A programming language designed by Sun Microsystems, in conjunction with Netscape, that can be integrated into standard HTML pages."
"Metadata -- ""data about data"" describe the content, quality, condition, and other characteristics of data."
"Module – (1) In software, a module is a part of a program."
A single module can contain one or several routines.
Performance - A quantitative measure characterizing a physical or functional attribute relating to the execution of a mission/operation or function.
"Performance requirement -- A system/software system requirement specifying a performance characteristic that a system/software system or system/software component must possess; for example, speed, accuracy, and frequency."
"Portability - (1) A term used to describe an object that can be easily moved, such as a portable computer; (2) When referring to computer software, portability refers to how easy a software program can be moved between computer Operating Systems."
"Software requirement – (1) A software capability needed by a user to solve a problem to achieve an objective; (2) A software capability that must be met or possessed by a system or system component to satisfy a contract, standard, specification, or other formally imposed document."
"System - A composite of equipment, skills, and techniques capable of performing or supporting an operational role or both."
"A complete system includes all equipment, related facilities, material, software, services and personnel required for its operation and support to the degree that it can be considered a self-sufficient item in its intended operational environment."
System Requirement - A condition or capability that must be met or possessed by a system or system component to satisfy a condition or capability needed by a user to solve a problem.
Use cases - A task analysis technique often used in software engineering.
"For each module of a system, common tasks are written up with the prerequisites for each task, the steps to take for the user and the system, and the changes that will be true after the task is completed."
"Use cases are especially useful for making sure that common tasks are supported by the system, that they are relatively straightforward, and that the system architecture reflects the task structure."
User interface – A user interface is what you have to learn to operate a machine.
"For examples, the graphical user interfaces (GUIs) -- windows, icons, and pop-up menus have become standard on personal computers."
User requirements - address what the users need to do their jobs.
"SWAT - Soil and Water Assessment Tool, a river basin, or watershed, scale model developed by Dr. Jeff Arnold for the USDA Agricultural Research Service (ARS)."
"SWAT was developed to predict the impact of land management practices on water, sediment and agricultural chemical yields in large complex watersheds with varying soils, land use, and management conditions over long periods of time."
AnnAgNPS - AGNPS is a tool to help evaluate the effect of management decisions impacting a watershed system.
The AGNPS system is a direct update of the AGNPS 98 & 2001 system of modules containing many enhancements.
"The term ""AGNPS"" now refers to the system of modeling components instead of the single-event AGNPS, which was discontinued in the mid-1990's."
These enhancements have been included to improve the capability of the program and to automate many of the input data preparation steps needed for use with large watershed systems.
New to AnnAGNPS Version 3.42 are many minor enhancements to algorithms and more output options.
The AGNPS Arcview interface has been better integrated with the components needed to develop AnnAGNPS datasets.
"The capabilities of RUSLE, used by USDA-NRCS to evaluate the degree of erosion on agricultural fields and to guide development of conservation plans to control erosion, have been incorporated into AnnAGNPS."
This provides a watershed scale aspect to conservation planning.
"This section is reserved for open requirements issues that remain to be resolved, including TBDs, pending decisions, information that is needed, conflicts awaiting resolution, and the like."
The pages will be designed for screen resolution of 800 x 600 pixels as a minimum.
"The title tag and the Meta description tag in the web pages will be carefully constructed to include the focused keywords so these keywords will be highly visible in the search engine results pages, making the STEWARDS product more useful to the general users after the public rollout."
Completion/Confirmation messages should be displayed when the application processes the data successfully.
"Messages generated shall be clear, succinct, and free of jargon."
The purpose of system design is to translate the system requirements into more technical specifications.
"Through a user case survey and a logical analysis of user’s expectations and system functionalities, the system components for STEWARDS are identified (Fig."
System design provides a detailed description for each identified component and produces a physical data system design (with documentation) that allow the system developers to construct each component (layer) accordingly.
"At the end of the system design phase, hardware, software tools and skill requirements, and other resources will be identified and a system developer team/plan will be drawn."
"After that, the construction phase will begins (Task flow of can be seen in Fig."
"The system design process can be divided into three main phases: conceptual system design, logical system design, and physical system design."
"In this appendix, only conceptual system design and logical system design for STEWARDS are documented."
Physical system design (how the logical structure of STEWARDS will be implemented) is still in a planning stage and will be described later.
As depicted in the conceptual model of STEWARDS (Fig.
The database design and interface/application design parallel each other within the system development process.
The total number of system components will depend on the level of detail.
"For example, the data component of STEWARDS can be further identified as watershed climate, image, soils, management, pollutant source, hydrology, socio-economic, water quality data, data search, data downloads etc (Fig."
Description for hardware infrastructure design will be provided separately.
"During the logical system design phase, a logical data system (all system components and their relationships) will be constructed and validated."
"In other words, the Entity-Relationship (ER) diagrams for measurement data and user graphic interfaces (UGIs) to connect all components will be developed."
"For example, an entity-relationship diagram for measured climate data at South Fork watershed, Iowa, is given in Fig."
"The tables – STEWARDS_Units_lookup_Table, [WS]_Topic_Table, and [WS]_Site_ID_Table are supporting data tables to the [WS]_Climate_Daily table."
The latter is the basic data table where climate data are stored.
Note that the characteristics (topic) of a theme (e.g. climate) in Fig.
"F3 become the fields (min_temperature, max_temperature, etc.)."
The data descriptors for the basic data table and supporting tables are shown in Tables F1 and F2 respectively.
A generalized data flow and table relationship is given in Fig.
"Three major system application components are identified: overview/summary, system search, and data access/visualization/downloads."
"For next level of detail, the system component diagram for access login component, system/summary system component, metadata search component, site summary search, component, watershed specific search component, topic search component, site specific search component, pre-existing search component, characterizing watershed GIS component, and data access/visualization component are given in Figs."
The tasks for importing data from the local sites into the centralized site required the following considerations.
"Therefore, translating empirical data is the only need."
Translation will be local site specific and done there.
There are three types of empirical data we will need to address.
Time series data (Type 1 data) with columns for different data collected at the same time.
A generalized data structure for this type of data is given in Fig.
"The mapping method allows a great flexibility in terms of data heterogeneity, table size, data type, etc."
Physical System Design: Build the specific data system for STEWARDS in terms of softwares and tools.
"For software requirements, the programming skills in developing Windows and Web applications using Microsoft Visual Studio .NET (BASICS, ASP.NET, C++, C#), XHTML, XML programming languages/scripts, Microsoft VISIO 2003 under MS Internet Information Services (IIS) and Microsoft SQL 2000/2005 servers will be pursued."
"F1 Logical model of STEWARDS Data System with four system components – System infracture, databases, applications/interfaces, and data uploading."
Each block represents a data entity (a topic object).
"An example Entity-Relationship (ER) diagram of climate data at South Fork Watershed, Iowa."
The definition text at the top of the table with gray color represents the context of an entity (e.g. [WS]_Climate_Daily) while the texts under the top gray area represent the field names.
PK represents primary key of a table and FK(x) is foreign key.
The line with an arrow shows the relationship between two tables.
A foreign key is the field in a relational table that matches the primary key column of another table.
The primary key of a relational table uniquely identifies each record in the table.
"The indexes, j,k,m, and n represent the number of topics, sites, variables, and tables, respectively."
The lines with arrows show the relationships between tables.
The numbers represent different application /interface system component at different levels.
The 2nd level of access login component of STEWARDS.
The first digit of the leading number of each subcomponent represents the first level of the system components and the second number represents the second level and so forth.
Data query - Create queries to derive specific information.
Data extraction - Download geographic data sets from the server.
Characterizing watershed GIS component of STEWARDS.
"As an ARS watershed data system to support SWAT and AnnAGNPS modeling in CEAP, ultimately the STEWARDS data system could be integrated with other similar ARS data/modeling systems such as OMS (Object Modeling System), iFARM (Integrated Farm And Ranch Management), and other general models (Fig."
"The OMS is a Java-based modeling framework that facilitates simulation model development, evaluation, and deployment."
"In general, the OMS consists of: 1) a library of science, control and database modules; 2) a means to assemble selected modules into a modeling package customized to the problem; and 3) automatic generation of a user- friendly interface."
"The framework employs the latest Java-based software technology for all the components, and is supported by data dictionary, data retrieval, GIS, graphical visualization, and statistical analysis utility modules."
G1 Linkage of STEWARDS to Other USDA/ARS Data/Modeling Systems.
H1) of STEWARDS shows that the task components in the development process.
The prototype has been implemented but is still under tuning.
The number in parentheses represent the system component number as shown in Fig.
Type 1: Time series data with columns for different data collected at the same time.
I1 shows a generalized data structure for this type of data.
"Type 2: Time series data, usually more sparse than the above, with an id field that explains what the parameter field contains."
I2 show a generalized data structure for this type of data.
I1 Data structure for time series data (Type 1 data) with columns for different data collected at the same time.
"Data structure for time series data (Type 2 data), usually more sparse than those shown in Fig."
"RD 12 Review of SLCCI SRD v1.0, Issue 1, Revision 0, Bruno Lucas, 08/08/2011."
"RD 13 Review of SLCCI SRD v1.1, Issue 1, Revision 0, Bruno Lucas, 25/01/2012."
"RD 14 Review of SLCCI SRD v1.2, Issue 1, Revision 0, Bruno Lucas, 18/04/2012."
"The System Requirements Document (SRD) serves to provide a complete set of system requirements for the SLCCI operational system, as requested in the Statement of Work (SoW), geared to the Sea Level ECV."
"The SRD will function as the primary input to the design of the operational system, as to be described by the System Specification Document (SSD)."
"This document is a revised issue of SRD v1.2, following ESA feedback [RD 14]."
"The System Requirements Document (SRD) defines the requirements of the Sea Level Climate change Initiative (SLCCI) operational system (henceforth the system), and so acts as the foundation to the System Specification Document (SSD)."
"The SRD is a living document, and it is intended that the document undergoes the necessary pressures of review and subsequent revision, during the lifetime of Phase 1."
"Where change takes place in the SRD, those deliverables which depend on the SRD must be appropriately updated."
The readership of this document is comprised of the SLCCI consortium parties and ESA.
"There may also be scope, following further investigation, as to the use of this document for the Software Engineering Working Group (SEWG), towards finding and forming common ground with other ECV projects as is encouraged by the Statement of Work (SoW)."
"This document is based on issue 1.4 of the Data Access Requirements Document (DARD), issue 1.0 of the Preliminary System Analysis Document (PSAD), Issue 1.1 of the Product Specification Document (PSD), and Issue 1.3 of the User Requirements Document (URD); refinement of this document will be necessary of catchment of future issues of these documents."
One of the types of product of the Sea Level Climate Change Initiative project.
"The phrases operational system, operational SLCCI system, SLCCI system all dethe SLCCI operational system being developed."
"Where the word system is used, it will similarly refer to the SLCCI operational system, unless it is clear from the context that another system is being referred to."
"The Sea Level Climate Change Initiative project is one of eleven parallel Climate Change Initiative (CCI) projects, each focussing on a specific Essential Climate Variable (ECV)."
"The CCI Statement of Work extrapolates from, and refines, this axiomatic objective into a series of constituent requirements and desirabilities, within a phased framework for realisation."
"The effort towards realisation of a system to enact the ultimate objective of the CCI is split into three phases, with Phase 2 implementing the operational system."
"Phase 1, within which this System Requirements Document (SRD) resides, declares the system requirements for the operational system of the Sea Level ECV, that is the specification of what the system should do, prior to the subsequent design deliverable describing how the requirements should be realised."
"The importance of the CCI Statement of Work (SoW) is acknowledged by its integration into the systems requirements elicitation, from which a series of business goals are formed."
One of the reasoned objectives elicited is the reuse of existing functionality towards the development of each CCI operational system.
"To this end, the System Requirements document (SRD) reasons for the apt adoption of certain requirements from an existing operational system, towards a measured realisation of an SLCCI system."
"The scope of the operational system from which the SLCCI system will be founded is therefore mature and well defined, given its proven validation over time in an operational context."
"The CCI Statement of Work does not directly preclude inclusion of any type of environment, but does encourage reuse of existing similar operational systems, as practiced in Chapter 6 (Requirements Elicitation), which may therefore indirectly constrain the environment(s) which may be considered to those adopted by the existing similar system."
"The CCI Statement of Work declares the desirability to a unified multi-ECV system, whereby all, or sets of, ECV operational systems share resources and infrastructure."
The CCI System Engineering Working Group (SEWG) has been set up as a vehicle towards satisfying this goal.
"To this end, acknowledgment and consideration is taken in the System Requirements Document (SRD) with the aim of exploring commonality between the SLCCI and other CCI projects."
"Additionally, one of the advantages of adoption of the existing system chosen, namely DUACS, is that it has been proven to reside in a broader, multi-variable, system similar to a possible pan-ECV CCI system."
"The lifecycle of the System Requirements Document (SRD) starts via a Preliminary System Analysis Document (PSAD) identifying the candidate system for reuse for SLCCI, namely DUACS."
"A set of system requirements is elicited and refined based on a judicious mapping with DUACS, prior to other inputs being considered."
The SRD thereafter undergoes an iteration of review and subsequent modification towards reaching a stable system requirements baseline at each iteration.
Requirements Elicitation – the attainment of system requirements.
Requirements Analysis – the analysis and refinement of system requirements attained.
"As will be seen in the following chapter (Requirements Elicitation), special consideration is given to the judicious absorption of an existing similar system into the SLCCI system requirements baseline, namely DUACS as realised for MyOcean SL TAC, identified by the Preliminary System Analysis Document (PSAD)."
"Re-use of the system for this System Requirements Document (SRD) is undertaken in the context of ECSS standard Q-ST-80C for Space Product Assurance ([RD 10], section 6.2.7), describing good practice for the re-use of existing software."
"A macro functionality is a distinct high-level area of functionality, representable by a use case, and ultimately mappable to a sub- system."
"The unrefined, raw, mapping elicited is analysed with the aim of outputting refined requirements to the System Requirements Baseline (Chapter 8)."
Description is made as to how each SLCCI equivalent system requirement need be modified and whether the mapping itself is valid.
The output of the Requirements Analysis is synthesised as a formal System Requirements Baseline.
"The system requirements are arranged via two dimensions, the SLCCI macro functionalities distilled from the Requirements Analysis, and (ii) the ECSS requirements groups."
Performance - Each requirement should be quantifiable.
"Identifiability - Each requirement should be associated with a unique identifier, associated in the context of where it sits in the system."
Singularity - Each requirement should be separately stated.
These ECSS criteria are compatible with IEEE 830 Standard on the characteristics of valid requirements.
"Initial requirements are directly elicited via (i) the CCI Statement of Work [RD 7] from which business goals and subsequent design requirements are extracted, which includes encouragement for system reuse (ii) a Preliminary Systems Analysis Document [RD 3] describing an adopted existing system significantly similar to SLCCI, namely DUACS, and (iii) relevant documents pertaining to how DUACS is realised for MyOcean in the form of the MyOcean SL TAC."
"The argument towards reuse of DUACS is aided by the context of system reuse good practice as promoted by ECSS standard Q-ST-80C on Software Product Assurance [RD 10, pg 27]."
"As depicted by Figure 6-2, the steps undertaken during Requirements Elicitation start with the extraction of business goals from the Statement of Work, the axiomatic needs for the SLCCI project towards an operational system (Section 6.2)."
"The pertinent business goal regarding system reuse is pursued through the identification and adoption of an apt system for re-use (Section 6.3); a line of argument is posited towards adoption of DUACS based on significant similarities, though also identifying differences for accountability of argument."
The ESA Climate Change Initiative Statement of Work [RD 7] represents the source from which the business goals of the system are herein elicited.
"The objective of Phase I Task 5 is the “preperation for Phase 2 of the CCI Programme” [RD 7, pg 26]."
"The CCI Phase I is defined largely as a scientific exercise by the CCI Phase I SoW [RD 7], given the Tasks defined therein."
"Tasks I to Tasks 4 relate to the scientific endeavour of engaging with the latest scientific understanding, with the ultimate aim of creating a prototype production system which reflects that understanding."
Task 5 is a specification of the operationalisation of that prototype production system for the outside world.
The CCI Phase I SoW [RD 7] is here analysed to extract a series of business goals pertinent to the operational system.
"These goals represent certain axiomatic needs of the operational system prepared by Phase I Task 5, and due to be built by future Phase II implementers."
"We scope our analysis for arriving at business goals of the operational system, by first defining operational system."
"The operational system is the operationalisation of the Task 3 prototype production system, that is a production system and the engineering in of capability onto the production system to allow it to be used in the outside world, following its construction by CCI Phase II."
The operational system is specified via Phase I Task 5 and built by future implementers via Phase II.
Our aim in analysing the Statement of Work is to infer a series of goals which are directly related to the operational system.
"We are not directly concerned, therefore, with the activities leading up to the prototype production system, nor are we directly concerned with the activities at a meta-level associated with the CCI programme organisation, such as the listing of other CCI ECV programmes."
"To that end, we have analyised the whole Phase I SoW, inferring business goals, which we illustrate with supporting evidence."
"It is imperative to note that for each business goal such evidence is one item of supporting evidence as labelled, and does not necessarily reflect all items of evidence used to reason the associated business goal."
"Therefore, a business goal cannot be necessarily inferred by observation of the associated supported illustrativetext alone, but rather by absorption and analysis of the whole document."
Business goals SLCCI-SRB-BUSINESS-GOAL_#1 to SLCCI-SRB-BUSINESS-GOAL_#14 regard the technical constraints listed in SoW §2.8 related to “planning and implementing the CCI project”; these inhabit section SoW §2 (CCI Programme Background) prior to commencement of the description of the tasks to be executed (§3).
"These §2.8 constraints apply to CCI projects as a whole, and irrespective of the Task at hand."
We distil these in context to the operational system alone.
"With SLCCI-SRB-BUSINESS- GOAL_#1, for example, we propose that since the scientific community represent the end users of the operational system, their expectations with regards to the performance of the operational system must be taken into account."
Development of the operational system shall be undertaken with apt consideration for scientific consensus on performance specification of the operational system.
Development of the operational system shall be undertaken with apt consideration for availability of input data from EO archives.
Development of the operational system shall be undertaken with apt consideration for quality of input data from EO archives.
"The supporting evidence from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#3 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#2 [RD 7, pg 11]."
"Development of the operational system shall be undertaken with apt consideration for availability of associated metadata, cal/val data and documentation."
"Development of the operational system shall be undertaken with apt consideration for quality of associated metadata, cal/val data and documentation."
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#5 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#4 [RD 7, pg 11]."
Development of the operational system shall be undertaken with apt consideration for compatibility of data from different missions.
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#6 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#4 [RD 7, pg 11]."
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#7 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#6 [RD 7, pg 11]."
"Development of the operational system shall be undertaken with apt consideration for trade-off between cost, complexity and impact of new algorithms to be developed and validated during the project."
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#8 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#6 [RD 7, pg 11]."
Development of the operational system shall be undertaken with apt consideration for advance planning for data from new missions to be integrated during the project.
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#9 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#6 [RD 7, pg 11]."
Development of the operational system shall be undertaken with apt consideration for end-to-end throughput of ECV production systems.
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#10 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#6 [RD 7, pg 11]."
Development of the operational system shall be undertaken with apt consideration for re-use of existing capabilities within Europe.
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#11 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#6 [RD 7, pg 11]."
Development of the operational system shall be undertaken with apt consideration for compliance of ESA standards.
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#12 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#6 [RD 7, pg 11]."
Development of the operational system shall be undertaken with apt consideration for availability of external validation data.
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#13 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#6 [RD 7, pg 11]."
Development of the operational system shall be undertaken with apt consideration for avoidance of duplication of activities covered by existing operational projects.
"The supporting evidence illustration from the Statement of Work for SLCCI-SR-BUSINESS-GOAL_#14 is the same as that described above for SLCCI-SR-BUSINESS-GOAL_#6 [RD 7, pg 11]."
"Similarly, in CCI Phase I SoW §2, which offers CCI Programme Background, we extract further information relating ESA’s vision of the operational system."
"Before commencement of description of the Phase I Tasks (SoW §3), SoW §2.5 briefly describes the three phases of the CCI programme."
"We take advantage of this Phase I SoW introductory section, to pre-empt future ESA expectations for Phase II, which concerns the building of the operational system."
"As described above for Business goals SLCCI-SRB-BUSINESS-GOAL_#1 to SLCCI-SRB-BUSINESS- GOAL_#14, we observe Phase I content general to the phase, and infer from that the goal specific to the operational context."
"As similarly described earlier, supporting evidence offered is illustrative and does not necessarily form all roots of the reasining."
"Similarly, as with the content quoted below, for example, we draw on modernity and adaptability of the operational system through other goals inferred."
We recognise the matter of cost effectiveness across the ECVs as imperative to achieving cost effectiveness.
We acknowledge the urgency of delivery of the operational system to the climate change community.
Full advantage shall be taken of the latest developments in computing architectures in the development of the operational system.
"Again, in the Phase I “CCI Programme Background” section, we interpret ESA’s vision of Phase I prior to the Phase I SoW Task specification; we assume this SoW visionary information underlies in part the motivation of content in the Phase I SoW prior Task definition."
"Supporting evidence – “CCI Phase 1 […] Full advantage must be taken of the latest developments in computing architectures, data management and communications technologies."
"Innovative structures for large-scale data sharing, data (re)processing and user access, need to be investigated and traded off alongside the associated cost models."
Full advantage shall be taken of the latest developments in data management in development of the operational system.
"The description and supporting evidence illustration from the Statement of Work for SLCCI-SR- BUSINESS-GOAL_#19 applies above to SLCCI-SR-BUSINESS-GOAL_#18 [RD 7, pg 8]."
Full advantage shall be taken of the latest developments in communications technology in development of the operational system.
"The description and supporting evidence illustration from the Statement of Work for SLCCI-SR- BUSINESS-GOAL_#20 applies above to SLCCI-SR-BUSINESS-GOAL_#18 [RD 7, pg 8]."
The operational system development should include cooperation with other consortia producing ECV products.
"We dehere the importance of pan-ECV collaboration across Task 5 endeavours, towards cost effectiveness, as is being realised by the System Engineering Working Group (SEWG)."
The operational system shall have provision for future data set updates.
"The operational system must be flexible enough to be capable to acquire, absorb and process the future data sets being created by scientific endeavour."
"Supporting evidence – “address the need for establishing data service systems that ensure ongoing accessibility to the Climate Data Sets into the future as well as the required capacity to update these data sets periodically by addition of new data or by reprocessing complete records when calibration improves or ECV generation methods evolve” [RD 7, pg 27]."
The operational system shall allow algorithm change.
"Similarly to the previous CCI Programme Background reasoning above for SLCCI-SRB-BUSINESS- GOAL_#22, the operational system needs to be flexible enough to accommodate algorithms being developed by science, as well as new data (SLCCI-SRB-BUSINESS-GOAL_#22)."
The operational system shall have an archiving facility.
"Of all the ingredients listed for inclusion in the SRD, our preliminary analysis points to these as already being considered as part of our system requirements engineering effort, leading to the system requirements baseline."
"We take explicit here of archiving, as this is pointed to as a functional need of the operational system."
"Supporting evidence – Appendix 2, describing content of deliverables, portrays the system requirements as needing to include “archiving requirements” (baseline data and interim products and outputs and their safeguarding to allow for reprocessing)."
The above elicited business goals are included as part of the Design Requirements & Implementation Constraints section of the System Requirements Baseline.
"Therefore, the axiomatic needs of the SLCCI system are made concrete directly in the System Requirements Baseline, so mitigating risk of loss of vision of the system during development."
The business goals earlier elicited make it clear that adoption of an existing system for reuse for SLCCI is desirable.
"ECSS standard Q-ST-80C for Space Product Assurance ([RD 10], section 6.2.7), which describes relevant good practice for the re-use of existing software, from which this System Requirements Document (SRD) will observe where apt for SLCCI."
The Preliminary System Analysis Document (PSAD) identified DUACS as a suitable system for adoption.
The input to the DUACS system and the SLCCI system are significantly similar.
The output to the DUACS system and the SLCCI system are significantly similar.
"The users, the audience, of DUACS and the SLCCI system are significantly similar."
"The climatology research community are the primary target audience for SLCCI, and represent a significant subset of the DUACS user base."
"We aim for SLCCI to be subsumed with other sibling ECVs in a higher-level system; such an objective has already been proven with DUACS in the context of the (pan-variable) MyOcean Endeavours are being made, and will continue to be made, through the CCI System Engineering Group (SEWG) towards reaching commonality with sibling ECVs towards system design."
"To accommodate this endeavour in an apt manner during the requirements stage, it is envisaged that the SLCCI system will hook in to higher level Central Information System (CIS) [RD 11], available at the CCI level across all ECV projects (including, in this content, SLCCI), with each ECV implementing its own INSPIRE compliant interoperability with the Central Information System."
Metadata will be associated with SLCCI in order to describe all output sea level products.
"It is anticipated that this SLCCI metadata will take the form of static and dynamic metadata, describing the characteristics and quality of the associated SLCCI product, respectively, as is similarly the case with DUACS metadata."
"This is recognised in context of the business goals associated to quality and availability of metadata, namely SLCCI_SRB_BUSINESS_GOAL_#4 and SLCCI_SRB_BUSINESS_GOAL_#5."
"As has been pointed out, both DUACS and SLCCI systems are both associated with a common and significant user type, namely the climatology research community; the complete user type for SLCCI represents a significant subset of DUACS users."
"DUACS NRT services, are irrelevant to SLCCI which is concerned exclusively with the climatology research community."
"DUACS generates Near Real Time (NRT) products , Delayed Time (DT) or Updated mode, and entire reprocessed time series (REP)."
SLCCI only addresses DT and REP specifically for climate applications.
"DUACS as realised for MyOcean SL TAC links to a higher level system, namely MyOcean."
"Although the envisaged Central Information System (CIS) for SLCCI is analogous to the MyOcean Information System (MIS), the CIS is intentionally flexible but nonetheless well scoped, rather than a concrete, existing, high level pan-variable system as is the case with MyOcean."
"No Acquisition Chain and Production Chain, as used by DUACS documentation, exist on the SLCCI."
"Instead, the term production pipeline is used to refer to the sequential macro-functionalities necessary in producing the data products."
"We further demonstrate that the DUACS system can be used for SLCCI product generation, by mitigating development risk in adoption of DUACS."
"To this end, it is pertinent to eliminate or manage any constraints to the SLCCI inherited from DUACS."
"On the first of these, the DUACS system was originally tailored for independent operational use rather than as a general (sub) system hookable elsewhere for re-use."
"However, use of DUACS towards reuse has been proven in the context of MyOcean, a large scale multi- variable processing and dissemination system, so proving that DUACS is capable of serving for reuse."
"On the second point, the Design Requirements & Implementation Constraints (Section 8.19) section absorb such matters."
Description of differences between DUACS and SLCCI (Section 6.3).
"To this end, the SRD declares the differences between the original DUACS system and the target SLCCI system (Section 6.3) to legitimise and reason the mapping."
These differences are observed during Requirements Analysis (which takes as its input the raw requirements mapping reasoned during Requirements Elicitation) in order to reason all changes necessary for those requirements which are derived based on the mapping from the original system.
"We acknowledge the good practice on system reuse (Section 6.3) as promoted via the ECSS standard for software reuse as elicited by the ECSS standard ECSS-Q-ST-80C (Space Product Assurance, Software Product Assurance), Section 6.2.7 (Reuse of Existing Software), and implement where apt and suitable for our system reuse of DUACS towards SLCCI."
"The elicitation of business goals from the CCI Statement of Work not only highlight the welcoming of system reuse, directly (as SoW explicit content on system reuse) and indirectly (via SoW content on cost efficiencies) , but also the adoption of latest technologies; to this end, the adoption of an existing, mature, system needs to legitimise the balance undertaken of reuse of existing technology with adoption of, or integration with, more novel technologies towards provision of a system of apt quality and timeliness."
"In the context of the System Requirements Baseline, an explicit list of constraints are offered in section 8.19 (Design Requirements & Implementation Constraints)."
"Such constraints are important during SLCCI design, in meeting apt and reasoned reuse of the existing DUACS system."
"During the design stage, the output of which is communicated in the form of the System Design Document (SDD), this pertinent matter will be attended to at the very earliest opportunity."
"The following diagram portrays the boundary of the DUACS system, and describes the interaction between the system and its external environment."
Upstream Systems from which data is collected for the production chain.
"Support Contributor, users internal to the DUACS system."
"Product Contributors, users internal to the DUACS system."
"While interacting with the system, he is to be considered as an actor and uses specific system capabilities."
While performing additional manual or procedural tasks and eventually storing his results in the System.
Monitoring (and follow-up of monitoring) System & Service & Products Solving incidents on the system”.
"Note that every contributor type is involved in each of NRT, DT and REP production ; each type has a higher frequency of activity involved in the NRT production only because NRT productions are daily compared to other productions which are of a lower frequency (REP,DT)."
"The SLCCI system will adopt the same system boundary and high level interaction with users, considering the aforementioned operational equivalencies."
"The DUACS system, as realised for MyOcean SL TAC, is part of the higher level MyOcean system, so dependencies with the Top Level, for instance the MyOcean Information System (MIS), are not directly included in the SLCC equivalent."
"Acknowledgement of this potential pan-ECV usage is of the very utmost importance, considering the business goals elicited which relate to system reuse, namely SLCCI- EB-BUSINESS-GOAL_#15, SLCCI-EB-BUSINESS-GOAL_#16, and SLCCI-EB-BUSINESS- GOAL_#21."
"To this end, a Central Information System (CIS) is adopted for SLCCI."
"The external users quoted for DUACS are a superset of those associated with SLCCI, considering the DT/REP-only nature of SLCCI products."
The SLCCI users relate to climatology research and so do not require degraded-quality NRT data products.
SLCCI Contributor – the highest level internal user type.
SLCCI Product User – the highest level external user type.
The diagram below (Figure 6) portrays all SLCCI user types.
"The SLCCI Product User is considered to be associated with external users of the SLCCI outputted products (Climate modelling communities represented by the CMUG group within the CCI Phase 1), namely the SLCCI FCDR and SLCCI ECV as described by the PSD."
"The SLCCI contributor, or Worker, des an internal user to the system."
"Moreover, the diagram represents the relationship between different types of user via the generalisation relationship."
"Therefore, for example, there are two direct sub-types of SLCCI User, namely an SLCCI Contributor and an SLCCI Product User; in other words, an SLCCI Contributor is an SLCCI User and an SLCCI Product User is an SLCCI User."
Indeed all user types in the diagram are SLCCI Users since the SLCCI User type is the ultimate base type of all user types.
"Following on, an SLCCI Product Contributor (responsible for the quality and management of products) and an SLCCI Support Contributor (representing SLCCI Contributor types supporting operational services), are both direct sub-types of SLCCI Contributor."
"Furthermore, there are different types of SLCCI Product Contributor (Scientific Expert responsible for modelling, Product Expert responsible for establishing and assessing the quality of products plus providing scientific judgement, Product Manager maintaining the product database, product catalogue content and managing metadata) undertaking the work done on the production chain, and different types of SLCCI Support Contributor (Service Desk interacting with external users, Service Manager overseeing the operational running, Support Operator supporting the systems operations internally) undertaking the support of operational running of the system."
"These four packages exhaustively realise the operational scenarios explored by SL TAC [RD 9, pg 12], and are operationally significantly similar to SLCCI to warrant adoption, given the argument and evidence offered earlier."
"To this end, the figure below offers an illustration of the SLCCI equivalent Use Case packages adopted."
"The following four sections will argue for the apt mapping of use cases and their associated system requirements to the SLCCI system, with each section representing one of the four use case packages, thus covering the entire use case package spectrum."
"As argued earlier for DUACS, and indeed also by the PSAD, the above use cases are mirrored by macro functionalities describing the pipeline between data input and end product [RD 3]."
Each of these high level use cases maps to a macro functionality.
"The SL TAC SRD [RD 9, section 8.1.1] fully describes the responsibility associated with each DUACS macro functionality."
"The high level DUACS use cases for production are each associated with a macro functionality, with each macro functionality associated with lower level requirements completely expressing the associated macro functionality."
"Given the evidence and argument so far composed, we may judiciously define a mapping of use cases and subsequently a mapping of the system requirements contained therein, from DUACS to SLCCI."
We therefore envisage the same use case to macro functionality parallel for the SLCCI as is the case with DUACS.
For convenience we explicitly map between SLCCI and DUACS macro functionalities rather than between their associated use cases.
"Given the evidence provided thus far, we argue that the DUACS production Use Cases, and therefore their associated macro functionalities, map to SLCCI equivalents."
"The View Product use case relates to visualisation of the product under two guises – a “Preview” of products, and a “Full View” of products [RD 9, pg 48] composed of generated static images."
"External tools are used to generate these views, namely THREDDS, OPENDAP, and WMS for such visualisation, which expect content in NetCDF format."
"As explored as part of the Requirements Analysis, these will not necessarily be adopted for SLCCI."
"With regards to the Get Product DUACS use case, the product is downloaded by means of ftp or OPENDAP [RD 9, pg 50]."
The product is also available via the MyOcean web portal.
"Again, the SLCCI equivalents, described in the Requirements Analysis, will illustrate where changes are likened or necessary in order to accommodate the mapping, for instance the adoption of ftp and OPENDAP."
"Regarding the Support Users use case, users’ demands for support and information are satisfied via a DUACS web portal supported by a service desk."
"A high level service desk distributes requests to an SL TAC specific service desk [RD 9, pg 51]."
"Four relevant user types pertain, the top level and SL level service desks, service manager and support operator."
"As stated in earlier, whereas DUACS hooks into an existing higher level infrastructure for the MIS, the SLCCI equivalent will be connected to a Central Information System at the CCI level."
An answer may be returned to an information request via different communication means and within a variable time span depending on information type or availability.
"For example, user might be directed towards online system capabilities for general information."
"As a single point of contact, the MyOcean Web Portal, is offered to users to get automated information, integrated system capabilities allow Support Contributors to automatically manage and publish information on this Web Portal."
"New dissemination interfaces (associated to ""Products"")."
"View Product relates to viewing details of product, as described by its metadata."
Get Product is the downloading of the product by an external user; this is accomplished via an SLCCI web portal.
Support User is a ticketing system similar as that earlier referred to for DUACS.
"However, where the mapping does not hold is that no higher level service desk exists for SLCCI, therefore the SLCCI service desk (i.e that at the level of the SLCCI rather than a higher level system) is referred to instead; it is d however that there is the potential to glue SLCCI to a higher level pan-ECV system, given that DUACS, in the frame of MyOcean SL TAC equivalent, already resides in a pan-variable infrastructure."
"Under SLCCI, it is envisaged that users referring to the SLCCI Support User use case are (i) Service Desk, (ii) Service Manager, (iii) Support Operator, that is the complete three types of SLCCI Support Operator."
These three user types will enact actions in the SLCCI system requirements on which the support user use case envelopes.
"The Use Case package describing the management of products in the DUACS system is described in the SL TAC SRD [RD 9, section 8.1.2]."
"Product information is supplied by static metadata (the Update Static Metadata use case) and dynamic metadata (the Update Dynamic Metadata use case), dependent on the kinds of product updates."
A Maintain the Products Database use case subsumes both these metadata update use cases.
"The Maintain the Product Database use case for DUACS, as realised for MyOcean SL TAC, is related to registering products in the product database and the maintenance of the static and dynamic metadata associated with the products."
"Actors involved pertain to the Product Manager, Product Expert, which are both Product Contributors, i.e internal users of the system."
"As earlier indicated, it is proposed that the SLCCI system have a Central Information System (CIS) equivalent to the MyOcean Information System (MIS) component, and therefore the mapping to an SLCCI equivalent during Requirements Analysis (Chapter 7) will accomodate the SLCCI equivalent accordingly."
"Authorization of the ""Product"" (so that MyOcean can start ?logging?"
"Again, an Information System is not proposed for the SLCCI system, as it is not currently warranted."
However this could be a valuable solution when relying on (at least partly) existing systems.
"As is the case with DUACS, a differentiation is made for SLCCI between two flavours of metadata, namely static and dynamic metadata, describing the characteristics and quality of the associated SLCCI product, respectively."
"It is anticipated, again, that the SLCCI equivalent will justifiably refer to both static (definition of the product characteristics) versus dynamic (definition of product quality) metadata types."
"The FTSS (Fast Track Service Specification) is a MyOcean document cataloguing products, containing descriptions to all products generated by MyOcean."
These matters are considered further during Requirements Analysis (Chapter 7) where the raw systems requirements mapping is exercised to produce and refine SLCCI equivalents.
"Each update (creation/deletion of a Product Line/Product specification, authorization of a Product) of the Products Database by the SL TAC Product Manager has to be reported to the Top-Level Product Manager for a validation (particularly regarding the state of a Product: operational or not)."
Such Product Lines won't have associated Product Specifications and are necessary to the product dependencies.
"Again, strengthened by the business goal requirement towards consideration of SLCCI metadata defining availability and quality of product, a semantic equivalency is proposed between DUACS metadata and SLCCI metadata."
"As earlier indicated during the analysis of the DUACS / MyOcean SL TAC product management, the SLCCI equivalent assumes similar distinction between static and dynamic metadata."
"The DUACS use case package containing all use cases therein related to monitoring of the system is the Monitoring package, are described in the SL TAC SRD [RD 9, section 8.1.4]."
"Certain DUACS requirements, as realised for MyOcean SL TAC, must be refined in order to reach their SLCCI equivalents, for instance the defining of raw measurements, and depiction of the CRM tool to be used."
Top Level dashboard shows consolidated indicators for all Top level Services.
"This dashboard allows Service Desk members (Support Operators, Service Managers), at all levels, to know the ""health"" of the Top Level Services at a glance."
"Note that the SLCCI equivalent will not (necessarily) have a top level tier, and so an equivalent at the SL level should be adopted for the SLCCI equivalent."
Several level of automation might be implemented from fully manual to advanced instrumented monitoring.
"As earlier indicated, ITIL Processes are irrelevant to SLCCI and therefore fall out of scope of the SLCCI system requirements."
"As earlier indicated, the SLCCI equivalent system will have a Central Information System (CIS), residing at the CCI level, equivalent to the MIS component, and therefore SLCCI requirements will reflect this equivalency."
The monitoring can be either an automated procedure or human action.
"Deferment of certain DUACS characteristics to a Service Management Plan, necessitates examination of the Service Management Plan during Requirements Analysis."
The production is monitored in the SL TAC Production Center.
"Athough fitting neatly into the MyOcean structure at a high level, the concept of the production centre is not established in the SLCCI equivalent."
"This information is produced and validated by the Product Expert (see ""Perform output checks and QC"", ""Do measures and build indicators on products"" Use Cases)."
The exact nature of the metrics to be monitored will be detailed in the Service Management Plan.
"Request monitoring at the SLCCI level, as required for Requirements Analysis cannot assume inclusion of a higher level system tier to SLCCI, but should flexibly observe a higher level tier where possible."
The list is described in the Service Management Plan.
"DUACS monitoring requests are enacted through a top level providing information on the user relevant to a request, and information regarding the products retrieved by that user."
Such assumptions cannot be assumed to be realised for the SLCCI.
"The SLCCI equivalent of the Monitoring package is as illustrated below, which mirrors the DUACS use case arrangement as realised for MyOcean SL TAC."
"Therefore, the three types of monitoring proposed in the DUACS system are similarly adopted for the SLCCI system."
"The main respect in which the equivalence between DUACS, as realised for MyOcean, and SLCCI does not hold is the presence of a higher level tier for the former."
"As earlier argued, a higher level presence for SLCCI does not (necessarily) occur, but can be accommodated through well scoped provision where apt for this stage, such as through inclusion of a CCI-level Central Information System."
"The Requirements Analysis takes as its input the argued equivalency between DUACS and the SLCCI operational system, in readiness for argued mapping at the system requirement level (§7.2)."
"The analysis also draws in other documents as referenced below, with a subsection similarly associated with each."
"As its input, therefore, the Requirements Analysis accepts a reasoned, though unrefined, system requirements between DUACS and SLCCI, based on argued equivalences of user hierarchy, scope, use case packages, use cases, and their associated system requirements during the Requirements Elicitation."
"The following four sections (Sections 7.2, 7.3, 7.4, 7.5) portray the judicious mapping from DUACS to SLCCI, given all supporting evidence and argument thus offered."
"Where the mapping is not possible to an SLCCI equivalent, this is reasoned."
"Similarly, where a mapping needs to be such that a pertinent difference must hold, then an explicit reference is made to the difference, in order to allow the mapping; the set of differences between the DUACS system, as realised for MyOcean SL TAC, and SLCCI have been given."
The following table lists the tables housed by each of these four sections.
Each section table represents the mappings for a use case pertaining to the associated use case package.
"The above categories pertain to the complete set of ECSS requirement groups apt for SLCCI [RD 5], other than (i) Functional Requirements and (ii) Performance Requirements, which are more aptly housed within each of the SLCCI macro functionality sections."
"We introduce the concept of a Central Information System (CIS) to our design, to represent our interfacing with other ECVs ; the consensus and specification of such an interface are still under discussion within the SEWG, but we want to make the maintain the concept of such an interface as part of the SLCCI design."
"Portal, but also make them available to our conceptual Central Information System."
"The System Requirements Baseline should include requirements derived from the consortium experience in operational systems within Earth Observation, and other sectors where applicable."
"Such requirements will draw on the operational demands to be put upon the Sea Level CCI system, as well as expectations the operational system should contain for the assessment of its operational health."
"Establishment of macro functionality performance expectations, to each of the production chain stages."
Each relevant stage of the production chain should have associated performance expectations.
"Inclusion of requirements related to operational matters, not directly connected to the production chain but nonetheless required for the running of an operational service, such as asset and inventory management, backups."
"To help maintain operational integrity to the system, transparency to the performance gathering aspects of the system should also warrant consideration, such as in the gathering of operational statistics."
The expectations of the system may bind to particular standards.
"Use of such standards differs to those to be adopted within the System Specification Document, where candidate standards are identified and a chosen standard reasoned towards helping satisfy system requirements."
"Analysis towards inference on, and refinement of, relevant expectations pertaining to the DUACS operational system, for example expansion of operational demands for user registration, download verification, and transaction accounting, linkage to a higher level system."
"Analysis on elaborating on the user perspective towards reasonably capturing future user demands, e.g concerning reasonable demands of user of operational system, for instance allowance of simultaneous downloads, and the associated storage resources required."
"At a meta-level to specifying requirements of the system, specification of requirements to do with the conduct of system specification and development itself, such as apt considerations arising from ECSS."
"Analysis on system configuration, installation and delivery."
"The system should, for instance, be able to anticipate Earth Observation data from the Sentinel cluster."
Our analysis of the URD [RD 1] captures the list of user requirements which the operational system should accommodate in a system context.
We do so by expressing the accommodation of these desired user requirements.
"These system focus centres on the SLCCI production chain, and preserve the user consensus on what should be accommodated by the operational system."
"This synthesis within the URD proposes the following categories of user requirements, which for the system specification we will bundle to declare that the SLCCI should accommodate such matters."
"Length of data set time series ([RD1] §5.1.1, UR-SLCCI-GEN-01)."
"Satellite coverage and overlap over the dataset ([RD1] §5.1.1, UR-SLCCI-GEN-02)."
"Acknowledegement of tidal influences ([RD1] §5.1.1, UR-SLCCI-GEN-06)."
"These matters do not directly point to the scientific practice undergone to arriving at the input data or product generation, but rather user-driven characteristics which the system requirements must be in keeping with."
"Our analysis of the PSD [RD 6] allows us to recognise the production chain product types, to be outputted by the operational system."
"In particular, declares the formats of these two product types, given both the PSD ([RD6] §2.2&3.2) and the endeavours of the Data Standardisation Working Group (§7.10)."
"Identification of the spread of satellites, missions, instruments and products necessary for application to the operational system, irrespective of the outcome of the Task 2 Round Robin ([RD2] §5)."
"This version of the SRD attains these identified necessary inputs, with a later version of the SRD introducing further products as input, following identification of the winning algorithm and associated data for Task 2 ([RD2] §5)."
Recognition of types of auxiliary data input by analysing ([RD2] §5).
Recognition that the system must understand data as well as metadata ([RD2] §5).
"The system needs to understand future data needs, not just accommodate existing data needs, so pointing towards the need for scalability of the operational system."
"The system should, for instance, be able to anticipate Earth Observation data from the Sentinel cluster ([RD2] §1)."
"Absorption of business goals within the Statement of Work, representing the axiomatic needs of the system2."
These relate to expectations of the system directly relevant the operational system scope ([RD7] throughout); see §6.2 for mapping detail per business goal.
"We offer a direct mapping from these attained business goals to the System Requirements Baseline, so preserving ESA’s vision of the operational system."
"These sit at a meta-level to other system requirements, describing the design requirements and implementation constraints of the operational system; [RD7] throughout, see §6.2 for mapping detail per business goal."
"Although these system requirements for a Phase II system are derived from a Phase I CCI, there is still a good distillation of information possible in terms of pointing to system requirements for the Phase II system ([RD7] §2.5)."
"We draw on ECSS-Q-ST-80C (Space Product Assurance) towards establishing reasonable expectations for software quality which should be satisfied by the future implementers during Phase II; these are not only beneficial in order for the Phase I SSD to be satisfied, but of benefit to Phase II implementers needing to formally attain and verify good practice."
An analysis should be carried out as to pros and cons of reusing software ([RD10] §6.2.7.2).
Appropriate attention should be directed to reflect corrective actions ([RD10] §6.2.7.9).
We analyse the PSAD [RD 3] to support the construction of the System Requirements Baseline.
"The objective of the PSAD was as an early analysis of how the Task 3 prototype may be used operationally, and conducted by each of the CCI ECV parties."
We also subsequently infer that a Reprocessing (REP) mode is required.
The PSAD defines two manners by which the operational system should absorb input data – passive and active acquisition.
"This information, together with the DARD analysis, allows the introduction of system requirements pertaining to the manner in which each of the expected operational system inputs should be acquired ([RD3] §3.3)."
"Interpreting the PSAD together with the DARD, allows the formation of system requirements pertaining to the data and database, such as the size of particular foreseen databases."
"Given the need to design an operational system needing to be capable of accommodating future mission data, points to consideration of scalability of the system ([RD3] §3.3, §3.4, §3.5)."
"We are active participants in the SEWG, and support ESA in their leadership of the group."
"A vehicle for collaboration which we have introduced into discussion is the concept of a Central Information System, a potential mediator across ECV systems and proxy to the ECV portfolio from the outside world."
"To that end, we have produced a Technical to the SEWG relating to pan-ECV collaboration in the context of such a mechanism [RD 11], and will continue to endeavour towards exploration of a reasonable solution for attaining cost-effectiveness across the ECVs."
"This document recognises the efforts of the Data Standardisation Working Group (DSWG), towards reaching consensus on a common format of data product across the ECVs, targeting NetCDF and CF, archiving standards, and other operational matters as described in [RD 11]."
"Moreover, the argument for defining the concept of the Central Information System is earlier elaborated in the §7.2 introduction, in reference to the concept through §6.3 point (7), §6.5.1, §6.5.2, §6.8.2, §6.9.2 and §6.10.3."
"This chapter represents the System Requirements Baseline of the SLCCI operational system, derived from the earlier requirements elicitation (Chapter 6) and subsequent analysis (Chapter 7), as illustrated by Figure 8-1."
Further requirements other than those directly elicited via DUACS system re-use are also added.
"The system requirements are arranged across two dimensions, garnered from macro functionalities and ECSS standard E-ST-40C ([RD 5], Annex D)."
"Of the ECSS engineering discipline branches, E-40 (Software Engineering) is observed as being the most considerably apt for exhaustive, complete, SLCCI requirement categories in relation to other ECSS discipline branches, and also appropriately envelopes relevant considerations in providing a software related system requirements realisation of ECSS-E-ST-10C (System Engineering General Requirements) clause 5.2, establishing linkage between E-ST-10C and E-ST-40C."
On one dimension lies a complete listing of relevant ECSS standard requirements groups (Figure 8-3).
The second dimension houses the complete list of macro functionalities proposed (Figure 8-2).
"Applying one dimension to another allows a complete, exhaustive, view of ECSS standard requirements involvement across the SLCCI macro functionalities."
The application of all macro functionalities across the Functional and Performance ECSS requirements.
Functional and Performance requirements differ significantly across the macro functionalities.
"That is, the SRD macro functionality system requirements groupings will ultimately map to SSD sub-systems, and for the design of each subsystem it is imperative to have the functional and performance SRD considerations treated per sub-system."
"The application of all ECSS requirements groups other than Functional and Performance (i.e the remaining ECSS requirements groups) to the SLCCI system as a whole (i.e across macro functionalities as a whole); these requirements groupings sit more comfortably neutral to each macro functionality, so applicable to the system as a whole."
The result of these two grids is that all ECSS standard requirements groups are aptly measured against the SLCCI system.
Grid 1 observes Functional and Performance requirements across all ECSS requirements groupings.
Grid 2 observes the macro functionality neutral ECSS requirements groupings across the whole system.
"The system requirements are formed in tables as illustrated below, with the following columns and associated abbreviated column names."
A list of traced items for the same system requirement is delimited with a comma character.
"It is often the case that a system requirement is inferred from a number of sources – for example a system requirement related to the storage of certain processed mission data, may use the PSAD to infer the data identity, DARD to attain mission references and operational experience to attain the formation of the storage constraint specified."
The form of verification for the system requirement.
"Also, with regards to the system requirements pertaining to the macro functionalities of the production chain, we have declared a single higher level system requirement for each macro functionality section which semantically composites all system requirements contained within its associated section."
We offer such higher level system requirements across the production chain as a convenient vehicle to describing the expectation of the associated macro functionality stage.
Such high level production chain system requirements are ded are satisfiable if and only if their constituent system requirements are entirely satisfied.
"For each macro functionality section, we declare the high level functionality and its associated constituents diagrammatically."
"The following functional system requirements have been positioned in this section for clarity and convenience as they essentially reflect the scoping of the SLCCI operational system production chain through (i) the inputs to the system, the (ii) outputs from the system, and the (iii) user expectations."
The Data Acquisition system requirements associated with functionality are comprised below.
Note that the required course of operational action for anomalous data acquisition events is as described by the Operational Requirements (§8.16).
If the application detects that it lacks at least one item of required before product generation can commence.
The Level2+ Cal/Val requirements associated with functionality comprise of the following.
"The specific temporal threshold for an automatic quality check is calculated as a multiple of the amount of input data and a calculation weighting; for instance, if the calculation weighting is 0.1, and the amount of data flow is flow."
There are no Product Assessment system requirements associated with the performance of product assessment.
Product Management is associated with no performance requirements.
Production monitoring is further explained by SLCCI-SRB-REQ_6-019 and SLCCI-SRB-REQ_6-020.
Request Monitoring expectations are specified by SLCCI-SRB-REQ_12-010.
SLCCI-SRB-REQ_1-420 Data backup operation shall be automated where possible.
The system shall make provision for at least <x> TBs of disk storage dedicated to the product pipeline.
The system shall make provision for at least <x> TBs of disk download by SLCCI Product Users.
The system shall make provision for at least <x> TBs of disk storage dedicated for SLCCI product archiving.
"These system requirements sit at a meta-level to others as they provide stewardship for the development of the system via the maintaining of the ESA vision of the operational system, and also include system requirements referring to approach of design and implementation which are appropriate at this early stage."
Note that system requirements associated with configuration control and system reuse are contained within §8.22.
SLCCI-SRB-REQ_15-010 Development of the system shall be undertaken with apt specification of the operational system.
SLCCI-SRB-REQ_15-020 Development of the system shall be undertaken with apt archives.
SLCCI-SRB-REQ_15-030 Development of the system shall be undertaken with apt consideration for quality of input data from EO archives.
SLCCI-SRB-REQ_15-040 Development of the system shall be undertaken with apt cal/val data and documentation.
SLCCI-SRB-REQ_15-050 Development of the system shall be undertaken with apt data and documentation.
SLCCI-SRB-REQ_15-060 Development of the system shall be undertaken with apt missions.
SLCCI-SRB-REQ_15-070 Development of the system shall be undertaken with apt sensors.
SLCCI-SRB-REQ_15-080 Development of the system shall be undertaken with apt validated during the project.
SLCCI-SRB-REQ_15-090 Development of the system shall be undertaken with apt missions to be integrated during the project.
SLCCI-SRB-REQ_15-110 Development of the system shall be undertaken with apt Europe.
SLCCI-SRB-REQ_15-130 Development of the system shall be undertaken with apt consideration for availability of external validation data.
SLCCI-SRB-REQ_15-140 Development of the system shall be undertaken with apt covered by existing operational projects.
The Security and Privacy system requirements are comprised as follows.
Note that the provision for authentication has been made in §8.13.
The Software Quality system requirements are derived from ECSS standard ECSS-Q-ST-80C.
The following table summarises the mapping between system requirement ID and associated traceability.
The system required ID is coloured red if the associated system requirement refers to a value yet to be determined; these cases are also listed under the “Lists of TBD”.
"The following table represents Appendix B (« List of Requirements ») of [RD 9], summarising the list of DUACS system requirements as realised for My Ocean SL TAC."
The system detects new data flows (input altimetry level 2 data and auxiliary data).
The system checks the synchronization between the input data and the auxiliary data (the dependency between input data and auxiliary data needed for the processing).
"In nominal case, input and auxiliary data are present and the system acquire them."
The Support Operator analyses the source for the detection of the abnormal flow.
Degraded level 2 data will degrade the quality of the output products.
The decision to take into account the new level 2 data must be taken by the Support Operator and approved by the Service Manager.
The acquisition process is forced by human intervention.
The products of degraded quality are not reprocessed but new products will use the new Level 2 data once they have been acquired.
The auxiliary data needed for the input data may not be present.
The input data are supposed to be acquired on a given date.
The system can wait for the acquisition until a defined delay.
"When the delay is expired, the support operator is automatically warned that the data flow is too late."
The unavailability of the input data is temporary (incident on an altimeter): the output products can be generated but with a degraded quality.
The information on the quality of the products has to be reported to the Top Level Service Desk through the SL TAC Service Desk.
"It may also be reported in the dynamic metadata of the products TBC, upon Service Desk Manager decision."
The unavailability of the input data is definitive (loss of one altimetry mission): the products of the corresponding mission will not be produced anymore.
The incident has to be reported to the Top Level Service Desk through the SL TAC Service Desk since it impacts the products available for the users.
The data are homogenized by using the suitable geophysical corrections to calculate the Sea Level Anomaly for each altimetry mission.
He warns the upstream data centers of the anomaly detected on the input data flows.
This error can be corrected by a new acquisition of the input flow that was initially corrupted (not detected at the acquisition level but at the step of the input checks).
"It may also be reported in the dynamic metadata of the products TBC, upon Service Manager decision."
The SL TAC system has to be modified to cope with the new configuration of input data.
The decision for the modification must be validated by the Service Manager.
The organization for such a scenario is described in the Service Management Plan.
The statistics are gathered in a synthesis report to be checked by the Product expert twice a week.
The validation loop may need to run several times the production chain.
"If the anomaly can be corrected in the SL TAC, the production chain is run again (the Use Cases which are impacted)."
"If needed, the Support Operator reports the anomaly to the Service Manager."
The system calculates the different KPI for the SL TAC.
The list of the KPI is described in the Service Management Plan.
"The KPI are available on a daily basis, for NRT products only in V0 and V1."
The system calculates the different Ocean Indictors for the SL TAC.
The list of the Ocean Indicators is described in the Service Management Plan.
"The system calculates interpreted indictors for the SL TAC, which are derived from KPI and scientific metrics."
"The product is distributed, even if the metadata are not updated."
"If the FTP server fails, an incident has to be reported to the SL TAC Service Manager."
"Once it is repaired, the products are available to the users but with delayed time."
The decision and the archive procedure is automatic.
The Product Manager must also register as Product Lines the upstream data that are delivered by providers external to MyOcean v1.
"The requests may be addressed via different communication means (for example through a form), and processed by a dedicated service (Service Desk, at top level) and are cascaded to the SL TAC Service Desk in case of requested information about SL TAC."
The input data and products of SL-TAC are archived by CNES.
The following physical interfaces and conventions are required by the SL TAC from the MIS: v1.
"The SL-TAC system shall comply with the security policy of all projects CLS carries for CNES, as SL-TAC activities are also carried out in the DUACS framework of SALP, the multi-mission center of the French space agency."
The SL-TAC system shall prevent any disclosure of information to unauthorized individuals or systems.
"This requirement is applicable to the Production Unit (limited access to internal documents, products and internal data) and to the Distribution Unit (limited access to Service Desk documents, database, and MIS Gateway configuration)."
The SL-TAC system shall prevent modification without authorization of any data.
The SL-TAC system shall prevent any conflict between concurrent operator requests.
The SL-TAC system shall be activated with scripts and command lines on Linux OS.
Automated sequences shall be defined for routine operations.
Internal or confidential documents shall be centralized in an access restricted area.
Accessibility shall remain a practical concern of the SL-TAC.
"The SL-TAC system shall be configured for strict monitoring, by favoring false alarms to undetected errors."
The SL-TAC system shall be able to detect problems and to send an automated warning within <<one hour>> of the event.
The SL-TAC system and contributors shall try and provide a level of service availability as close to nominal in working hours as possible.
"The backup system shall be located either in CLS’ disaster recovery data center located within the CNES campus, or in CLS’ ARGOS backup data center in Washington."
"The SL-TAC system shall be designed to minimize the risk of central failure and to create, as many workaround solutions as possible if sub systems are unavailable."
The only exception to this rule are major incidents and new versions the SL-TAC system.
"In both cases, the intervention must be discussed and controlled by system and scientific experts."
All possible measures to ensure integrity is not compromised shall be taken.
The end-to-end Near Real Time production shall be able to process an innovative data flow of up to <<4 days from 4 altimeters>> every day.
The processing sequence shall also include up to <<40 days>> of older data not changed since the previous production.
The SL-TAC shall be compliant with INSPIRE European Directive.
The SL-TAC shall be compliant with CNES’ SALP project rules and guidelines.
"The SL-TAC shall be compliant with French and European laws on the following topics: privacy and right to own data about one’s account (respect to France’s CNIL regulations), intellectual property and copyrights, IT fraud control, cryptography and electronic identity, legal duration of data retention."
The SL-TAC production system shall expand on the pre-existing CNES/CLS DUACS system (both in DT and NRT) and be compliant with its design interfaces and constraints.
The SL-TAC distribution system shall expand on the pre-existing CNES AVISO system and be compliant with its design interfaces and constraints.
"The overall goal of the DESSIN ESS software system is to support users implementing the DESSIN ESS evaluation framework and sustainability assessment, as described in the DESSIN Cookbook (D11.2)."
"This document describes how the software should do this, from the end-user perspective."
The document is organized into so-called “user stories”.
"Each user story describes a task that a user would like the software to perform, and explains why performing the task provides value to the user."
"The users stories are organized into “epics”, which are groups of similar stories."
"There are five epics, one for each of the five parts of the DESSIN Cookbook (D11.2)."
"Most of the user stories are written from the perspective of an evaluation lead carrying out an ESS assessment, as this was thought to be the most likely user of the system."
"The software framework presented here was developed by DHI, ECOLOGIC, SINTEF, and IWW in collaboration with the DESSIN user group, which consists of the demo site representatives who will be the end users of the software."
User stories are accompanied by acceptance criteria that define when a story is complete.
There is not a one-to-one correspondence between the user stories and the “steps” of the cookbook because some steps were too complex to fit into a single coherent user story.
"A number of potential user types were considered in the development of the user stories presented here, from scientists to SME representatives to technical specialists with computer programming expertise."
"However, most of the user stories are written from the perspective of an evaluation lead carrying out an ESS assessment, as this was thought to be the most likely user of the system."
"Although the software is targeted to this user group, it is hoped that the software will go on to be used by others performing ESS and sustainability assessments after the conclusion of DESSIN."
"This document describes what the DESSIN ESS software valuation software should do, from the end-user perspective."
"The purpose of the document is not to provide technical details for the software implementation, but rather to outline what the software should be able to do, and how the software should appear."
The software requirements presented here are the result of consultations with individuals involved in developing the DESSIN ESS and sustainability assessment methodologies developed as part of DESSIN work package 11.
"In addition, the software requirements were refined through consultation with the end-users of the software (i.e., representatives of the DESSIN demo sites)."
This document presents software requirements in a series of “user stories”.
Each user story describes a task that a user would like the software to perform.
"In addition, each user story explains why performing the task provides value to the user."
Note that the example states what the user would like to do (“order and item”) and why the user would like to do it (“receive what I want”).
"User stories are accompanied by “acceptance criteria”, which outline what the functionality described in the story should be able to do when implementation is complete."
"In other words, acceptance criteria describe when a user story is complete."
"In this document, user stories are organized into “epics”, which group similar stories."
"Together, the different epics support the overall goals of the software system."
A conceptual diagram of the organizational structure is provided in Figure 1.
"The overall goal of the software system is to support users implementing the DESSIN ESS evaluation framework and sustainability assessment, as described in the DESSIN Cookbook (D11.2)."
The user stories represent the different tasks that should be carried out to implement the methodology in the DESSIN Cookbook (D11.2).
"As part of the development of user stories, the WP23 partners identified potential users of the software."
All of the user stories are written from the perspective of one or more of these users.
A list of user profiles and a brief description of each user is provided in Table 1.
"Most of the user stories presented in this document are written from the perspective of the evaluation lead, as it was thought this profile is representative of the most likely user of the software."
"Because resources available to the DESSIN project do not allow for implementation of all of the user stories described in the document, it is also necessary to prioritize."
Must: Stories labeled as “must” are stories that must be included in the Final solution.
All stories labeled as “must” will be implemented in the final version of the software tool (D23.2).
Should: Stories labeled as “should” are stories that should be included if possible.
"These stories are not essential for fulfilling the purpose of the software; however, not including them may force users to undertake time-consuming work-arounds."
All stories labeled as “should” will be implemented in the software tool if resources are available after implementation of the stories labeled as “must”.
"These stories are not essential for fulfilling the purpose of the software, and work-arounds are relatively easy."
All stories labeled as “could” will be implemented in the software tool if resources are available after implementation of the stories labeled as “must” and “should”.
User stories are also given an estimate of the level of effort required to implement each story.
The purpose of the first epic is to prepare the evaluation by delineating general basic characteristics of the study area including: the geographical location and spatial extension; the intended audience and expected results of the assessment; and to gather economic and demographic information.
The software must provide the possibility of entering information on the geographical location and spatial extension of the study area.
The user is prompted to select from a list of Eurostat-defined geographical areas.
The user is able to download population and density data from Eurostat for the region selected in 1.3.
The user is only able to download data for the most recent year available (2014).
The user is able to download GVA data from Eurostat for the region selected in 1.3.
The user is able to download employment data from Eurostat for the region selected in 1.3.
Each text entry possibility should offer some links to information sources.
The links should be to datasets that cover all of Europe with appropriate local-scale detail.
The links are the same as the links defined in 1.3 and 1.4.
This can be an alternative solution if 1.3 and 1.4 cannot be implemented because of resource constraints.
Each text entry possibility should offer some guidance on what should be entered.
I would like a separate entry possibility for text describing each characteristic needed to provide an overview of the study area.
"Refer to Table 1, row 3 of Cookbook for complete list."
This section presents mock-ups of the visual appearance of the stories outlined in Epic 1.
Epic 2 represents the first step in the core evaluation and is the entry point towards describing the entire DPSIR cycle.
Here the relevant Drivers and Pressures are identified in order to understand the full picture of the system under study.
"This enables the user to decide which Pressures to focus the rest of the evaluation on, and provides initial insight on what appropriate measures could be."
"The purpose of this epic is to produce a qualitative overview of the Drivers present in the study area, relate these to resulting Pressures, and describe the latter."
"As a rule within the DESSIN assessments, Pressures should be described qualitatively."
"In specific cases where the proposed measures are expected/found to influence Pressures, then changes in those Pressures should be quantified."
The list of drivers in the DESSIN Cookbook (D11.2) is available to the user.
The user selects from the list and is prompted to enter a specification for each selected driver.
A specification is made by entering text in a text field.
The software should provide the possibility of entering additional driver types as text.
The user should then be prompted to enter a specification for each additional driver.
The user must provide a specification about each case-relevant driver.
The user is provided with examples from the mature sites.
The user receives a message to consider using information from Part I – Study description (e.g. economic activities found to be taking place in the study area).
A list of associated pressure categories is generated for each driver.
The user is presented with the list and is prompted to select those relevant in the study area and enter a specification for each selected pressure.
"For those additional drivers that were inserted by the user in 2.2, the software should present the full list of pressure categories for the user to associate the additional drivers to one or more resulting pressures."
The user is presented with Table 2 of the DESSIN Cookbook (D11.2).
The software should provide the possibility of entering additional pressure types as text.
The user should then be prompted to enter a specification for each additional pressure.
The user is prompted to associate the new pressure to the list of drivers.
The user must provide a specification for each case-relevant pressure.
The user is prompted to use information from Part I – Study description (e.g. economic activities found to be taking place in the study area).
The software should provide the possibility of navigating back to this screen from the response analysis screen in order to include additional quantitative information to the description of case-relevant pressures.
This section presents mock-ups of the visual appearance of the stories outlined in Epic 2.
"Epic 3 describe the Responses (i.e. the proposed measures) that can be implemented to address the problems in the study area, as identified in Part II."
It also aims to identify the case-relevant ESS (i.e. the ESS hypothetically affected by the proposed measure).
"Finally, ESS are linked to Beneficiaries, and this information is used to categorize the case-relevant ESS as Final ESS or Intermediate ESS."
I can provide an expected lifetime that is known to the system in a number format.
I can describe the capability qualitatively in a text field.
I can describe if the capabilities are theoretical or tested.
I can select drivers from the list identified in part II.
I can select pressures from the list identified in part II.
I can select state parameters from the list on worksheet “State indicators” in the supplementary material file for each measure.
The list is grouped using the same system that is used in the supplementary material file.
I am able to read a definition of each state parameter.
I am able to enter the name of an additional state parameter.
I am required to provide a description of the parameter.
A list of case-relevant ESS is generated based on my selection in 3.5.
The list is generated by the links provided in the State-Impact I Provision table in the supplementary material.
The list consists of ESS classes in the CICES system.
"For each additional state parameter identified in 3.6, the user is provided with the full CICES list and prompted to select ESS classes affected by the additional state parameter."
The software should provide text entry possibility to allow for a description of each case-relevant ESS that is more detailed than the CICES ESS class titles.
"For each case-relevant ESS, I select beneficiary types that benefit from that ESS."
I select from the list given in column C of the worksheet DESSIN Beneficiaries-Final ESS in the supplementary material.
"The list also includes the information provided in columns D, E and F in order to assist me with the selection."
The software must allow the user to compare each entry in the stakeholder list created in Part I to each beneficiary type from the ones selected in 3.8 (i.e. the ones associated to each case-relevant ESS).
The user must then assign a beneficiary type to each stakeholder in the study area.
"The choice can include “none”, as some stakeholders might not fall within any of the categories listed in the subset of beneficiary types."
Each case-relevant ESS that has a beneficiary type that could be associated with a stakeholder is classified as Final.
I am presented with a list of case-relevant ESS classified as Final and Intermediate and select the ones that will be analysed further in Part IV.
This section presents mock-ups of the visual appearance of the stories outlined in Epic 3.
"The purpose of Epic 4 is to assess the effect of the proposed measure (Response) on the system under examination by quantifying the state of the ecosystem, Impact I (ESS provision) and Impact II (ESS use)."
"State, Impact I and Impact II have to be estimated for two scenarios: a baseline scenario (before) and one where the proposed measure is already implemented (after)."
Finally the scenarios are compared and the change in the elements of the DPSIR is evaluated.
The software must retrieve the parameters of State previously found to be affected by the proposed measure.
These must be presented in relation to the case-relevant ESS for clarity.
The user is presented with a list of examples including those in column D of worksheet “State indicators” and columns C and D of worksheet “Impact I Provision indicators” in the supplementary material file.
The user is prompted to assign State indicators to each of the case-relevant parameters of State based on the examples presented or the creation of custom indicators.
The user is prompted to create custom indicators using text entry.
The user is presented with information on the existing State indicator scripts from the indicator script library in MIKE WORKBENCH.
The user can select existing State indicators from the library and use them in his model.
The user has access to the scripting capabilities of MIKE WORKBENCH.
The user can load existing scripts or script new state indicators to be used in the analysis.
The user is presented with a list of examples including those in columns C and D of worksheet “Impact I Provision indicators” in the supplementary material file.
The user is presented with information on the existing Impact I indicator scripts from the indicator scripts library in MIKE WORKBENCH.
The user can select existing Impact I indicator scripts from the library and use them in the analysis.
The user can load existing scripts or script new Impact I indicators to be used in the analysis.
"The user is presented with the list of case-relevant Final ESS to be further analysed (stories 3.9 and 3.10), showed according to CICES section, class and class type."
"As guidance, for each listed ESS class type, the user is presented with examples from column G (Examples of Impact II (ESS Use) Indicator(s)) of the Impact II Use indicators worksheet in the Supplementary Material File."
"In level I, the user is presented with a list of valuation method examples including those in column H (Valuation Method(s)); and references from column I (Data/Literature) of the Impact II Use indicators worksheet in the Supplementary Material File."
"In level II, the user is presented with extended information for any given study of his/her choice from column I (Data/Literature) of the Impact II Use indicators worksheet in the Supplementary Material File."
The extended information about each specific study can be found in the Impact II Monetization worksheet in the Supplementary Material File.
This is the studies table (all columns) and abstracts table per study.
A table similar to Table 11 in the DESSIN Cookbook (D11.2) is generated with the first two columns populated with the Final ESS and Beneficiaries identified in previous steps.
"The user has the capability to load the models, datasets, etc."
The user should have the capability to access and adapt existing datasets and tools from the MIKE WORKBENCH libraries.
The user must be able to run simulations and compute the previously selected indicators using the loaded data.
The user must be able to define the time range for which the indicators are quantified.
The user interface should be targeted at the Evaluation Lead or SME (i.e. non- expert users).
The user must be able to compare between the results of the baseline and after implementation scenarios with ease.
I can export results to Excel so that I can make custom plots and other reporting tools.
This section presents mock-ups of the visual appearance of the stories outlined in Epic 4.
The purpose of this chapter is to supplement the ESS evaluation by advising how to conduct an additional sustainability assessment (SA) of innovative solutions aimed at mitigating water scarcity or water quality issues.
"The SA allows the user of the DESSIN ESS Evaluation Framework to widen the analysis, putting the evaluated changes in ESS into perspective by considering multiple dimensions."
"These multiple dimensions include wider social, environmental, financial, governmental, and asset performance aspects of the examined solution."
This allows for the consideration of potential disadvantages like costs and environmental effects (e.g. additional greenhouse gas emissions) and their comparison with the advantages in terms of benefits expected from implementing the solution.
I am able to make use of the data inserted in part I (e. g. system boundary and information about economic activities).
The SA uses the same Eurostat region definition that was selected in Epic 1.
I am able to specify the number of technologies that will be compared.
I am able to specify whether the system is a water supply or wastewater system.
I am able to specify a lifetime for each technology under consideration.
I am able to specify a start-up time for each technology under consideration.
I am able to define a common start time for the analysis.
I am able to define one or more times in the future when I would like to take a snapshot of the performance of each technologies under consideration.
All times are time periods are defined in units of years.
"The indicator list should contain all indicators from the sustainability indicator list grouped by dimension, objectives and criteria."
I am presented with an indicator list that is filtered based on whether I am analysing one technology or comparing more than one.
I am presented with an indicator list that is filtered based on the water system type.
Each indicator is populated with a set of properties.
I am able to indicate data availability for each indicator by choosing between “yes” or “no”.
All indicators rated “yes” will be assessed quantitatively.
All indicators rated “no” will be assessed qualitatively.
An overview of my current sustainability indicator list and all specifications made up to this point is available.
I can add a regulatory threshold value where one exists.
I can populate all necessary properties for each indicator.
"I am able to assign new indicators to a certain dimension, objective and criteria."
Two or more fields should be presented for each indicator: one for inserting a “before” value and one or more for the “after” values.
"The number of ""after"" values should be the same as the number of snapshots of the future defined in 5.3."
The “after” values are labelled using the snapshot times defined in 5.3.
I can add a reference to each value inserted in a text field.
I can compute indicator values from indicator scripts.
The indicator scripts can accept time series input.
I am able to extract data from a model that I connected to MIKE Workbench.
I am able to select and take over single result values from parts III and IV.
I am able to calculate indicators based on data and time series inserted in parts III and IV.
Data that is taken from the ESS Evaluation part should be marked in the table with an automatic reference provided.
"I can calculate GHG emission in three different ways: (1) those emitted directly from fossil fuel consumption during the solution use such as water pumping to the atmosphere; (2) those emitted indirectly from electricity consumption in the solution such as water pumping, water treatment to the atmosphere; (3) those emitted indirectly from material flux (resulted from embodied energy of materials) and chemicals used for treatment processes."
"I am asked to insert the total fossil fuel consumption, the electricity consumption and the material and chemical fluxes for each solution."
"I can select from a database the conversion coefficient as kg of CO2 equivalent per consumption unit and is specific for different energy types, chemicals and materials."
"OR I am asked to specify the conversion coefficient, to be applied, as kg of CO2 equivalent per consumption unit and is specific for different energy types, chemicals and materials."
"All the aforementioned GHG emissions are calculated by multiplying the amount of energy, chemical and material consumed by a conversion coefficient for that specific energy, chemical and material."
Results of the life cycle assessment are directly allocated to the respective indicator of En213.
I can select indicators from those calculated in the financial dimension.
"I can define specific interest rates, a discounting rate and the time horizon of the analysis."
"I can introduce the values for ""r"", the discount rate, such as the rate of inflation, and for ""t"", the number of compounding periods, such as years into the future."
"If the number is higher than 0, then cost coverage is guaranteed."
I can describe each indicator qualitatively in a text field.
It is possible to add a score value to each indicator referring to a scale from 1 to 5 (strong negative impact – some negative impact – neutral – some positive impact – strong positive impact).
I can compare the performance per indicator of each solution for the baseline scenario and the after implementation scenario (to the regulatory threshold) in a bar chart.
The after implementation scenario can be represented by one or more of the periods for snapshot analysis selected in 5.3.
It is possible to view results at two or more points in the future.
I can compare the performance level of each solution for several indicators for the baseline scenario and the after implementation scenarios by comparing the indicator values from different points in each time series.
The indicators should be normalized to a regulatory threshold.
I can choose which indicators should be presented in the graph(s).
"I can select dimensions for each scenario (before and after), and then select relevant indicators for each dimension."
All indicator values are normalized automatically after the user defines if the highest or the lowest value is the best for each.
"I can add a weighting on the indicator level, the criteria level or the dimension level."
I do not only aim at ranking those indicators derived directly from the SAT but also anything else that is incorporated into the host environment.
For each scenario the calculated values of each k-th indicator (fk(x)) are available.
"I can select the indicators, from those calculated in monetary terms to estimate the cost part of the analysis."
"I can select the indicators, from those calculated to be used to estimate the benefits side of the analysis and convert them in monetary terms."
I can calculate the discounted value of each cost and benefit using the following net present value formula: NPV = value / (1 + r)^t.
I am able to add each present value of cost and benefit.
I can divide the present value of benefits by the present value of costs.
"If the number is less than 1.0, then the cost- benefit analysis is negative."
"If it's greater than 1.0, then there's a positive return."
This section presents mock-ups of the visual appearance of the stories outlined in Epic 5.
The software specifications document presented here represents the consensus of partners involved in DESSIN Work Package 23: Software Framework for ESS valuation.
Partners include parties involved in the development of the DESSIN ESS evaluation framework (WA1) as well as partners who will apply the software tool as part of the implementation of the Demo cases (WA3).
"Because the software requirements have been developed in close consultation with the developers of the ESS evaluation framework as well as the end user group, it is anticipated that the resulting software tool will be useful to the Demo site partners when they apply the DESSIN evaluation framework at their sites."
"Furthermore, the specifications team have been mindful of how the tool will be used after the conclusion DESSIN, and have attempted to create a tool that will be broadly accessible to researchers and practitioners in Europe."
This document relates to the Phase 1 SKA Signal Transport and Networks Domain Element and its Sub‐elements.
It is of a maturity commensurate with a Concept level of definition of the STaN Domain and the SKA Observatory as a whole.
"It also forms the working basis of the Domain Requirements Document to be prepared for the future System Requirements Review, and its Table of Contents is intended to be subject to the present Review."
"The purpose of this document is to provide a summary of all flowed, derived, allocated and introduced Requirements pertaining to the full life cycle of the Domain."
The following documents are applicable to the extent stated herein.
"In the event of conflict between the contents of the applicable documents and this document, the applicable documents shall take precedence."
The following documents are referenced in this document.
"In the event of conflict between the contents of the referenced documents and this document, this document shall take precedence."
The interconnecting lines define the association between the blocks in the diagram.
Quality: A quality requirement is to change the way something is done.
Constraint: Constraints are restrictions or limitations on possible solutions.
Each of these requirements is to satisfy a goal owned by a particular stakeholder that plays a role in a scenario of the system.
Scenarios are associated with the modes and configurations of the system and define the dynamic behaviour.
This document includes Use Cases to provide a path to discovering associated requirements.
As detailed in Figure 2 a requirement comprises of more information the just the requirement description.
This information in effect forms attributes for the requirement.
The Requirement ID provides a unique identifier for each individual requirement.
The sting provides a unique descriptor identifying the item within the systems hierarchy that the xxxx is a four digit decimal number uniquely identifying the requirement within the requirement set.
The requirement should be a single active sentence as short as possible.
"The requirement should focus on naming a single desired result Requirements should avoid conjunctions such as: “and”, “or”, “with” and “also” as these tend to wrap multiple requirements into one which is not desirable."
Requirements should not specify the design envelope.
"As stated in the requirement description, all requirements are to be verifiable."
The method of verification is to be attached as an attribute to the requirement.
The priority of the requirement is to be attached as an attribute to the requirement.
Requirements are not static statements but have a life‐cycle.
The originator of the requirement should be attached as an attribute.
The date that the requirement was created should be attached as an attribute.
Making assumptions explicit and connecting them to an argued rationale enables decisions to be re‐ visited without starting all over again.
An understanding of rationale enables accurate prioritisation and is an aid to preventing essential requirements from being deleted.
The requirements for STaN form part of the overall system hierarchy as illustrated in Figure 3.
Each tier in the hierarchy has its own set of requirements which are derived from the next hierarchical tier above.
There is also a feedback path via the architectural design process to inform the requirements at the higher tier whether there are any issues.
The flow‐down and feedback is an on‐going process iterating towards a stable and eventually base‐lined requirement set.
The initial requirements for the concept phase of STaN Sub‐Element level is the scope of this document.
It identifies the subset of concept phase system requirements that are applicable to STaN and presents additional requirements where there are gaps.
This process forms part of an iterative feedback path to the system level.
In the next phase these requirements will be refined so that they can be utilised by each of the STaN Sub‐Elements.
The aim of the next phase in the project is the definition of the requirements.
"The quality, design, development and other requirements will be developed in the next phase and the constraints identified."
These will be presented at the STaN System Requirements Review.
In this phase requirements analysis and validation are undertaken in order to ensure that the complete set of requirements is understood and is present.
Gaps will be identified and actions to address these shortcomings will be initiated.
The result of these activities will be captured in the relevant Requirement Specifications to be reviewed at the conclusion of this phase.
Architectural design activities will also be initiated with the aim of producing a first draft design document at the end of the phase.
Interfaces will be refined and finalised as far as possible (especially functional interfaces).
This phase will be concluded by the (Sub) System Requirements Review (SRR).
It shows how the STaN Sub‐Elements fit within the STaN domain.
This section provides an Applicability Matrix showing the Applicability of AD[1] Requirements to the STaN Domain and whether the requirement has been analysed in the scope of the STaN CoDR.
SKA1 shall be able to measure electromagnetic radiation in a frequency range from 70 MHz to 3 GHz.
The SKA Phase 1 shall be designed so that the fractional instantaneous bandwidth is comparable to the observing frequency.
It shall be possible to position this band anywhere within frequency band is a contiguous (TBC) band selected from the total frequency range.
The resolution with which the 500 MHz and 1 GHz bands can be selected shall be TBD or less.
It shall not be possible to select different digitized bands for the two polarizations of a single dish/antenna/array.
The subband bandwidth after station level beamforming shall be less than TBD Hz.
"The digital processing capacity shall be sufficient to process all sub‐bands (Q: and beams, and polarizations, or should there be exchangeability)."
The phase relations between the sub‐bands and channels within a beam shall be known to such a precision that wider bands and corresponding time series can be reconstructed from sub‐bands and/or channels.
"The SKA Phase 1 shall be designed so that the bandpass does not show ripples or systematic fluctuations, on scales smaller than a frequency corresponding to about 300 km s1, that are larger than twice the thermal noise level after an integration of 1000 hr."
SKA1 shall offer a spectral resolution in each polarization for Spectral resolution.
SKA1 shall offer a spectral resolution in each polarization for science processing of: 100kHz in the band 70 to 240 MHz; ‘This requirement follows directly from the radial resolution science requirement.
"For reference, assuming the concordance cosmology, at these redshifts, the co‐moving length is given by ≈ 1.7 Mpc (ν/100 kHz)."
"Therefore, to match the angular resolution a frequency resolution of Spectral resolution."
"SKA1 shall offer a spectral resolution in each polarization for science processing of: 1 kHz in the band 70 to 240 MHz; ‘In practice a more stringent requirement of 1 kHz in frequency resolution is required to identify and excise RFI, reduce bandwidth smearing, and calibrate ionospheric effects.’ Sub‐band and channel phase relations."
The signal processing performed on each sub‐band shall leave the relative phases of subbands and spectral channels intact or predictable.
SKA1 shall have a spectral dynamic range of: ≥61 dB in the Spectral dynamic range.
SKA1 shall have a spectral dynamic range of: ≥43 dB in the Sensitivity (Aeff/Tsys).
The SKA1 shall have a sensitivity of: 103 m2 K‐1 in the Sensitivity (Aeff/Tsys).
The SKA1 shall have a sensitivity of: 105 m2 K‐1 in the Survey speed.
The SKA1 survey speed requirement is: ~107 m4 K‐2 deg2 for the Survey speed.
The SKA Phase 1 shall be designed so that a major survey can be completed in 2 years of “on‐sky” observation time.
The SKA Phase 1 shall be designed so that a deep field can be completed in 1000 hr of integration time.
The magnitude and phase variations of any SKA1 compound beam over a 12 hours period at any point of its half‐power contour shall be less than 1% (TBC) relative to the beam peak.
The SKA Phase 1 shall have an attainable time resolution of at least as short as 50 μs.
Changing the beam former weights shall be possible every 60 seconds (TBC) in the case of scheduled switching sequences.
Changing the beam former weights shall be possible within 60 seconds in case of changes due to manual interaction or changes in schedule.
Observation data (specify: both uv(w)‐data and tied array beams) acquired during a change of beam direction shall be flagged.
The SKA shall be able to provide ‘near simultaneous access to Beam polarization stability.
External calibration measurements shall be necessary at a rate of no more than once per hour (TBC).
SKA1 shall provide visibility data in all four Stokes parameters.
"The polarisation introduced by the calibration, shall be less than 0.5% of the total intensity."
"The SKA1 shall have limited (TBD) susceptibility to bursty/spiky RFI (for pulsars, Transient RFI detection."
The post station level processing shall detect and flag invalid data.
It shall be possible to image the entire field of view Imaging dynamic range.
SKA1 shall be able to provide an imaging dynamic range for continuum imaging (thermal noise imaging to classical (micro Jansky (Jy)) confusion ‘studies of star formation at high redshift with a continuum deep field Dish beam absolute pointing accuracy.
The pointing accuracy of the dish beams is: AA beam absolute pointing accuracy.
The pointing accuracy of the AA beams is: TBD Dish beam pointing estimation accuracy.
The pointing estimation accuracy of the dish AA beam pointing estimation accuracy.
SKA1 shall provide a monitoring and control function.
"The monitoring and control function shall ensure that all parts of the maintenance functions, are part of the M&C system."
"The monitoring and control function shall ensure that failures in hardware, software or signal transport are detected and reported."
The monitoring and control function shall take autonomous action to ameliorate failures where possible and support a fail‐safe philosophy.
"M&C shall take autonomous action in safety critical situations such as system power failure, over‐temperature, and storms (dish‐stowing)."
The monitoring and control function shall give user transparent parameters.
The monitoring and control function shall be designed to operate the instrument fully remotely.
The monitoring and control function shall provide TBD performance monitoring data to users.
The monitoring and control function shall provide for a long‐term logging sub‐function with workflow support for the Operational Team and with sufficient information to relate system events to artefacts in the data.
It shall be possible to abort an observation if monitor parameters exceed user specified limits (including RFI mitigation performance indication parameters).
Individual element calibration information shall be available to the measurement function.
SKA1 shall have a control system that actively controls all system settings in the instrument.
"The control system shall be capable of autonomously calculating system settings in response to changes in instrument status, environment or measurement results."
It shall be possible to activate the calculated system settings either automatically (autonomous control) or after explicit confirmation by the operator (manual control).
It shall be possible to specify when settings should be activated automatically and when they need to be confirmed by the operator.
It shall be possible to receive and accept updated schedules before the end‐time of the currently active schedule has expired.
It shall be possible to consolidate monitoring information to produce high‐level monitoring information from low‐level monitoring information.
Subsystems shall report completion of actions to M&C S&C summary reports.
It shall be possible for all user roles (specification of these roles TBD) to produce summarized historical monitoring information.
The results of control actions shall be verified with measurements made expressly for the purpose.
"If the normal measurement sequence does not provide for control verification in a timely fashion, such measurements shall be made out of sequence."
"It shall be possible to consolidate monitoring designated logical concepts like observation, correlator."
SKA1 shall provide a synthesis imaging mode where compound beams are correlated to form visibilities.
"In synthesis imaging mode it shall be possible to form visibilities between all corresponding monochromatic compound beams (same frequency, same direction) from all dishes or all aperture arrays (stations)."
This means that the central processing function should be able to handle the full data stream from the dishes or aperture arrays in synthesis imaging mode.
"SKA1 shall provide a tied array mode where the signals from all dishes are phased up, after real‐time correction of instrumental effects, and transformed back into time series for pulsar processing."
In this mode the Autocorrelations of all single dishes / aperture (sub)arrays are recorded.
Each dish / sub‐array is tracking a different position on the sky.
SKA1 shall provide an aggregate mode in which bandwidth is exchanged for spatial coverage in the correlator.
SKA1 shall provide instrumental real‐time calibration functions in all observational modes.
It shall be possible to re‐process data retrieved from archive.
To which extent this will be supported needs further discussion.
SKA1 shall be able to produce final data products based on automated and interactive (manual) processing of acquired data.
"SKA1 shall produce recordable intermediate data products, for example pulsar voltage time series and RFI statistics."
SKA1 shall be aimed to be operated continuously (7 days per week 24 hours per day).
It shall be possible for the operator to control and monitor the SKA1 instrument from the SKA station sites and core site.
The system shall provide security to prevent unauthorized physical access to facilities and resources.
Reconfiguration of SKA1 from one observational mode to another shall not take longer than 5 minutes (TBC) provided all software applications are present at their designated location.
"It shall be possible to control all SKA1 functions from the operational centre, without requiring physical access to the instrument, including start‐up and shut down."
The start‐up of SKA1 functions shall follow a pre‐defined sequence taking not longer than: 10 minutes for a hot start (= restart) Start‐up sequence.
The start‐up of SKA1 functions shall follow a pre‐defined sequence taking not longer than: 24 hours for a cold start Start‐up and shut‐down individual antenna systems.
It shall be possible to start‐up or shutdown individual dishes or aperture arrays without disturbance [TBC] of routine operations.
The shutdown of SKA1 shall follow a pre‐defined sequence taking not longer than TBD minutes.
"SKA1 shall also have an emergency shut‐down for wind (stowing dishes), lightning, and electric power anomalies."
Initialization of shut‐down and start‐up sequences shall be restricted to designated operators and engineers.
To be defined: security requirements on different access levels (e.g. engineering mode).
Any dependencies in the start‐up and shutdown sequences shall be automatically verified (so they do not depend on operator intervention).
The shutdown of pre‐defined parts of the SKA1 system shall have no (TBC) impact on SKA1 operations after appropriate re‐calibration performed automatically.
"SKA1 shall be designed to enable an operational readiness check, including redundancies, prior to commencement of any SKA1 operations (initial check‐out)."
The operational readiness check shall not take longer to complete than 5 minutes.
"As far as possible, no single failure in the SKA1 shall lead to personnel safety hazards."
Failures in one of the SKA1 subsystems shall not lead to failures in other subsystems.
"No single operator command shall cause catastrophic, serious, or major consequences."
"No voltage‐transients or ""cutoff"" of lectrical power shall lead to catastrophic or serious consequences."
This includes voltage transients applied to the input of the receivers.
The absence of operator commands shall not cause catastrophic or serious consequences.
Single‐pointfailures in the design shall be listed.
"Each‐single‐point failure in the design shall be justified, and assessed against alternative design(s) where this single‐pointfailure would not occur."
The correct functioning of each single‐point‐failure in the design shall be monitored by a watchdog function.
"Failing equipment shall indicate the problem if power is on, and the control function shall take appropriate measures."
The status report of the functioning of a subsystem shall be available in 5 seconds.
The status report of a subsystem shall reflect the functioning of the subsystem at or after the operator request has been submitted to the system.
"The status report shall display the status of a function, together with the system time the status was determined."
"Each dish or aperture array system shall have the capability to answer to an operator interrogation, in case of detected failures at the dish, which antenna chain has failed."
"The system shall have the capability to be operated by an operator in an autonomous mode, and in a manual control mode."
"In the autonomous mode, all malfunctioning equipment and/or stations may be switched off autonomously, and a message with all details of this action shall be brought to the attention of the operator, and recorded in the systems log‐file."
"In the manual control mode, the operator shall have the capability to switch on or off all equipment and/or stations."
"Operator actions shall be recorded in the systems log‐file, in such a way that a complete picture of all correct functioning and/or all malfunctioning equipment, together with their operational and/or switch off statuses, can be achieved."
It shall be possible to take recovery actions without consequences for other parts of SKA1; the system shall minimize impact of recovery actions.
SKA1 shall be able to recover autonomously in case of failures that are classified as minor or negligible.
The SKA1 design shall ensure that disabled units do not corrupt the remaining system.
SKA1 shall be designed for a continuous operational period of 6 month.
"After this time maintenance may be necessary, g. exchange/cleaning of airconditioning filters and refurbishment of cryogenic systems."
"SKA1 shall be designed for a minimum life time of TBD years, including initial installation, testing and commissioning period."
The average availability of SKA1 during the operational period shall be better than 90% (TBC).
Availability is defined here as being available for scheduled observations in at least one of the supported operational modes.
Large scale maintenance and/or an upgrade shall give the possibility to reach a life time of 50 years (TBC).. Full fail rate.
"SKA1 shall be designed to fully fail less than two times per year (TBC), the number determined as average over its operational period."
"The maximum period of repair once a failure of SKA1 has been established, shall be 1 (TBC) week."
"Here, a failure is defined as not being able to meet the scientific specifications due to (sub)system failure(s)."
All users with scheduled measurements during the failure period shall be informed of the non‐availability of the system Data loss due to power outage.
All subsystems shall not lose more than 4 hours of acquired or processed measurement data (not yet permanently stored) as a result of an outage in the external power supply.
"All subsystems shall have the capability to restart autonomously and without failures, after an outage in external power supply."
All subsystems shall be available within 5 minutes (TBC) after restart.
"It shall be possible to replace all software/firmware configuration items in SKA1 through softwareupgrades, initiated by an engineer."
Software configuration items shall provide unambiguous inputs to allow the maintenance of a configuration management database.
The software identification shall be available to the operator within 10 seconds (TBC) after the request was made.
All subsystems shall include functions that allow maintenance of hardware and software.
The SKA design shall be fully compliant to all environmental rules applicable to the SKA site.
SKA shall be designed to have no lasting adverse environmental effects on the facility and site.
SKA shall be designed or protected against any deterioration leading to failure to meet the requirements specified herein caused by climatic and environmental conditions during its complete lifetime (both operating and non-operating).
The design of SKA shall be appropriate (TBD) for operation in the natural environment for the geographical deployment location of the SKA.
Buildings or parts of buildings containing central processing equipment and operator areas shall have a climatic conditioning system which can control the temperature within the range of 18 ºC to 23 ºC and the humidity within the range of 50 % to 70 % independent of weather conditions.
SKA equipment and operating facilities shall be adequately protected against intrusion by unauthorized persons or by “larger” wandering animals.
SKA equipment shall be able to operate without degradation of the performance during any type of precipitation (to be specified).
"SKA equipment shall be adequately protected against performance degradation caused by contaminating particles (dust, sand etc), polluted air or any precipitation."
SKA equipment located at the dishes or aperture arrays or outside the central processing and operating facilities shall be able to withstand moisture and humidity levels up to 100 % RH.
SKA equipment located at the dishes or aperture arrays or outside the central processing and operating facilities shall be able to withstand (non-operating if necessary) an outside air temperature within the range of - Air temperature operation range.
SKA equipment located at the dishes or aperture arrays or outside the central processing and operating facilities shall be able to operate within specification if the outside air temperature is within the range of -5 ºC (TBC) to +50 ºC (TBC).
"SKA equipment shall be able to survive wind velocities up to 160 km/hr (TBV), and shall operate within normal specification ranges for wind velocities up to 40 km/hr (TBC)."
SKA shall not be damaged by RFI signals less than TBD V/m.
"SKA shall not be susceptible to RFI signals, in-band or out-band, other than via the receptors."
The dynamic range of the ADC’s in the SKA shall be such that no clipping will occur.
Clipping occurs when the range of the input signal voltages to the ADC is larger than the ADC voltage range.
The number of ADC bits shall therefore be sufficient to prevent clipping due to strong interfering signals such as airplane DME and satellite signals.
"The EMC safety margin, which is defined as the ratio between susceptibility threshold and the interference at any point within the system, shall be greater than TBD dB."
"All ""off-the-shelf"" equipment applied within SKA shall posses as a minimum the host country EMC marking, including electrical and electronic supporting and infrastructural equipment."
A hybrid grounding concept as shown in figures TBD shall be used for EMC purposes.
"Ground loops involving DC, and low frequency AC, currents shall be avoided inside the system."
Intentional currents through structure are not EMC design efforts.
Maximum effort (to be detailed) shall be put into designing signal interfaces to withstand noisy environments and to minimize the generation of excessive noise.
Interference due to selfgenerated RFI shall not degrade the performance of the instrument by greater than 1% by any measure (TBC).
SKA dedicated buildings and equipment located on sites shall be protected to minimize the effects of a direct lightning strike using certified methods (e.g. as described in NEN 1014).
Observation data taken during a lightning strike shall be flagged.
Electrical safety ground shall be designed according to the regulations imposed by the local government.
SKA equipment and buildings shall be protected against corrosion.
SKA electronics and connectors in areas with a higher air flow (for cooling) or outdoor environment shall be additionally protected against corrosion.
SKA equipment and buildings shall be protected against earthquakes with a magnitude up to 3.8 (TBV) on the scale of Richter.
The SKA1 shall be installed at the SKA core site and at the SKA station sites.
The SKA1 front‐end and cabling shall fit in the available feedboxes.
"The total mass of any feed payload, including the RF cables to the ground, shall not exceed: TBD."
"Each subsystem supplier shall establish, collect, review and deliver the Materials, Parts and Processes lists including all the Materials, Parts and Processes intended for use in the SKA1 equipment by his suppliers and himself."
"Materials, Parts and Processes lists shall reflect the current design at the time of issue."
"The estimated availability of the Parts and products obtained from Materials and Processes used shall be compatible with the final system’s life cycle (tests, storage, mission)."
All materials used in the SKA1 design shall be fully compliant to all environmental rules applicable to the SKA1 core and remote sites.. Long‐term environmental effects.
Materials used in the SKA1 design shall not have any lasting effect on the site location.
Materials used for the parts subject to the outdoors environment shall be maintenance free.
Method of marking shall be compatible with the nature of the item and its use.
"Identification numbers shall be marked on documentation and, where possible, on respective items."
The SKA1 shall connect to the available power distribution at the SKA core and remote sites.
"The power consumption of all equipment at any AA or dish station, including the motors driving the dishes, shall be less than TBD kVA."
The total power consumption of the SKA1 observatory shall be less than TBD kVA.
SKA1 equipment and electronics shall be developed and produced according to the ISO9001 (TBC) quality standard.
The field return rate of equipment shall be less than 0.5% (TBC) during installation and the first year full usage.
General workmanship standards shall be applied as specified in the Product Assurance Plan (TBD) both for Software and Hardware production.
SKA1 dedicated workmanship standards shall be Scope of workmanship standards.
"SKA1 dedicated workmanship standards shall and shall cover all phases of production, assembly and integration, testing, handling, and include clear requirements for acceptance/rejection criteria."
"The SKA1 design shall possess design margins to cover all uncertainties in environment, analysis and properties of the materials and processes used."
It shall be possible to specify on a per user basis which SKA1 facilities and resources (both hardware and software) may be accessed by the user.
The reliability of SKA1 equipment to meet its performance requirements over a period of 10 years shall be greater than 99.4 % (TBC).
"The SKA1 design shall require a minimum of special tools and test equipment to perform assembly, integration and repair and maintenance activities."
Inaccessible hardware or structures shall require no maintenance during operation and should have built in test capability when applicable.
Test and repair instructions shall be written for fault detection and maintenance of the SKA1 equipment.
It should be possible to execute regular maintenance jobs with not more than two (2) people per job.
The SKA1 design (hardware and software) shall have a modular approach.
The SKA1 design (hardware and software) shall provide flexibility and expandability to support anticipated areas of growth or changes in technology or mission.
The SKA1 design for both hardware and software shall provide self‐test capabilities.
All servicing and test points shall be clearly marked using TBD labelling standards.
"SKA1 parts, test equipment or supporting equipment with transportation."
It shall be possible to disassemble SKA1 equipment for the reason of transportation or storage in its main parts.
It shall be possible to store SKA1 equipment (spare parts) for 10 years without any degradation of its function or performance If special storage facilities are needed they shall be supplied as part of the spares procurement.
Reusability of SKA1 equipment shall be ensured through design and by refurbishment and maintenance where this has been demonstrated as being cost effective.
SKA1 spare parts shall have a storage life consistent with availability and use during the full operational lifetime of the SKA1 equipment to which it applies.
SKA1 support equipment shall be designed to maintain SKA1 for 12 (TBC) years.
The power supplied to the SKA systems shall have the following Central facility UPS.
The power source to the central facility shall have back-up provisions for controlled shut-down (TBV).
Each SKA AA or dish system shall maintain an internal time standard with an accuracy of TBD nanosec.
All SKA subsystems shall synchronize their internal time standards to the central timing standard with an accuracy of TBD nanosec Limiting excessive currents.
"SKA equipment circuitry shall be protected against excessive currents by a current limiting device, which shall not itself produce excessive currents."
SKA sub-systems shall be protected against power transients and surges.
SKA equipment circuitry shall be protected against the effects of inadvertent wrong polarity connections.
All dishes and aperture arrays shall time-tag received and processed data with the accuracy of their internal time standard.
SKA subsystems shall specify what special test resources they require in the operational phase.
Preventive maintenance of SKA1 hardware shall be performed in accordance with the maintenance program established for SKA.
"SKA1 Dishes shall be designed, built and verified such that they can accommodate Phased Array Feeds."
"SKA1 Dishes shall be designed, built and verified such that they can meet AD1 optical requirements up to 10GHz."
"SKA1 feeds, receivers and digital processing subsystems shall be designed to provide the AD1 polarization purity requirement of 40dB."
SKA1 elements shall be designed to provide an imaging Spectral dynamic range.
SKA1 elements shall be designed to provide a spectral dynamic range of 67 dB.
The requirements traceability matrix in figure 1. shows the STaN functional requirements as a subset of the system level requirements described in AD[1].
"The layout of receptors is defined by the configuration, which can be found in the SKA configurations design [3]."
"The parent in the SRS is TBD, so it is not clear where it comes from and what it refers to."
These are new system level requirements identified as important.
Are there any other transient requirement timings that need to be included at system level?
Upon switching do the receivers need to return to the same phase?
This requirement does not appear in the SPF Receiver requirements – should it?
Does this imply it should be possible to image the entire field of view at the same time or can this be achieved in increments?
"They are broadly classified as External, namely those interfaces to entities outside the STaN Element, and Internal, between Sub‐elements of STaN."
"Some of the External interface requirements, such as those stemming from interfaces to the environment, operations, monitoring and control functions (as opposed to fulfilling network functions for M&C), sustaining engineering and human actors, are found in their dedicated sections."
"This section, as of STaN CoDR, is highly preliminary as this stage is in advance of formal Architecture development."
"It is expected that, in addition to an analysis of the Architecture and negotiations between the System Engineering disciplines of the Elements and Sub‐elements, AD[13] will provide Requirements in this section."
"These requirements are intended to be general, but where specific, reference will be made to Interface Control Documents (ICDs)."
"ICDs undergo a great deal of change until late in the development and therefore are the proper repository of such low level, changeable data."
These data should not be expressed as requirements for this reason.
"It is expected that these requirements will be sourced primarily from ADs [5], [6] & [8]."
"It is expected that these requirements will be sourced primarily from AD[1] (Extensibility),[7] [8], [9] & [10]."
It is expected that these requirements will be sourced primarily from ADs [4] [7] [8] & [10].
"These requirements will be sourced primarily from ADs [5], [6], [8], [12] & [13]."
These requirements will be sourced primarily from AD [12].
This document may only be released according to the Destination Control Statement on the front cover.
"This specification establishes the performance and design requirements for the Gateway as allocated from Human Exploration and Operations Directorate Requirements, HEOMD-004."
Requirements in section 3.2 define the performance of the Gateway as a whole.
Requirements in sections 3.3 through 3.6 are constraints with which the Gateway must comply.
"The performance requirements herein are applicable during nominal operations, maintenance, and contingency events."
This document is applicable to the assembly and assembly complete stage of the Gateway.
Proposed changes to this document shall be submitted via a Change Request (CR) to the Gateway Program Control Board (GPCB) for consideration and disposition.
"All such, requests will adhere to the Gateway Configuration Management Change Process documented in DSG-PLAN-004."
The appropriate National Aeronautics and Space Administration (NASA) Office of Primary Responsibility (OPR) identified for this document is the Gateway Vehicle Systems Integration (VSIO) Requirements Development Team.
"Rationales, included for many of the requirements, are intended to provide clarification, justification, purpose, and/or the source of a requirement."
"In the event that there is an inconsistency between a requirement and its rationale, the requirement always takes precedence."
"The Gateway Program will utilize NIST SP811, Guide for the Use of the International System of Units (SI) for standardization and conversion of the units of measure."
"For the purpose of this document, the term ‘document’ can also refer to ‘digital artifacts,’ ‘models,’ or ‘viewpoints’ as needed to convey and exchange configuration managed data or information."
"An objective of the Gateway Program is to evolve into a digital engineering environment and away from the traditional document-based approach for capturing data, reports and baselines."
"The following documents may include specifications, models, standards, guidelines, handbooks, and other special publications that are called out in sections 3.2 through 3.6."
The documents listed in this paragraph are applicable to the extent specified herein.
Type 1 documents or standards are those that contain requirements the Program must meet as written.
Type 2 documents or standards are those that contain requirements the Program can either choose to adopt or accept an alternate proposal.
Type 3 documents or standards are those that represent the ‘best practices’ observed by or normally used by NASA over the substantial development history of both human and non- human spaceflight missions.
The Program does not need to either formally adopt the documents or recommend an alternate.
This section identifies the Technical Authority (TA) Standards and Requirements and designations.
The NASA Program Manager and TAs are responsible for determining how these standards and requirements are applied depending on the specified type.
There are currently no Type 1 TA Standards and Requirements identified.
Type 2 documents are those that contain requirements the Program can either choose to adopt or accept an alternate proposal.
The Element or Module provider will be allowed to propose alternate requirements within documents that they consider to meet or exceed the intent of the Type 2 designation to the Program Manager.
Any ‘Applicable’ document listed in a Type 2 document is also considered to be Type 2 unless specified otherwise.
The Element or Module will assess equivalency of the requirements and risk to the Program and present the evidence to the NASA TAs and Program Manager for approval.
"The process for accepting alternates is defined in DSG-PLAN-007, Gateway Systems Engineering Management Plan, Section 5.5.8 Standards."
Type 3 documents are those that represent the ‘best practices’ observed by or normally used by NASA over the substantial development history of both human and non-human spaceflight missions.
The following documents contain supplemental information to guide the user in the application of this document.
These may be called out in section 3.2 rationale or other areas of the document.
"In the event of a conflict between the text of this specification and the references cited herein, the text of this specification takes precedence."
"Nothing in this specification, however, supersedes applicable laws and regulations unless a specific exemption has been obtained."
"The Gateway is a reusable and sustainable command center in Lunar orbit, providing a safe location for crew transition to a lunar landing vehicle after checkout."
The Gateway also provides a location for deep space human and systems testing as a stepping stone to Mars exploration.
"Phase 1 – Initial complement of modules needed to support BOTM 2024, Power Propulsion Element, Minimum Habitation Capability & Logistics Module."
"Phase 2 – Remaining elements of the architecture to support longer duration missions and greater utilization capability, International Habitat, US-Habitat, Airlock and Extravehicular Robotics."
"The Gateway is a lunar orbiting facility, which is supported with consumables, maintenance items, and experiments."
The Orion spacecraft will bring crews to the Gateway and return them to Earth once the mission is completed.
"The Gateway will employ radio-frequency (RF) links with Earth based networks for audio, video, data, and command communications."
The Gateway functional breakdown is described below.
"The PPE provides the capability to generate power for the Gateway, transport Gateway between cis-lunar orbits, perform orbital maintenance, provide attitude control for the Gateway in multiple configurations, provide communication (to and from Earth, space to space communication, space to lunar communication, and relay EVA communication to Earth), and also provides accommodations for external utilization."
"The MHC provides the capabilities for early habitable utilization of the Gateway, such as internal and external payload accommodations, external robotic interfaces, power and thermal control, oxygen/nitrogen supply and air circulation, and logistics storage for crew consumables."
"The EVR provides the capability to deploy and retrieve external utilization payloads, utilize the science airlock to retrieve/deploy payloads, deploy free-flying payloads, inspect the Gateway system, capture and berth/unberth of robotic spacecraft, berth and unberth modules to support assembly and reconfiguration if needed, support lunar and planetary missions by assembling spacecraft and transferring equipment, perform scheduled and contingency maintenance including by transferring ORUs to the interior via the science airlock, support self-maintenance of robotic components and support EVA crewmembers."
"The EVR nominally performs its tasks autonomously so that it can operate any time that it is required, without crew presence, without a guaranteed ground downlink and without real-time ground supervision."
The EVR will be delivered on a LM and be able to be activated and walk off onto Gateway by remote ground commanding and without EVA assistance.
"The External Robotics will have the capability to translate along the Gateway infrastructure, by walking to grapple fixtures placed externally along the Gateway modules."
The HABs are where the astronauts will live and work.
"With the intention of using the Gateway as a technology demonstration activity to enable future, more ambitious missions, the HABs provide life support for the crew to perform science/utilization, maintain and conduct crew health and performance/medical operations, as well as pressurized cargo and logistics stowage."
Habitation functionality will be distributed across the MHC and two HABs.
The Gateway will have two HAB modules: an International HAB (I-HAB) and a U.S. HAB (US-HAB).
I-HAB will be the habitation element provided by the International Partners.
Allocations of the habitability functions between the pressurized volumes will be adjusted as the architecture matures.
"The US-HAB will be the U.S.-provided habitation element that, together with the I-HAB, provides the primary habitability functions for the Gateway."
"The Airlock provides the capability to enable crewed EVAs, accommodate EVA suit/tool storage, accommodate pre-EVA checkout and preparations to includes pre-breathe protocols, accommodate post-EVA activities, as well as accommodate demonstration of future EVA technologies."
"The LM provides the capability to deliver pressurized and unpressurized cargo to the Gateway enabling extended crew mission durations, science utilization, exploration technology demonstrations, potential commercial utilization, system outfitting, and other necessary supplies."
LMs may or may not be permanent fixtures of the Gateway and will depend on individual module configurations.
"When provided as a commercial resupply service, LM's are expected to be fully independent spacecraft with their own propulsion, power, thermal control, GN&C, and communications systems during undocked mission phases."
"When docked at Gateway, LMs extend specific Gateway functions to support crew systems, integration with the Gateway command and control systems, communication, and habitation, but still retain some independence for power generation, thermal control, and spacecraft systems management."
"Potential visiting vehicles, other than LM, are being defined at this time but could conceivably include robotic and human lunar landers (HLLs) as well as crewed vehicles built by NASA and International Partners."
"The requirements contained within the NPR prescribe that a human- rated system accommodates human needs, effectively utilizes human capabilities, controls hazards with sufficient certainty to be considered safe for human operations, and provides, to the maximum extent practical, the capability to safely recover the crew from hazardous situations."
Formal Human Rating certification will be obtained for each integrated architecture/mission (including Gateway Modules and the docked crewed vehicle) prior to each crewed flight.
The Human Rating Certification Package (HRCP) is the documentation of compliance/evidence for the NPR outline human rating progress and compliance that will occur at various stages of maturation as the Gateway is assembled (content in the annexes will not be part of the endorsed/certified package; it is informational only).
"Lastly, the HRCP will include the NPR requirements trace and applicability matrix, by mission."
The status of the HRCP will be provided at key Gateway milestones with its content and format evolving along the way.
Deliverable expectations (for the HRCP as well as those products owed to the HRCP by Programs and Elements) will be provided along with progress of each deliverable.
The actual HRCP document will not be complete and ready for endorsement until all compliance evidence expected for assessment is received.
This section provides general design considerations and descriptions for the Gateway.
"The content contained within this section is not formally verified, but in many cases it is complementary to and influenced by verifiable requirements found in Section 3.2 of this document, and other Level 2 requirements."
The considerations are derived from the unique mission of the Gateway and the unique natural and induced environments the Gateway will experience.
Adherence to these considerations and ground rules are important to ensure the Gateway can perform the intended mission and endure the expected lifetime while providing a habitable productive environment for the crew.
"In the case of any apparent conflicts between content in Section 3.1 and requirements housed in Section 3.2 or other requirements documents, requirements shall supersede Section 3.1 content."
"Each Gateway module should be capable of storing power, receiving/distributing power, controlling temperature, and providing Command and Data Handling (C&DH) independent of other elements."
"Gateway should have a system architecture that allows sharing of resources (to include power, thermal control, C&DH, and Environmental Control and Life Support (ECLS) for pressurized modules) across module interfaces."
The Gateway will be assembled in cis-lunar space at a planned cadence of one flight per year.
"Therefore, each Module should be as self-contained as practical and each on-orbit stage must result in a sustainable spacecraft."
"In addition, power storage and temperature control will be needed by the module from launch to activation to keep the module within allowable temperature limits."
The purpose of independence and sharing resources provides the capability to respond to real time on-orbit anomalies and failures.
Sharing of resources may be needed to recover from a loss or diminished resources in one module being supplied from an adjacent module.
Gateway modules should be designed to be assembled primarily by automated docking with automated deployable mechanisms.
External robotics will be used for external payload installation and removal.
Rationale: Initial assembly missions may not have crew available to support assembly tasks while external robotics capability is also not expected to be available for early missions.
EVA capability is reserved for contingency maintenance and will not be available until late in the assembly timeframe.
"The Gateway should be designed with the –Z surface clear of structure, including planned Visiting Vehicles (VV), to avoid communication blockage."
"Rationale: Based on the initial Gateway reference architecture, the planned Near-Rectilinear Halo Orbit (NRHO), and the planned Solar Pressure Equilibrium Attitude (SPEA), the –Z surface of the Gateway is the optimal location for High Gain Antennas to support lunar and Earth communications."
This assumes the –Z axis is nominally directed towards ecliptic north.
Placing additional primary structure or secondary structure on the existing configuration could result in structural blockage of the communication line-of-sight.
The origin is located at the center of the PPE forward docking interface at the center of the docking mechanism Hard Capture Surface (HCS).
Active and Passive thermal systems should be designed with enough robustness and capacity to allow Gateway to fly in attitudes that are driven/support operations for extended periods.
This is achievable using body mounted radiators if there is enough surface area for the required radiators.
Radiators are most effective in rejecting heat when pointed towards deep space because they are not subjected to the heat radiated from the Moon or Earth.
"In the NRHO at the SPEA orientation, the surface area of Gateway that is facing deep space and the surface area facing radiation from the Moon and/or Earth changes over time."
"Therefore, to meet the thermal attitude independence, the Gateway will need radiators on each face of the external surface."
"Window(s) and secondary structure for other systems, such as Low Profile Grapple Fixtures (LPGFs), Small Orbital Replacement Unit (ORU) Interfaces (SORIs), EVA translation aids, GNC sensors, batteries, propellant lines, etc."
"In determining the location of external secondary structure, preservation of surface area for thermal radiators should be considered."
"Gateway should be designed to accommodate autonomy (as implemented by Vehicle System Manager (VSM), Intravehicular Robotics (IVR) and Extravehicular Robotics (EVR) systems) to the greatest extent practical."
"The Gateway will operate in cis-lunar space with infrequent, short periods of on-orbit crew."
The Gateway has a requirement to sustain a period of uncrewed operations for three years and then return to a state ready for resumed crew operations.
"EVR, IVR, and VSM will provide unique capabilities that provide reduced Earth reliance for future missions."
"EVR and IVR services can be utilized during all phases (crewed, non-crewed) and will support operations, maintenance, and utilization."
"Gateway will largely be an uncrewed vehicle, making robotics essential systems for utilization."
The Gateway design should be resilient to contamination from lunar regolith.
The Gateway dust mitigation strategy will be to limit dust from arriving at Gateway by placing constraints on lunar excursion vehicles.
"However, it is anticipated that dust cannot be completely eliminated, so Gateway should protect for meeting performance requirements when exposed to lunar dust."
"As the lunar enterprise campaign continues, the Gateway Program will develop quantitative requirements for the expected induced environment on Gateway and corollary requirements to levy on visiting vehicles to constrain the amount of dust that enters the Gateway environment."
"At that time, this design consideration will be replaced with quantitative requirements."
Internal Architecture is the methodology and design for outfitting a habitable volume to accommodate systems and humans while meeting mission objectives.
"A consistent, well-planned architecture will maximize volume efficiency, enable and enhance crew health and performance, and promote the extensibility of the spacecraft to meet future capabilities and mission requirements."
"A successful approach will employ commonality in orientation across pressurized elements, lighting techniques that enhance the living space, and clear and unencumbered translation paths to optimize movement."
"The architecture must provide solutions for securing equipment and stowage, so that crew can interact with it."
These solutions should anticipate reconfiguration and growth and provide a development strategy that protects the quality of the architecture as the space evolves.
"For example, a crew workstation may be initially hosted in I-HAB and might be moved at a later stage or supplemented by additional workstations in US-Hab."
"Habitability is the extent to which a space is suitable for human life and it should be a prime consideration in the design of all vehicles, habitats, and hardware used by a crew."
Habitable volumes will provide an atmosphere for the crew for all nominal missions.
"Functional allocation is the distribution of tasks, capabilities, and volumes within a habitable element or set of habitable elements."
"This distribution drives the flow of traffic, which can dramatically affect the architecture."
Complimentary tasks should be co-located and antagonistic tasks should be separated.
"Functional areas should be separated for tasks that could degrade emergency response or safety, or that produce environmental conditions detrimental to mission performance or habitability (for example, glare, noise, vibrations, heat, odors, etc.)."
"The relationship between tasks should be examined with respect to suitable compatibility, cleanliness, visual and auditory privacy, resource needs, and translation."
Gateway should establish a human-based frame of reference across the entire vehicle that enables the crew and ground to identify and communicate about locations within the system at any given time.
The internal living space should provide adequate habitable volume to perform the expected functions and to translate through the space.
"A clear, unencumbered translation path should be defined and maintained to facilitate the performance of mission tasks."
Working and living spaces intended for crew occupancy should be intuitive and aesthetically pleasing to facilitate human productivity and mission productivity.
"Colors, textures and lighting provisions should be chosen to support the functions intended for each working or living space, and, when used to provide visual orientation cues, should be capable of consistent throughout all habitable areas."
Lighting is an essential element of architecture that should be leveraged to help crew use the space.
It should be designed to complement the architecture.
"Acoustics should be managed to reduce hearing problems or annoyance, minimize unnecessary disruption to crew work and habitation functions, not inhibit speech communications, and ensure the detection and appropriate conveyance of urgency of auditory cautions, warnings, and alerts."
Outfitting refers to hardware and soft goods installed in the pressurized elements.
All mechanical systems outfitted for launch should be accessible and maintainable by the crew.
The need for secondary structure should be minimized in order to reduce element mass.
"The outfitting approach should be modular to accommodate reconfiguration and interoperability between elements, and it should be extensible to accommodate growth in equipment, systems, and stowage."
"Growth, including the addition of stowage and outfitting, should not compromise the clear and unencumbered translation path and living space."
"Spacecraft scalability should consider non-obstructive cable/hose routing so as to maintain translation paths that are free of entrapment (tangles, snags, catches, etc."
The design of the interior should have features that manage the addition of equipment cables and hoses without intruding on the living and translation space.
"For hardware that can restrain or restrict the crew, that hardware should allow for quick (guideline of 30 seconds) and sufficient crew egress from that apparatus such that the crewmember can don an emergency breathing apparatus and/or an emergency entry suit if required."
"All outfitting required to be installed on orbit, removed for return or disposal, or transferred between elements should be designed to fit through the smallest corridor."
Payload and stowage mounting and resource interfaces should be standardized across all elements allocated those functions.
Radiation exposure should be mitigated by vehicle design and operational approaches.
"During radiation events, if thresholds are reached, crewmembers would seek shelter in higher shielded locations of Gateway in order to minimize exposure."
"Design considerations should be given to providing the radiation safe haven protection as part of the habitable volume, ideally as part of the crew quarters location."
The Gateway should include supportability and maintainability as part of the system's design characteristics.
Designing for supportability and maintainability assists in ensuring system life- cycle availability and affordability.
"To assist with supportability, Gateway should strive for highly reliable systems to minimize maintenance."
"When external maintenance is required, the Gateway strategy is to use robotic capability first, while crewed and uncrewed, and use contingency EVA capability as a backup."
The Gateway should have modular hardware designs that reduce hardware to smallest replaceable unit and utilizes common component/system interfaces that allow items to be interchangeable between modules/elements.
Modularity requirements early in design will pay off in life cycle by reducing resupply weight and enabling commonality across modules at the lowest level practical in each system.
Interchangeable elements will minimize the number of unique spares required.
The Gateway should be maintainable and reconfigurable on-orbit using a minimum set of tools and fasteners that are as common as feasible with the other systems.
It is understood that exploration missions beyond LEO will be particularly mass and volume limited.
There will not be the ability to provide a tool kit that consists of over 500 unique tools like on the ISS.
"Additionally, common tools reduce the training and support requirements for the system."
"For those reason, providers of spacecraft, spacesuits, EVA tools, scientific payloads, IVR and other hardware will need to design their hardware to be maintained by a smaller set of common tools."
Under this Common Tools umbrella are two parts: the IVA Tools and EVA Tools.
There would be an IVA Tool Kit with a limited set of tools to perform maintenance on any hardware inside the habitable volume and will drive IVR end effectors.
"This includes maintenance of the spacesuit, EVA Tools, payloads, replacing spares, hatch operations or anything else that is stowed or brought into the habitable volume."
"There would also be a limited set of EVA Tools designated to be used for maintenance on any hardware outside of the habitable volume, such as an external antenna, solar arrays, a rover, or an external science payload."
"As a goal, Gateways should design all components and assemblies to utilize the Common Tools and Fasteners lists identified in the DSG-SPEC-CS-006, Gateway Program Subsystem Specification for Crew Systems for IVA tools/fasteners and the DSG-IRD-EVA-008, Gateway Program EVA Compatibility IRD for EVA tools/fasteners, though it is understood that it will not be practical 100% of the time."
"However, the intent of this requirement is that all planned maintenance and contingency tasks must be carried out using this Common Tools Kit."
Any designs that create the need for an additional tool outside of this set of tools should be routed through the appropriate Program Control Boards for approval.
The Gateway should provide for upgradeability which should allow technology infusion as well as address obsolescence issues.
Upgradeability will be necessary in the future to support exploration needs such as Lunar and Mars exploration activities.
"Upgrades should be considered through initial and follow-on phases of the program and include commonality to identify and recommend potential supportability enhancements such as identical interfaces, interchangeable parts, common tools, and interoperable items that can be used in different modules."
The Gateway should establish operational availability consistent with mission objectives.
Operational availability (Ao) is achieved by implementing highly reliable systems and incorporating common and modular hardware designs that consider ease of maintenance.
"For Gateway, there will be times when operational availability is required to be at the highest possible level for manned operations (for example, to support surface operations) and perhaps to a lesser degree for unmanned operations."
"Operational availability (Ao) typically relies on allocation of hardware reliability for inherent availability (Ai), reliability centered maintenance (RCM) (or preventative maintenance) for achieved availability (Aa), and the logistics/maintenance support infrastructure to achieve the designated requirement for Ao."
"Additional detail is captured in the Gateway Integrated Logistics Support Plan (ILSP), DSG-PLAN-020."
The Gateway shall be capable of launching modules on a commercial launch vehicle or as a Co-manifested Payloads (CPL) on the Space Launch System (SLS).
"Rationale: Having a commercial launch vehicle & SLS, keeps trade space open for a robust assembly sequence, and protects for development issues with co-manifesting, extended flight suspension of SLS or Orion, etc."
The Gateway modules will be launched to assemble the Gateway in Cis-Lunar Space.
The Gateway shall use docking systems compliant with the DSG-SPEC-MECH-017 Gateway Program Docking System Specification.
Rationale: All docking ports shall utilize common design to support interoperability.
The Gateway shall have a minimum of four Gateway Docking System compliant docking ports available for non-permanent use in any combination of radial or axial configurations.
"Rationale: Accommodations include allocation of ports to the PPE and to support habitation, logistics resupply, airlock capability, extensibility options, and crewed vehicle contingency docking."
"These modules will deliver supplies and utilization systems to the Gateway, as well as the capability to resupply, refuel, and dispose of trash."
Pressurized and unpressurized logistics should be accommodated.
"It could also include docking of a HLL or additional HABs providing communications, thermal, power, orbit maintenance and attitude control."
"As required, assessments will be performed for each new module."
"Implementation of the DSG-SPEC-MECH-017, Gateway Docking System Interface Definition Document will ensure interoperability of docking systems for all modules regardless of module provider."
Rationale: A SEP system that is extensible to future human deep space exploration missions will be demonstrated on the Gateway.
"Rationale: Orbit trade studies, cited in DSG-DDD-002 Gateway Mission Design Document (MDD), identified a Near-Rectilinear Halo Orbit (NRHO) as optimal for minimal energy orbit maintenance, and accessibility to multiple deep space destinations."
"Specifically, an L2 orbit in a 9:2 resonance with the lunar synodic period with apolune over the South Pole was selected for extended lunar communications with surface assets at the South Pole."
The Gateway shall be capable of performing a single round trip transfer to Distant Retrograde Orbit (DRO) and back within 11 months.
"Rationale: A series of robust uncrewed capabilities, in diverse cis-lunar orbits, will reduce risk, maximize closure of knowledge gaps, and prepare for operations beyond the Earth- Moon system."
"The transfer is assumed to occur with a fully- constructed stack, not including logistics modules, crew visiting vehicles, or lander elements (IAC-3 configuration 14)."
The targeted DRO will remain stable for 3 months for cislunar transfer applications.
The DRO will remain stable for 100 years for Gateway End-of-Life applications.
The Gateway shall provide a fuel capacity that would support performing a minimum of two round-trip uncrewed low-energy cislunar orbit transfers between a near-rectilinear halo orbit (NRHO) and a distant retrograde orbit (DRO) and orbit maintenance for a period of 15 years between refueling <TBR-HEOR-002>.
"Rationale: A series of robust uncrewed capabilities, in diverse cislunar orbits, will reduce risk, maximize closure of knowledge gaps, and prepare for operations beyond the Earth- Moon system."
"For this purpose, the selected NRHO is a nearly stable 9:2 lunar synodic Earth-Moon Lagrange 2 (EML2) halo orbit with perilune passage around 3300 km (TBR), while the selected DRO is a highly stable Earth-Moon orbit that averages 70,000 km in distance from the Moon entirely in the Earth-Moon plane (0-degree inclination) and appears retrograde in motion to the Moon <TBR-HEOR-002>."
"These transfers could occur between the selected NRHO DRO, another EML2, or another NRHO orientation (such as NRHO North to NRHO South) between refueling depending on mission needs."
Rationale: Minimum lunar flyby altitude is needed to constrain proximity to the moon in the case of uncertain conditions in performance of maneuvers to ensure lunar impact is avoided and to limit thermal concerns.
The minimum altitude is an instantaneous occurrence as the trajectory is propagated toward and away from the moon.
The reference trajectories are defined in detail in the MDD.
"The Gateway shall operate in an orbit that limits the time during perilune passage, below 10,000 km but not lower than 1500 km altitude, above the lunar surface to less than 8 consecutive hours."
"Rationale: Minimum Lunar distance is required to ensure orbit maintenance capability and needed to define natural environments for thermal and power systems, and lunar observation opportunities for utilization."
"Depending on the NRHO targeted, the minimum altitude can vary."
The closest approach will be for a short period of time which can be used to constrain thermal needs.
"Low Lunar Orbits (LLO) are not planned because Orion cannot reach LLO and Gateway costs and technical challenges are significantly higher for orbit maintenance, power, communications, and thermal constraints."
The Gateway shall provide a mission life capability for each module of at least 15 years after deployment.
"The 15 year Gateway life is needed to accommodate the mission flight rate for the buildup of the Gateway, the time necessary to test and demonstrate the deep space capabilities, to support to various science objectives, and to allow the uncrewed Gateway operations to facilitate successive crewed Mars missions and sustain mission cadence."
"Gateway will perform science, commercial, international and exploration activities during deep space expeditions."
"The Gateway life in remote cis-lunar space will drive the design for robustness, durability, and maintenance concepts that take into account limited logistics and onboard spares volume."
These design drivers for long life in remote locations and harsh environments will be shared with the needs for the Gateway and will therefore also provide experience to support the deep space development.
"During the course of the Gateway lifetime, service life extension assessments will be performed on each element to continue safe and reliable operations of Gateway well into the Phase 3 plan sequence."
"The Gateway shall support a crew of two, three, and four."
"The Gateway is intended to be a test bed to increase crew duration, demonstrate technologies, systems, and operations in deep space."
"The Gateway will nominally support a crew of four on a minimum 30-day mission once propulsion, habitation and sufficient logistics have been aggregated in cis-lunar space."
"The visiting crew vehicle(s) may not always fly four crew and in that scenario, the Gateway needs to be capable of operating with a minimum of two crew."
The Gateway shall accommodate crew for a minimum of 30 continuous days independent of visiting crew vehicle's systems and consumables.
The Gateway is intended to be a test bed to increase crew duration in deep space.
"Gateway will support a crew of four on a minimum 30-day mission once propulsion, habitation and sufficient logistics have been delivered to cis-lunar space independent of the visiting crew vehicle(s)."
This establishes the first incremental increase in deep space crewed duration beyond the VV's capability.
Gateway stack configurations lacking a fully outfitted habitation module are not intended to meet this requirement.
The Gateway shall be capable of uncrewed operations for up to 3 continuous years <TBR- HEOR-001> without resupply.
"Rationale: When uncrewed, the Gateway will perform operations via a series of robust autonomous capabilities that will reduce risk, maximize closure of knowledge gaps, and prepare for missions beyond the Earth-Moon system."
"These operations may include performing systems diagnostics and repair, logistics and consumables stowage, exploration capability testing, aggregation of robotically returned destination surface samples, science measurements and operations, communications relay, lunar vicinity mission support, etc."
The Gateway shall remotely transition from an uncrewed state to accommodate a safe crew ingress.
"The Gateway must survive for long periods without crew such that, prior to the next crew arriving, any actions required to prepare the stack can be performed so that the Gateway is safe and habitable upon ingress."
The Gateway SLS Co-Manifested modules shall have a launch mass not exceeding 9000 kg.
"Rationale: Based on SLS performance allocation to Gateway CPL as documented in DSG-GRA-004, Cross Program Groundrules and Assumptions (GR&As) for Analysis and Development."
Gateway control mass allocation does not need to account for the SLS Payload Attach Fitting (PAF).
"The control mass must account for Gateway Mass Growth Allowance (MGA), Maturity Estimate Reserve (MER), and Program Manager’s Reserve (PMR) as documented in DSG-PLAN-002, Gateway Margin Plan."
"The Gateway shall have module launch masses not exceeding those in Table 3.2.3-1, Gateway Element Launch Masses <TBR-L2-GW-004>."
The Table 3.2.3-1 defines the launch masses for each module and supporting systems.
Allocations in Table 3.2.3-1 include MGA and MER in accordance with the Gateway Margin Plan and are independent of the Launch Vehicle chosen.
The Gateway shall protect far side of the moon as a unique radio science location.
"Rationale: Gateway – Lunar communications will need to comply with International Telecommunication Union (ITU) Protection of Frequencies for Radioastronomical Measurements in the Shielded Zone of the Moon, Rec."
ITU-R RA.479-5 as d in the International Communication System Interoperability Standards (ICSIS).
"The Gateway shall operate internal systems, required to maintain control of the Gateway, during and after exposure to pressures from nominal operation pressures down to zero psi, within <TBD-L2-GW-003> minutes (or a depress rate), for a duration up to <TBD-L2-GW-004> hours."
"Rationale: Critical Avionics and Power Hardware must be able to survive and operate over a full range of pressure, from standard upper operating design spec pressure through a transition to partial pressures down to zero."
"This implies that those units need to be conductively cooled and designed for the range of temperature and environment changes, such as designed to address corona concerns, humidity changes, etc."
Non-critical items such as payloads as well as potential non-critical air cooled electronics are assumed to be powered off during a depress transition.
The Gateway shall accommodate automated delivery of logistics cargo and payloads.
Rationale: Accommodating automated delivery encompasses the Logistics visiting vehicle having the capabilities to arrive and dock with an uncrewed Gateway.
"The Gateway and the logistics module must have the necessary capabilities to access and transfer internal and external, cargo, payloads, ORU’s, etc., that were delivered etc."
"The Gateway shall allow for safe disposal of the on-orbit Gateway, to preclude the generation of space debris, at the end of its useful life."
Rationale: Consideration of the method of disposal during design will ensure required resources and functions are available.
Safe disposal is important to protect future exploration environments and destinations.
"The Gateway shall comply with applicable requirements in DSG-SPEC-GNC-009, Gateway Program Subsystem Specification for Guidance, Navigation and Control (GNC)."
Rationale: GNC will be implemented across the Gateway to ensure proper flight dynamics and orbits meet Gateway objectives.
Requirements specific to Gateway GNC are documented in the subsystem specification for GNC.
"The specification levies GNC requirements applicable to two or more modules, identifying each requirement’s module allocation."
"The Gateway shall manage the mass properties for the integrated stack, from initial deployment through operational capabilities for the purposes of bounding the center of mass, moments and products of inertia and total mass to enable integrated stack rotational and translational control."
The Gateway GNC needs to have a mass property limits to enable requirements verification and vehicle dynamics analysis.
The Gateway shall change the Gateway attitude to any orientation (as needed) to meet operational constraints for all configurations.
"The main drivers requiring attitude deviations from solar pressure equilibrium attitude (SPEA) are for orbit maintenance maneuvers, crewed operations with Orion such as docking events where the Gateway is the passive vehicle, and for the Orion tail-to-sun requirement."
The Gateway shall provide integrated attitude control services for the integrated stack.
Rationale: Operational concept derived requirement for a single entity to perform the attitude control of the integrated Gateway Stack (including docked VVs).
The Gateway shall acquire and process navigation data onboard to determine absolute position/velocity without communications with the earth.
"Rationale: Gateway must determine navigation state (position, velocity, attitude and attitude rate) without communications with the earth."
"Requirement L2-GW-0044 states Gateway must be able to operate for 21 days without ground communications, driving the Earth independence requirement."
The Gateway shall incorporate an Absolute Attitude Determination capability.
The absolute attitude determination system design requires provision for the spacecraft to estimate the vehicle's attitude and attitude rate in inertial space.
The Gateway shall incorporate an Absolute Navigation State Determination capability.
The absolute navigation state determination system design requires provision for the spacecraft to estimate the vehicle’s position and velocity in inertial space.
This can be achieved autonomously or with updates from ground based systems.
The Gateway shall provide integrated vehicle translational control for the integrated stack.
"Rationale: Operational concept derived requirement for a single entity to coordinate the maneuvering of the docked modules (including docked VVs), from one location in space to another location."
Translation control includes Gateway orbit maintenance.
"The Gateway shall control attitude and attitude rates, within <TBD-L2-GW-001>."
"Rendezvous, Prox-Ops, and Docking (RPOD), science observations, communication with Earth and/or Lunar asset, and transfers within cislunar space."
The Gateway shall limit maximum magnitude of linear rigid-body acceleration at the integrated stack center of gravity during integrated vehicle translations to 0.1g.
Rationale: Gateway accelerations need to be bounded.
External robotic systems specify a maximum of 0.1g to minimize impacts to robotic elements.
"The Gateway shall support autonomous docking, undocking, berthing, and unberthing of Visiting Vehicle and modules while there are no crew present on the arriving/departing module or Gateway."
Rationale: Launch cadence for vehicles should not depend on crew being present on board the Gateway since this would impose undue time and programmatic constraints.
"Autonomous vehicle operations reduces mission risk, conserves valuable Gateway crew time, and provides important capabilities needed for science utilization and future exploration."
"The Gateway shall provide docking targets as defined in the DSG-SPEC-GNC-009, Gateway Program Subsystem Specification for GNC."
"The chaser vehicle will utilize the targets on the docking mechanisms to perform rendezvous, proximity operations and docking, or while station keeping in the “capture box”."
The Gateway shall be on-orbit refuelable for both Xenon and Hydrazine propellants.
The Gateway will have refuel capability incorporated via DSG-SPEC-MECH- and RCS propellant.
The refueling capability will provide robustness and flexibility of cis- lunar operations.
Additionally the PPE has a commercially provided refueling capability on the aft end of the vehicle.
The Gateway shall use a monopropellant hydrazine propulsion system.
The specification of the propellant allows for clarity in the fluid interface between PPE and the docking mechanism.
The use of monopropellant hydrazine also simplifies the PPE tanks liquid acquisition device and gauging or flow measurements.
Use of bipropellant nitrogen tetroxide limits the commercial options for acquisition devices and introduces saturation issues.
"In addition, the use of hydrazine reduces plume contamination concerns that bi-propellants would introduce into a Gateway environment."
"The Gateway shall comply with applicable requirements in DSG-SPEC-COMM-005, Gateway Program Subsystem Specification for Communications."
Rationale: An integrated Gateway Communication System will be implemented across Gateway to provide the communication capabilities for Gateway and Gateway utilization functions.
"This includes communications between Gateway and Earth, Gateway and Visiting Vehicles, Gateway and Lunar Systems, Gateway and EVAs, wireless communications, and intra-Gateway networking between Gateway modules."
"The Gateway Program Subsystem Specification for Communications defines the specific functionality required from the different communication system to enable the capabilities, support interoperability and be compatible with other communication systems and infrastructure assets (example: Deep Space Network)."
"The Gateway shall incorporate modular, reconfigurable communication systems to support expandability and extensibility for additional capabilities."
"Rationale: Exploration communication systems will need to support multiple signal formats, data rates, network management scenarios and interface with different ground and space assets during the various mission phases."
"The signal formats, standards and capabilities will also evolve over the life of the mission and the system will need to support these upgrades."
"In addition, accommodation for demonstration of technologies leading to operational systems, like optical communications, needs to be provided."
"The Gateway shall comply with spectrum selection/allocation, certification, and usage restriction policies set forth in NPD 2570.5, NASA Electromagnetic (EM) Spectrum Management Document."
The National Telecommunications and Information Administration (NTIA) regulates the licensure and use of RF spectrum for U.S. Government systems.
"Allocations of frequency spectrum for U.S. Government systems, including NASA, are managed by the NTIA."
"The Gateway shall implement security functions and controls for a high potential impact system utilizing NIST Special Publication 800-53, Security and Privacy Controls for Federal Information Systems and Organizations or approved international equivalent."
Rationale: Gateway needs to secure systems based on the security assessment and controls.
"The Gateway shall provide spherical coverage for the different mission phases and links, excluding non-Gateway structural blockage, as given in Table 3.2.6-1, Data Download Volume to Earth <TBR-L2-GW-018>."
Rationale: Gateway will need to provide communications coverage for critical mission phases and links involved.
"The particulars of the link, including data rates, protocols, etc."
The Gateway shall communicate with Earth for data exchange and radiometric tracking.
"Rationale: Gateway communications with Earth enables data transfer between Earth and the Gateway (including commands, file uploads, telemetry, engineering and science data, voice, video and images, and crew-related data), as well as supports tracking and position determination of the Gateway."
The Gateway shall support a minimum of 3 simultaneous RF communication links.
"Rationale: Gateway will need to communicate simultaneously with VV, Earth and Lunar Surface Asset; or with Earth, EVAs, Lunar Surface Assets, etc."
Therefore the Gateway will have to have the necessary architecture framework and communications resources to support 3 or more simultaneous RF links.
The Gateway shall communicate with Earth without placing constraints on flight attitudes during nominal operations.
The Gateway stack could be oriented in any direction in the ecliptic plane for any amount of time to support SEP operations or other objectives.
"This means that the Gateway communication system(s), during nominal operations, must be able to support communications with Earth in any flight attitude."
The Gateway shall support at least 7.49 Tbits per day (~935 GB per day) data downlink capacity to Earth.
"Rationale: Gateway will need to provide communication data downlink capacity to support science, payload, crew, etc."
Specifying a total volume/day allows Gateway to: a. allocate and schedule the necessary network resources; b. determine data rates and coverage needed; c. determine onboard data storage needs.
Rationale: Gateway to Lunar surface / Lunar orbit communication link will be used to communicate with Lunar systems and in conjunction with the Gateway -Earth link be used to relay data between the Earth and the Lunar systems.
"In addition, the Gateway-Lunar surface link could be used to “tele-operate” Lunar surface robotic systems."
Gateway – Lunar communications will need to comply with ITU Rec.
The Gateway shall support at least 1.62 Terabits (TBs) per day data transfer from Lunar Systems.
"Rationale: Gateway will need to support science, payload, crew, etc."
Specifying a total volume/day allows Gateway to: a. allocate and schedule the necessary network resources; b. determine data rates and coverage needed; determine onboard data storage needs.
The Gateway shall have the capability to communicate with at least 2 Lunar Systems simultaneously.
Rationale: Lunar System assets will require command and telemetry links to execute command and relay data from their sensors and experiments to the Gateway.
There may be more than one lunar surface or lunar vicinity system at any given time and will need to communicate with Gateway.
Gateway will be able to communicate with 2 assets at any given time.
The Gateway shall provide integrated communications services for all docked modules/vehicles.
Rationale: Gateway will be capable of relaying bent-pipe communications from the ground to all docked modules/vehicles.
"Visiting Vehicles (VV), having their own comm link to earth, will also be capable of communicating directly with the ground while docked at Gateway."
Gateway and these VV will pre-coordinate to ensure communication links don’t interfere with each other.
The Gateway shall communicate with Visiting Vehicle for data exchange and radiometric tracking.
"In addition, the radiometric tracking will provide range and range rate information to the VV’s GNC system to augment its navigation sensor information."
"To maintain compatibility with Orion rendezvous link, the ICSIS defines this link at S-band."
The Gateway shall support direct voice communications between crewed spacecraft during proximity operations.
Rationale: Direct voice communication means that the signal is not routed through mission control or another communication relay satellite.
The Gateway shall provide an antenna and RF electronics connecting to visiting vehicles to provide communications coverage during RPOD.
"Rationale: For launch configurations that are co-manifested on SLS, the co-manifested modules obstruct Orion's crew module antennas."
Having the co-manifested module provide antenna and RF electronics and connecting these to Orion's comm system will provide the necessary communication coverage between Orion and Gateway during RPOD.
The Gateway shall provide internal and external wireless communications.
"Rationale: Gateway needs to support high rate data transfer between Gateway, robotic inspection cameras, robotic arms, EVAs, wireless sensors, payloads and other user applications."
This data can also be relayed to Earth or other modules as needed.
The Gateway shall support internal voice communications between Gateway crew and ground operators.
Rationale: Crewmembers must maintain voice communication with ground systems during nominal and off-nominal activities.
Private voice communication with the ground during medical exams is considered nominal operations but may also be considered off-nominal.
"Other off-nominal events may require wearing a contingency breathing apparatus, which may hinder clear communication between crewmembers, which is essential during an emergency."
The Gateway shall communicate with up to 4 EVA crewmembers.
"Rationale: Gateway needs to support emergency/contingency EVAs and part of that, Gateway will need to communicate with the EVA crew."
The same EVA radio used on-board Gateway will be used for lunar surface operations.
The requirement to support 4 crew is to ensure that the EVA radio is designed to handle 4 EVA crew to support surface operations even though the on Gateway there is no plans to have 4 crewmembers to go outside to conduct EVAs.
"The Gateway shall comply with applicable requirements in DSG-SPEC-VSM-003, Gateway Program Subsystem Specification for Vehicle System Manager (VSM)."
The Vehicle System Manager will be a system whose function is to manage the overall vehicle.
"As such, the VSM will need to interface with all modules and all systems."
It is important that a common set of requirements exists to describe both the VSM itself as well as the interfaces to the VSM.
Adherence to this specification will direct the controllability and compatibility of the Gateway and the VSM.
The Gateway shall provide a VSM to manage the Gateway modules and coordinate with crew and ground controllers.
Rationale: Coordinated control is needed on the vehicle level.
Command hierarchy should be enforced to ensure proper and robust configuration and control of vehicle.
Data must flow up to the VSM and the VSM must be the main vehicle control interface with human operators.
Orderly flow of data and commands reduces complexity and increases robustness.
"Interfaces to this system to support situation awareness, system management, diagnosis, response planning, annotation, and retrospective analysis."
"The Gateway shall provide for autonomous operations for up to 21 continuous days independent of ground communications, with or without crew."
"Rationale: Gateway will be operated as both a crewed and uncrewed spacecraft, and will experience extensive resupply and communication constraints."
This will necessitate the capability for autonomous operations.
"The Gateway needs to provide autonomous vehicle control, nominal and off-nominal systems management, and utilization as well as providing essential system capabilities like data storage."
More data on autonomous functionalities that will be necessary can be found in the VSM subsystem specification document.
The Gateway shall curate data based on priorities and events.
Rationale: Reduced bandwidth and lack of crew will challenge the situational awareness of ground operators.
The Gateway VSM will manage the resource of bandwidth in order to provide the ground controllers with the best possible information.
"This will involve responding to priorities set by ground, crew, or events on board the Gateway."
The curation of data must occur throughout the vehicle because of limited processing and network resources throughout the spacecraft.
"The Gateway shall comply with applicable requirements in DSG-SPEC-FSW-014, Gateway Program Subsystem Specification for Software."
Rationale: Requirements specific to Gateway FSW are documented in the subsystem specification for software.
"The specification levies FSW requirements applicable to two or more modules, identifying each requirement’s module allocation."
The Gateway shall transport data required for vehicle operations.
Rationale: Data flow through the Gateway System ensures all modules and systems are receiving the information required to operate the vehicle and achieve objectives set forth in the Mission Plan.
"This includes, but is not limited to, delivery of commands, routing health & status data, providing fault data, and delivering reconfiguration data updates."
This capability also includes delivery of data to and from the Ground.
The Gateway shall capture data required for recovery of vehicle systems.
"Rationale: State data critical for recovery or restoration of Gateway systems ensures ongoing operation of the vehicle if a situation arises where a system must fault down, safe, and recover."
"When software secures data, it takes steps to ensure the data is correct in storage."
"As such, securing state data reduces the risk of an incomplete or insufficient recovery due to data integrity issues."
"The Gateway shall detect, report, and annunciate faults for alerts, caution, warning, and emergency events to the on-orbit crew (IVA and EVA), lunar-surface crew, Earth (e.g. control centers), Visiting Vehicle, and/or autonomous operations."
"Rationale: Off-nominal events are usually divided into the following four categories to simplify training and user comprehension: emergencies, warnings, cautions, and alerts (action required events)."
"During off-nominal events, crew attention should be directed to commensurate with the urgency of the situation and the use of multiple modalities, e.g., both visual and auditory, provides redundancy to ensure the attention of the crew; except for advisories, which may not have an auditory annunciation."
Annunciation to crew shall include audible and visual notification.
The Gateway shall be able to update executable Flight Software (FSW) and configuration data to support ongoing vehicle operations and configurations.
"Rationale: As the Gateway increases in capacity and capability, software updates will be required to meet changing objectives."
Providing the capability to update all executable FSW and configuration data will provide flexibility.
This capability allows the Gateway to stage software releases.
"Rationale: Three specific cases (a, b, c) are included as part of the requirement as written in the NPR 8705.2C, requirement 3.3.3."
This capability will likely be implemented using a mission control on Earth.
"Logically, there will be times when the crew is unavailable to monitor, operate, and control the system."
"If the crew vacates one module of the system or transfers to another Human-Rated system as part of the reference mission, there is a capability for humans to monitor the unoccupied modules."
"In some of these cases, the crew may be able to perform this function from their new location."
"In other cases, mission control may perform this function."
The Gateway shall have FSW that performs maintenance tasks to limit required periodic servicing of the software by ground and crew.
"Rationale: FSW maintenance tasks include, but are not limited to, memory management, data storage management, application refresh, self-tests, etc."
"Given that communication with the Ground will be minimal and Crew visits infrequent, routine maintenance and servicing that keeps the software operating efficiently must be automated to eliminate dependencies on human operators."
These self-maintenance tasks will be conducted with minimal to no impact on Gateway operations during crewed and uncrewed flight phases.
The Gateway shall utilize the Core Flight Software (cFS) as the standard software framework.
Any application developed as a cFS compatible software configuration item can be re-hosted on another module as long as processor capacity exists.
The Gateway shall provide the capability to isolate and recover from faults identified during system development or mission operations that would result in a catastrophic event.
"The intent is to provide isolation and recovery from faults where the system design (e.g., redundant strings or system isolation) enables the implementation of this capability."
"Also, any faults identified during system development should be protected by isolation and recovery."
"However, it is acknowledged that not all faults that would cause catastrophic events can be detected or isolated in time to avoid the event."
"Similarly, system design cannot ensure that once the fault is detected and isolated that a recovery is always possible."
"However, in these cases, isolation of the fault should prevent the catastrophic event."
The crewed Gateway shall provide the capability for the onboard crew to manually override software functionality when the transition to manual operation will not cause a catastrophic event.
"The intent of this requirement is to allow crew intervention of the crewed space system and/or subsystem software to perform operations that would nominally be automated, or when software design is incapable of responding appropriately or as desired to real-time events."
"While this capability should be derived by the program per requirement L2-GW-0310 Crew Monitor/Operate/Control Capability, the critical nature of software control and automation at the highest system level dictates specific mention in this requirement set."
"The displays and controls for manual intervention should be conveniently located, readily accessible, and intuitive for the intended task and its duration as long as the transition to/from manual operation is feasible and will not cause a catastrophic event."
The definitions in the Appendix for “Crewed Space System” and “Subsystem” provide guidance on the depth and breadth to which manual override capability should be provided.
"Identifying which specific automated functions require the crew override capability will be driven by task analysis with concurrence from the Gateway Program, the JSC Flight Operations Directorate and the Technical Authorities."
The crewed Gateway shall provide the capability for the crew to manually control the attitude and translation of their crewed space system.
The capability for the crew to manually effect changes in the attitude and translation of Gateway is a fundamental element of crew survival.
"The most robust satisfaction of this requirement is provided by direct manual flight control of the vehicle translation and attitude, through an independent flight control pathway (bypassing the affected vehicle guidance, navigation, and control system failures)."
A minimum implementation of manual flight control allows the crew to bypass the automated guidance of the vehicle by interfacing directly with the flight control system to effect any possible attitude or translation change/adjustment within the capability of Gateway’s design.
Limiting the crew to choices presented by the automated guidance function is not a valid implementation of manual flight control.
Safe operation requires accuracy of crew inputs to meet human rating requirements.
"Tools include, but are not limited to, telemetry, displays, video, instrumentation, and windows."
Tools will be verified in a Gateway flight-like environment to ensure they are adequate to support manual control and operations.
Rationale: This capability flows directly from the definition of human-rating.
"Within the context of this requirement, monitoring is the ability to determine where the vehicle is, its condition, and what it is doing."
Monitoring helps to create situational awareness that improves the performance of the human operator and enhances the mission.
Determining the level of operation over individual functions is a decision made separately for specific space systems.
"Specifically, if a valve or relay can be controlled by a computer, then that same control could be offered to the crew to perform that function."
"However, a crew member probably could not operate individual valves that meter the flow of propellant to the engines, but the function could be replaced by a throttle that incorporates multiple valve movements to achieve a desired end state (reduce or increase thrust)."
"The first condition recognizes that the crew performs functions to meet mission objectives and, in those cases, the crew is provided the designated capabilities."
This does not mean that the crew is provided these capabilities for all elements of a mission.
"Many considerations are involved in making these determinations, including capability to perform the function and reaction time."
"The second and third conditions recognize that, in may scenarios, the crew improves the performance of the system and that the designated capabilities support that performance improvement."
"The Gateway shall comply with applicable requirements in DSG-SPEC-CDH-004, Gateway Program Subsystem Specification for Avionics."
"The Gateway Program Subsystem Specification for Command and Data Handling defines the specific functionality required of the Inter-module network system to enable top level capabilities, associated design standards, and module level functional and performance requirements."
"The Gateway shall comply with applicable requirements in DSG-SPEC-CHI-018, Gateway Program Subsystem Specification for Computer Human Interface."
"Rationale: DSG-SPEC-CHI-018 provides specifications for interoperability and commonality of Hardware and Software in the areas lighting, imagery (still and video), audio, displays, and controls."
The Gateway shall provide a total of three TTE planes through each inter-module connector for redundancy.
Rationale: Three separate cables must run between the elements in order to meet TTE fault tolerance specification.
This is consistent with meeting the docking adapter data interface between modules.
The Gateway shall incorporate a shared data storage system.
The architecture must account for a capacity that considers the modules’ systems data and additional storage capacity that can be accessed and used by the Gateway.
"The overall capacity needed will be determined by assessing the mission configuration, module and systems data priorities, and anticipated operations."
"Rationale: Top-level requirement to provide shared processing for Gateway system functions, imagery, internal robotics, crew health and performance, payloads, etc."
Robot mass and power can be reduced if some of the processing can happen off board the robot.
The Gateway shall provide crew displays and controls that are operable by a crewmember from within any habitable environment.
"Rationale: Crew capability (data/command interfaces) provides monitoring of the C&W as well as nominal and off-nominal control of life support, thermal control, communication, and other system functions necessary for safe operations from any habitable module."
The Gateway shall provide internal lighting for the illumination required for all operational tasks dependent on visible light.
Rationale: A wide range of crew and robotic tasks is expected to be performed within the vehicle.
The required lighting levels vary depending on the task being performed.
"Examples of crew tasks include critical inspection and legibility, personal hygiene, telerobotics, and cleaning and maintenance."
"Examples of robotic tasks include inspection, localization, and object identification."
The combined lighting system and architectural layout are a factor in the development of a usable lighting environment.
"During waking hours, lighting systems must provide the crew with retinal light exposure that is sufficient in intensity, optimal in wavelength, and implemented at the proper times and durations to entrain the human circadian pacemaker to a 24-hour day and facilitate schedule shifting."
"Effective lighting systems for internal operational environments support human/camera color vision within the appropriate chromaticity range, color accuracy, and allow for control, position adjustment, and glare prevention."
"Effective lighting systems for robotics have similar characteristics, although an additional consideration is the reduction in variations in lighting across locations or time as much as possible."
The Gateway shall illuminate external surfaces <TBR-L2-GW-014> required for all operational tasks dependent on external visible light.
Rationale: Lighting is expected to be poor on the non-sun-facing surfaces of Gateway.
Supplemental lighting is required in order for imagery to be acceptable.
This is needed for EVA situational awareness and will be helpful for EVR operations.
"The Gateway shall comply with applicable requirements in DSG-SPEC-PWR-011, Gateway Program Subsystem Specification for Power."
"Rationale: An integrated Modular Power System will be implemented across Gateway to provide power to the Gateway systems, utilization, and visiting vehicles."
The Gateway Program Subsystem Specification for Power defines the specific functionality required from the modular power system to enable the interoperability and compatibility of both the electrical power system and the electrical power consuming equipment across all Gateway power interfaces.
The Gateway shall provide a minimum of 32kW for Gateway use when SEP is inactive.
The Gateway will generate power for all elements including power utilized by the PPE itself.
When the SEP is inactive there will be a minimum of 32kW available to transfer.
It is expected that more than 32kW is available and can be distributed when both power domains are utilized.
"The Gateway shall conform to the DSG-SPEC-PQS-020, Gateway Electrical Power Quality Specification Requirements for 120Vdc."
The Gateway will conform to the Gateway PQS for both the Electrical Power System and for the Electrical Power Consuming Equipment (EPCE).
"The PPE element itself is excluded from this requirement, but the power PPE provides to any Gateway equipment located on the PPE will conform to the Gateway PQS."
The Gateway shall allow for full use of available array power.
"Rationale: While critical systems must be capable of running from a single power domain, more power above allocated limits is available when SEP is not being utilized or is running at low power."
"Both power domains are expected to operate simultaneously for all Gateway operations, but maintain an overall fault tolerant (FT) system operation."
The Gateway shall distribute primary power using two bi-directional power domains to each axial docking port.
The Gateway primary power transmission from the PPE to the Gateway modules utilize bi-directional axial port feeds.
This bi-directional power transmission allows module launch order independence and integrates the Gateway distributed battery system to be able to power the Gateway during eclipses and allows the distributed batteries to recharge.
The Gateway shall implement a redundant 16kW bi-directional primary power pass-through to each radial docking port.
The Gateway will provide redundant primary power transmission to each radial docking port to provide the adjoining (docked) Gateway element access to the over-all Gateway primary power.
The bi-directional power transmission to each radial docking port allows element launch order independence with either Gateway HAB element and integrates the Gateway distributed battery system to be able to power the Gateway during eclipses and allows the distributed batteries to recharge.
"The radial docking port primary power system interfaces are redundant, meaning that in case of a single radial docking connector failure, the remaining docking connector has to transfer at least 16 kW."
The bi-directional primary power interface at the radial docking port has been pre-defined and utilizes the high power docking Rectangular Umbilical Connector (RUC) with each high power RUC having one (1) utilized for grounding purposes or spares.
The Gateway shall provide dc-isolation between the Gateway primary power domains and the secondary power domains.
"Rationale: To facilitate Gateway power quality verification without the presence of all Gateway modules and power consuming equipment within an integrated test, the Gateway will provide dc-isolation between the Gateway primary power domain and the secondary power domain of the applicable elements."
This will allow independent power quality verification of all Gateway secondary loads and it will allow independent verification of the Gateway primary power.
Source and load emulators will be required to verify the power quality between power interfaces.
The Gateway shall be capable of operating critical systems off of a single power domain.
"The module-to-module primary power is redundant, meaning that in case of a single docking system connector failure, the remaining NDS connector has to carry the full limit of a single power domain."
The Gateway shall provide energy storage capacity capable of supplying a minimum of 32kW during non-insolation periods of at least 1.5 hrs.
"Rationale: Once a module is attached to the Gateway, that module's battery is part of the integrated Gateway primary power system and feeds all elements of the Gateway."
"Collectively, all the batteries have to supply power to the Gateway during non-insolation periods such as an eclipse."
The overall Gateway battery energy is rated to maintain 32kW for 1.5 hours of nominal operations for all of Gateway's modules including Science.
The 1.5 hours is based on a Lunar synodic resonance NRHO which will essentially eliminate the Earth shadow and keep the Lunar eclipses less than 1.5 hours.
The Gateway shall provide a minimum of 24kW for system use when SEP is active.
The 24kW electrical power value represents the minimum required continuous transfer power that is transferred to all Gateway electrical loads other than to the PPE housekeeping when the SEP is active and consuming up to 26.6kW.
"The Gateway shall adhere to the Program Element Power Allocation in Table 3.2.10- 1, Gateway Power Allocation and Table 3.2.10-2, EVR Power Allocation."
The Gateway elements will be required to adhere to the Gateway Element Power Allocation Tables to prevent excessive power demands from over loading the PPE array.
The Gateway shall reserve a minimum of 4kW power for utilization use.
Rationale: Utilization needs to have a minimum of 4kW power reserved to support the various utilization and science objectives planned for Gateway.
"The Gateway shall be automatically booted to an operational and commandable state with the energizing of the Ground Support Equipment (GSE), or initial delivery vehicle, or the Gateway primary power interface."
"Rationale: First time power activation of the Gateway element or a restart after being completely deactivated will be accomplished by applying power to either the GSE, initial delivery vehicle, or Gateway primary power interfaces."
Both of the elements power domains will be capable of independent activation.
The start-up sequence will automatically energize the appropriate power and avionics equipment to get the element to a commandable state.
The Gateway shall provide a Gateway standard power interface for internal portable electrical equipment including science and IVR.
"The Gateway will support the use of internal portable electrical equipment, science, and robotics by providing standard common electrical outlets that provide electrical shock hazard protection."
The Advanced Modular Power System (AMPS) will provide variable voltage sources that may be incorporated into the elements Power Distribution Unit (PDU) that will then feed the standard panel interface for Portable Equipment.
The Gateway shall provide imagery to support operations during all mission phases.
"The Gateway imagery system must include a capability to monitor internal and external activities and inspect internal and external equipment to support ground situational awareness of general operations, including vehicle condition, in-flight maintenance, utilization/science, and public affairs and outreach."
The Gateway shall enable two-way private audio and motion imagery communication between the ground and crew.
"Rationale: Gateway needs to provide for privacy during personal crew communications including private space, internal cameras, etc."
The Gateway shall provide imagery and associated synchronized audio to the Crew.
"Rationale: Top-level requirement establishing the need for any Gateway-generated imagery (and associated audio, where applicable) to be made available to the crew."
"This requirement covers all imagery, internal, external, motion (video), and stills."
Audio/Video Synchronization with the Gateway onboard clock can occur at the source or on the ground depending on implementation.
The Gateway shall record imagery with associated audio.
"Rationale: Top-level requirement establishing the need for any Gateway-generated imagery (and associated audio, where applicable) to be recorded onboard."
"This requirement covers all imagery (internal & external), motion (video), and stills."
The Gateway shall provide imagery with associated audio to Exploration Systems.
"Rationale: Top-level requirement establishing the need for the Gateway vehicle to generate imagery (with associated audio, where applicable) and make that imagery available to other Exploration systems (Orion, Mission Systems, etc.)."
"The Gateway shall comply with applicable requirements in DSG-SPEC-ECLS-007, Gateway Program Subsystem Specification for Environmental Control and Life Support System (ECLSS)."
"Rationale: An integrated Environmental Control and Life Support System will be implemented across Gateway to ensure habitability across all habitable volumes, including visiting vehicles attached and open to the Gateway."
"The Gateway Program Subsystem Specification for ECLSS defines the specific functionality required of the ECLSS to enable top level capabilities, associated design standards, and module level functional and performance requirements."
The Gateway shall condition the atmosphere in habitable volumes and attached visiting vehicles to maintain temperature and humidity levels and to provide proper atmosphere circulation within the habitable volumes.
"Rationale: Air conditioning includes circulation of air to ensure proper mixing, and maintaining the temperature and humidity levels within system capabilities."
This function must be performed during crewed and uncrewed periods to protect both crew and vehicle systems.
Further specification may be found in the Gateway ECLS Subsystem Specification.
"The Gateway shall provide potable water for crew, system and payload use."
Rationale: Potable water is necessary to maintain crew hydration during Gateway operations.
"Water may also be needed for operating science and technology payloads, and other systems such as the EVA suit."
Water safety establishes that physiochemical and microbiological limits are met.
Water quantity and delivery specifications will be defined in the DSG-SPEC-ECLS-007 ECLS Subsystem Specification and the Payload IRD.
"The Gateway shall provide fire detection, suppression, isolation, and recovery for any internal fire events when there are potential flammable materials or ignition sources present, or credible oxygen enrichment."
"Rationale: Fire protection includes fire prevention, fire detection and fire suppression."
This capability is needed in both crewed and uncrewed mission phases.
End item fire protection is accomplished primarily by controlling flammable materials and ignition sources.
"Flammable materials are controlled per NASA-STD-6016, Standard Materials and Processes Requirements for Spacecraft, and ignition sources are minimized via adherence to electrical design requirements such as proper bonding, grounding, wire and fuse sizing, and circuit protection."
An ignition source is a source of heat sufficiently intense and localized to induce combustion.
"Any item that could cause sparks, such as a brush motor, is also considered an ignition source."
"If materials flammability and electrical requirements are not met, detection and suppression must be discussed during the safety review process."
Gateway shall maintain airborne contaminants below applicable limits for nominal human performance during crewed periods.
"Rationale: Contaminants may be added to the atmosphere by crew, including carbon dioxide, particulates, and trace gases."
Trace gases are added to the atmosphere through normal off-gassing from system surfaces.
"Additionally, particles associated with lunar regolith may be presented to the Gateway after a human lunar mission and through lunar sample return through the Science Airlock."
Specific capabilities and limits will be further defined in the Gateway ECLS Subsystem Specification.
"The Gateway shall collect, contain, and dispose of crew bodily wastes."
"Rationale: This requirement applies to the collection of crew metabolic waste associated with the toilet including urine, feces, vomit and other waste."
"While collection is only applicable during the crewed period, any long term storage may need to be managed during the uncrewed period."
"It is expected that waste will be collected in the Habitation Element and may be transferred to another module, such as a LM, for long term storage and disposal."
"Venting of pretreated urine must be coordinated with structures and external systems, and must be balanced or non-propulsive to minimize Gateway stack attitude impulses."
"The Gateway shall provide emergency equipment for crew survival, accessible within the time required to respond to the emergency."
Rationale: This is hardware needed in each element with hazards that might lead to a compromised atmosphere to allow crew to translate to a safe location within Gateway or the vehicle intended for crew return to Earth.
"Efficient transit includes appropriate orientation with respect to doorways and hatches, as well as obstacle avoidance and illumination along the egress path."
Hardware must be readily accessible to allow escape in the shortest amount of time.
Likewise an emergency lighting system must be automatically activated to allow operators and other occupants of a module to move to a safe location in the minimum amount of time.
"The portable hardware classified as emergency equipment should be provided as Common Equipment to the modules to ensure commonality, compatibility, and portability."
The Gateway shall be designed to operate in atmospheric conditions with 0% humidity during uncrewed periods.
"Rationale: During crewed operations, the dew point will remain within crew comfort levels."
"During the uncrewed period, the cabin may be very dry with a dew point less than 4C (39F) at lowest allowable temperature."
Humidity may be removed purposefully to prevent condensation and microbial growth.
The humidity will passively be reduced as the pressure is maintained with dry gasses and no crew is present to replenish atmospheric vapor.
Appropriate design of electronics must be included to control electrostatic discharge (ESD) hazards.
"Design Specifications to minimize risk of ESD may be found in DSG-RQMT-004, Gateway Electromagnetic Environmental Effects (E3) Requirements Document, and DSG- RQMT-007, Gateway Requirements for the Control of Electromagnetic Interference Characteristics of Subsystems and Equipment Document."
The Gateway shall operate in conditions up to 24.1% oxygen with nominal operating functions at the nominal atmospheric pressure of 101.3 kPa (14.7 psi).
Rationale: Enriched oxygen concentrations increase the flammability of materials within that environment.
Extensive flammability materials has been captured and is reflected in the NASA Materials Selection Database for flammability at this operating point.
Oxygen concentration control ranges will be defined in the Gateway ECLS Subsystem Specification.
The Gateway shall operate in conditions up to 30% oxygen for atmosphere pressures up to 70 kPa (10.2 psia).
Rationale: Elevated oxygen concentrations are needed at lower pressures to sustain human life.
Oxygen concentration will be defined in the Gateway ECLS Subsystem Specification.
The Gateway shall maintain an internal habitable environment at pressures between 65 kPa (9.5 psia) to 102 kPa (14.9 psia); with the exception of airlocks.
"Rationale: When crewed, the Gateway will be nominally maintained at pressures near to Earth sea level 101 kPa (14.7 psi)."
"The full range allows for operational flexibility during crewed and uncrewed periods, including response to contingency scenarios and potential reduction of consumables during uncrewed periods."
Pressurized modules have a design pressure for structural design purposes higher than 14.9 psia to account for pressure set points of positive pressure relief valves (PPRVs) and fault tolerance of the ECLS system.
The required maximum design pressure for structural design is provided in the element and module allocated requirements sections.
The Gateway shall maintain interior atmosphere temperature to between 4°C (39°F) and 27°C (81°F).
Rationale: This requirements establishes the full temperature control range for the Gateway during both crewed and uncrewed periods.
The Gateway will maintain temperatures according to crew capability during crewed mission phases.
These ranges will be further specified in the Gateway ECLS Subsystem Specification.
The Gateway shall equalize the pressure between adjacent isolated modules.
Rationale: Vestibule pressurization is required prior to hatch opening between modules and to allow a visiting vehicle to be opened to the Gateway Habitation Element.
This is required during crewed and uncrewed mission phases.
The Gateway shall limit disturbances caused by venting of fluids and gasses per the <TBD-L2- GW-059> table.
Rationale: Nominal ECLS functions include venting of waste gases and fluids from ECLS systems and payloads.
"Additional venting would occur with nominal venting associated with pressure control functions, included reduction in in the internal atmosphere pressure, depressurization of vestibules to support departure of visiting vehicles, and airlock operations."
Thermal Control Subsystem capable of maintaining its own equipment within thermal limits at all times for any flight attitude.
Modules within the Habitation Element will be capable of sharing thermal control resources with an adjacent module for flexibility during contingencies.
Each module may utilize active and/or passive thermal control methods to meet thermal requirements.
"Thermal Control Subsystem Specification defines the specific functionality required to enable top level capabilities, associated design standards, and element/module level functional and performance requirements."
Thermal Control System that maintains all habitable volumes and internal and external components within thermal limits.
"Rationale: Each Element/Module in the integrated Gateway stack must maintain its components, both internal and external, within thermal limits."
Any modules with habitable volumes must also maintain the internal environment within thermal limits for both crewed and uncrewed operations.
The Gateway shall operate within thermal limits independent of flight attitude.
The integrated Gateway stack must have the flexibility to be pointed in any direction to support mission objectives.
"Thermal Control System to operate within thermal limits at any attitude necessary, making its performance flight attitude independent."
"However, indefinite duration capability at any attitude is not possible, so duration limits must be established and provided to stakeholders."
The Gateway shall apply an architecture that provides for module thermal independence during non-contingency operations.
Rationale: Each Module's TCS will need to be responsible for its own thermal independence and ability to manage its own heatloads during nominal operations.
"The Gateway shall have crew hatches in accordance with DSG-SPEC-HTCH-019, Gateway Program Subsystem Specification for Hatches."
"Rationale: Providing a common set of functional requirements for all Gateway crew hatches simplifies crew training, eases operations, increases reliability of operation, and streamlines the development process by providing a ready set of base requirements for an end item specification."
"The Gateway shall continuously record structural dynamic responses at discrete locations and process data to assess structural life consumption and perform damage detection, location, and assessment."
The structural health monitoring system is required to measure responses of the Gateway to actual dynamic loads in order to assess structural life usage vs predicted loads.
Knowledge of life state can be used to modify operations to either add constraints to protect structural life or to reduce un-needed constraints.
"Due to limitations on crew time and other Gateway resources, automated structural damage detection, location, and assessment can be utilized to determine criticality of damage and focus remediation efforts."
The Gateway shall limit atmospheric leakage rate to less than 0.05 kg/day at ambient pressure in isolated module configuration.
Rationale: This leakage rate is consistent with ISS experience and reflects the leakage of multiple elements aggregated on-orbit.
The Gateway shall detect atmospheric leaks greater than <TBD-L2-GW-011>.
"Rationale: Detection of leaks will allow for response and repair, in the event of an atmospheric leak, by the crew or autonomously."
The Gateway shall localize atmospheric leaks to within <TBD-L2-GW-012> location in any pressurized habitable volume.
"Rationale: Localization of leaks will allow for response and repair, in the event of an atmospheric leak, by the crew during crewed periods or autonomously during uncrewed periods."
"The Gateway shall have an 800mm -0.3mm/+unlimited diameter transfer passageway between modules mated with the Gateway Docking System (GDS), as described in the DSG-SPEC- MECH-017, Gateway Program Docking System Specification."
"Rationale: DSG-SPEC-MECH-017, Gateway Program Docking System Specification compliant mechanisms only provide an 800mm diameter passageway for a distance of 3-4 ft when mated."
Items to be transferred between Gateway Elements need to be sized appropriately.
The Gateway shall be equipped with passive or active crew exercise equipment isolation systems to reduce induced loads to the primary structure to less than or equal to <TBD-L2-GW- Gateway structure.
The Gateway shall have a Probability of No Penetration (PNP) greater than or equal to for items with the potential to create a catastrophic hazard if impacted or punctured by MMOD.
Rationale: This requirement sets the limit for the probability of no penetration.
This requirement is based upon the ISS PNP requirement for permanent modules.
Area is the outer most surface area of the module and is in m^2 and Time is in years.
Time used for calculation should encompass the expected life of the module.
"For the purposes of MMOD, a penetration is defined as damage/failure to stored energy devices that causes a hazard to crew or Gateway survivability."
"Typically, penetration is defined as a partial or complete perforation of the pressure vessel or casing, detached spall from the pressure vessel wall, damage to the pressure vessel that would allow unstable crack growth, or deformation of a casing of rotating machinery such that the deformation could intrude into the dynamic envelope of the rotating device."
"For metallic tank pressure vessels, critical damage is defined as a penetration depth in the pressure shell of 20% of the thickness of the pressure shell."
"For composite overwrapped pressure vessels, critical damage is defined as penetration of 90% of the composite overwrap thickness."
Solar array panels are not included in this requirement.
"The meteoroid environment is defined in NASA/TM-2015-218214, NASA Meteoroid Engineering Model Release 2.0, and the orbital debris environment is defined in NASA/TP-2015-218592, NASA Orbital Debris Engineering Model."
The Gateway shall provide at least single failure tolerance to catastrophic events.
"Catastrophic hazards that cannot be controlled using failure tolerance may be exempted from the failure tolerance requirements with mandatory concurrence from the Technical Authorities and Director, Johnson Space Center (JSC) (for crew risk acceptance)."
"Exemptions from failure tolerance shall be requested in accordance with DSG-RQMT-011, Gateway Hazard Analysis Requirements."
Rationale: Compliance with this requirement can be accomplished at the end item level or through a combination of hazard controls at the Module/System levels and end item level.
A common way to improve reliability and thus meet safety requirements is to use systems that tolerate failures when complete failure avoidance isn’t practical.
"Specific hazard controls and implementation must be derived from an integrated design and safety analysis performed in accordance with DSG-RQMT-011, Gateway Hazard Analysis Requirements."
Acceptance of these approaches by the Technical Authorities avoids processing waivers for numerous hazard causes where failure tolerance is not the appropriate approach.
Additional failure tolerance may be required to meet systems reliability requirements.
"The Gateway shall provide the capability for autonomous operation of system and subsystem functions, which if lost, would result in a catastrophic event."
"Rationale: This capability means that the system does not depend on communication with Earth (e.g., mission control) to perform functions that are required for control of catastrophic hazards."
"While the crew is present, the Gateway should automate catastrophic hazard controls to minimize the need for crew actions, using crew action only as a last resort where automation is not practical."
"Rationale: Critical hazards do not require failure tolerance for human-rating, however, critical hazards can have a significant impact on Loss of Mission (LOM) risk."
The Gateway Program will derive the specific hazard controls and implementation from an integrated design and safety analysis performed in accordance with DSG-RQMT-011.
Failure tolerance for critical hazards may be required to meet probability of loss of mission or system reliability requirements (if applicable).
The Gateway shall provide the appropriate failure tolerance capability without the use of emergency equipment and systems.
"Rationale: Emergency systems, EVA or emergency operations cannot be used as a leg of failure tolerance as these emergency systems and equipment cannot definitively prevent an initiating event."
"As a result, the mitigation of catastrophic and critical hazards will implement a FT strategy without the use of EVA, emergency systems, or emergency operations."
"However, the use of EVA, emergency systems, and contingency or emergency operations will be considered a Crew Survival Method (CSM) to prevent Loss of Crew (LOC) in the event all other approved hazard controls have failed."
"The Gateway shall protect redundant systems, redundant subsystems, and redundant major elements of subsystems (such as assemblies, panels, power supplies, tanks, controls, and associated interconnecting wiring and fluid lines) to ensure that an unexpected event which damages one is not likely to prevent the other from performing the functions."
"Rationale: Where redundancy is used to satisfy the failure tolerance requirement, this design requirement provides maximum protection from common cause events."
This requirement does not mandate physical separation but physical separation has been a historically demonstrated method to mitigate common cause failures.
"System analysis needs to consider the channelization of all capabilities necessary to manage Fault, Detection, Isolation and Recovery (FDIR) including sensors and utility services such as power, thermal and data."
"Rationale: For NASA sponsored end items the risk of human casualty on the ground is limited to less than 1 in 10,000 as required per NASA-STD-8719.14A, Process for Limiting Orbital Debris."
The NASA-STD is a companion to NPR 8715.6 and provides specific requirements and assessment methods to assure compliance with the NPR.
"The principal factors used in calculating the risk of human casualty from uncontrolled reentries include the number of debris expected to reach the surface of the Earth, the kinetic energy of each surviving debris, and the amount of the world population potentially at risk."
The last factor is a function of both the orbital inclination of the space structure prior to re-entry and the year in which the re-entry occurs.
"Extensive human casualty studies by the U.S. Government, including the Department of Defense and the Department of Energy, have examined the probability of injury and/or death from falling debris for a variety of impacting kinetic energies to humans."
A kinetic energy threshold criterion of 15 joules is widely accepted as the minimum level for potential injury to an unprotected person.
"The Gateway shall comply with the requirements in DSG-SPEC-CHP-010, Gateway Program Subsystem Specification for Crew Health and Performance (CHP)."
Rationale: DSG-SPEC-CHP-010 includes content decomposed from requirements in DSG-RQMT-001 regarding crew health and performance.
"This specification addresses aspects of crew health and performance such as Medical Capability, Environmental Health, Behavioral Health, Wellness Support, Crew Performance Capability, Countermeasures, and CHP Data Integration across all Gateway modules and includes an applicability Matrix denoting applicability to specific Gateway Elements."
The Gateway shall provide a habitable volume that accommodates crew living and working tasks.
"Rationale: To maintain a habitable volume and high level of mission performance and safety, it is important that the architectural layout of the vehicle is functionally designed to provide defined locations and volumes that allow for expected crew activities, including mission operations, habitability functions, and translation (for example, movement between areas)."
"Required volume is a function of the number of crewmembers, number of mission and contingency days, and crew operations (both nominal and off-nominal)."
"Adequate internal size, in terms of volume and surface area, needs to be provided to ensure expected number of crewmembers can safely, efficiently, and effectively perform mission tasks, including, but not limited to, work, sleep, eat, personal hygiene, private crew areas, translation, egress, ingress, pressurized suit donning, emergency medical treatment, and other tasks necessary for a safe and successful mission."
"Mission and volume designers are to carefully analyze volume needs of the crew, crew equipment, storage, trash containment volumes and trash transition plans to ensure they are adequately sized to provide adequate net habitable volume for the crew to effectively and efficiently perform mission objectives."
"Every effort should be made to separate functional areas for activities that could degrade or operationally conflict with each other, particularly emergency response activities, or that produce environmental conditions that are detrimental to mission performance or safety (for example, glare, noise, vibrations, heat, odors, etc.)."
Co-location of unrelated activities could degrade operations resulting in increased workload and operational delays.
"Furthermore, traffic flow is not to interfere with other unrelated operational and recreational activities of the crew."
"These activities may include sensitive spacecraft control, routine servicing, experimentation, eating, sleep, and relaxation."
"Similarly, co-location of related, sequential functional work areas can reduce transit time, communication errors, and operational delays."
"For example, food stowage and food preparation areas should be located near one another to minimize the time required to retrieve food for meals and promote group dining for behavioral health benefits; and consistent spatial orientation and visual distinctions such as identifiers and aids can promote effective execution of mission tasking."
"The management of crew nutrition is defined as influencing the design, provision, and operational implementation of in-flight nourishment of crewmembers over the course of the mission to perform Gateway tasks."
"Nutrition capabilities include provisions for food and food hydration, crew hydration, storage and preparation facilities, dining accommodations (group meals), tracking of nutritional intake, food system training, and implementation of individualized or standard in-flight menus."
"Nutrition also includes management of food system quality (food acceptability and metabolic intake (Intravehicular Activity (IVA) and EVA)), food safety (food micro-organism levels, cross-contamination prevention, cross-contamination separation), and food preparation (heating, rehydration, dining accommodations, in-flight food preparation time), and clean-up (food system waste, food system spill control, food system cleaning and sanitizing)."
"The Gateway shall manage crew medical care, per DSG-SPEC-CHP-010, Gateway Program Subsystem Specification for CHP."
"The management of medical care is defined as influencing the design, provision, and operational implementation of the relevant in-flight medical capabilities."
"Medical care capabilities include clinical care, imaging, laboratory management, and pharmacy management, wellness support, and an integrated crew health and performance data system."
"Clinical care provides in-flight capabilities for the prevention, diagnosis, treatment, monitoring, and long-term management of medical conditions."
"Imaging provides in-flight capabilities for diagnostic imaging in support of the provision of clinical care and includes all hardware, software, and analysis capabilities required for the capturing and processing of diagnostic imaging."
"Laboratory management provides in-flight capabilities for laboratory analysis in support of the provision of clinical care and includes all hardware, software, and analysis capabilities required for the collection and processing of biological samples."
Pharmacy management provides in-flight capabilities for the administration of pharmaceuticals in support of clinical care and includes all medications and the mechanisms used to prepare and deliver them and track their use.
"Wellness support capabilities include functions required to promote, maintain, and protect the physical and mental well-being of the crewmembers."
"This support comes in the form of physiological health management, nutrition management, behavioral support, and sleep management."
Medical care also encompasses two-way private voice and video communication with Mission Systems.
"Also under medical care are the capabilities and plans for handling deceased crewmembers that are socially, biologically, and physically acceptable."
"NASA-STD-3001, Volume 1, includes definitions of the levels of medical care required to reduce the risk that exploration missions are impacted by crew medical issues and to ensure that long-term astronaut health risks are managed within acceptable limits."
"As mission duration and complexity increase, the capability required to prevent and manage medical contingencies correspondingly increases."
"The ability to provide the designated level of care applies to all flight phases, including during pressurized suited operations."
"A medical system provides preventive care, diagnostic care, and medical treatment and must consider any possible in-flight medical need including persistent health conditions."
Additional information on Levels of Care can be found in NASA/TM- System Development.
"To date, there have been multiple illnesses and injuries during all mission phases and, in the absence of adequate clinical capabilities, the likelihood of significant negative impact to mission viability due to crewmember illness or injury is increased."
"Because immediate transport to a clinical facility is not an option on-orbit, in flight health care is essential and is optimal with an integrated crew health data system, to support the detection, diagnosis, and treatment of illness and injury."
"An integrated crew health data system aids in the management of crew health in-flight, especially for the early detection and intervention for medical issues."
"During missions with longer evacuation times and mission duration, the management of data, information, and ability for extensible knowledge augmentation becomes increasingly important in order to manage the medical care and wellness of the crew efficiently."
"To aid the crew in basic decision support through automatic organization of data and knowledge augmentation materials (such as medical references), an integrated system should collect, process, and store all crew health-relevant data from various sources (vehicle and ground), in addition to crew task performance data, and make this data available to both the crewmembers and ground support."
"Necessary capabilities include data sources interfaces for secure data collection, data storage, descriptive analytics, advanced analytics, and data user interfaces."
"Descriptive analytics provides in-flight capabilities for modelling and analytics, data mining, discovery and search and report generation."
Advanced analytics can provide in-flight capabilities to store knowledge bases and provide basic decision support functionality.
"Data user interfaces provides in-flight capabilities for the crewmembers to interface with the vehicle's habitat data infrastructure, including messaging, data input, and display."
"The management of crew behavioral health is defined as influencing the design, provision, and operational implementation of in-flight behavioral health."
"Behavioral health capabilities include the assessment, monitoring, and intervention pertaining to psychological adaptation, workload, sleep and fatigue issues, key relationships (e.g., relationships with family and friends, intra-crew relationships, and relationships between the crew and ground), and behavioral medicine."
"Also includes the implementation of individually-tailored countermeasures, support of work/life balance, provision of leisure activities, delivery of family support services, provision of private crew areas, motivation, alertness, cognition, and adaptation of the crewmember during flight."
Behavioral health management is needed to prevent and ameliorate the deleterious effects of living in an isolated and confined space and to preserve both individual and “crew as a unit” behavioral health and performance and cohesive functionality.
"The management of crew behavioral health includes: design, provision, operational implementation, and hardware/software that is necessary to provide in-flight behavioral health support."
"Behavioral health and performance capabilities include assessment, monitoring, and mitigation strategies are related to psychological adaptation and dependent on workload, sleep and fatigue issues."
"Providing individualized countermeasures to support work/life balance, private crew areas, leisure activities and family support services are dependent on the crew member’s alertness, cognition, motivation, and adaptation."
"The management of crew sleep is defined as the design, provision, and operational implementation of in-flight sleep capabilities."
"Sleep capabilities include, but not limited to, sleep accommodations that are temperature controlled and that eliminate noise and light pollution, schedules for sleep shifting for mission essential tasks, variable wavelength light assemblies, software supporting electronic devices with visual displays consistent with circadian rhythm lighting requirements, prevention of fatigue-induced performance errors, and preservation of the ability of crewmembers to respond in contingency situations."
"Sleep maintenance includes blue blocking glasses, and properly ground tested medications including but not limited to: chronobiologic, alertness, sedative- hypnotics, soporifics and control of ambient environmental factors."
The Gateway shall manage crew physiological health.
"The management of crew physiological health is defined as influencing the design, provision, and operational implementation of in-flight pre, in, and post-flight countermeasures systems to mitigate risks to crew health and performance."
"Physiological health capabilities include activities such as exercise, hygiene, and other conditioning and countermeasures against physiological disturbances to body systems (e.g., musculoskeletal, cardiovascular, respiratory, gastrointestinal, genitourinary, neurovestibular, ocular, hearing, immune, and reproductive)."
"Pre-flight, in-flight, and post-flight countermeasures shall include resistance and aerobic exercise hardware, sensorimotor preservation hardware and software systems, exercise software, nutritional supplementation, pharmaceutical supplementation, and human health and performance software optimization tools."
"Nutritional / pharmaceutical supplementation may include provision of additional caloric content, specific macronutrients, and/or other pharmaceutical supplementation to the existing food system."
"These may be used pre, in, and post flight and factors including shelf life, and storage should be incorporated in nutritional tracking software."
Human health and performance optimization tools will require incorporation of vehicle systems data and other CHP systems data in a data management system that will allow for running existing algorithms to inform/predict crew health and performance capabilities.
Incorporating this information into display/informatics systems is critical.
The intent of this specific countermeasures is to align with the phased approach of using Gateway as a proving ground to develop tools for improved crew autonomy.
The Gateway system shall limit cross-contamination between food preparation areas and body waste management and hygiene areas.
Rationale: Limiting the transfer of microorganisms to the food preparation areas protects crew health.
"To properly control the contamination of the food preparation area from the body waste management and hygiene areas, a task analysis must be performed to identify important design factors (i.e. concurrent use of the areas, volume needed at each location to prevent contact, distance between areas, storage and accessibility requirements, etc.)."
The chance of cross-contamination can be further decreased by designating body waste management and personal hygiene areas as far away from food preparation areas as possible.
"While vehicle design constraints may limit the distance between the areas, measures must be in place to prevent food contamination during preparation, such as a higher quality body waste containment and isolation system."
The Gateway shall protect crew from toxicological hazards.
"Rationale: Environmental hazard protection includes capabilities to measure, monitor, assess, alert, and respond to toxicological concerns in the Gateway atmosphere."
"Toxicological protection ensures in-flight capabilities for toxicological monitoring, assessment, and mitigation in Gateway air and water."
"Additional examples include provisions of personal protective equipment for crew survival in a compromised atmosphere, data recording and display, fire detection, warning, and extinguishing, and emergency equipment accessibility."
The Gateway shall protect crew from microbial hazards.
"Rationale: Environmental hazard protection includes capabilities to measure, monitor, assess, alert, and respond to microbial concerns in the Gateway atmosphere."
"Microbial environmental protection ensures in-flight capabilities for monitoring and mitigating microbial contamination in the air, water, and surfaces as well as capabilities for decontamination."
This also includes the capability to maintain personal hygiene and have adequate food and waste storage.
The Gateway shall protect crew from acoustic hazards.
"Rationale: Environmental hazard protection includes capabilities to measure, monitor, assess, alert, and respond to acoustic concerns in the Gateway atmosphere."
"Acoustic environmental protection ensures in-flight capabilities for monitoring, assessing, and mitigating harmful acoustic environments through hearing protection and acoustic and vibrational dampening countermeasures."
The Gateway shall protect crew from radiation hazards.
"Rationale: Environmental hazard protection includes capabilities to measure, monitor, assess, alert, and respond to radiation concerns in the Gateway atmosphere."
Radiation environmental protection ensures in-flight capabilities for the monitoring and provision of alerts and warnings for the space weather (ionizing radiation) environment.
"This also includes protection from, and treatment of, exposure to highly ionizing radiation environments, in addition to capabilities to maintain safe levels of non-ionizing radiation exposure."
The Gateway shall maintain a shirt sleeve environment in all habitable volumes during crewed missions.
"Rationale: A safe, breathable atmosphere is critical to crew health and performance."
"Monitoring atmospheric quality, alerting ground and crew of off-nominal conditions, and evaluating environmental data trends during vehicle flight operations is essential to crew health support."
"The vehicle system needs to be robust enough to control or allow crew control of atmospheric pressure, humidity, temperature, ventilation flow rate, airborne particulates, partial pressure of O2, CO2, and trace contaminants within ranges necessary to maintain human health and safety."
"The vehicle must also be robust enough to maintain safe, comfortable atmospheric conditions within physiological ranges during crew induced thermal loading such as exercise."
The Gateway shall manage expected biological hazards.
"Rationale: Management is defined as influencing the design, provision, and operational implementation of the capability for controlling biological hazards."
"Biological hazards include blood, bodily fluids, medical equipment, and sharp items."
"If not properly contained, contents could damage equipment, injure crewmembers, and transmit disease."
"Biological waste, including vomit and feminine hygiene products, can also cause injury and transmit disease."
The Gateway shall incorporate window(s) in a habitable element for crew viewing that maximize views of both the Moon and Earth measuring no less than 50.8 centimeters (20 inches) in diameter.
"Rationale: This requirement supports crew psychological health, vehicle inspection, and public outreach."
The window size supports simultaneous use by two crewmembers and is consistent with the window currently in the ISS U.S.
"More than one window may be required as the nominal Gateway NRHO orbit and SPEA attitude constrains observations (duration, distance, and look angle) for any single window."
"While attitude changes can optimize window views, no propellant has been allocated for maneuvers and CMG desaturations."
"The Gateway shall tolerate an inadvertent operator action, as identified by a human error analysis (HEA), without causing a catastrophic event."
"Rationale: An operator is defined as any human that commands or interfaces with the space system during the mission, including humans in the control centers."
"The appropriate level of protection (i.e., one, two, or more inadvertent actions) is determined by an integrated human error and hazard analysis."
This requirement is not intended to prevent operators from initially selecting the wrong control.
The system needs to ensure the crew can recover from inadvertent input with minimal impact by incorporating the capability for undoing control input.
The Gateway shall tolerate inadvertent operator action in the presence of any single system failure.
The intent of this requirement is to provide a robust human-system interface design that cannot be defeated by a system failure.
"Where the system is designed to protect for more than one inadvertent action, the level of protection after a single system failure may be reduced - but still protects from a single inadvertent operator action."
"In addition, this ensures that back-up capabilities, such as back-up flight software, maintain the same-level of tolerance to human error as the primary system."
"Prevent human error in the maintenance, operation, and control of the system."
Design the system to limit the negative effects of errors.
"Rationale: Human error is either an action that is not intended or desired by the human or a failure on the part of the human to perform a prescribed action within specified limits of accuracy, sequence or time that fails to produce the expected result and has led or has the potential to lead to an unwanted consequence."
Controlling Human Error requires identification of human errors through human error analysis (HEA).
"The HEA is a systematic approach to evaluate human actions, identify potential human error, model human performance, and qualitatively characterize how human error affects a system."
HEA provides an evaluation of human actions and error in an effort to generate system improvements that reduce the frequency of error and minimize the negative effects on the system.
"The human error analysis considers mission operations while the crew is interacting with the space system - including crew operations, ground control operations (typically covered via hazard reports), and ground processing operations with flight crew interfaces."
The analysis also covers response to system failures and abort scenarios.
"Identify other types of human error that would result in a catastrophic event (e.g., operational errors, errors of omission, timing errors)."
Apply the appropriate error management as described in this requirement.
The Gateway shall protect crew from decompression sickness (DCS).
The Gateway systems and ConOps must protect crew from DCS related to pressure changes for EVA operations (including preparation and return) and off-nominal depressurization situations.
DCS risk limits are defined in NASA-STD-3001 Volume 1 paragraph 4.4.3.6.1 DCS Prevention.
This requirement works together with V2 6009 DCS Treatment Capability and V2 11032 LEA Suited DCS Prevention Capability.
"For EVA operations, the DCS prevention design must be coordinated for total pressure, ppO2, and pre-breath protocol between all vehicles/elements inhabited by EVA crew prior to and after EVA (e.g., Orion, Gateway, Airlock, Lander)."
"The Gateway shall comply with applicable requirements in DSG-SPEC-CS-006, Gateway Program Subsystem Specification for Crew Systems."
"The Crew Systems system includes IVA subsystems such as galley, housekeeping, crew hygiene, restraints and mobility aids, crew sleep, stowage, inventory management, tools and maintenance, and trash management."
Some of these subsystems are distributed across multiple Gateway modules and are desired to function with crew and IVR.
"The specification levies some Crew Systems requirements to multiple modules, identifying each requirement’s module allocation."
The Gateway shall provide for crew to conduct personal hygiene.
"Rationale: Personal hygiene includes body and hair washing, shaving, dental hygiene, and changing clothes in a private volume."
The volume should be separate from sleep and body waste management volumes.
The Gateway shall provide a trash management system to contain expected trash and evolved gases.
"The trash management system must contain all trash, including hazardous waste, with appropriate wrappings and/or barriers that is usable by crew and does not allow inadvertent release of trash into the habitable volume."
"If not properly contained, trash contents could damage equipment, injure crewmembers, or transmit disease."
Operations analysis should be performed to drive trash containment design.
"Analysis should evaluate all crew tasks that will generate trash over the duration of a mission, including ascent and return."
"The trash containment design should consider crew usability, how and where trash will be stowed, duration of stowage until disposal, and method of disposal."
The Gateway shall provide an inventory management system (IMS).
"Inventory management allows the identification of flight equipment in specified locations to maintain organization and efficiency for the crew or IVR, and to identify usage and usage rates for usage and resupply decisions for the crew and ground support."
"IMS needs to assist in tracking and potentially locating logistics, cargo, payload, or utilization items, and provides logistics awareness to ground support."
The Gateway shall provide a stowage system that can be monitored via the IMS.
The stowage system does not include vehicle secondary structure.
The Gateway shall accommodate restraints and mobility aids for IVA operations.
"Rationale: Without gravity to hold an individual on a standing or sitting surface, the body naturally moves in the opposite direction of an applied force."
The cognitive and physical work required to maintain body position during a task can interfere with the task performance.
"Mobility aids, such as hand and foot restraints, allow crew-members to efficiently move from one location to another in 0 g, as well as reduce the likelihood of inadvertent collision into hardware that may cause damage to the vehicle or injury to the crew."
"Mobility aids must be designed to accommodate a pressurized suited crew-member, a non-suited crew-member, and IVR assets by providing clearance, non-slip surfaces, and non-circular cross sections."
"Without predefined mobility aids, personnel will use available equipment that may be damaged from induced loads."
The restraints and mobility aids should be compatible with IVR.
The Gateway shall provide for self-rescue of an EVA crewperson who becomes separated from the Gateway spacecraft.
The Safety Tether is the primary means of crew restraint for EVA.
An EVA crewmember could become separated from the Gateway (i.e. if the crewmember loses grip or comes out of the foot restraint AND if the safety tether breaks or is improperly configured).
"If the combination of these happen, the crewmember would need a self-rescue method for survival to return to the Gateway."
Orion does not support astronaut egress or ingress for EVA (nominal or contingency) from the crew module.
"The Gateway EVA capability is needed to support external contingency maintenance operations, EVA system demonstrations, and payload and utilization needs."
EVAs may be nominal (pre-planned prior to the crewed mission) or contingency (responding to an off-nominal scenario which arises during the mission).
"EVA support includes the capability to deliver and prepare the EVA suits, ingress and egress the gateway while minimizing the loss of cabin atmosphere, translation and post-EVA suit maintenance and stowage."
EVA operations will be available once the Gateway airlock module is added to the Gateway and EVA suits are present.
Nominal maintenance operations and utilization operations will be performed by EVR.
The Gateway shall establish EVA worksites <TBR-L2-GW-013>.
"Rationale: Worksites will be assessed as the design matures to determine if they require handrails, Body Restraint Tether (BRT), Worksite Interface (WIF), Articulating Portable Foot Restraint (APFR) i.e. dedicated vs. free-float."
Worksites <TBR-L2-GW-013> could include EVR backup and utilization.
"Further analysis will be done on forces, torques, envelopes, and LPGF clocking, etc., to support manipulator end-effector requirements and design."
"The specific number and placement of LPGF's will be determined through joint, integrated analysis by the Contractor and NASA."
The total number of SORI-OVs to be placed on the PPE is dependent on the PPE design and integrated Gateway utilization philosophy and will be determined through an integrated assessment with Gateway.
An integrated analysis will be performed to determine worksite locations based on Gateway system and module needs.
"The Gateway shall comply with interface requirements in DSG-IRD-EVA-008, Gateway Program Extravehicular Activity (EVA) Compatibility Interface Requirements."
"Rationale: HEOMD-004, Human Exploration Requirements, specifies the Gateway shall provide the capability for EVA operations."
EVA interfaces are designed to be compatible with EVA operations.
"This includes restraining the crewmember, safeguarding both the vehicle and crewmember while working, and accommodating EVA contingency operations using a standard EVA tool set."
The Gateway shall accommodate EVA capability without blocking access to the visiting crewed vehicle(s) during the EVA.
"Rationale: During prebreathe operations, campout, or if the need arises to depress equipment lock as secondary ingress path, an airlock situated in between the stack and the crewed vehicle isolates IVA crew from the VV or indicates they have to sit in the VV (and may not be able to command Airlock repress from that side)."
The Gateway shall provide EVA compatible accommodations to support continuous translation across adjacent (berthed/docked) modules.
Rationale: EVA translation across the Gateway stack is necessary to support both EVA test objectives and contingency EVAs regardless of the status of EVR capabilities.
"Translation aids, such as EVA Handrails, and a path free of obstructions or hazards must be designed to support the movement of EVA crew members between the crew lock and EVA work sites."
Each module is responsible for linking translation paths between modules.
This may result in the need for handrails to be installed around the circumference of the end of each module and/or extending radial towards the end-cone or docking adapter.
"It is not assumed that each module will have a consistent “clocking” of translation paths, therefore a flexible design solution may be necessary depending on the stack architecture."
Reference DSG-IRD-EVA-008 for EVA translation path requirements to ensure that the translation paths are designed in accordance to be compatible with the suit.
An integrated analysis will be performed to optimize continuous translation paths across the integrated Gateway system.
The Gateway shall provide recharge services for at least two-crew EVA suits two times per crewed mission.
Rationale: Part of enabling EVA is servicing the EVA suits.
"Servicing and checkout of the suits are performed between EVAs on a maintenance schedule and proceeding any EVA, including recharging consumables."
Vehicle services to the suit are included through an umbilical interface panel and umbilicals in the Airlock.
"Supporting prebreathe and volume for suit don/doff, and suit stowage are necessary to support EVAs."
"The EVR IRDD provides the interoperability requirements to enable common robotic interface installation on modules, ORUs and payloads."
"The Gateway shall provide power, data, video, structural support and thermal services, as applicable, to external robotically compatible equipment, during all phases of operation."
The external robotics includes a set of worksite/payload interface equipment (including SORI) that transfers these services from Gateway modules to payloads.
These services will also be provided during manipulation (except thermal control).
Thermal services are specifically transfer of ATCS fluid.
An integrated analysis will be performed to determine the location of translation paths.
The Gateway shall provide worksites for external robotics operations in accordance with CSA- GWY-ID-0001.
Rationale: EVR operations to remove and install equipment require work areas that are designed for robotic compatibility.
Worksites implies both the contact regions where equipment is installed and the surrounding area which must have clearance and inadvertent contact resistance.
Operations include but are not limited to inspection.
A Gateway integrated analysis will be performed to identify where EVR worksites will be located to support Gateway operations.
The Gateway shall have external ORUs that are compatible with robotics per the EVR Interface Requirements and Definition Document CSA-GWY-ID-0001.
"Rationale: Gateway EVA is available on a contingency basis only, therefore any external ORUs must plan for robotics to be the primary means for installation and removal."
The Gateway shall autonomously perform off-loading and re-loading of external logistics vehicles.
The Gateway will provide a capability to off-load the external ORUs and experimental payloads that can be used without requiring crew or constant ground communication.
"The Gateway shall provide external robotically compatible attachment locations that provide services for ORUs, systems, and payloads during all ORU/payload life-cycle phases: operation, non-operation, external stowage, robotic manipulation and any others."
"Rationale: External robotically-compatible attachment locations with standard SORI, LPGF, and LORI fixtures will be used for ORUs for Gateway maintenance, external cargo not used immediately on delivery by the Logistics Module (or other source), and active payload instruments and hardware."
"Multiple instruments may be hosted on a single SORI or LPGF, assuming the instruments stay within the resource, structural and volume envelopes."
The interface plate should allow for additional capability of long duration stare/pointing.
Quantities and locations will be defined in <TBD-L2-GW-065> for utilization planning and module procurement.
The Gateway shall provide a robotically compatible science airlock.
Rationale: To support science and utilization of robotic transfer of payloads and ORUs into/out of the Science Airlock by both internal and external robotics.
The Gateway shall provide redundant robotic translation paths and utilization access (single- fault tolerance).
Rationale: Ensures that any single LPGF failure cannot trap the arm or eliminate access for utilization and maintenance.
Translation paths need to be designed according to manipulator reach and maintained to be free of obstructions.
The Gateway shall support external robotics performing end-over-end translation to perform its functions on all external surfaces of the Gateway where robotics activities are planned.
"The external robotic manipulators are expected to be dual-ended with walk- over capability, and a moving base analogous to ISS-MBS is not planned."
"In order to fulfill the operational need, it has to translate around the Gateway in order to execute its functions."
This includes reconfiguring the TTE network and the power distribution network.
Rationale: Gateway needs to provide spaced out base points for External Robotic manipulators to access the areas where activities are planned to take place.
"To do this, Gateway needs to attach grapple fixtures to structural hard points and route cabling to the connectors."
The coverage of Gateway will be assessed and analyzed to determine the location requirements.
"The Gateway shall have an external robotic system capable of autonomous operations that implements the following functions on the exterior of Gateway: inspection, installation and removal of payloads, transfer of equipment through the science airlock, off-loading and re- loading of logistics vehicles, free-flying vehicle capture and release, lunar and planetary mission equipment transfer, lunar and planetary element assembly, berthing and unberthing of modules and vehicles, removal and replacement of ORUs, self-maintenance, and assistance to EVA."
"Rationale: This provides the list of primary functions that EVR will furnish to Gateway, and which Gateway needs to support with the appropriate infrastructure."
"The functions are intended to be autonomous to eliminate dependence on crew presence, to reduce communication and control resource usage on the ground, to reduce operational lifecycle costs and to be a proving ground for path to Mars."
"The Gateway shall limit disturbances to the vehicle and robotics, during sensitive External Robotic operations, to a level <TBD-L2-GW-014> that will not affect robot performance and safety, without the need for flight-specific analysis, including after a single failure."
"Rationale: Based on ISS experience, attitude and orbit control systems need to have a passive mode to minimize disturbances during robotic ops."
"On ISS this involved selection of a Torque Equilibrium Attitude (TEA) to maximize CMG control capacity, controlling exercise, not performing dockings or orbital maintenance, and inhibiting CMG desaturations when the robotic hardware was within 2 ft of structure."
The Gateway shall support a network with a TTE end-over-end translation of the external robotics.
"Rationale: Robotic end-to-end relocation will require a reconfiguration of TTE topology, as well as payload and ORU mate/demate operations."
The Gateway shall support self-deployment of the EVR Element upon initial delivery.
"Rationale: When the logistics module arrives at Gateway, there will likely be no crew to assist, and EVA time is not meant to be expended on nominal operations even if they were there."
"The Gateway shall comply with applicable requirements in DSG-SPEC-IVR-013, Gateway Program Subsystem Specification for Intravehicular Robotics."
"To promote the successful integration between the internal robotics and the Gateway modules and systems, a set of requirements that dictates interface, performance, and functions was developed."
Adherence to this subsystem specification will ensure that the internal robotics system can successfully achieve its tasks and goals while minimizing the overall impact to the Gateway.
The Gateway shall provide the ability to access and service designated internal payloads and logistics without the need for crew intervention.
"Rationale: During uncrewed periods, payloads and logistics will be delivered to the Gateway and will need to be able to be extracted, moved, unpacked, installed, operated, maintained and serviced."
The Gateway shall have internal robotic assets capable of inspection.
"Rationale: Per requirement of dormancy / uncrewed periods of up to 3 years (HEOMD-01: DSG-R-5), multiple activities in Gateway may require mobile robots, or robots with dexterous manipulation capability, to perform detailed inspections."
IVR can be controlled either autonomously or with assistance from Earth-based mission control.
The Gateway shall support internal robotics access between modules.
"Rationale: During uncrewed periods, internal robotics must be able to either pass through open hatches or pass objects through open hatches to successfully accomplish most tasks."
"Based on vestibule length, this might include the need for IVR translation aids near the hatch or even in the vestibule."
The Gateway shall provide a method for determining and communicating internal location information that is common to internal robotics and human operators (crew and ground).
The Gateway needs to provide a similar approach and a common language for discussing location that satisfies both robotic and human needs.
Complexity of a robotic system is greatly reduced if an appropriate markings system is used to simplify identification and localization.
"The Gateway shall ensure that payloads, equipment, and tools used by internal robotics have interfaces for both humans and robots."
Rationale: This will ensure all locations accessible by internal robotics is also accessible to crew.
Complexity of a robotic system is greatly reduced if design of human interfaces also considers robotic manipulation.
Equipment includes systems that are maintainable and repairable.
These interfaces and any possible adapters will be covered in the IVR ICD.
The Gateway shall provide stowage and charging interfaces to support internal robotics operations.
Rationale: Gateway needs to distribute resources required to support internal robotics operations to the modules where internal robotics operations are performed.
"In particular, certain modules will need to serve as ""home base"" for IVR system components."
These docking stations will include room for IVR stowage as well as charging and network interfaces.
The Gateway shall provide a reconfigurable mobile video camera system for inspection and internal robotic operations support.
"Rationale: Robotic tasks can be aided by a free flying camera providing a ""bird's eye view"", however, this view can be moved/vary between and during tasks."
This will be compatible with internal wireless communications.
The Gateway shall use robotically compatible interfaces to allow the IVR system to access/retrieve/install internal logistics cargo.
"Rationale: To help reduce crew time required for logistics management during the 30 day mission, the modules should use robotically compatible interfaces to allow the IVR system to access/retrieve/install logistics cargo."
The Gateway shall provide resources and interfaces for Utilization payloads and payload accommodations as defined in the Gateway Utilization Payload Interface Requirement Document <TBD-L2-GW-062>.
"Rationale: Gateway is intended to support diverse science, (along with associated exploration), activities and close Strategic Knowledge Gaps."
"Gateway will accommodate crewed and uncrewed placement and operation of science assets e.g. internal investigations, external packages, In Situ Resource Utilization (ISRU) operations, transfer of surface samples, sample return to Earth, and science data collection/transfer."
"Operations of the Gateway will also include a robotic arm for installing experiments, a science airlock, and the ability to conduct operations on each element."
Internal and external payloads will be operated during crewed and uncrewed periods.
Payloads will need the specified Gateway resources available during operations.
Most payloads would not require crew interaction (likely apart from instrument installation and setup) and would continue to operate during uncrewed periods.
Resource interfaces between Gateway modules and the internal research accommodations (facilities) and between the accommodations and the payloads need to be standardized throughout Gateway.
Maximizes placement flexibility for internal payload facilities and payloads.
Minimizes flight hardware development to support payloads.
Minimizes ground support equipment for hardware test.
The Gateway shall allocate a minimum of 5.15 Tbits/day (644 GB/day) for utilization use.
"Rationale: Out of the total 7.49Tbits per day data downlink capacity, 5.15 T/Bits per day is allocated for utilization (science & technology demonstrations) use."
The Gateway shall provide a minimum of three (3) cubic meters (m3) of internal volume for powered payload locations.
"Gateway will accommodate crewed and uncrewed placement and operation of science assets e.g. internal investigations, external packages, ISRU operations, transfer of surface samples, sample return to Earth, and science data collection/transfer."
"Enhanced operations of the Gateway could also include addition of a robotic arm, a science airlock, and ability to conduct operations on each element."
"Active internal (pressurized) utilization payloads will need internal volume and systems resources (power, data, cooling, etc.)."
"This volume does not include stowage volume or volume for multi-use equipment (separate requirements), however this volume may be used for stowage if powered payloads are not occupying the volume."
This volume does not include payloads or equipment that could be deployed in open spaces or passageways.
"The Gateway shall provide a minimum of five (5) cubic meters (m3) <TBR-L2-GW-016> of internal volume for utilization stowage, in addition to powered payload volume allocations."
"Internal stowage volume will be needed to store utilization equipment, consumables, samples, etc., in addition to active payload volume."
This volume can vary and will be managed mission by mission along with all stowage capacity.
"The Gateway shall provide <TBD-L2-GW-016> internal volume for powered multi-use equipment to support utilization, in addition to volume for powered payload locations."
There is an expressed need for internal lab equipment to support biology and sample analysis from multiple utilization customers.
"The equipment may include glovebox, microscope, video equipment, freezer, centrifuge, etc., in addition to volume allocated for powered payload locations (separate requirement)."
"The Gateway shall have a minimum of 1,000 kg on-orbit mass allocated for utilization, for each crewed Gateway mission."
The Gateway shall provide enhanced inherent capabilities to facilitate science.
Rationale: PLACEHOLDER: with expectation for clarification of enhanced capabilities as we move forward.
"Enhancements of inherent gateway capabilities (e.g., precise clock, precise position knowledge) will capture more science return."
Rationale: Several utilization payloads would benefit from deployment from the Gateway into final orbits.
"The deployer could be on a Gateway module, the external robotic arm, a docked visiting vehicle, docked logistics module, or docked tug."
"Capability should allow reloading of the deployer by crew or IVR internally, or by EVR externally, depending on the deployer as additional small satellites (e.g. CubeSats) are sent to the Gateway."
The Gateway shall transfer samples and external hardware from free-flying vehicles and payloads to the Gateway interior for return to Earth.
"The Gateway systems will need to collectively support the return of lunar, planetary, and other extraterrestrial samples from free-flying vehicles to the Gateway and transfer them inside for potential decontamination, processing, analysis, and transfer to the crew vehicle for return to Earth."
External payloads may also have samples and hardware that need to be returned to Earth.
"The Gateway Probability of LOC shall have a mean value no greater than 1 in 400, for a 30-day crewed mission including 2 EVAs."
Rationale: NASA policy as described in NPR 8705.2C is to establish thresholds and goals for human space exploration for flight crew safety in terms of the probability of LOC.
The LOC limits specified are established to ensure that the Gateway modules adhere to the Agency thresholds.
"These LOC values are derived from an integrated preliminary Gateway Probabilistic Risk Assessment (PRA) model used to determine LOC achievability which includes the following modules: PPE, MHC, I-HAB, US-HAB, LM, Airlock and EVR."
"The Gateway Probability of LOM shall have a mean value no greater than 1 in 10, for a one year mission including a 30-day crewed mission."
"The LOM value has been derived from an integrated preliminary Gateway PRA model used to determine LOM achievability which includes the following modules: PPE, MHC, I-HAB, US-HAB, LM, Airlock and EVR."
"LOM includes all credible, quantifiable events that result in the loss of a defined major mission objective (as agreed to be the Gateway Program) initiated by Gateway such as LOC, Loss of Gateway, Inability to dock of a major element, etc."
"The Gateway modules shall have the predicted system hardware reliability listed below, for its defined mission environment considering capability for corrective maintenance in space."
Rationale: Gateway module allocated hardware reliability supports Gateway compliance with program-level LOC and LOM requirements.
Software was explicitly excluded because there is not a standard methodology for performing software reliability.
The Gateway critical systems shall be designed to be maintainable.
"Rationale: Maintenance activities may include removal, replacement, service, and repair of hardware and software."
Gateway items that require preventative and corrective maintenance activities need to be repairable with minimal crew support per DSG-RQMT- to unavailability of Downmass for repair at depot.
"Both upmass and onboard stowage resources are constrained resources for Gateway; therefore, hardware items to be maintained must be defined at the lowest level possible, balancing mass and volume of the items with crew time required for repair."
These items must be accessible and repairable by both crew and robotic assets utilizing Gateway IVA and EVA Common Tool Kits.
"Robotics is the preferred means of performing maintenance due to the limited availability of the crew; however, early phases of Gateway assembly will be solely reliant on crew for maintenance."
"IVR capabilities will be developed in later phases of Gateway assembly per DSG-SPEC- IVR-013, Gateway Program Subsystem Specification for Intravehicular Robotics."
External hardware items to be maintained should be designed for maintenance via extravehicular robotic assets.
During Lander operations only 2 crew will be available on board Gateway to support any maintenance activity.
"The Gateway shall meet all safety, performance, utilization, and mission objectives during and after exposure to the natural space environments as defined in SLS-SPEC-159 Cross-Program Design Specification for Natural Environments (DSNE)."
"Rationale: Gateway hardware must perform in all of the natural space environments including ionizing radiation, meteoroids, orbital debris (during earth orbit and departure phase), plasma/spacecraft charging, natural thermal, gravitational, etc., environments."
The Gateway shall design for induced loads in accordance with <TBD-L2-GW-068> Gateway Loads Data Book.
Rationale: Gateway structures need to be able to limit the induced loads they produce as well as perform thru induced loads imparted upon them.
"The Gateway shall comply with the intent of the technical standards listed in Table 3.3.2-1, Type Technical Authorities have designated these as Type 2 documents."
"As such, Gateway Elements or Modules may choose to directly adopt or propose alternates as long as they meet or exceed the intent of the imposed standard, in accordance with the process defined in DSG- PLAN-007, Gateway Systems Engineering Management Plan."
The standards identified with an * in Table 3.3.2-1 are standards for which PPE will either meet through the use of an equivalent partner standard or provide justification for the suitability of non-equivalent standards including relevant data on past usage and other supplemental information that allows NASA/GW Program to adequately assess the risk.
"In the case of a tailored standard (Table 3.3.2-2 Type 2 Tailored Technical Standards Table), PPE will provide justification against the original standard from which the tailored standard was derived from."
All other standards identified in the table are not applicable to PPE.
"Rationale: Gateway must apply documents, specifications, and standards to its modules/elements in order to adequately ensure quality of end items delivered, and the ability of those end items to meet their functional and human certification requirements."
The applicable standard and revision is identified below.
"If new document revisions are released, the program will determine applicability and update as necessary."
"When the normative references cited within documents do not have an applicable revision specified, the applicable revision shall also be the current revision in effect on the date of the agreement or contract."
"The Gateway shall comply with requirements and standards specified in DSG-RQMT-002, Human System Requirements (HSR)."
"The NASA Health and Medical Technical Authority (HMTA) has designated this as a Type alternates as long as they meet or exceed the imposed requirement, in accordance with the process defined in DSG-PLAN-007, Gateway Systems Engineering Management Plan."
"Rationale: DSG-RQMT-002 includes content tailored from NASA-STD-3001, NASA Space Flight Human-System Standard, as required by NPR 8705.2C."
"HSR content includes cross-cutting requirements applicable to all Gateway systems, including content such as physical accommodation of humans, acceleration and vibration limits, acoustics, designing for cleanliness, design for physical hazards, and operability."
"The Gateway shall be designed with fluids that comply with Multi-Purpose Crew Vehicle (MPCV) 70156, Cross Program Fluid Procurement and Use Control Specification."
"Rationale: Derived requirement similar to SSP 30573, Space Station Fluid Procurement and Use Control Specification."
"The Gateway shall be designed so that exterior Gateway surfaces are cleaned before close-out, including areas that are inaccessible in the final assembly and that may act as contamination sources while on orbit."
"Rationale: Derived requirement similar to SSP 30426, Space Station External Contamination Control Requirements."
"The Gateway shall provide interfaces for the Visiting Vehicle, per the Interface Design Document (IDD) <TBD-L2-GW-021>."
"The Gateway shall provide interfaces to the Gateway Ground Segment per documents <TBD- L2-GW-037> Gateway to Ground Network ICD, <TBD-L2-GW-066> VSM to Ground ICD, and <TBD-L2-GW-067> Gateway Program International Ground System Specification."
"The Gateway to Ground Network ICD (IRD) will provide the communication link interfaces between Gateway and the ground networks starting from the frame formatting, encoding, encryption, modulation and transmission to signal reception, decryption, decoding and frame parsing."
This information ensures that the ground network and the gateway systems are compatible with each other and provide reliable data exchange.
"VSM’s success depends on the ability of the ground operators to use, understand and configure it and the VSM to Ground ICD will provide the necessary details to enable this."
Gateway Program International Ground System Specification will provide the interface requirements for the Gateway Ground Segment.
The Gateway Ground Segment will function as Gateway’s connection to the ground assets.
"The Gateway Ground Segment describes the ground-based resources necessary for operations of onorbit Gateway, Lunar Systems and payloads, and it contains detailed specifications related to realtime command, control, and monitoring support."
"This section contains the formal qualification requirements that are necessary to show compliance with each ""shall"" statement in section 3.0 of this document."
"Only ""shall"" statements are checked for compliance."
Data for the reliability analysis will be collected and recorded during qualification.
"If development test data is intended to be used to qualify hardware, its intent shall be predeclared."
It encompasses the entire range of activity to verify that the design conforms to requirements when subjected to environmental life-cycle conditions.
Flight-like hardware is normally used for qualification testing.
"If actual flight hardware is used for qualification testing, it shall be in accordance with <TBD-L2-GW-069>."
Environmental models shall be used to represent environments that cannot be achieved under the conditions of ground testing.
"Simulators, used for verifying requirements, require validation so that the item undergoing qualification cannot distinguish between the simulator and actual operational hardware/software."
Integration testing and checkout shall be conducted during end item buildup.
"Activities such as major component operation in the installed environment, support equipment compatibility, and documentation verification will be proven during qualification."
"In general, system-level qualification will be conducted by analysis of segment-level qualification results."
"When analysis of segment-level qualification results is not adequate to prove compliance with the stated requirement, system level qualification activities will be conducted as identified in section 4.2."
Verification by inspection is the physical evaluation of equipment and/or documentation to verify design artifacts.
"Inspection is used to verify construction features, workmanship, and physical dimensions and condition (such as cleanliness, surface finish, and locking hardware)."
The Placard shall be Red.” can be verified by inspection.
Verification by analysis is a process used in lieu of (or in addition to) testing and inspection.
"Analysis techniques may include statistics and qualitative analysis, computer and hardware simulations, and computer modeling."
"Analysis should be used only when all of the following conditions apply: (1) rigorous and accurate analysis is possible, (2) verification by test is not feasible or cost effective, and (3) verification by inspection is not adequate."
"When conducting Verification by Analysis, the models, simulations, and analysis tools must be accredited by the Program and Element/Modules to certify appropriate fidelity and software development quality."
"The accreditation authority ensures that the tools have sufficient pedigree to provide usable information for decision-making, at the level of criticality required."
Verification by demonstration is the actual operation of flight or ground equipment or teams to evaluate its functional performance and/or its interfaces to other equipment or teams.
"The primary distinction between demonstration and test is that demonstrations provide qualitative results, whereas tests provide quantitative results."
Human in the Loop (HITL) is a method of demonstration that may be used to verify complex integrated crew requirements.
"Verification by test is the actual operation of flight, flight-like, and/or ground equipment with the necessary test support equipment and test environment."
Test also applies to hardware or software verifications done on flight like systems in test facilities such as a System Integration Laboratory (SIL) and a Multi-element Integration Test (MEIT) lab.
The audit will check that the child requirements have been satisfied and that the verification of all lower level requirements satisfy the parent requirement.
"If the audit requires additional analysis to complete, it should be verified by analysis."
"A ground based test facility that integrates avionics and software products across the gateway, supported by high fidelity simulation."
GRAIL will integrate Engineering Units (EUs) or other appropriate fidelity avionics hardware.
GRAIL will include interfaces to ground and mission control assets as needed by verification requirements.
The facility uses both non-flight and flight-equivalent hardware to support testing.
"A ground based facility that tests Radio Frequency (RF), wireless, and other communication channels."
The GICTF includes flight-like infrastructure used by mission operations.
"The facility will software (including antenna with hat coupler would be ideal, but may need to defer that for the compatibility testing that is required by ground station)."
"The (ICTL) will interface with Gateway avionics system integrated with flight software, and have connectivity with the respective ground stations and mission operations centers."
The integrated comm facility will communication system with the new waveforms.
A ground based capability to support integration across multiple Gateway module facilities and operations capabilities.
GIVS includes interfaces to cross-program includes interface to Visiting Vehicle simulations.
Ground based test facility to demonstrate robotics operations on Gateway.
Ground based facility to verify docking operations.
A simulation that models kinematic robot arm operations.
The ability to separate a spacecraft (and its crew) from Earth-bound control and oversight.
CATASTROPHIC HAZARD: Any hazard that may result in: loss of life or permanently disabling injury; loss of Gateway; loss of crew carrying vehicle; a condition that requires safe haven; or a loss of a major ground facility.
"CRITICAL SYSTEMS: (a) Systems which could cause a catastrophic or critical hazard if unable to perform the required functions, as determined by hazard analysis in accordance with DSG- RQMT-011 Gateway Program Hazard Analysis Requirements; (b) Components with criticality category 1/1R/1S or criticality category 2/2R failure modes as assessed by Failure Modes and Effects Analysis in accordance with DSG-RQMT-011, Gateway Program Failure Modes and Effects/Critical Items List (FMEA/CIL) Requirements."
The generic reference to a loss of function or functional redundancy.
"Specifically: the inability of a system, subsystem, string, ORU, component, or part to perform its required function(s) within specified limits."
Manufacturing processes that are identical or significantly similar* to those utilized in flight equipment.
Contain parts or assemblies that are identical or significantly similar* in design to flight hardware (includes manufacturing processes at the piece part level).
Equipment whose design (electrical or mechanical) is identical or significantly similar* to flight equipment when such design is critical to functional performance.
HABITABLE: Intended for crew occupancy and maintained in a condition suitable for human life.
"HABITABLE VOLUME: Any part of the spacecraft volume used by crewmembers to work, sleep, eat, egress, ingress or perform tasks necessary for a safe and successful mission."
"HAZARD: A condition, a state, an event, or an activity, internal or external to a system, which has the potential to cause harm."
"HAZARD CONTROLS: Appropriate means for eliminating, reducing, or controlling risk."
"HUMAN-IN-THE-LOOP (HITL): HITL evaluation is a special class of demonstration and test verification methods, requiring human interaction with a system."
"Typically the human subjects are NASA crewmembers as a subset of the test subject population that perform identified tasks in a representative mockup, prototype, engineering, or flight unit."
"The fidelity of mockups used for human-in-the-loop evaluations may range from low-fidelity, minimal representation, to high- fidelity, complete physical and/or functional representation, relevant to the evaluation."
"Human- in-the-loop demonstration/test is performed for complex interfaces or operations that are difficult to verify through modeling analysis, such as physical accommodation for crew ingress and egress."
"Demonstration/test requirements are normally implemented within a test plan, operations plan, or test procedure."
"INSOLATION: (a) In general, solar radiation received at a surface."
The rate at which direct solar radiation is incident upon a unit horizontal surface at any point on or above the surface.
"The function of keeping items or equipment in, or restoring them to, a specified operational condition."
"It includes servicing, test, inspection, adjustment/alignment, removal, replacement, access, assembly/disassembly, lubrication, operate, decontaminate, installation, fault location, calibration, condition determination, repair, modification, overhaul, rebuilding, and reclamation."
Maintenance includes both preventive and corrective maintenance both on-orbit and on the ground.
METEOROID/ORBITAL DEBRIS PENETRATION: Penetration of the habitable module M/OD protection system is defined as complete penetration or detached spall of the pressure shell by the primary impacting particle.
MISSION CRITICAL FAILURE: A failure of an ORU or system that results in a scrubbed mission.
"The total remaining volume available to on-orbit crew after accounting for the loss of volume due to deployed equipment, stowage, and any other structural inefficiencies (nooks and crannies) which decrease functional volume."
"OPERATOR ERROR: An inadvertent action by flight crew or ground operator that could eliminate, disable, or defeat an inhibit, redundant system, containment feature, or other design feature that is provided to control a hazard."
The intent is not to include all possible actions by a crewperson that could result in an inappropriate action but rather to limit the scope of error to those actions which were inadvertent errors such as an out-of-sequence step in a procedure or wrong keystroke or an inadvertent switch throw.
The operation of one spacecraft in the vicinity of another spacecraft with the relative positions stabilized and the attitude rate small enough to preclude the requirements for re-rendezvous.
STORAGE ITEM: An item which has a permanent internal or external location on orbit in a passive state until it is required or consumed.
"STOWAGE ITEM: An item which is placed temporarily in a location, and which is later removed and installed in a system, placed in a permanent location, or used to support Station or payload operations."
The table To Be Determined Items lists the specific To Be Determined (TBD) items in the document that are not yet known.
The TBD is inserted as a placeholder wherever the required data is needed and is formatted in bold type within carets.
"The TBD item is numbered based on the document number, including the annex, volume, and book number, as applicable (i.e., <TBD-XXXXX-001> is the first undetermined item assigned in the document)."
"As each TBD is resolved, the updated text is inserted in each place that the TBD appears in the document and the item is removed from this table."
"As new TBD items are assigned, they will be added to this list in accordance with the above described numbering scheme."
The table To Be Resolved Issues lists the specific To Be Resolved (TBR) issues in the document that are not yet known.
The TBR is inserted as a placeholder wherever the required data is needed and is formatted in bold type within carets.
"The TBR issue is numbered based on the document number, including the annex, volume, and book number, as applicable (i.e., <TBR-XXXXX-001> is the first unresolved issue assigned in the document)."
"As each TBR is resolved, the updated text is inserted in each place that the TBR appears in the document and the issue is removed from this table."
"As new TBR issues are assigned, they will be added to this list in accordance with the above described numbering scheme."
The Verification Matrix identifies the L2 Program verification methods that will be utilized to satisfy the L2 Program requirements.
"HSR 10049, HSR 10052, and HSR 10081. sufficient for required processing (metrics TBD)."
The telescope is designed as a monostatic system to both transmit laser energy and receive light from targeted objects through common optics and a common optical path.
"The gimbal drives the telescope to track Earth orbiting satellites, stars and fixed ground targets."
"This subsystem includes the telescope and Coudé path through the tracking subsystem, two cameras mounted on the telescope (one low light camera for viewing dim targets and one wide field of view camera for visual tracking), and all associated environmental monitoring and control devices such as temperature sensors, accelerometers, etc."
"It also includes the gimbal, encoders, servo electronics, and additional hardware/software to monitor/maintain environmental limits."
The gimbal portion of the telescope and gimbal subsystem is attached to a riser which is mounted on a concrete pier and maintains vibrational isolation from other components of the shelter and dome to minimize disturbances to the gimbal pointing and tracking.
This subsystem has components in both the dome and the shelter.
"The optical bench (OB) subsystem is designed to allow the laser subsystem, receiver subsystem, and star camera to reside in an environmentally controlled environment, while supporting laser divergence changes for different satellites, point ahead of the laser beam for satellites, beam blocking and beam attenuation for laser safety, system configuration changes for the various modes (star calibration, ground target ranging and satellite tracking), and reduction in the background light that the detector is exposed to (ND wheel, spatial and spectral filters)."
Laser light is directed along a path on the optical bench that is aligned to the telescope optical axis.
"The transmitted light goes from the laser to the pit mirror (which is part of the OB subsystem), along the Coudé path, and eventually out through the telescope."
Receive light captured by the telescope is directed to the receive path on the optical bench which is also aligned to the telescope optical axis.
"Finally, this subsystem includes diagnostic components to monitor the laser characteristics and to support alignment."
The star camera is part of the optical bench subsystem.
"The range receiver subsystem consists of the detector and associated electronics to detect and measure the start and stop event times, support the software(cid:859)s determination of the signal from the background noise and the range to the target, and provide angular offset information to allow for closed loop tracking."
"The range receiver subsystem also includes the RCE (Range Control Electronics) which provides the software with control of the laser fire frequency, provides the software range gate control for the detector during satellite tracking, and provides fixed ground target range gate control."
In addition the range receiver subsystem includes a wide field of view low light Acquisition Camera for use in acquiring targets with poor predictions.
"Part of this subsystem sits on the optical bench, the rest is in the electronics rack."
"The laser subsystem consists of the laser, associated control electronics, a chiller to maintain the laser(cid:859)s internal temperature and additional hardware/software to monitor/maintain environmental variables and control power output of the laser."
"The laser subsystem is contained within the shelter with the laser itself on the optical bench, the associated electronics in the electronics racks, and the chiller rack mounted in the optical bench area."
"The laser safety subsystem is designed to meet all NASA, ANSI, FAA, and local safety standards for outdoor laser use as well as to protect SGSLR and other ground personnel."
"It includes an instrument for aircraft detection which is co aligned with the laser beam, support electronics, beam blocks and ND filters for eye safety external to the system, and sensors to inhibit the laser should a subsystem fault occur or should someone access an area in the system where the laser light can cause damage, such as the roof of the shelter or the dome."
"The aircraft detection components reside on their own stand outside of the shelter, the beam blocks and ND filters are on the optical bench, and the support electronics and computer interface are in the electronics racks."
Some of the sensors are outside of the shelter and some (such as the door to the optical bench room) are inside the shelter.
The Time and Frequency subsystem generates and regulates the various timing signals used by other subsystems as well as the time of day used by the software.
"It acquires a GPS time and ensures that the timing signal remains stable, and outputs the 1 PPS from an oscillator disciplined by GPS and the 10 MHz signal that is synchronized to that 1 PPS."
The system also includes a monitoring subsystem that uses a secondary GPS timing source to compare the GPS Timing and Frequency subsystem.
Most of this system is contained within the shelter.
The GPS antenna(s) are mounted outside of the shelter.
The Meteorological subsystem is designed to measure outside environmental conditions to provide information for precise ranging and health and safety of the system.
This subsystem consists of a variety of measurement devices all located roughly together outside the shelter and dome.
"The most important of these measurements for ranging accuracy are the barometric pressure, temperature, and humidity."
The system also includes stands and associated hardware for the system.
"This subsystem includes the components which enclose, protect and support the SLR operation."
"These are primarily the structure, but may also contain additional components as described below."
The dome is designed to contain and protect the telescope and the gimbal (part of the tracking subsystem) and associated hardware while allowing transmission and reception of light while operating.
"This component includes the dome structure with an opening, the shutter over the opening, motors to open the shutter, motors to rotate the dome with the telescope, a structure to allow the rotation, and any additional hardware needed to measure/maintain the environment within the dome."
"The shelter is designed to contain and protect the optical bench, laser and all the electronics, as well as provide work space for support personnel."
"In addition to the structure, it includes HVAC, humidity control, lighting and all necessary additional hardware for monitoring the interior environment."
"The shelter provides the other subsystems with power, UPS, and surge protection, including protection from lightning."
It also provides a pass through for internet and telecommunications.
The pier provides physical support for the telescope and gimbal and vibrational isolation from the shelter.
The riser is designed to mate the tracking subsystem to the pier.
"The computer and software subsystem contains all the computers and the software to control, calibrate, and maintain the system as a whole, and to communicate with the control center."
"The software is designed to support local, remote, and fully automated operations."
"This subsystem links all other subsystems together, transfers and stores data, processes the ranging data, and communicates with the IGSOC."
"With a standard clear atmosphere or better, SGSLR stations shall be capable of tracking geosynchronous satellites whose arrays satisfy the ILRS retro reflector guidelines."
Data precision for LAGEOS NPT shall be < 1.5 mm when averaged over a one month period.
The LAGEOS Normal Point range bias shall be stable to 1.5 mm over 1 hour.
Over one year the RMS of station's LAGEOS NPT range biases shall be < 2mm.
"SLBP3.4: SGSLR Station shall be capable of producing an annual volume of 45,000 LEO, 7,000 LAGEOS and Normal Point time of day shall be accurate to < 100 ns RMS."
Systems shall have a modular design supporting maintenance and upgrades.
Systems shall be capable of local and remote operation by an operator with a path to full automation.
Systems and operations shall satisfy local and NASA safety requirements.
Systems shall be capable of following ILRS procedures and formats and handle ILRS defined restricted tracking.
SGSLR Stations shall not introduce any unquantified biases into the legacy SLR network.
The telescope shall be capable of maintaining alignment.
In order to determine the pointing accuracy at each laser fire rate.
Light throughput needs to be optimized to maximize signal.
Required for testing and diagnostics with engineer present.
To provide enough stars for mount pointing calibration.
"To allow for trouble shooting in the field, either locally or remotely."
Different time of flight ranges require different gating and protection for stray light into the detector.
To maintain the required annual normal point data volume.
Stability of the laser is needed for millimeter level system performance.
The laser safety subsystem must be able to be located in and operate at sites with wide temperature ranges.
The laser safety subsystem must be able to be located in and survive in a wide variety of climates.
The shelter subsystem shall mitigate lightning damage.
The pier and riser must be able to support the telescope and gimbal and maintain stability.
Light needs to get to the optical bench from the telescope.
To allow the GTA azimuth rotation to match horizontal.
The computers shall have the capability of sharing data.
"Information is collected by various computers, but all of the decision making as well as for generation of the science data product."
"As part of the ILRS, the SGSLR systems must be able to track most of the targets, this includes tracking targets that have restrictions on their tracking."
The ILRS requires that stations follow the mission tracking restrictions.
Rapid analysis gives allows quicker response by SGP to performance problems.
Time critical functions in real time systems are best initiated by timing interrupts.
The computers and software shall adhere to NASA(cid:859)s IT Technology).
The hardware must have control of the laser safety.
This adds one final layer of checking before firing.
"The system must be capable of protecting itself by rejecting damage, or that could compromise safety."
SGSLR requires a daily schedule in order to operate.
This official draft has not been approved and is subject to modification.
"This Specification is published by the National Aeronautics and Space Administration (NASA) to describe essential technical requirements for purchased or in-house items, services, functions, or processes for NASA programs and projects and includes procedures necessary to determine that the requirements covered by the Specification have been met."
These requirements are mandatory when specified as such by program documentation or contracts.
"This Specification is approved for use by NASA Headquarters and NASA Centers, including Component Facilities and Technical Service Support Centers."
The Specification also applies to the Jet Propulsion Laboratory and other contractors to the extent specified in section 1.2 in this document.
This Specification establishes requirements for pyrovalves and other parent metal barrier normally closed (NC) valves used in ELV payload hazardous spacecraft applications.
"Pyrovalves meeting these requirements will provide programs, NASA Payload Safety, and United States Air Force (USAF) Range Safety consistent and reliable hardware."
"Requests for information, corrections, or additions to this Specification should be submitted via “Feedback “in the NASA Standards and Technical Assistance Resource Tool at https://standards.nasa.gov/."
The purpose of this Specification is to establish and implement the manufacturing and test requirements and applications guidelines for normally closed (NC) parent metal shear-section valves.
The Specification is a guide for design engineers to develop more detailed requirements for specific pyrovalve applications.
Adherence to these requirements will reliably prevent NC parent metal valve leakage or other failure-induced release of hazardous fluids (liquids or gases) from National Aeronautics and Space Administration (NASA) payloads on Expendable Launch Vehicles (ELVs).
"This Specification does not address NC parent metal valve sizing, pressure drop, and other requirements."
"This Specification may be called out in procurement specifications or other programmatic documentation to ensure valves meet structural requirements and are considered to be equivalent to other hazardous fluids pressure components, such as tubing, tanks, and fittings, and that any mode of external or internal leakage of the contained hazardous fluid is extremely improbable (3 X 10-5) in accordance with NASA-STD-8719.24, NASA Expendable Launch Vehicle Payload Safety Requirements, and AFSPCMAN 91-710, Air Force Space Command Range Safety User Requirements Manual, or equivalent document for the applicable range."
Appendix A of this Specification presents a checklist of documents to be prepared for NASA and/or Range Safety.
The checklist is provided for manufacturers of NC pyrovalves used in personnel hazardous applications.
It is a tool for documenting the detailed compliance to the intent of the safety specification.
"The checklist also provides an aid for payload safety, Range Safety engineers, and other subject matter experts in reviewing the documentation."
Closed Pyrovalves for Hazardous Flight Systems Applications.
"For the purposes of this Specification, hazardous valve applications involve hazardous flight hardware pressure systems as defined by NASA-STD-8719.24 and AFSPCMAN 91-710, Volume 3, Chapter 12, Section 12.1."
"This Specification applies to NC pyrotechnically operated valves (pyrovalves), as well as to valves that use a different means of applying force, e.g., memory shape alloys to break out a section of a parent metal section allowing flow."
"The parent metal shear sections and interface tubes are defined by the term “parent metal” when they are machined from a single, certified bar of high-purity metal alloy with no welds."
This Specification is intended to be applied when these NC parent metal shear-section valves are used to prevent failure-induced release of hazardous fluids (liquid or gas) from spacecraft.
"It is primarily applicable to ELV payloads subject to NASA Payload Safety and United States Air Force (USAF) Range Safety Requirements, where a consistently high level of reliability and safety is required."
"This Specification is approved for use by NASA Headquarters and NASA Centers, including Component Facilities and Technical and Service Support Centers, and may be cited in contract, program, and other Agency documents as a technical requirement."
"This Specification may also apply to the Jet Propulsion Laboratory or to other contractors, grant recipients, or parties to agreements only to the extent specified or referenced in their contracts, grants, or agreements."
Requirements are numbered and indicated by the word “shall.” Explanatory or guidance text is indicated in italics beginning in section 4.
Tailoring of this Specification for application to a specific program or project shall be formally documented as part of program or project requirements and approved by the Technical Authority.
Any tailoring shall also be documented and communicated in writing to the appropriate range safety organization and the NASA Payload Safety Program Manager.
"Pyrovalves (figure 1, Basic Pyrovalve Design and Features,) are typically lighter, more reliable, and in most cases less expensive than other types of valves."
They are single-use devices that are used in propulsion systems to isolate propellants or pressurant gases.
"These fluids may be hazardous because of their toxicity, reactivity, temperature, or high pressure."
Note that in the simplified block diagram below not all detail features are shown so that those of major interest are more prominent.
The diagram is provided to point out the various features that are discussed in this Specification.
Features of some NC parent metal valve designs may differ.
"In 2013, the NESC concluded an extensive study of the reliability and safety of NC parent metal valves used in payloads carried aboard ELVs."
The assessment successfully evaluated technical data to determine the risk of NC parent metal valve leakage or inadvertent activation in ELV payloads.
The study resulted in numerous recommendations to ensure personnel and hardware/facility safety during ground processing of ELV payloads.
One of those recommendations was to establish a NASA specification for NC parent metal valves.
"This Specification is a result of that recommendation, which is documented in NESC-RP-10-00614."
The documents listed in this section contain provisions that constitute requirements of this Specification as cited in the text unless waived by the responsible Technical Authority.
The applicable documents are accessible via the NASA Standards and Technical Assistance Resource Tool at https://standards.nasa.gov/ or may be obtained directly from the Standards Developing Organizations or other document distributors.
Contact White Sands Test Facility Publications for access.
This Specification establishes requirements for NC pyrovalve and other NC parent metal shear- section valves used in ELV payload hazardous applications but does not supersede nor waive established Agency requirements found in other documentation.
Low notch sensitivity is usually associated with ductile materials and high notch sensitivity with brittle materials.
The object(s) within a payload fairing carried or delivered by a launch vehicle to a desired location and trajectory.
"A generic term that applies to all payloads , including but not limited to satellites, other spacecraft, experimental packages, reentry vehicles, dummy loads, cargo, and any motors attached to them in the payload fairing."
"For this Specification, the term refers to cargo carried aboard a launch vehicle."
May include non-destructive and destructive test(s).
Stringer: An elongated configuration of microconstituents of foreign (metallurgically distinct) material aligned in the direction of working.
The term is commonly associated with elongated oxide or sulfide inclusions in steels.
"For more details, see Appendix B in this Specification."
NC parent metal valves should undergo a complete development and qualifications program.
This is typically performed according to a specific program or project technical specification.
Analysis should be accomplished before manufacture to help preclude additional redesign and testing.
The short-duration impulse loadings from pyrotechnic actuation are generally evaluated based on test results because of the challenges of accurately analyzing stresses from these loadings using mathematical or computer modeling.
The spacecraft system designer should be aware of system-level issues relative to inadvertent actuation of the NC parent metal valve.
Comprehensive testing and analysis of the ignition system may be required before the possibility of inadvertent ignition can be fully mitigated.
"However, this testing and analysis is beyond the scope of this Specification."
"Although actuation of the valves used in aerospace applications is normally by pyrotechnics (initiators), the basic valve requirements can be applied to valves actuated by mechanical, electrical, hydraulic, and pneumatic or a combination of means."
"Whatever actuation method is chosen, the maximum no-fire energy should be known to a reliability of 0.995 at a 95-percent confidence level so that a factor of safety can be determined from all inadvertent sources of that energy (checklist item 2D)."
"Statistical Methods Appropriate for Evaluation of Fuzed Explosive-Train Safety and Reliability, (the Bruceton test) or ISO 14304, Annex B, All-Fire/No-Fire Test and Analysis Method, (the Neyer test) that requires 20 to 50 initiators for each test (checklist item 3BD)."
"Other sources of electrical energy, such as radio frequency (RF), can be compared to the No-Fire level of the initiator by tests to meet the factor of safety of a minimum of 20 dB, which is Requirements and Test Methods for Space Systems, paragraph 4.4.1.a) (checklist item 4BD)."
"Mechanical, hydraulic, pneumatic, or a combination of means should have a similar safety margin."
System testing should include the range of environmental conditions appropriate to the application (checklist item 5D).
All valves shall be proof tested toa minimum pneumatic proof pressure at 1.5xMEOP.
"This capability shall be demonstrated on every unit during assembly, with pressure applied individually to each line and separately to the valve housing through the actuation ram chamber while the lines are vented."
Fracture mechanics and damage tolerance testing are to satisfy NASA-STD-5019.
Control Board for spacecraft requiring this in programmatic requirements.
"NASA-STD-5019 (see section 4.1 of this Specification), growth of the maximum credible crack size shall be demonstrated to the fracture control authority to be non-credible, based on knowledge of quality control and manufacturing techniques used to make the NC parent metal valve."
The minimum hold time for each burst pressure test shall be 5 min.
NC parent metal used in hazardous systems without additional barriers to leakage may be required by USAF Range Safety and NASA Payload Safety to have a minimum design burst pressure requirement of 4.0 times maximum ground working pressure (MGWP).
"NC parent metal valves used in hazardous systems without additional barriers to leakage are considered Category A ordnance devices and have to follow NASA-STD 8719.24 and AFSPCMAN 91-710, Volume 3, Chapter 13, or equivalent document for applicable range."
This requirement should be identified and documented early in the launch facility coordination process and be documented in the tailoring agreement.
"This requirement would not apply to Category B ordnance pyrovalve applications, which are, by definition, non-hazardous."
CAUTION: An expended (fired) pyrovalve may retain significant pressure in the primer chamber assembly for an indefinite period of time.
"Additionally, if the valve does not fail after 4.00xMEOP, it meets the full safety factor applied to tubing <3.81 cm (<1.5in) in diameter (checklist item 33D)."
"Other shear-section barriers, such as a metal-to-metal seal, elastomeric seats, or O-rings, do not provide the same level of confidence and do not meet the intent of this Specification (checklist item 9A)."
The internal shear-section shall be a continuous unit of non-welded parent metal.
This pertains to the area of the shear-section around the parent metal barrier that is opened upon actuation of the valve.
The shear-section normally has flanges larger than the shear- section outer diameter that are welded to the valve housing to prevent leakage after actuation.
"When installed in the system, the parent metal sections are directly welded to the system tubing (checklist item 9A)."
"Although many materials can be considered for the parent metal shear-section, the use of vacuum furnace remelt 304L stainless steel has a significant legacy for the shear-section application (checklist item 13D)."
"Other metals may require heat treatment after welding, as judged necessary by the responsible NASA materials specialist (checklist item 15D)."
The yield and tensile strength callouts may vary depending on the strength requirements.
The standard yield and tensile strength may be used if they will meet the stress/force analysis requirements.
"The NASA Materials and Processes Technical Information System II (MAPTIS II), a single-point source for materials properties for NASA and NASA-associated contractors and organizations, contains physical, mechanical, and environmental properties for metallic and non-metallic materials.3 Other relevant resources for materials properties are NASA-STD-6016, Standard Materials and Processes Requirements for Spacecraft, AIAA SP-084-1999, Special Report: Fire, Explosion, Compatibility, and Safety Hazards of Hypergols – Hydrazine; AIAA SP-085-1999, Special Report: Fire, Explosion, Compatibility, and Safety Hazards of Hypergols – Monomethylhydrazine; and AIAA SP-086-2001, Special Report: Fire, Explosion, Compatibility, and Safety Hazards of Nitrogen Tetroxide."
Investigations have shown that the stringers that may occur in 304L are usually approximately 0.00127 cm (0.0005 in) in diameter and that the stringer material is not attacked by common fuels and oxidizers over a period of several years.
"Even if the stringers are oriented perpendicular to any thin break section, the chances of a leak from stringers are remote."
"However, a commonly used dye-penetrant etchant (a solution of nitric acid and hydrofluoric acid) has been shown to dissolve stringer material in 304L stainless steel."
The solution attacks the material in the stringer and can cause leaks in thin sections.
This solution should be avoided on any part of the valves (checklist item 17D).
"Note that, for 304L stainless steel, any significant stringer is screened out during the required proof and helium leak testing process."
The use of vacuum remelt raw material significantly reduces the likelihood of stringers occurring.
"The housing and all other internal material that will be in contact with the hazardous fluids after actuation, e.g., rams, plugs, seals, shall also have the same requirements for materials compatibility with the hazardous fluids and the same welding compatibility requirements (checklist item 18D)."
"Before firing, a leak in the upstream-side parent metal seal could allow hazardous fluid at system pressure to enter the ram area."
"Similarly, after firing, leakage past the ram might occur."
"In either case, hazardous fluid could enter the ram area."
"Therefore, to ensure at least single-fault tolerance against external leakage, all internal valve materials that could then become wetted are to be fully compatible with the hazardous fluid."
Specific mission requirements may drive other requirements that are not covered by this Specification.
"For example, some applications require that the valve be in the system and pressurized for many years with corrosive propellants after it operates, causing stress corrosion or metal nitrate formation."
This design is generally considered to contain two inhibits to flow and is the preferred design approach.
"Both designs, when qualified, can be acceptable for use in ELV payload hazardous flight applications (checklist item 20A)."
Components require independent certification that the materials of construction conform to drawing specifications before fabrication.
The shear-sections shall be from the same melt and bar stock lot (checklist item 21D).
Material certifications and traceability records shall be maintained and available.
Parent metal shear-section valves used in single isolation configurations (without additional inhibits) need additional inspection and rigorous analysis to ensure the high unlikelihood that critical flaws exist.
Shear-sections should be cleaned using the standard documented cleaning process for the material (checklist item 24D).
"If applicable, the “V” notch angle, depth, and tip radius shall be measured by optical comparator or equivalent and verified to fully meet drawing requirements and indicate measured tip radius (checklist item 27D)."
"It is also recommended that the actual radius be documented to within measurement system accuracy (within ±0.000635 cm (±0.00025 in), traceable to a national standard)."
"This specification requires that the valve meet a demonstrated safety factor of 2.5 to 4.0, as applicable."
"Dye penetrants are generally used on flat surfaces (not in sharp groves), are not recommended, and should not be used unless a well-documented probability of detection (POD) study has been conducted to prove that the POD is greater than 90 percent with 95 percent confidence (termed commonly used for other similar applications, such as detecting cracks in critical bolt threads, and could be considered for this application, as long as the technique has been fully validated."
Questions regarding validation should be addressed to the NASA NDE Technical Fellow.
"Welding shall be done on a weld lot basis, using the same weld schedule and weld instructions for a specific weld and be done in a way that minimizes or eliminates “V” notch residual weld stress (checklist item 30D)."
This means that the shear-section is to be outside the weld heat affected zone.
"All manufacturing and inspection records and tested units shall be retained by the manufacturer for a minimum of 10 years, unless otherwise specified by contract (checklist item 36D)."
"After manufacturing is complete, the lot of valves shall be submitted to LAT."
"The non-destructive 100-percent acceptance testing shall be performed in accordance with the product procurement specification (checklist item 34D), where required."
Destructive acceptance testing shall be performed where specified by procurement documentation.
The purpose of this appendix is to provide guidance by assisting manufacturers to properly document compliance to the intent of the NC parent metal valve Specification.
The following checklist is provided for the manufacturer of an NC pyrovalve used in a hazardous application.
The checklist assists in documenting the detailed compliance to the intent of the safety specification.
It is understood that different NC pyrovalve designs may meet a safety requirement with a different approach or new backup material.
The checklist also provides an aid for Range Safety in reviewing the documentation.
Note that the manufacturer and the system designer may have to collaborate to complete the checklist.
"List operating hazards, including cryogens, flammables, combustibles, or hypergols."
"List MEOP and stored energy levels exceeding 19,307 J (14,240 ft·lb) in accordance with AFSPCMAN 91-710, Vol."
"Provide qualification testing data for vibration, shock, and other environmental conditions."
Provide detailed calculation of MEOP for the pyrovalve and the pressurization system when personnel could be endangered.
"For hypergol systems, document that this is followed by helium leak test at a minimum of 1.0xMEOP with a leak rate less than 1x10-6 standard cc/sec."
Document burst pressure testing in qualification test before and after firing and after firing for LATs.
Provide drawing of the non-welded parent metal shear-section to confirm it is a continuous unit of non-welded parent metal.
Document when the NC parent metal valve will be actuated to the open position.
Provide safety analysis of inadvertent operation or leakage of hazardous materials.
Provide verification that the only part of the valve in contact with the hazardous fluids before actuation is the parent metal shear-section.
Provide a description of the material used for the parent metal shear-section.
"If the material used for the parent metal shear-section is 304L stainless steel, checklist items 14 through 17 do not apply."
Document the compatibility of the material used for the parent metal shear- section with the hazardous fluids to be used in the system.
"Document the compatibility of any cleaning, test, or service fluids with stringer materials to ensure they are not etched away."
Document the compatibility of the hazardous fluids with the housing material.
"Document the NC parent metal valve design used: single parent metal, dual parent metal, or some other design."
"Document that the valves have been manufactured, assembled, tested, and documented on a manufacturing lot basis."
Document that the shear-sections are from the same melt and bar stock lot.
Verify that the samples of the shear section bars have been examined for voids and other anomalies and document the results.
"Verify that samples of the shear-section bar have been tested for composition, tensile strength, yield strength, and elongation and that the results met the specification requirements for the shear-section material."
"Verify that shear-sections were machined at the same machine shop, using the same tooling and setup for the lot."
Verify the proper passivation of the shear-sections.
Verify that critical shear-section dimensions are 100 percent inspected and recorded for each shear-section.
Document the results of the shear-section “V” notch radius inspection and show how it meets the requirement(s).
Verify that an independent inspector (from a different company organization or company or as directed by contract) inspected and recorded the critical dimensions.
Verify the serialization of the top assembly and the recording of the top assembly production and inspection steps by serial number.
Verify the welding of the shear-sections to the housing using the same weld schedule and weld instructions.
Document the lot numbers of all ordnance items used in the production and testing of NC parent metal valve lot.
Proof pressure test all weld joints and parent metal shear-sections at with a resulting leak rate less than 1x10-6 standard cc/sec.
All welds are to be tested either during assembly or acceptance testing.
"Verify that, during qualification testing, one unit was tested for burst pressure at 2.5xMEOP (cid:73)(cid:82)(cid:85)(cid:3)(cid:79)(cid:76)(cid:81)(cid:72)(cid:86)(cid:3)(cid:90)(cid:76)(cid:87)(cid:75)(cid:3)(cid:71)(cid:76)(cid:68)(cid:80)(cid:72)(cid:87)(cid:72)(cid:85)(cid:86)(cid:3)(cid:149)(cid:22)(cid:17)(cid:27)(cid:3)(cid:70)(cid:80)(cid:3)(cid:11)(cid:149)(cid:20)(cid:17)(cid:24)(cid:3)(cid:76)(cid:81)(cid:12)(cid:3)(cid:82)(cid:85)(cid:3)(cid:23)(cid:17)(cid:19)(cid:91)(cid:48)(cid:40)(cid:50)(cid:51)(cid:3)(cid:73)(cid:82)(cid:85)(cid:3) lines with diameters <3.8 cm (<1.5 in) and then actuated and retested at the respective burst pressure test value."
Record any required non-destructive testing results as part of the Lot Acceptance Test Report.
Record any required destructive testing results as part of the Lot Acceptance Test Report.
"Retain all manufacturing, inspection, test hardware, and test results for a minimum of 10 years, unless otherwise specified by contract."
This appendix contains guidance in the form of additional details for design analysis and evaluation that may be required in certain situations.
"As valves subject to this Specification have to have a safety factor of at least 2.5, analysis is not generally required for shear valves unless there is measurable deformation."
The following section is added for reference purposes; note that a minimum safety factor of 2.5 applies.
"Depending on the stress levels, non-linear analysis may also be required."
"This analysis should result in identification of the regions that control the design, the net and peak stresses in these regions, and resulting factors of safety."
"The minimum design factors of safety are 1.5, based on yield strength, and 2.5, based on ultimate tensile strength, as needed to successfully complete the S-080-1998, Table 2."
These analyses are based on worst-case assumptions for tolerances and material properties.
The purpose of this appendix is to provide guidance in the form of reference documents.
Available in electronic form at http://www.sti.nasa.gov.
"KSC-DE-512-SM establishes overall requirements and best design practices to be used at the John F. Kennedy Space Center (KSC) for the development of ground systems (GS) in support of operations at launch, landing, and retrieval sites."
"These requirements apply to the design and development of hardware and software for ground support equipment (GSE), ground support systems (GSS), and facility ground support systems (F-GSS) used to support the KSC mission for transportation, receiving, handling, assembly, test, checkout, servicing, and launch of space vehicles and payloads and selected flight hardware items for retrieval."
"During the 1950s and early 1960s, the Missile Firing Laboratory (later renamed to the Launch Operations Directorate) was the launch operations arm of Redstone Arsenal and the Army Ballistic Missile Agency."
The Missile Firing Laboratory used Army specifications and standards for its design and development of ground systems.
"KSC’s effort to develop standards began with GP-863, General Criteria for Design of New Equipment and Facilities, which was released in July 1970 and updated three years later."
"GP-863 focused on operability, reliability, maintainability, useful life, environmental, transportability, human performance, safety, logistics, documentation, and quality assurance."
"KSC-DE-512-SM, Facility Systems, Ground Support Systems, and Ground Support Equipment, General Design Requirements, replaced GP-863 in accomplishing detailed designs."
Later revisions became more formal and the “shall” statement became the phrase to identify each requirement.
This standards manual supplements NASA-STD-5005 by including KSC-site-specific and local- environment requirements.
"KSC-DE-512-SM is a single, complete document for design and development of KSC ground systems for use at launch, landing, and retrieval sites."
"These requirements and practices are optional for equipment used at manufacturing, development, and test sites."
"KSC-DE-512-SM establishes requirements and guidance for design and fabrication of ground systems (GS) that includes: ground support equipment (GSE), ground support systems (GSS), and facility ground support systems (F-GSS) to provide uniform methods and processes for design and development of robust, safe, reliable, maintainable, supportable, and cost-effective GS in support of space flight and institutional programs and projects."
"This standard is intended to supplement the minimum requirements of NASA-STD-5005 by applying more stringent, restrictive, or demanding requirements applicable to the specific KSC environment."
This standard also provides requirements for GSS and F-GSS because these systems are not covered in NASA-STD-5005.
The applicability of KSC-DE-512-SM relative to other NASA and industry design standards is shown graphically in Figure 1.
This standards manual applies to all new GS for programs and projects assigned to KSC.
"This standards manual is intended to establish uniform engineering best practices and methods in the design, documentation, procurement, fabrication, assembly, test, and installation of ground systems to support KSC operations."
"This standards manual is required for use by KSC design entities and their support contractors and may be cited in contracts, projects, and other documents as necessary to provide a technical requirement."
"The requirements of this standard are optional for hardware used only at manufacturing, development, or test sites but are required for hardware used at launch, landing, and retrieval sites."
A program may invoke additional requirements that differ from the requirements stated herein.
These requirements will be evaluated and approved for use by the KSC Engineering and Technology Directorate Technical Authority.
"Engineering and Safety and Mission Assurance (S&MA) have the responsibility to determine categories or types of GS (e.g., critical vs. noncritical) and any additional requirements resulting from these categories or types."
NASA-STD-5005 may be applied by the governing program for GSE provided by entities other than KSC.
"KSC-DE-512-SM does not cover the design and fabrication of tools, facilities and utilities, and COTS equipment."
"However, other KSC standards and industry standards may apply to these designs."
"Individual provisions of this standards manual should be and are intended to be tailored (i.e., modified or deleted) to meet specific program and project needs."
All tailoring shall be evaluated for use by the KSC Engineering Directorate Technical Authority (see KSC-PLN-5400).
Waivers to institutional requirements shall follow the process in KDP-KSC-P-1865.
The latest issuances of documents listed in this section contain provisions that constitute requirements of this standard as cited in the text.
The applicable documents are accessible via the NASA Standards and Technical Assistance Resource Tool at http://standards.nasa.gov or may be obtained directly from the standards developing organizations or other document distributors.
"This standard establishes requirements and guidance for design and fabrication of KSC ground systems (GSE, GSS, and F-GSS), but does not supersede or waive established Agency requirements found in other documentation."
Conflicts between this standard and applicable documents cited herein shall be resolved by the responsible Technical Authorities.
"Rationale: Engineering analysis proceeds by separating the engineering design into the components and disciplines, analyzing, or estimating each component of the operation or failure mechanism separately, and recombining the components in accordance with physics and engineering principles."
The methods selected must be supported by appropriate technical rationale and be documented in detail.
Rationale: Commercial items or components should be used when they satisfy the ground systems function and will not degrade the safety or reliability of the ground or flight system.
Requirements should be specified in terms of functionality or performance rather than design.
"To qualify as COTS, equipment must not be modified (see modified off-the- shelf [MOTS])."
"Rationale: In the corrosive marine (sea coast) environment at KSC, the most common sources of corrosion are moisture and sodium chloride."
"The launch-induced environment also introduces hydrochloric acid, which exacerbates the corrosive effects of the marine environment."
Rationale: Criticality of a ground system (GS) is determined by a Safety and Mission Assurance study analysis of the function and application of the equipment.
"The classifications assigned to the GS will guide the design team in determining which specifications and standards to apply, which materials to select, and how to document the GS."
This method is generally employed where qualitative operational performance is to be verified.
"It is the responsibility of the program/project to determine recertification requirements, which may include refurbishment, analysis, or test."
"Facility systems include heating, ventilation, and air conditioning (HVAC); 60-hertz (Hz) power; potable water; elevators; lighting; shop air; etc."
Facility systems may support or have interfaces with ground systems.
"The term facility does not include ground support equipment, ground support systems, facility ground support systems, tools, or special test equipment."
"F-GSS are specialized systems that are designed, built, and tested to more stringent requirements than conventional facilities and their integral facility systems."
"Rationale: F-GSS includes fixed environmental control systems (ECS), breathing air systems, long-run piping systems, high-pressure gases, liquid hydrogen (LH2) and liquid oxygen (LO2) storage spheres, etc."
"The requirements for F-GSS and GSS are the same, and the distinction between the two is not always clear."
The important distinction is between F-GSS and conventional facility systems.
Conventional facility systems are not covered by this standard.
"If the factor of safety is defined in terms of stress, it is the ratio of the ultimate or yield stress to the maximum design stress."
"In fatigue design, it is the ratio of the calculated fatigue life to the allowable design life."
"This standards manual specifies the minimum factor of safety for GS for specific structural applications (e.g., pressure vessels, threaded fasteners, and aluminum structures)."
Rationale: This definition is consistent between ground and flight hardware.
It reduces to the traditional stress-based definition in the simplest case.
Rationale: Equipment used during the manufacturing of flight hardware is not considered to be GSE.
Each program defines when manufacturing ends and processing of the flight hardware begins.
"If manufacturing equipment is to be used after flight hardware processing begins, it must be designed to meet GSE requirements."
GSE does not include tools that are designed for general use and not specifically for use on flight hardware.
"It does not directly interface with flight hardware, although it may supply commodities, power, or data that eventually reaches the flight hardware after being conditioned or controlled by GSE."
"Rationale: Design standards for GSS may be similar to or, at the discretion of the program/project, identical to the design standards for GSE."
Protective features designed into the GSE prevent failures from propagating to flight hardware.
"Limited-life items require periodic replacement or refurbishment, which must be defined in design and maintenance documents."
"Rationale: Modification of COTS voids the design intent of the original equipment and places responsibility for performance, functionality, and reliability on the designer."
"The structure supports or provides direct access to flight hardware (e.g., test stands, launch complexes, access platforms in operational or research facilities, towers, and similar special-purpose facilities)."
The transition between conventional and nonconventional is the interface between the structure specifically designed for processing and vehicle access and the generic building structure whose purpose is the physical support of the overall facility.
The transition region between conventional and nonconventional structures should be designed to meet the criteria for both types of structure.
This value is marked on the device indicating maximum working capacity.
STE is classified as GSE or GSS and designed to the requirements of this standards manual.
"Rationale: Although its use is limited, STE has the potential to cause damage to flight hardware or injury to personnel."
STE includes equipment traditionally known as shop aids.
It includes measurements taken with certified and calibrated tools in accordance with generally accepted scientific or engineering principles.
"Tools are calibrated, when necessary, in accordance with industry standards."
"Rationale: Tools are not designed to specifically interface with flight hardware, nor are they designed to perform a function specific to flight hardware."
Their design and general use in industry includes a variety of applications that may be required on flight hardware or GSE.
"Examples of tools include torque wrenches, crow’s feet, voltmeters, go/no-go gages, screwdrivers, wire cutters, and pliers."
"Rationale: Documentation may include the origin of materials and parts and certification of personnel and processes during fabrication, assembly, procurement, installation, activation, verification, and validation."
"Verification may be determined by a combination of test, analysis, demonstration, and inspection."
"In order to meet customer requirements, individual system and equipment design projects may need criteria that are more stringent than those specified herein."
"In such cases, these criteria should be determined by the responsible design organization in consultation with its customers (e.g., users and operators)."
Each program/project has the responsibility to define its own policy for the acceptance of commercial-off-the shelf (COTS) equipment in ground systems (GS).
COTS equipment shall be evaluated for acceptability from a materials and processes (M&P) standpoint (see 6).
Qualification tests and inspections shall be indicated in the engineering documentation.
Modifications to COTS shall be performed in accordance with this standards manual.
"COTS equipment should be used to the maximum extent possible when (1) it satisfies the intended function, (2) it will not degrade the safety or reliability of the flight or ground system, and (3) it provides a cost savings that exceeds possible cost increases due to unique maintenance or logistics requirements, modifications, or an increase in the complexity of the interfacing equipment."
Vendor or contractor documentation and supporting test data should be incorporated into system control documents.
The GS design shall support the program/project-specific operational requirements of flight hardware.
"In addition to operational requirements, GS should be designed for ease of production, manufacturing, construction, and inspection."
GS should be designed to minimize the complexity and frequency of maintenance.
Close manufacturing tolerances should be avoided unless required by design and performance.
"GS shall not degrade or contaminate flight systems, other GS, subsystems, or experiments while it is being used, checked out, serviced, or otherwise handled."
"GS design shall include access provisions for handling, servicing, calibrating, maintaining, and replacing components and limited-life items."
"GS design should provide for ease of operation, maintenance, servicing, cleaning, and inspection of hardware and software."
GS fault detection and isolation should be considered based on criticality and cost of failures.
Interfaces should be verified by test and/or analysis.
"As a design goal, the number of connections at interfaces should be minimized."
"Fluid, mechanical, or electrical connections in close proximity shall be designed to prevent cross-connections."
Unique design configurations and clear identification marking should both be used to minimize the probability of incorrectly mating connections.
"Design configurations include threads, flanges, sizes, orientation (male/female, left-hand, right-hand), pins, and keys."
"Identification marking (see 5.6.1) should indicate function, commodities, pressure, reference designator, etc."
GS shall be compatible with all facility interfaces.
An assessment may be required to determine whether it is more cost-effective to modify the facility interface or design the GS to meet the existing facility interface.
Some GS interfaces directly to the facility; some GS interfaces to GSS or to facility ground support systems (F-GSS).
GS shall be designed for the operational life specified by program or mission requirements and identified in design drawings and maintenance documents.
Engineering documentation should specify maintenance requirements to meet design life.
Existing GS that was verified to meet the GS requirements of a previous NASA program shall be considered acceptable for use without further verification to the requirements of this standards manual.
"GSE requirements for previous NASA programs are defined in SW-E-0002, NASA-STD-5005, SSP 50004, or a previous version of this standards manual."
Items with limited life shall be identified on design drawings and annotated with the specific limitation to the life of the item.
Use of items with a projected lifetime that is less than the design life of the GS for which the items are intended should be avoided whenever possible.
Elapsed time or cycle indicators should be employed to accumulate operational time or cycles for limited-life items.
The age of items that are installed in a nonoperating mode should also be tracked.
The colors in Appendix A shall be used for GS designed and painted for NASA/KSC.
"If the equipment is COTS, the colors in Appendix A should be used as guidance to make equipment consistent with other GS."
"GS should be designed to minimize the probability of system failure and reduce the severity of the failure effect of the system, including failures caused by operator errors and human-system interaction."
"Procedures and instructions to perform and document analyses (such as Failure Mode and Effects Analysis [FMEA]/Critical Items List [CIL] or sneak circuit analysis), will be in accordance with KNPR 8720.2."
"Redundant systems, subsystems, or components shall be physically oriented or separated such that the failure of one will not prevent the other from performing its intended function."
The design of redundant systems shall provide methods for verifying each redundant element without compromising the reliability of the redundant system.
Failure tolerance is not possible for primary structure and pressure vessels/tubing in rupture mode.
Safety of these systems is achieved by application of design requirements contained in this standards manual.
"More stringent fault tolerance requirements (e.g., two-fault tolerant for loss of flight crew) may be applicable depending on program requirements."
Failure modes/inadvertent operator actions are controlled using a systematic application of approved standards and design margins.
GS may be designed to terminate operations autonomously after the first failure or inadvertent operator action and in time to preclude any scenario that results in loss of life.
This approach is consistent with the historical use of the term “fail-safe” in GS design.
"Purges, ground special power, and launch release systems are examples of systems that interface with other systems whose loss would propagate failures."
Requirements for availability of system functions during launch processing may necessitate fail-operational design.
GS shall be designed such that failures will not be propagated to the flight systems.
"The design of GS should consider how flight hardware/software failures could propagate through the GS and affect other flight systems (vent systems, etc."
"The criticality of a system failure mode will be assigned on the basis of worst-case credible failure effect, assuming the loss of all redundancy (where applicable)."
"This will include possible catastrophic or critical effects of system failure, including the effects of loss of hardware functions."
System inputs (including dependencies such as electrical power and pneumatic purges) and outputs (including all control and monitoring functions) that could fail with potentially catastrophic or critical consequences shall be identified as reliability critical (FMEA is required).
System inputs and outputs can be obtained from a system requirements document if available.
Systems with hazards to personnel or equipment during normal or credible use scenarios shall be identified as critical (Hazard Analysis is required).
"In addition, information obtained from criticality assessments is often used in determining how a system will be designed, documented, fabricated, assembled, installed, and tested."
Single failure that could result in loss of life or vehicle.
"Redundant hardware item, which if all failed, could cause loss of life or vehicle."
"Single failure in a safety or hazard monitoring system that could cause the system to fail to detect, combat, or operate when needed during the existence of a hazardous condition and could result in loss of life or vehicle."
"Single failure that could result in loss of mission, damage to a vehicle system, or major damage to a significant ground asset."
"Redundant hardware item, which if all failed, could cause a loss of mission, damage to a vehicle system, or major damage to a significant ground asset."
"In determining the criticality of a subsystem, emergency systems or contingency and emergency operations (e.g., fire suppression, crew escape, and abort) will not be considered as a level of redundancy."
"In determining the classification of criticality categories, it will be assumed that personnel actions will be performed to activate standby redundant items, as long as requirements for detectability and time to effect are met."
Manual standby redundancy must be activated by a trained operator in accordance with a preapproved written procedure.
"Based on the results of the FMEA, components having failure modes that could cause an undesirable event (other than criticality 3) shall be identified, categorized, and approved in accordance with the applicable agency, program, or KSC requirements."
"In the absence of a program requirement, the methodology of KNPR 8700.2 shall be used."
"All components other than criticality 3 are included in a CIL report, where they are reviewed for criteria such as qualification, failure history, tests, and verifications that will justify the design."
The criticality categories shown in Table 1 shall be used when the program does not identify categories.
"Static components, such as pressure vessels, pressure lines, cables, connectors, and wiring, shall be considered only if failure can be attributed to an active component failure."
Analysis ground rules and exceptions to program methodology or related to the scope of analysis should be clearly stated with justification.
"A Hazard Analysis shall be performed on those systems and subsystems determined by the criticality assessment to be a potential threat to flight systems, ground systems, or safety."
"Based on the results of the Hazard Analysis, those hazards that could not be eliminated by design or mitigated to an acceptable level shall require a Hazard Report."
The Hazard Report summarizes all controls and verifications that would be used to mitigate the hazard.
"As with the FMEA, Hazard Analyses are performed and Hazard Reports are written in accordance with the applicable program requirements."
"In the absence of a program requirement, the methodology of KNPR 8700.2 applies."
FMEA and/or Hazard Analysis including the results of the analysis shall be combined into a Systems Assurance Analysis (SAA) to summarize the risks resulting from each system/subsystem analysis.
CIL and Hazard Reports shall be approved and maintained as part of the design documentation.
GS shall be designed to perform in the natural and induced environments to which it will be subjected during its life cycle.
GS used or stored in an uncontrolled exterior environment shall be designed to function after exposure to the natural environment at its respective geographical location as specified in NASA-HDBK-1001.
"Specifications in NASA-HDBK-1001 may be tailored to reflect program-defined risk and exposure times, including operation within the launch commit criteria of the vehicle."
"Purging of enclosures to protect GS components from the natural environment should be considered essential, in addition to purging of enclosures in hazardous areas as required in 5.4.17."
Testing of GS for launch-induced environment shall be applied in accordance with KSC-STD-164.
"GS not required to function after exposure to the launch-induced environment shall not cause damage or create a hazard to flight hardware, facilities, other GS, personnel, or the environment."
Temperature: +15 °C (60 °F) to +27 °C (80 °F) and within the extremes of +11 °C (52 °F) to +40 °C (104 °F) for a maximum of 1 hour.
"Humidity: nominal 55%, within a range of 30% to 70%."
GS shall be designed to meet the program/project contamination control requirements.
"GS used in an uncontrolled interior environment shall be designed to meet the most severe exterior environmental conditions for humidity and temperature expected at the respective geographical locations, as defined in NASA-HDBK-1001."
"Some uncontrolled interior environments can exceed the most severe exterior environment, g., an enclosed trailer in a hot (tropical or desert) exterior environment."
"If GS will be operated in locations where fire or explosion hazards exist, as defined by NFPA 70, Article 500, it shall be hazardproofed in accordance with the requirements in KSC-STD-E-0002."
Environmental methods and conditions required for testing and qualification of GS components shall be in accordance with MIL-STD-810 and KSC-STD-164.
GS used in Zones 3 or 4 as defined in NASA-HDBK-1001 shall be designed to resist the effects of a seismic event using the criteria and guidelines in ASCE-7.
Documentation in Appendix B should be released and made available to the user.
"Drawings and specifications required for the fabrication, construction, installation, modification, test, operation, maintenance, sustaining, and use of GS shall be prepared in accordance with drawing practices equal to or more stringent than the engineering drawing practices of ASME Y14.100 and KSC-GP-435, Vol."
"Technical documentation (e.g., manuals and reports) shall be prepared in accordance with KSC-DF-107."
"GS design documentation shall identify spare parts, components, materials, and items necessary to support construction, fabrication, installation, activation, test, verification, and operation."
"Limited-life items shall be controlled from the date of their manufacture through their period of operational use, including the time they are in storage."
The status of limited-life items shall be documented.
All components used in critical GS shall undergo qualification to verify performance in their intended environment in accordance with KSC-STD-G-0003.
Qualification of components is guided by NPD 8730.2.
Quality assurance is the function that verifies the compliance of hardware and software to specified requirements.
Quality assurance includes quality engineering and quality inspection.
KSC minimum requirements and best practices are given in KNPR 8730.2.
GS design shall incorporate quality requirements in accordance with the program’s/project’s S&MA Plan.
"Quality requirements shall be defined on the engineering drawings or in other technical documents that are included in the design, fabrication, or installation contract."
"The design documentation should include special quality-related requirements, such as any special processes, certification of personnel or special testing that should be conducted, and any other special requirements that are necessary to produce a quality product."
"Certification documentation for required training of personnel performing processes during fabrication, assembly, installation, and testing of GS shall be maintained in accordance with KNPR 8730.2."
Testing requirements shall be specified in engineering documentation.
Testing shall verify compliance with the applicable specifications and the ability of the GS to perform its required design functions.
"Test documentation, data, and results shall be produced, maintained, and archived in accordance with KNPR 8730.2 and program or project requirements."
Load testing of fixed GS structures may be accomplished using a representative section of the structure.
The minimum test load shall be 125% of the design or working load for GS not used for lifting.
Lifting devices and equipment shall be proofload tested in accordance with NASA-STD-8719.9.
"In the absence of design analysis, a load test of 8 times the safe working load shall satisfy the factor of safety requirements of this standards manual."
This load test is to eliminate the need for structural analysis.
The 8-to-1 load test screens out flaws that could propagate to failure in a structure used at or below the design load.
This option should only be used for ductile materials.
NDE for components and materials shall be in accordance with 6.4.14.
"Metrology and calibration of all test equipment and tools used in support of fabrication, assembly, installation, and test of GS shall be in accordance with KNPR 8730.1."
Documentation shall be provided by the design organization to verify compliance with this standard in accordance with the program/project verification plan (see Appendix B).
"Test, analysis, demonstration, and inspection (including similarity) are recommended methods to verify that each requirement of Sections 4 and 5 of this standard has been satisfied."
"Requirements for packaging, transporting, shipping, and handling shall be in accordance with NPR 6000.1."
"GS should be designed so it can be transported by ground, air, or sea, using commercially available methods."
"Containers shall be compatible with onsite transportation, handling, and storage methods."
Container attachment points shall be provided for crane hoists and tie-downs.
"Containers shall be designed so that indicators that require monitoring (e.g., desiccants, humidity monitors, shock meters, and tilt meters) can be monitored without opening the shipping container."
Containers having a gross weight of more than 65 kilograms (144 pounds) should be provided with integral skids or pallets for shipment.
Procedures shall be employed to protect parts during manufacturing and in-plant handling and storage.
"Any procedures, methods, materials, and devices (such as carts, boxes, containers, or transportation vehicles) that are used to protect parts should be standardized to prevent damage to hardware."
Precision-cleaned parts shall be packaged in accordance with NPR 6000.1 and program contamination control requirements.
The design of conventional steel structures shall be in accordance with AISC 325.
The design of nonconventional steel structures shall be in accordance with established design practices using the factors of safety in 5.1.2.
"Nonconventional steel structures may be designed using provisions of AISC 325, provided that the factors of safety are adjusted to be consistent with 5.1.2."
Galvanizing and other zinc coatings may cause hydrogen embrittlement in high-strength carbon steel fasteners that is difficult to detect.
"When possible, ASTM A325 or SAE Grade 5 fasteners should be used instead."
The design of conventional aluminum structures shall be in accordance with ADM.
The design of nonconventional aluminum structures shall be in accordance with established design practices using the factors of safety in 5.1.2.
"Nonconventional aluminum structures may be designed using provisions of ADM, provided that the factors of safety are adjusted to be consistent with 5.1.2."
"The following minimum factor of safety shall be used for support structures (excluding lifting devices, pressure vessels, preload in threaded fasteners, and springs) when not otherwise specified."
"For brittle metals (less than 5% elongation-to-failure), the factor of safety shall be 5 against exceeding the ultimate tensile strength (UTS)."
"For metal castings without an M&P-approved quality plan, the factor of safety shall be 10 against exceeding the UTS."
"For metal castings with an M&P-approved quality plan, the factor of safety shall be 5 against exceeding the UTS."
"For ductile-matrix composites with no test data, the factor of safety shall be 10 against exceeding the UTS."
"For ductile-matrix composites with test data, the factor of safety shall be 5 against exceeding the UTS."
"For brittle-matrix composites, the factor of safety shall be 10 against exceeding the UTS."
Threaded fasteners shall meet the factors of safety contained in (a) when only the operating load is considered.
Springs shall be designed to a minimum factor of safety of 1.4 against exceeding the UTS.
"Due to the nature of their design, springs do not meet the factors of safety specified for other engineering applications and should be designed in accordance with the Handbook of Spring Design from the Spring Manufacturers Institute."
Structures exposed to cyclic loads shall be designed for a minimum factor of safety of 4 against the design life.
The ratio of fatigue life to design life is 4 as a minimum.
The designer/analyst has the responsibility to determine when cyclic loads are significant in the design.
The relationship between stress/strength and fatigue life is highly nonlinear.
The structure is designed to withstand four times the number of load cycles expected during the design life.
Structural design loads shall be specified in the design documentation.
"The design should consider loads created by the assembly, lifting, handling, transportation, operations, wind conditions, launch-induced environments, and seismic events."
The design of GS used for pneumatic servicing shall be in accordance with KSC-STD-Z-0005.
"Media includes but is not limited to nitrogen, helium, hydrogen, oxygen, methane, breathing air, and special mixtures of these gases."
Breathing-air respirator systems shall conform to 29 CFR 1910.
Vacuum systems shall be designed in accordance with ASME B31.9.
Compressed-air systems above 1.0 MPa (150 psi) shall be designed in accordance with ASME B31.3 and KSC-STD-Z-0005.
ASME B31.1 meets or exceeds the requirements of ASME B31.3 and may be used as an alternative.
"The design of GS used for cryogenic servicing with liquid hydrogen, liquid oxygen, and liquid nitrogen shall be in accordance with KSC-STD-Z-0009."
The design of GS used for cryogenic servicing with liquid methane shall be in accordance with NFPA 59A.
The design of GS used for cryogenic servicing with liquid helium and cryogenic fluids should use KSC-STD-Z-0009 as a guide.
"The design of GS used for hypergolic-fuel or oxidizer servicing with monomethylhydrazine (MMH), unsymmetrical dimethylhydrazine (UDMH), nitrogen tetroxide (N2O4), aerozine 50 (A-50), or hydrazine (N2H4) shall be in accordance with KSC-STD-Z-0006."
"Hypergolic propellants are fuels and oxidizers or fuels and catalysts that, when combined, produce a violent, explosive, high-energy exothermic reaction, without any other ignition source."
"Hypergolic propellants are highly toxic, are very sensitive to material selection for containment or sealing, and require the use of personal protective equipment (PPE) for operators of GS."
"The design of GS used for servicing with hydrocarbon fuels (JP-4, JP-5, RP-1, and ASTM jet fuels A and B) shall be in accordance with ASME B31.3."
The design of GS used for servicing hydraulic systems shall be in accordance with ASME B31.3 and with KSC-STD-Z-0005.
Gaseous nitrogen shall be isolated from the ECS air ducting system by using two valves in series in the gaseous nitrogen supply line and vented to exterior atmosphere between the valves.
"If the gaseous nitrogen supply is connected to the ECS duct system, ECS shall include the capability of monitoring the oxygen content in the ducting."
The design of ducting shall be in accordance with ASME B31.3 or SMACNA 1958.
Prefilters should be used in fresh-air intakes and be located upstream of primary filters to prevent excessive loading of the primary filter.
Filters should be located immediately upstream of all interfaces where control of particulate matter is required for system performance.
The design of GS used for life support systems shall be in accordance with KSC-STD-Z-0008.
"Items (valves, gages, levers, bolts, nuts, and any other items required to be moved, turned, manipulated, or monitored) should be located in a position that will make it easier for a PHE-suited operator to access the item while standing."
Sufficient clearance should be provided to preclude the operator from brushing against other surfaces.
The design should include suitable provisions to prevent discomfort or fatigue for the PHE-suited personnel.
Use of expanded metal surfaces and other sharp edges should be avoided.
The design for installation of threaded fastener shall not exceed a preload of 70% of the yield stress on the net cross section of the fastener.
"The installation criteria for structural bolts, such as those specified in ASTM A325 and ASTM A490, shall be in accordance with AISC 325."
ASTM A490 structural bolts should be avoided in a corrosive environment.
Galvanizing and other zinc coatings may cause hydrogen embrittlement that is difficult to detect.
"When possible, ASTM A325 bolts should be used instead."
"Installation criteria shall be documented on the fabrication, assembly, or installation drawing."
This section addresses the design of and maximum allowable preload for threaded fasteners.
"The design application may require a lower preload value due to actual applied loads, gaskets, seals, etc."
Other sources for installation/torque criteria include MSFC-STD-486 and KSC-SPEC-Z-0008.
"For nonstructural applications where a specific clamping force is not required, the designer may specify that fasteners be installed snug tight (tighten the fastener with standard tools, using ordinary force, until the assembly layers come into firm contact, determined visually and by feel)."
Quick-release pins and pin tethers shall be in accordance with KSC-STD-P-0006.
The design of jacks shall be in accordance with ASME B30.1.
GS used for transporting flight hardware shall be designed in accordance with SAE ARP 1247.
Towed GS shall be designed in accordance with SAE AS 8090.
Transportation equipment shall be designed so that loads imparted to flight hardware do not exceed 80% of the flight limit loads.
Transportation loads should be evaluated early in the design cycle since they may be the governing design load case.
All pressurized systems shall comply with NASA-STD-8719.17.
"All NASA designs are required to comply with NASA-STD-8719.17, which encompasses many of the specific requirements contained in this document."
This standard and the standards cited herein are intended to provide additional requirements.
Shops and welders repairing or altering code vessels require R stamp certification.
"For noncode vessels, R stamp certification is not required but is good practice."
COPVs should be used only when necessary because of weight constraints.
Special training and certification are required for personnel handling and repairing COPVs.
Damage to COPVs can be difficult to detect because reliable NDE methods have not been developed.
"COPV failure modes can be catastrophic, requiring special safety clears during pressurization."
All ASME code-stamped vessels shall be registered with the National Board of Boiler and Pressure Vessel Inspectors.
Pressure vessels used for transporting hazardous commodities shall meet the Department of Transportation requirements in 49 CFR 171 through 180.
"Piping and support systems, except those in remote or “cross country” areas or where personnel traffic is low, shall be in accordance with ASME B31.3 the piping system may be designed to ASME B31.8."
"Examples include piping between facilities in low-traffic areas, buried pipelines, and long-run piping between remote facilities."
"Where ASME B31.3 piping connects to ASME B31.8 piping g., at facility interfaces), the design should consider the differences in internal diameters and how the piping will be cleaned (via pipeline cleaning pigs)."
"The design of pressure systems, including pressure vessels, transmission lines, and GS, shall comply with KNPR 8715.3, Section 13, which complies with NASA-STD-8719.17."
Reusable umbilicals shall be designed in accordance with KSC-GP-986.
The design of GS for electrical control and monitoring shall be in accordance with KSC-STD-E-0001.
AFSPCMAN 91-710 and MIL-HDBK-454 should be consulted for general guidance in electrical/electronic design.
The electrical design of pneumatic and hydraulic components shall be in accordance with KSC-STD-E-0004.
The design of pyrotechnic GS shall be in accordance with NASA-STD-8719.12.
The design of electrical power systems covered by NFPA 70 shall be in accordance with NFPA 70 and NFPA 70E.
"Incorporation of batteries in the design of GS should follow the recommended practices in the following documents: IEEE 484, IEEE 1106, IEEE 1187, IEEE 446, ANSI C18.2M, Part 1, and ANSI C18.3M, Part 1."
"For nonfacility ground systems, bonding and grounding shall be in accordance with the requirements of KSC-STD-E-0022 and NFPA 70."
"For facility systems and earth ground, bonding and grounding shall be in accordance with the requirements of KSC-STD-E-0012 and NFPA 70."
The designer should be aware whether the system being designed will be operated under a lightning protection system or where induced static electricity is possible.
"For additional information on lightning protection, refer to International Electrotechnical Commission standard IEC 62305, Parts 1 through 4."
"The design of electronic equipment and wiring for all voltages in hazardous locations shall be in accordance with NFPA 70, Article 500; and KSC-STD-E-0002."
Software incorporated into the design of GS shall meet the requirements of NPR 7150.2.
"This ensures that KSC-developed software meets the Agency requirements for software engineering practices, software assurance, and software safety."
NPR 7150.2 contains provisions applicable to COTS software in NASA-developed systems.
Firmware incorporated in the design of GS shall meet the requirements of NPR 7150.2.
EEE parts shall be selected in accordance with KSC-PLN-5406.
This plan provides detailed requirements and guidelines for selection and utilization of EEE parts in accordance with KNPR 8720.2.
"All ESD-sensitive components and assemblies shall be handled using practices in accordance with ESD S20.20, MIL-STD-1686, and MIL-HDBK-263."
Insulator materials should not be used near ESD-sensitive components or assemblies.
Austenitic stainless-steel tubing shall be in accordance with KSC-SPEC-Z-0007.
"Stainless-steel tubing shall be fabricated, tested, and installed in accordance with KSC-SPEC-Z-0008."
"When directly exposed to a corrosive environment, tubing shall consist of Unified Numbering System (UNS) N08367 or S31245 superaustenitic stainless steel (trade name AL6XN or 254SMO) in accordance with KSC-SPEC-P-0027."
"Superaustenitic stainless-steel tubing shall be fabricated, tested, and installed in accordance with KSC-SPEC-Z-0008."
Stainless-steel pipe for fluid systems shall be in accordance with ASTM A312.
Aluminum pipe for fluid systems shall be in accordance with ASTM B241.
Expansion joints used in fluid systems in marine or launch-induced environments shall be made from UNS N06022 (Hastelloy C22) material.
"Flared tubing fittings, tube weld fittings, and pipe fittings shall be selected in accordance with KSC-GP-425."
"Protective covers shall be provided for all hoses, ports, fittings, and other fluid-fitting connections to GS to protect the threads, protect the sealing surface, and maintain the cleanliness of the system."
"Prior to installation, protective caps, plugs, and covers shall be maintained clean at the same level or better than the system that they are protecting."
"Caution should be used in selecting caps and plugs as covers due to the potential for generating debris during installation or removal, especially in oxygen systems."
"When possible, the protective cover should be connected with a lanyard or the equipment should have a designated storage provision."
"If a part is not covered by the 79K80000 series of specifications, it shall be documented with the following minimum information: commodity, environment, performance, installed dimensions, connection interfaces, recommended vendor, materials, compatibility, qualification/acceptance criteria, and recommended maintenance."
Electrical-power receptacles and plugs within GS shall be in accordance with KSC-GP-864.
"Flexible, multiconductor, jacketed electrical cable and cable harnesses shall be in accordance with KSC-GP-864."
"Fiber-optic cable assemblies, installations, and terminations shall be in accordance with NASA-STD-8739.5 and KSC-GP-864."
Protective caps shall be provided for all fiber-optic connections to GS so that the mating surface is protected.
"Electrical hookup wire shall be in accordance with SAE AS 50861, MIL-DTL-16878, or SAE AS 22759."
"Electrical multiconductor connectors for GS used for electrical control and monitoring shall be selected from the following documents: SAE AS 50151, MIL-DTL-22992, MIL-DTL-24308, MIL-DTL-38999, IEC 60807, or KSC-GP-864."
Coaxial RF connectors shall be selected from MIL-PRF-39012.
Protective covers or caps shall be specified for use with electrical-connector plugs and receptacles in accordance with KSC-GP-864 when they are not connected.
Metallic protection caps should be used during transportation or other potentially damaging handling situations.
Optical covers/caps should be easy to install and remove.
"The covers/caps should be connected with a lanyard, or the equipment should have a designated storage provision."
Sensors and transducers used in the design of GS systems shall be selected using KSC-NE-9187.
Measurement applications that provide visibility only and are not relied upon to control a condition that could potentially damage flight hardware or potentially create a safety hazard may use COTS components.
"If a part is not covered by KSC-NE-9187, it shall be documented with the following minimum information included: commodity, environment, performance, recommended vendor, materials, compatibility, and qualification/acceptance criteria."
Purged electrical enclosures in hazardous locations shall be in accordance with NFPA 496.
Purged electrical enclosures in nonhazardous locations shall be outfitted with purge hardware in accordance with 79K07491.
NFPA 496 contains requirements for the protection of electrical and electronic equipment recognized by NFPA 70 for installations in hazardous locations.
"Electronic racks, panels, and enclosures shall be in accordance with KSC-SPEC-E-0002."
"Electronic racks, panels, and modular enclosures should conform to the configuration and dimensional requirements of ECA EIA/ECA 310-E."
"Rigid, flexible, and rigid-flex printed circuit boards (single, double, metal-core, or multilayer structures) shall meet the design specifications of the following standards, as applicable: IPC-2221 (For critical applications, performance classification 3 shall be used."
All board types within the IPC-2221 series standard documents are acceptable.
"Rigid, flexible, and rigid-flex printed circuit boards (single, double, metal-core, or multilayer structures) shall meet the qualification and performance specifications of the following standards, as applicable: IPC-6011, (For critical applications, performance classification 3 shall be used."
Printed circuit assemblies that will not be exposed to vibration or thermal cycling at space flight levels shall be fabricated in accordance with IPC J-STD-001.
Printed circuit assemblies that will be exposed to vibration or thermal cycling at space flight levels shall be fabricated in accordance with IPC J-STD-001ES.
"Motors and generators used in GS shall be selected in accordance with the system requirements for speed, torque, horsepower, and environment."
Motors and generators shall meet the applicable National Electrical Manufacturers Association (NEMA) standards and NFPA requirements that govern the classification and general application of motors and generators.
"NEMA MG 1 is a comprehensive document that includes the classification, general standards, manufacturing, and test of motors and generators."
This document should be used as a guide for specification and selection of GS motors and generators.
NFPA 70 provides the size of wiring and conduit required for the motor connections.
"Motor starters and controllers shall be in accordance with the type of motor, performance ratings, and type of control required."
Enclosures for motor starters and controllers shall meet the environmental requirements for their locations.
"NEMA ICS 2, Parts 1 through 9, is a comprehensive document that provides practical information concerning ratings, construction, test, performance, and manufacture of industrial control equipment."
"NEMA ICS 61800-2 specifies ratings for low-voltage, adjustable-frequency AC power drive systems."
NFPA 70 provides the size of wiring and conduit required for the starter/controller connections.
GS fasteners used in critical applications shall have lot traceability from the manufacturer to final installation.
NASA RP-1228 should be used for guidance in selecting and analyzing fasteners.
The reuse of self-locking fasteners shall be permitted when the running torque before clamp-up remains between the maximum self-locking torque and the minimum break- away torque.
Self-locking fasteners should be used wherever possible.
Fasteners used in corrosive environments and applications where condensation can occur shall be installed using a corrosion-resistant sealant while the sealant is still wet (wet installation).
"When liquid-locking compounds are used for fastener installation, engineering drawings shall specify a validated process for application."
Liquid-locking compounds should be selected in accordance with ASTM D5363.
Electrical and electronic GSE and GSS (nonfacility) shall be designed and tested for electromagnetic compatibility as specified in KSC-STD-E-0022.
Facility systems and facility GSS shall be in accordance with the requirements of KSC-STD-E-0012.
The application of MIL-STD-461 to GSE systems should be based on an evaluation of the potential for flight hardware interaction and any existing commercial standards to which the hardware is already certified.
GS shall be identified and marked in accordance with KSC-STD-E-0015.
"GS that have been load-tested shall be identified and marked in accordance with KSC-STD-141, and for lifting equipment, NASA-STD-8719.9."
Ground piping systems shall be identified and color-coded in accordance with KSC-STD-SF-0004.
Compressed-gas cylinders shall be labeled in accordance with CGA C-7.
"GS used for transportation, handling, and personnel access shall be conspicuously marked to indicate the maximum safe working load in accordance with KSC-STD-E-0015, and for lifting equipment, NASA-STD-8719.9."
Labels for cable assemblies shall comply with KSC-E-166.
Labels shall meet the requirements of KSC-STD-E-0015.
Labels for wire harnesses shall comply with KSC-E-166.
"Labels shall be of heat-shrinkable sleeving that conforms to the requirements of SAE AMS-DTL-23053/5, Class 1."
"The heat-shrink labels shall be marked in accordance with SAE AS 5942 and shall meet the testing requirements of MIL-STD-202, Method 215."
MIL-DTL-23053/5 was replaced by SAE AMS-DTL-23053/5.
"Serial numbers or other unique identifiers shall be marked on those parts, components, or assemblies that contain limited-life items (e.g., valves or regulators) or that require periodic inspection, checkout, repair, maintenance, servicing, or calibration (e.g., pressure transducers or gages)."
Other unique identifiers include A-numbers and drawing dash numbers for end items.
"Hardware assemblies, components, and parts with the same part number shall be physically and functionally interchangeable."
"All GS shall be designed and fabricated in accordance with 29 CFR 1910, 29 CFR 1926, and NPR 8715.3."
"A hazard analysis shall be conducted in accordance with program-defined methodology as part of the GS design process to identify, mitigate, and control hazards."
"In the absence of a program- defined methodology, KNPR 8700.2 shall be used."
GS to be used at KSC shall meet the safety requirements of KNPR 8715.3.
"GS to be used on Air Force property shall meet the requirements of AFSPCMAN 91-710, Volume 3."
GS to be used at other NASA facilities shall meet the safety requirements of those facilities.
GS shall provide caution and warning indications to alert personnel of impending or existing hazards.
GS should be designed to allow efficient implementation of the applicable Occupational Safety and Health Administration (OSHA) lockout/tagout requirements.
HF-STD-001 shall be used to establish human factors criteria for GS design.
The design of GS shall meet the IT security requirements in NPR 2810.1.
M&P used in the design and fabrication of GS shall be selected by considering the worst-case operational requirements for the particular application and the design engineering properties of the candidate materials.
"For example, the operational requirements should consider operational temperature limits, loads, contamination, life expectancy, exposure to moisture or other fluids, corrosive environments, and launch-induced and natural environments."
"Properties that should be considered in material selection include mechanical properties, fracture toughness, flammability and offgassing characteristics, corrosion and stress corrosion resistance, thermal- and mechanical-fatigue properties, glass-transition temperature, mismatches between coefficients of thermal expansion, vacuum outgassing, fluid compatibility, microbial resistance, moisture resistance, fretting, galling, and susceptibility to ESD and contamination."
"The following documents shall be used to establish materials properties for use in system or component design: DOT/FAA/AR-MMPDS, MIL-HDBK-17-2, MIL-HDBK-17-4, MIL-HDBK-17-5, and voluntary-consensus standards or codes (e.g., ASME BPVC-VIII and ASME BPVC-X for pressure vessels, and AISC 325 for structural steel)."
The values listed in the codes or standards are minimum material properties.
"The use of minimum material properties, as stated by the code, is intrinsic to the factor of safety, margin of safety, strength factor, etc., of the design."
Parts machined from polychlorotrifluoroethylene (PCTFE) shall comply with ASTM D7194.
ASTM D7194 requires an annealing process for parts machined from PCTFE.
"Annealing results in dimensional stability, which minimizes the occurrence of flow friction in oxygen system components with PCTFE soft goods."
"If the material is not covered by a design code or one of these sources, the Aerospace Structural Metals Database or other published industry sources should be used in accordance with the best practices for design."
"The properties listed in these documents are typical values, not minimum values; this must be considered when applying the factor of safety appropriate for the design."
The design drawings shall be signed by an M&P engineer authorized by NASA.
Composition and properties of all materials and parts shall be certified by the manufacturer or supplier as required by the procuring document.
"The Materials and Processes Technical Information System (MAPTIS) shall be consulted to obtain material codes and ratings for materials, standard and commercial parts, and components."
"For noncritical GS, the M&P organization’s approval on the engineering drawing approves deviations from other M&P requirements of this standard."
The use of materials and processes that do not comply with the requirements of this standard may still be acceptable in the actual hardware applications.
Materials shall be tested in accordance with NASA-STD-6001.
Material flammability ratings and tests based on NASA-STD-6001 are available in the MAPTIS database for many materials.
"When a material is sufficiently similar (chemically and physically) to a material found to be acceptable by testing in accordance with NASA-STD-6001, this material may be used without additional testing if its use is approved by the M&P organization."
"If a material passes the flammability test on a metal substrate, it shall be used on metal substrates of the same thickness or greater."
"If the material will be used on a thinner or non-heat-sinking substrate (or on no substrate at all), it shall be retested or considered flammable."
"Many situations arise in which flammable materials are used in an acceptable manner without testing, but such uses require mitigation practices and approval by the M&P organzation."
Guidelines for assessment and mitigation of hardware flammability characteristics can be found in JSC 29353.
"Electrical-wire insulation materials shall be evaluated for flammability in accordance with NASA-STD-6001, Test 4."
"Arc tracking shall be evaluated in accordance with NASA-STD-6001, Test 18."
"Arc tracking testing is not required for polytetrafluoroethylene (PTFE), PTFE laminate, ethylene tetrafluoroethlyene (ETFE), or silicone-insulated wires because the resistance of these materials to arc tracking has already been established."
"For the purposes of this standard, the definition of “hazardous fluids” includes gaseous oxygen, liquid oxygen, fuels, oxidizers, and other fluids that could cause corrosion, chemically or physically degrade materials in the system, or cause an exothermic reaction."
"NASA-STD-6001, Test 15, tests materials for short-term exposure to fuels and oxidizers."
"NASA-STD-6001, Test A.7, tests materials for incidental exposure, such as a splash, to fuels and oxidizers."
"For many materials, material compatibility ratings and test results based on NASA-STD-6001, Test 15, are available in the MAPTIS database."
"Appropriate compatibility tests shall be conducted for materials that are subjected to long-term exposure to fuels, oxidizers, or other hazardous fluids."
The test conditions are customer-specified and shall simulate the worst-case use environment that would enhance reactions or degradation of the material or fluid.
"Liquid oxygen and gaseous oxygen systems shall use materials that are nonflammable in their worst-case use configuration, as defined by NASA-STD-6001, Test 17, for upward flammability in GO2 (or Test 1 for materials used in oxygen pressures that are less than 350 kPa (50 psia)."
Material flammability ratings and test results based on NASA-STD-6001 are available in the MAPTIS database for many materials.
KTI-5210 may be consulted for a summary of oxygen compatibility test results for various materials used in liquid oxygen and gaseous oxygen applications.
The configurational test method and acceptance criteria shall be reviewed and approved by the M&P organization.
The as-built configuration shall be verified against the oxygen compatibility assessment to ensure that mitigation methods identified in the report were incorporated into the design and construction of the hardware.
"For compressed-air systems and oxygen-enriched systems, the need for an oxygen compatibility assessment shall be addressed on a case-by-case basis."
Compressed-air systems and oxygen-enriched systems are inherently less hazardous than systems containing pure oxygen; the hazard increases with oxygen concentration and pressure.
"Guidelines on the design of safe oxygen systems are contained in ASTM MNL 36, ASTM G88, ASTM G63, ASTM G94, and NASA/TM-2007-213740."
"Components shall be retested if the results are invalidated by actions occurring after the test (such as rework, repair, or interfacing with hardware for which the cleanliness level is unknown or uncontrolled)."
"Carbon and low-alloy steels heat-treated to strength levels at or above 1,240 MPa (180 ksi) UTS shall be approved by the M&P organization due to sensitivity to SCC."
The ductile-to-brittle transition temperature exhibited in steels should be considered when using carbon and low-alloy steels in hardware operating in or exposed to low temperatures while in service.
"For some alloys, the transition temperature may be as high as the ambient temperature."
"Welding should be performed only on low-carbon, stabilized grades, or superaustenitic grades (i.e., UNS S30403, UNS S31603, UNS S32100, UNS S34700, UNS N08367, and UNS S31254)."
"Welding higher-carbon, unstabilized austenitic stainless steel can result in sensitization in the weld heat-affected zone."
"Caution should be exercised in using martensitic and ferritic stainless steels because these are susceptible to hydrogen embrittlement, corrosion, and stress corrosion."
Austenitic stainless steels are susceptible to pitting corrosion and crevice corrosion in a marine environment; some austenitic stainless steels are susceptible to SCC in a marine environment.
UNS N08367 (trade name AL-6XN) or UNS S31254 (trade name 254 SMO) shall be used in pressure piping and tubing in lieu of 300-series stainless steel when the piping or tubing is directly exposed to a corrosive environment.
Hardware should be designed to avoid fretting or wear of stainless-steel alloys.
Lubricants and lubricated coatings should be considered for use with stainless-steel materials in applications where they come into contact through a sliding movement.
Stainless-steel alloys (such as Nitronic 60) that resist galling should be considered as alternatives.
"Alloys in the 5000-series containing more than 3% magnesium shall not be used in applications where the temperature exceeds 66 °C (150 °F), because grain boundary precipitation above this temperature can create stress-corrosion sensitivity."
Hardware made with aluminum alloys should not be loaded through the short transverse grain direction because resistance to SCC is at a minimum in that direction.
"Alloys with high nickel content are susceptible to sulfur embrittlement; therefore, any foreign material that could contain sulfur, such as oils, grease, and cutting lubricants, shall be removed before heat treatment, welding, or high-temperature service."
"Some of the precipitation-hardening superalloys are susceptible to depletion of the alloying element at the surface in a high-temperature, oxidizing environment."
"This effect should be carefully evaluated when a thin sheet is used, since a slight depletion could involve a considerable proportion of the cross section of the material."
Titanium and its alloys exhibit very poor resistance to wear.
"Fretting may cause cracking, potentially leading to fatigue failure."
The design should avoid fretting or wear in titanium and its alloys.
Titanium alloys shall not be used with LO2 or GO2 at any pressure or with air at oxygen partial pressures above 35 kPa (5 psia).
"The surfaces of titanium and titanium alloy mill products shall be 100% machined, chemically milled, or pickled to a sufficient depth to remove all oxygen-contaminated layers (alpha case) formed as a result of mill processing, heat treating, and forming operations at elevated temperatures."
All cleaning fluids and other chemicals used during manufacturing and processing of titanium hardware shall be verified to be compatible with and not detrimental to the material’s performance.
"The use of titanium in hydrochloric acid, chlorinated solvents, chlorinated cutting fluids, fluorinated hydrocarbons, and anhydrous methyl alcohol should be avoided due to titanium’s susceptibility to SCC."
"Contact of titanium alloys with mercury, cadmium, silver, and gold should be avoided at certain temperature ranges because of liquid-metal-induced embrittlement and/or solid-metal-induced embrittlement."
"Copper alloys, brasses, and bronzes that are resistant to general corrosion and pitting, and highly resistant to SCC in accordance with MSFC-STD-3029 shall be used in GS."
GS should be designed so that copper is not exposed to hydrazine environments.
"Copper has the potential for SCC when exposed to ammonia, which is a product of hydrazine decomposition."
"Beryllium copper (UNS C17200) is commonly used for high-strength, nonsparking structural components in applications where it is subject to contact and wear."
"Beryllium particles, beryllium oxide, and other beryllium compounds are toxic when inhaled."
Extreme caution must be exercised during fabrication to avoid exposing personnel to beryllium or beryllium compounds.
"Machining, grinding, and finishing operations on beryllium and beryllium alloys shall be performed either wet, using a liquid coolant with local ventilation, or dry, using high-velocity, close-capture ventilation."
Refer to the appropriate Material Safety Data Sheet for more detail.
Tin solder and tin plating shall be alloyed with at least 3% lead to prevent the growth of tin whiskers.
"For critical GS, lot sampling shall be used to verify the presence of at least 3% lead."
Elastomers shall be in accordance with MIL-HDBK-149.
"Elastomers shall operate within the parameters of a design service life, including the vendor-specified shelf life."
Elastomers shall be cure-dated for tracking purposes.
Elastomers shall not have a corrosive effect on other materials when exposed to conditions normally encountered in service.
Examples include one-part silicones that liberate acetic acid when they are cured.
"Composite materials used in GS shall be in accordance with MIL-HDBK-17, Volumes 1 through 5."
Refractory concrete used for heat and blast protection of flame deflectors and other areas of the launch pad shall be in accordance with KSC-SPEC-P-0012.
"NASA-TM-86556, Parts A and B, should be used in evaluating and selecting solid and liquid lubricants for GS."
Guidelines on additional lubricants are contained in NASA/CR–2005-213424.
Long-life performance should be considered when selecting lubricants.
Use of lubricants near precision-cleaned hardware or electrical connections should be minimized or tightly controlled to prevent cross-contamination.
Lubricants containing chloro-fluoro compounds shall not be used with aluminum or magnesium.
Lubricants containing chloro-fluoro compounds shall not be heated above their maximum temperature rating.
The decomposition/reaction products that result from overheating lubricants that contain chloro- fluoro compounds can attack metallic materials and can be toxic.
Lubrication of flared tube fittings shall be in accordance with KSC-SPEC-Z-0009.
Materials that are not expected to meet the design life requirements but must be used for functional reasons shall be identified as limited-life items in accordance with 4.2.2.2.
Materials should be selected to meet the useful life of the hardware without the need for additional maintenance.
"Useful life includes storage life, installed life in a nonoperating mode, and operational service life."
"Thin plastic films and tape materials used in GS shall be tested in accordance with and meet the requirements of the following for flammability, ESD, and hypergolic ignition/breakthrough characteristics, respectively, as appropriate for the application: NASA-STD-6001 (Test 1 and and MMA-1985-79."
Material flammability ratings and hypergol compatibility test results for many PFAs are found in the MAPTIS database.
"KTI-5212 may be consulted for a summary of flammability, ESD, and hypergol compatibility test results for various PFAs."
Fluorocarbon polymers (including ETFE) and silicones are considered acceptable.
Riveting should be in accordance with MSFC-STD-156.
"Though MSFC-STD-156 is not current, it does contain the best practices for riveting."
"Fusion welding of GSE shall meet all requirements for nonflight hardware in AWS D17.1, with the exception of pressure systems (see 5.2.13)."
Welding of pressure systems is covered by ASME BPVC and ASME B31.3.
"The selection of parent materials and weld methods for GSE should be based on consideration of the weldments, including adjacent heat-affected zones, as they affect the operational capability of the parts concerned."
"Welding procedures should be selected to provide a weld of the required quality, use the minimum amount of energy, and protect the heated metal from contamination."
"A WPS is always required, even if the procedure is considered to be prequalified by an applicable AWS standard."
WPSs for stainless steels and nickel alloys must always be qualified by testing.
"Prior to the start of any production welding, all WPSs and procedure qualification records (PQRs) shall be approved by an M&P engineer authorized by NASA."
"Prior to the start of production welding, each welder and welding operator shall be qualified."
"Prior to the start of any production welding, all welder/welding operator performance qualification (WPQ) shall be approved by an M&P engineer authorized by NASA."
Brazing should be conducted in accordance with AWS C3.3.
Brazing of aluminum alloys shall meet the requirements of AWS C3.7M/C3.7.
"Torch, induction, and furnace brazing shall meet the requirements of AWS C3.4M/C3.4, AWS C3.5M/C3.5, and AWS C3.6M/C3.6."
"Subsequent fusion welding operations in the vicinity of brazed joints or other operations involving high temperatures that might affect the brazed joint shall be prohibited unless it can be demonstrated that the fixturing, processes, methods, and/or procedures employed will preclude degradation of the brazed joint."
The shear strength of brazed joints shall be evaluated in accordance with AWS C3.2M/C3.2.
"For furnace brazing of complex configurations, such as heat exchangers and cold plates, destructive testing shall be conducted on preproduction brazed joints to verify that the brazed layer that extends beyond the fillet area is continuous and forms a uniform phase."
Brazing of pressure vessels shall be in accordance with ASME BPVC VIII.
Soldering of electrical connections not exposed to vibration or thermal cycling shall be in accordance IPC J-STD-001.
Soldering of electrical connections exposed to vibration or thermal cycling shall be performed in accordance with IPC J-STD-001ES.
"For critical GS, lot sampling shall be used to verify the lead content."
Soldering shall not be used for structural applications.
Steel parts shall be heat-treated to meet the requirements of SAE AMS-H-6875 or SAE AMS 2759.
Electrodeposited nickel plating shall be applied according to the requirements of SAE AMS 2403 or SAE AMS 2423.
Electroless nickel plate shall be applied in accordance with SAE AMS 2404.
The nickel-aluminum interface in nickel-plated aluminum shall be protected from exposure to corrosive environments.
"Nickel and aluminum form a strong galvanic cell at the nickel-aluminum interface, and exposure of the aluminum alloy to a corrosive environment can rapidly debond the nickel plate."
All repairs to damaged galvanized coatings shall be in accordance with ASTM A780.
Chromium plating shall be in accordance with SAE AMS 2460.
Cadmium plating shall be in accordance with SAE AMS-QQ-P-416.
"For critical GS, after the forging technique (including degree of working) is established, the first production forging shall be sectioned to show the grain-flow patterns and to verify mechanical properties."
The procedure shall be repeated after any change in the forging technique.
The information gained from this effort should be used to redesign the forging technique as necessary.
The resulting data shall be retained and made available for review by the procuring activity.
"Forging techniques should produce an internal grain-flow pattern parallel to the principal stresses, because mechanical properties are optimum in the direction of material flow during forging."
The forging pattern should be free from reentrant and sharply folded flow lines.
Castings shall meet the requirements in SAE AMS 2175.
"Structural adhesive bonding shall be in accordance with MSFC-SPEC-445, with the exception of retesting."
Retesting of adhesives used for production parts is not required if they are within the manufacturer’s recommended shelf life.
Structural adhesive bonding processes shall be controlled by a documented process to prevent contamination.
The sensitivity of structural adhesive bonds to contamination is of particular concern.
"In the absence of relevant performance data, bond sensitivity studies should be conducted to verify that the required adhesive properties are maintained after exposure to the expected materials at the expected concentrations, including ozone, ambient humidity, cleaning fluids, and lubricants."
Adequate cleanliness inspections should be conducted during the fabrication part of the bonding process.
Bonded primary structural joints shall demonstrate cohesive failure modes in shear at ambient temperature.
"Surface cleanliness of fluid systems shall be in accordance with ISO 14952, Parts 1 through 6."
The cleanliness level and test method shall be specified in the design documentation.
"For GS interfaces with precision-cleaned fluid systems for flight, the supply interface/final filters shall be located as close to the flight hardware interface as possible."
"Interface filters shall be used on outlet lines if it is determined that any operations, such as the servicing or deservicing of fluids, could permit flow in a reverse direction."
Interfacing fluid system GS shall be cleaned to meet or exceed the cleanliness level of the flight hardware.
"The following standards are considered functionally equivalent to ISO 14952: KSC-C-123, MSFC-SPEC-164, JPR 5322.1, ASTM G93, IEST-STD-CC1246, and SAE ARP 1176."
Other precision cleaning standards may be used if determined equivalent by an M&P engineer approved by NASA.
Crimping shall be in accordance with NASA-STD-8739.4.
Potting and molding of electrical connectors shall be in accordance with KSC-STD-132.
"Electrical cables shall be designed and fabricated in accordance with KSC-GP-864 as determined by application, criticality, and operational environment."
"Where electronic circuitry can be damaged or degraded by moisture, dust, chemicals, temperature extremes, mechanical stress, or vibration, conformal coating shall be required in accordance with NASA-STD-8739.1."
"When established, requirements for conformal coating should be stated in the design documentation."
"Protective coating of hardware should be appropriate to the condition, use, and environment to which the hardware will be exposed during its life cycle."
The coating should minimize corrosion and its color should indicate its use (see 4.2.2.3).
"Guidelines for corrosion control for facilities, systems, and equipment are given in TM-584."
Protective coating of hardware shall be in accordance with NASA-STD-5008.
Corrosion control of galvanic couples shall be in accordance with MIL-STD-889.
"For critical GS, faying surfaces of metal alloys and electrical bonding connections, except for nickel-plated surfaces, shall be sealed in accordance with NASA-STD-5008, except for nickel-plated surfaces."
"In critical applications, metals exposed to the KSC environment shall be selected from alloys that are highly resistant to SCC as specified in MSFC-STD-3029."
"In noncritical applications, the designer should select from alloys that are highly resistant to SCC as specified in MSFC-STD-3029."
"When COTS items are selected, the designer should attempt to identify the materials used and determine if an SCC failure would be critical."
"Materials protected from the environment, such as lubricated roller bearings and gears within a sealed gearbox, are exempt from the above requirement."
The M&P authority’s signature or electronic approval of the design drawings constitutes approval to use the materials of the design in the intended application.
"Typical NDE methods include penetrant, magnetic particle, radiographic, ultrasonic, and eddy current testing."
"NDE inspection is not limited to these methods and may include additional methods such as leak testing, and advanced methods such as shearography and thermography, as required."
The embrittlement of a metal or alloy by hydrogen involves the diffusion of atomic hydrogen into a component subject to a manufacturing process or environmental event.
"The entrained hydrogen reduces the ductility of the metal and load-bearing capacity, resulting in brittle fracture at stresses below the yield stress of susceptible materials."
"Hydrogen can be introduced by processes such as electroplating, phosphating, pickling, passivation, and welding."
Hydrogen can also be introduced as a by-product of a corrosion reaction in which some of the hydrogen enters the metal in atomic form.
Test data may have to be generated in a simulated environment to support the approval rationale.
Guidelines for designing safe hydrogen systems are contained in ANSI/AIAA/G-095.
"After electroplating, phosphating, pickling, passivation, or other processes that can introduce hydrogen, materials that are susceptible to hydrogen embrittlement shall undergo a final baking heat treatment in accordance with SAE AMS 2759/9."
Corrosion protection shall be in accordance with NASA-STD-5008 to minimize the risk of hydrogen embrittlement due to corrosion.
Engineering documentation shall specify internal and external surface cleanliness levels for all GS.
The GS provider is responsible for submitting documentation to verify that the hardware/software has been developed in accordance with this standard.
"The GS provider is responsible for providing all the necessary documentation to the using organization when the GS is delivered for use, regardless of who “owns” the GS at the time of delivery."
"The using organization requires documentation for safely operating, maintaining, and servicing the GS."
"To reduce risk to the mission, as well as to ground personnel and flight crews, a Failure Modes and Effects Analysis should be completed and submitted in accordance with the criticality assigned to the GS by the responsible program or project."
KDP-P-2713 lists typical documentation requirements.
"The preparing activity must complete blocks 1, 2, 3, and 8."
"The submitter of this form must complete blocks 4, 5, 6, and 7."
The preparing activity must provide a reply within 30 days from receipt of the form.
"This form may not be used to request copies of documents, nor to request waivers or clarification of requirements on current contracts."
Comments submitted on this form do not constitute or imply authorization to waive any portion of the referenced document or to amend contractual requirements.
"NATURE OF CHANGE (Identify paragraph number and include proposed rewrite, if possible."
"The public reporting burden for this collection of information is estimated to average I hour per response, including the time for reviewing instructions, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information."
"Send comments regarding this burden estimate or any other aspect of this collection of information, including suggestions for reducing this burden, to Department of Defense, Washington Headquarters Services, Directorate for Information Operations and Reports (0704-0188), 1215 Jefferson Davis Highway, Suite 1204, Arlington, VA 22202-4302."
"Respondents should be aware that notwithstanding any other provision of law, no person shall be subject to any penalty for failing to comply with a collection of information if it does not display a currently valid OMB control number."
PLEASE DO NOT RETURN YOUR FORM TO THE ABOVE ADDRESS.
"The sensing, measuring, controlling and business processes optimization technology networks approaching our daily life."
"Various IoT platforms are emerging on the market to manage these networks and deliver new business models and services Nevertheless, these data-providing infrastructures are currently acting as isolated islands in the global IoT landscape."
"Interconnection of these islands might bring significant added value driving IoT market development, but exploitation of these benefits is inhibited by various interoperability barriers that are present in the current IoT ecosystems."
"The VICINITY consortium – together with stakeholders from energy, building, transport and health domains – thoroughly explored these barriers & drivers1 in parallel with the VICINITY demonstration sites survey (which results in extraction of pilot site needs – operational requirements)2."
"Moreover, the IoT market will be likely influenced by new major EU legislative changes and proposals in the past year, such as the European Commissions’ Winter Package, the European Performance of Building Directive, the Energy Efficiency Directive, the Eco-Design Working Plan, the Renewable Energy Directive, the Electricity Directive, Electricity Regulation, and ACER Regulation, the Single Digital Market and the General Data Protection Regulation (GDPR)."
"Stakeholders’ drivers & barriers, operational requirements of demonstration sites together with EU legislative changes and proposals formed basis for business requirement context in which set of high- level user requirements for IoT interoperability of ubiquitous applications, services and other smart objects were identified (see Table 1: Business Requirement Context)."
"It spans between economics driven requirements, drive for new services provision on one hand and by compliance needs and response towards on-going disruptions in industry and public sector."
"Secure and privacy-preserving infrastructure when exchanging data (especially people’s behaviour) in buildings, energy, transport and eHealth, through security policy of VICINITY and connected infrastructures; transparent auditable information sharing management; end- to-end data encryption; identification of data sources and smart objects behaviour; private data access based on data owners’ consents."
"The business requirements conclude the VICINITY Objective 1.2 “IoT interoperability requirements and barriers are elicited, captured and analysed as principal drivers of the VICINITY research activities”."
Objective 5 “Value-added services explored and demonstrated” will be supported in exploration of potential new business models used to identify divers service across IoT domain with commercial benefit mind-set.
This document is prepared as a starting point for business audience to understand the basic concepts of the VICINITY solution.
"The IoT paradigm and standards landscape is large and complex, and while the technology is still evolving, the adaption of standards is still immature."
"Interoperability is a key element, and ensures cooperation between the different domains."
It is in this context that VICINITY may bridge the gap between domains by placing the ontology outside the physical domain (see task 2.1).
"Requirement management process facilitates elicitation of stakeholders’ expectation through requirements definition, technical specification and architecture design followed by the detailed design, implementation and validation phase."
The business requirements establish consistent base- line stakeholders’ expectation reflecting realistic real-world needs.
The business requirements provide basis for solution validation.
The business requirements specification process5 has been tailored to the needs in VICINITY as described in D1.1 and detailed for business requirements in this section.
From the collected inputs the business requirements are extracted per each vertical domain (Figure .
"All business requirements for each vertical domain as described in section 4.1, 4.2, 4.3 and 4.4, are consolidated and sorted."
"Moreover, common business requirements are identified and clustered in separated horizontal fields, as described in section 4.5."
"The business requirements will be transformed into technical requirement specification and architectural design, which drives the whole VICINITY solution definition and subsequent implementation."
Many requirements have been identified that will need to be fulfilled by VICINITYs proposed architecture and implementation.
"The requirements identified in D1.3: “Report on pilot sites and operational requirements”, D1.4: “Report on VICINITY business requirements” and D1.5: “VICINITY technical requirements specification” need to be addressed."
"Furthermore, the results of D1.6: “VICINITY architectural design” also have an impact on the overall model of requirements."
The process on how VICINITY will deal with these requirements is depicted in Figure 4: VICINITY requirement structuring process.
Partner UNIKL will use the inputs from D1.3 to D1.6 to create a SysML Model of all requirements VICINITY needs to address.
This model is on one hand used to track that these requirements are met by the VICINITY.
"On the other hand, the model is used during WP6 to check and validate these inputs."
"If some proposed requirements cannot be met, either the architectural design or the requirements themselves need to be changed as previously described in section 3.1."
"Either way, problems and errors can be identified early in the design process."
"A new iteration starts, of which the results are reexamined."
"The same happens if during the lifetime of the VICINITY projects, some of the requirements will change."
"Not only does this allow validating that all requirements are met, but also which of them may cause or are subject to threats and risk and thus need to be handled with special care."
"In a business environment, the BRS describes how the organisation is pursuing new business in order to fit a new business environment for VICINITY, and how to utilize the system as a means to contribute to the business."
Each pilot has one or more domain focus - and hence differentiated business requirements.
Common assets in a neighbourhood need to be understood in order to identify the value of the assets.
"When capacity is high and need is low, the price for sharing is normally low."
"When capacity is low and need is high, the prices for sharing will be high."
A modern neighbourhood is equipped with a complex range of technical systems.
"Interoperable with city IoT infrastructures, like LoRaWAN and NB-IoT."
"Optimise sizing, monitoring of space and energy consumption; New rental models for sharing of assets need to be prepared; Standard process for emergency cases need to be adopted and adhered; Standard applications and business models used in telecom IoT infrastructures."
Buildings are some of the most expensive assets to operate and maintain used in our cities and urban centres.
It was found that building owners and managers see economic value through a potential improvement in efficient usage of resources and optimization of building maintenance as facilitated by IoT and VICINITY.
Building efficiency includes not only how and when the resources are used but also how many users need the same resource within the buildings neighbourhood.
"A recently conducted study [16] in collaboration with Statsbygg, the Norwegian State Property owner, reports that a standard university building has an average energy cost optimization potential of about 15 – 20 % of the total energy cost."
"However, a lack of visualisation of consumption of resources and lack of accountability prevents these savings to be made."
"IoT gives the property-owner a high-resolution multichannel information-window, making possible to optimise the use of considerable resources inside the building as well as between buildings (cross assets) within a neighbourhood both virtually and physically."
"As grids reach maximum use capacity or reach its exploitation limit, the importance of load management increases."
"To be able to trade between buildings and grid owners, working markets with load pricing, as well as load shedding and shifting prices must be in place."
"Facility managers and grid owners should support to interoperability between various IoT assets (i.e. load flexibility and constraints) that are needed for load management across various building (e.g. devices, charging station) and energy assets (such as RES, batteries,), to be able to trade loads in practice."
"Transport: parking space occupancy, parking space prices payments."
Collecting and storing data related to people’s behaviour in buildings should be governed by transparent contracts and happen in accordance with relevant rules and regulations.
Encryption and/or aggregation of data to protect identities where relevant.
A modern building is usually equipped with a vast and complex range of technical system.
A communication flexibility and information architecture that can handle the speed and heterogeneity of current and future technical developments is needed.
"The managers need incentives to share data from buildings, parking spaces, local grids, such as reduced peak loads, rent on parking spaces or sales of locally produced energy."
Availability of IoT based tools with simple management will change how facility management as a service can be delivered.
"Dynamic systems, flexible to interconnect or extended various services and devices together, are expected to replace legacy systems."
IoT technology provides opportunities to obtain a new basis for digital data in the building industry.
"This basis gives us completely new opportunities for monitoring, classification, analysis of the use and performance of a building and thus new opportunities for control and management."
Access to such data will change many of the existing business models and will push forward many new models and new types of services.
"Facility owners, tenants, building managers should be supported in measurement and visualisation of the interior conditions and parameters to understand the resources consumption and their effects on wellbeing."
"The facility owner, tenants and building managers should be supported in measurement the resource usage and / or occupancy to optimise resource maintenance or identify situations required manual or automatic intervention."
"Aggregated energy consumption patterns of equipment usage can be offered to the building owners and managers, providing an opportunity to understand the impact of EV charging within a building and manage the process in an economic way avoiding peak consumption."
The service providers should have access to devices utilisations to be able to customise the device operation and maintenance leading towards “appliances as a service model”.
"The facility owners, managers and tenants should have access to information of activities and resource consumption in order to identify and optimise the buildings operative parameters."
"The facility owners, managers and tenants should have access to an overview of registered activities and resource consumption, in order to identify areas in actual need of cleaning, thus reduce the energy consumption and minimise the wear on other parts of the building."
The Energy sector has a high strategical value and there are high expectations as to potential impact of the IoT within the industry as a whole.
"IoT overall and VICINITY as one of the particular solutions is expected to help in achieving RES energy penetration targets, energy efficiency goals and decarbonisation of economies on the high level, while increasing visibility of processes and improving quality of data resulting in higher quality of services."
The Energy ecosystem approach on the municipal level adapted by VICINITY is expected to facilitate data sharing and visualisation of impact on various stakeholder entities.
Continuous energy consumption monitoring and control should be supported by interoperability across standards and vendors of the connected devices.
Energy consumption systems should addresses functionality that extends beyond energy load balancing during peak periods (periods with high energy consumption).
The need for continuous monitoring through system analysis and integration in the building environment should also contribute to the data analysis.
Such services would open for B2B solutions and a B2C spectrum of services where a common platform could support the increasing in level of services driven by similar logic and approach.
Management energy source across different standards and appliances’ vendors enables management of various sources of production (electricity and heat) and sinks (consumption/ uses of energy) to meet demand as smoothly and sustainably as possible.
Management of energy sources should be supported by interoperability across standards and vendors of the connected devices.
Establishing and visualising the process of managing a wide range of occasionally used supplies and sinks enables create new business opportunities and add flexibility to the use of electricity.
Management of intermittent supplies and sinks should be supported by interoperability across standards and vendors of the connected devices.
"Create Interoperable and secure IoT systems to facilitate and form the building blocks of supply and demand management systems, including: in-home communication between smart appliances and energy management systems; and integration to grid operators as well as auxiliary service providers."
The Synergies with other systems in buildings should also be incorporated in the energy management system (e.g. water).
Many resources provided within a building consume electricity in addition to the appliances and other devises.
Interdependencies of one resource consumption and the impact on the other resource are not well understood.
Increasing interoperability in consolidating this information is expected to create positive synergies.
"Consumers with a B2C relationship will need “a system which should learn the user's preferences and optimize automatically without the need of user interaction.” To achieve this, hybrid fully- automated systems enabled by IoT solutions should be designed, demonstrated and tested."
"Engaging consumers in both sectors, businesses and households to manage, produce and store energy and other available resources."
"Ownership of data and information about ownership, access, and other related information about the device, should be made available for improved data management and transparency when installed."
"The data in question could be e.g. heartbeats, value, volt detection, device ID code, registered ownership, placement etc."
"Energy consumers would be anticipating potential economic gains, while transitioning from passive to active energy monitoring."
"This also increases energy efficiency, because with advice the users might achieve a better rational use of energy, benchmark designed performance and actual performance of systems."
"They are willing to give data access to service suppliers and intermediaries but have concerns as to: their privacy, level of data protection that can be guaranteed and the security of their data."
Energy consumers should provide access to data in secure and privacy-preserving way.
"The facility owners and managers should be supported in monitoring of energy production/ consumption and facility resource occupancy and/or utilization and heat production over various devices in order to be able to improve the understanding of production, consumption and utilization and provide an opportunity to optimize billing for renters."
"The facility owners, managers and tenants should be supported to measure, cluster and visualise of the energy and water consumption of devices to provide an opportunity to do assessment of alternative models of management reduce resource consumption and systems substitution decision making."
The data owners should be supported to share available weather data to energy producers from scientific equipment providing them an opportunity to optimise their renewable energy production.
"EV charging enabled parking place may be booked by facility owners, thus offering the ability to manage energy production and consumption (demand-response) as well as EV charging utilization to facility owners and/or managers, to identify smooth positive and negative peaks in the electrical energy consumption of buildings taking into account energy price, parking place occupancy plan and price."
"The facility owners should be supported in optimization of parking space, EV Charing utilization and management of energy production and consumption."
The household owners should be supported with information on resource consumptions and demand response services providing them opportunity to improve energy efficiency of their households and/or improve usage of excess renewable energy.
"Plans for solar panel cleaning based on condition of soiling as opposed to periodic cleaning, could be offered by solar panel operators in order to improve panels’ quality of service and reduce costs for cleaning."
Solar panel operators should be supported in soiling monitoring.
"Facility owners, manager and tenants should be supported to benchmark progress/compliance towards reaching energy efficiency targets with and without energy audits."
Sharing more data via VICINITY would increase the visibility of processes and enhance data quality resulting in better quality of services which might lead to higher financial returns in a medium to long term period.
Knowledge sharing at municipal level as well as increased competitiveness through deployment of new systems are positive drivers for early adopters.
"A lack of internal resources, lack of commitment from the management, and regulatory compliance issues complicates this further, such that data protection and security by design will be a key driver."
"The transport sector is recognised by a large amount cross-domain technologies and standards within fields such as road side technologies, car-to-car communication, car-to-road communication, tunnel technology, smart traffic light, smart signs etc."
"The transport sector covers all means of logistics, being on the ground, rail, at sea or by air."
This is commonly part of ITS (Intelligent Transport System).
"Solutions that offer a foundation for exchanging information between systems, opens for many opportunities."
"Transportation technology can be considered the life blood of smart cities, as areas that suffer from pressure on the infrastructure reduce green areas, residents’ quality of life and financial status of the affected areas."
It is in this context that VICINITY focus on smart parking technology for demonstration purposes.
Smart parking is based on optimising the usage of areas in and around the parking facility.
"Not just based on available space, but also on specifications that ranges from particular needs and demands to scheduling, environmental considerations, accessibility, security/privacy issues to available services."
"For a more in-depth analysis and descriptions, see Annex II: Transport – market and demands."
Further descriptions of requirements for the transport domains are listed below.
"Parking sites should abide to legislation for ownership models, income from rental, privacy6 and security7 agreements regarding access and authorisation to indoor parking sites8."
"Contracts that define responsibilities for ownership of parking space, access and personal data should be defined."
"Transaction and rental models should be introduced for long term, short time, subscription based and contract based usage."
"Agreements should adhere to standards 9used for exchanging (semantic) data with ITS equipment, traffic control centrals, nearby vehicles, and digital signs."
Support for standardised communication protocols used for smart parking and relevant equipment needs to be anchored on a contractual level.
The European standard DATEX II should be the preferred choice.
"The common rules in the field of data provision and publication are based on this standard, and it is the basics for public procurement and apply for all smart parking detection technologies, payment terminal and other transactions, traffic information and control centres data work."
"The encryption and storage of data, should adhere to EU's Data Protection Directive 95/46/EC2 as well as national legislation."
This includes anonymising person data and other information that can identify an individual.
"Integration with other transport related sectors – most notably car sharing and public transport should also be supported in order to establish the foundation for a healthy ecosystem, and also alleviate some of the pressure on the infrastructure, thereby reducing the climate footprint."
"Support and access to updated information on available EV charging stations with technical information, current status and availability, should be supported."
Different ways of getting access – in particular to underground garage facilities – should be defined.
"This would include authorisation equipment and systems like camera systems for reading licence plates, car based sensor, card reader, RFID, Bluetooth, geo fencing and biometric systems."
Other reader/detection units might be integrated when deemed necessary.
Demands on user experience design should be an integral part of the solution.
"This should address devices and accessibility, in particular with an emphasis on supporting unified design."
Certain disabilities and lack of previous experience might affect the usability aspect.
"Especially users on that handles the parking experience on small devices need to be receive specific attention, as there is little or no time for training, and the systems will be based on a on-demand approach."
This is even more important when the mobile devices will offer interaction with 3rd party services that will be built on top of the parking experience.
User experience should be continuously measured and evaluated by UX designers through anonymous tracking of user navigation on the panel.
"Access to and visualisation of structural plans/layout for garage facilities should be included in the information about access points, charging stations, fire extinguishers, escape exists, alarm signals as this is necessary in order to provide a proper service that can be implemented and expanded on a longer term."
"The transport domain contains challenges within areas such as logistics (e.g. assignment, allocation, optimising routes, history)."
"Transportation does also include such topics as authorisation/ authentication/access, integration of other services and visualisation of complex information."
"This means that proper knowledge of priorities, special requirements for vehicles and users, historical data and ownership of transport related equipment and services will be one of many parameters that will influence logistics and other outcomes from the transport related issues."
"Therefore, Interoperability on these areas including other value added services should be supported."
Interoperability on rulesets that support actions based on changing values and their relevance to the transport domain should be supported.
"This includes data from manual booking, trigger mechanisms based on rulesets integrated with other domains (i.e. eHealth and building), request from technical or health care personnel, ground based sensors and visual data from other sources."
"The Technical Specification standard CEN 16157-6:2013, Annex D (Data Dictionary), describes DATEX II data exchange specifications for traffic management and information, of which part 6 deals with Parking publication."
"Standardisation of DATEX II establish a basis for common exchange between the traffic and the travel information sector, thus opening for cross-domain value-added services."
This standard serves for setting out the rules for parking management and should be part of the common framework for handling smart parking related activities.
"Camera with Automatic Licence Plate (ALR) detection and reading capabilities affect authentication and authorisation processes, and is part of the entrance security system."
This operation also provides the facility owners and managers with information about how many and what registered vehicles that are present at any time.
Detection of parking space occupancy could be applied to optimisation of both short-term and long- term parking space usage.
These data can also be when correlated with data from ALR-detection and hence improve parking services processes.
The health sector is one of the core areas to be included to and benefit from the concept of smart cities.
"Under the context of the VICINITY project, two health related scenarios were studied during the requirement analysis process; assisted living at home and preventive medicine."
"In order for the demonstrations to be tested appropriately and effectively, a set of specific business requirements should be defined and followed."
"Multiple sensors, mainly in the form of wearables but other activity tracking sensors as well, will provide several real-time health condition measurements by monitoring patients’ behaviour, ideally taking into account the “sensitivity” of health related data, a number of other challenges arises regarding ownership and usage of data, security and privacy, trust of authorized third parties and legal challenges as well."
"Moreover, concerns regarding trust in data origin are principal business inhibitor."
"Therefore, a business requirements framework is necessary for the case."
"Therefore, as the demonstrations run in municipality level, the participating municipality should ensure the involvement of the necessary healthcare personnel."
"The devices involved should be low cost and effective, in terms of measuring and tracking as many health conditions as possible but also in terms of ease of use."
The right balance among the latter factors will guarantee a decent amount of potential active participants.
"Complex, inefficient devices might lead users to reduce their level of participation or even completely abandon them."
"As authorised third parties will have access to user’s personal data – especially in case of emergency, the user should have a fully-detailed, complete picture of who and when accessed his/her data."
"Therefore, an effective audit management mechanism should be introduced."
"As users’ personal health data will be shared to authorized third parties, trust is a major concern."
"Therefore, contracts defining ownership of data, usage of data and privacy should be introduced."
Miscommunication is a major issue to be addressed in all domains.
"However, it is of even higher importance for Health domain where any missing information could prove crucial."
"Therefore, a common interoperability “language” should be defined in order to overcome linguistic barriers that could lead to possible misconceptions."
"The latter could be achieved by following equivalent integration profiles such as IHE, HL7, DICOM and Continua."
"As one of the deployment scenarios, specifically assisted living at home, might possibly involve emergency incidents triggered by the participants, especially the elderly, a standard process of specific steps should be identified to serve the case."
"Ideally, the latter should be an override mechanism that follows “break the glass” principles."
The suggested framework should be accepted by all sides involved and strictly followed by authorised third parties.
Access to health status and in-house conditions could be provided to caretakers for identifying abnormal behaviour with the supervised person.
Affordable devices used for condition assessment using could be made available to elderly citizens and caretakers.
Caretaker should have access to smart drug dispense usage statistics to be able to detect abnormal drug usages.
Simple wearable devices should be supported for elderly people when their ability to operate smart phones or other technical equipment are limited.
Household appliances usage data could be offered to healthcare providers in order to identify abnormal behaviour in elderly citizens’ households.
"Weather data from scientific equipment to municipalities could be shared by providers, hence municipalities may recommend maximum time of sun exposure to citizens."
Information about the perceived temperature due to the influence of wind speed and air humidity could be offered to citizens.
This section includes business requirements identified for cross-domain applicability.
It builds upon the findings presented in the domain specific requirements.
"Younger population expect to have same user experience regardless of different type of mobile devices and wearables used, however different type of devices might have different set of features."
Elderly people expect use simple and affordable wearable devices while their ability to operate smart phones are limited.
"Building owners, managers and tenants expect that VICINITY enabled system should be operated by youth segment that needs special care, however are able to handle tasks."
This would potentially create inclusion into the job market of the fastest growing special care group.
Business domain owners expect cross-availability of IoT data that removes vendor locks from IoT eco systems.
The ontologies should be extensible to provide semantic interoperability for new devices.
Caretaker and elderly citizens expect to use affordable VCINITY enabled devices.
"Affects use case: UC 1.1.2.5, UC 1.1.2.6, UC 2.4, UC 2.5, UC 2.6, UC 2.7, environment to allow for third parties services building for demonstration purposes."
Concept of the solutions will be considered in D1.5 VICINITY Technical specification requirements and D1.6 VICINITY Architecture design.
European Commission introduced the EU Data Protection Reform and adopted the Regulation processing and storing of the personal and sensitive data.
"Moreover, the regulation defines concepts of how the data protection should be maintained in the organisation processing private data."
Requirement consent 11as described in the Data Protection directive no.
Security functional requirements need to be defined for each potential threat.
Selection of the functional requirements need to balance the cost of the security measure and cost of potential security breach.
The actor should have authorization to access the assets managed or facilitated by VICINITY.
Authorization should be managed by the organization connecting to VICINITY.
Action performed in VICINITY should be traceable to actor who performed the action including evidence that it has been done so.
The unsolicited access or operations in high-volumes can cause unavailability of the part or whole system.
Each of these security threats needs to be addressed by one or several security measures to minimize the security risk to acceptable level.
"After Mile Stone 1 – “VICINITY requirements, barriers, pilot surveys and audits available”, the requirements will be implemented into a tool (SysML) for easy definition and maintenance."
"IoT ecosystems generate data that can be harvested to provide novel commercial services, or public services for the benefit of society."
This review was designed to identify benefits and issues related to data sharing both within a single domain and across domains.
Achieving interoperability across domains is a key objective of VICINITY.
"In the context of VICINITY, interoperability is the ability of a system or a product to work with other systems or products without special effort on the part of the customer."
"In order to collect and analyse business drivers and barriers in the context of IoT interoperability, a survey was conducted using a questionnaire to interact with stakeholders and visit to the pilot sites demonstration VICINITY solution."
"The scope of the survey included several separate vertical domains (buildings, energy, transport and health) and several horizontal cross-domains (legal & ethics, security & privacy and the technical domain)."
"Barriers which are similar across domains were identified, along with some more domain- specific ones."
The potential for cross-domain synergies was identified which could maximise the use of clean energy and/or optimise the management of resources.
"According to several stakeholder studies, security and privacy are some of the most common barriers to the interoperability of IoT."
Other barriers identified are lack of standards and low level of product maturity from customer standpoint.
There are many IoT ecosystems with actors that operate within cross-domain areas.
"These ecosystems generates big data that could be harvested to provide novel commercial services, or services for the benefit of society."
"In many case the owners of these data sources are unwilling to share access to their data, especially if they do not have a business case, which enables them to benefit directly from the new services derived from their data."
"At this stage of project development VICINITY system´s perceived strengths by the stakeholders in general are as follows: “Interoperability and integration of various standards and protocols which would allow for broad use of the product, allowing for rapid innovation”."
"The system is expected to provide efficient, time saving performance and value-added services from a business perspective, while minimising environmental impact and yielding cost savings."
The overall goal of VICINITY is to deliver improved quality of life and open for innovative services that can be built on top of the architecture being offered by solution.
"Among weaknesses, resistance to change can be expected from strong market players with existing proprietary products."
"On consumer side, potential loss of privacy and security, compatibility, complexity and legislation are voiced as potential weaknesses."
"These strengths and weaknesses identified from stakeholders’ interactions also known as drivers and barriers are analysed in vertical domains energy (section 4.2), health (section 4.4), transport (section and building (section 4.1) and horizontal domains (section 4.5) legal & ethics, security & privacy domain."
"Stakeholders perceive VICINITY as a project, which has the potential to integrate various disparate standards and protocols."
This report constitutes one of the components of the VICINITY project.
The approach and philosophy employed by VICINITY takes into consideration stakeholders’ opinions in order to build solutions focused on meeting their requirements whilst tackling issues they have identified.
The deliverable uses information derived from the representative list of stakeholders and pilot site operators.
"Further deliverables in Work Package 1, such as D1.5 and D1.6, will identify functional and technical requirements, resulting in a system architecture, thus completing the knowledge base upon which the VICINITY solution will be developed, tested, deployed and demonstrated."
This annex will be used in development of concrete business plans that will look to maximize the exploitation potential of identified assets results as well as address stakeholders’ needs and expectations.
Exploitation Strategy and Business Plan Development (WP9 Task 9.5) will monitor and compile the partners’ exploitation activities and seek maximum synergies from them.
One major part of the exploitation planning will be the identification of potential target groups and business cases based on the outcome of the project.
"Moreover, market requirements and future application areas will be captured."
Each exploitable result’s related target group will be identified to make sure each target group is informed about the relevant information / activities within the project.
Definition of both individual & consortium exploitation/business/financial plans for each exploitable result.
"An annual report will detail exploitation status and perspectives, at partner’s and Consortium’s levels."
"The results will be presented in D9.5 in two issues of the document during the second half of the project (M24, M36 and M48)."
This annex defines the normative content of the business requirements specification (BRS) document for VICINITY.
The project shall produce the following information items in accordance with the project’s policies with respect to the business requirements specification document.
Organisation of the information items in the document such as the order and section structure may be selected in accordance with the project’s documentation policies.
Describe at the organisation level the reason and background for which the organisation is pursuing new business or changing the current business in order to fit a new management environment.
In this context it should describe how the proposed system will contribute to meeting business objectives.
Defining the range of business activities included in the business domain concerned.
"The scope can be defined in terms of divisions in the organisation and external entities that relate directly to the business activities, or functions to be performed by the business activities."
It is helpful to show environmental entities which are outside of the scope.
Describing the scope of the system being developed or changed.
Describe major internal divisions and external entities of the business domain concerned and how they are interrelated.
"List the major stakeholders or the classes of stakeholders and describe how they will influence the organisation and business, or will be related to the development and operation of the system."
Define external and internal environmental factors that should be taken into consideration in understanding the new or existing business and eliciting the stakeholder requirements for the system to be developed or changed.
"The environmental factors should include possible influences to the business and consequently the system from external conditions like market trends, laws and regulations, social responsibilities, and technology base."
Describe the business results to be obtained through or by the proposed system.
Describe methods by which the business mission is expected to be achieved.
"The description should be concentrated on the methods supported by the system to be developed or changed with the items such as product and services, geographies and locales, distribution channels, business alliance and partnership, and finance and revenue model."
Business Motivation Model (BMM) Specification by OMG.
"Describe the overall strategy for the organization level decisions on common bases for multiple project portfolio – when multiple system projects are running or planned to pursue the same business goal, the priority, relative positioning, and possible constraints come from the portfolio management strategy."
Provide description of the procedures of business activities and possible system interfaces within the processes.
The purpose of this information item is to represent how and in which context the system supports the business activities.
"In general, business processes make a hierarchical structure with decomposition and classification."
Each business process should be uniquely named and numbered in the hierarchy.
The description of the individual business process should be represented as a diagram representing a sequence of activities.
Describe logical propositions applied in conducting the business processes.
"The propositions will be conditions to start, branch and terminate the sequence of the business activities in the business processes; criteria for judgment in the business processes; or formula to evaluate a quantity, which will likely be addressed in functional requirements in the SyRS and SRS."
"The policies and rules shall be uniquely named and numbered, and shall be referenced in the description of the business processes."
Describe conditions to be imposed in conducting the business process.
"The conditions may be on a performance constraint (e.g., the process shall be finished within a day after the triggering event occurs), or may be from a management requisite such as 'every occurrence of the process shall be monitored and recorded'."
"Describe methods to conduct the business operation in an unsteady state, for example, a state when business operations might be extremely busy due to some intensive occurrence of events."
An unsteady state of business operation includes a manual operation mode when the proposed system is not available due to some unexpected situation like an accident or natural disaster.
Define the level of quality required for the business operation.
"For example, a business process may address required urgency with higher priority than the reliability of the business process."
"Identify and describe the structures in the business relevant to the system, such as organizational structure (divisions and departments), role and responsibility structures, geographic structures, and resource sharing structures."
"There may be a need to alight the system functions to these structures, and to support future structural changes."
"Describe the proposed system in a high-level manner, indicating the operational features that are to be provided without specifying design details."
Describe examples of how users/operators/maintainers will interact with the system (context of use).
The preliminary (upper-level) scenarios are described for an activity or a series of activities of business processes supported by the system.
"The scenarios should be uniquely named and numbered, and should be referenced in the description of the business processes in 6.1.9."
"Describe how the system of interest if to be acquired, deployed, supported and retired."
Describe constraints to performing the project within cost and schedule.
"The core of the smart parking case is to offer interoperability of various suppliers to demonstrate how to provide the same service, with a specific focus on real time occupancy and transaction data in the standard data format DATEX II."
Smart parking is a concept that can be assigned for different kind of areas.
"Examples like sites near apartments, parking sites near work places or public buildings, parking sites on industrial areas or for commuters, sites for disabled people, indoor sites, outdoor sites, street based parking sites, road side parking, parking sites for cars or trucks, electrical vehicles (EVs) can be envisioned."
"Parking space is a resource that is on-demand, and where is usually is a shortage."
"Different uses have different needs, either because of the vehicles, or because of disabilities or other concerns with the passengers/drivers/owners."
"Cost efficiency is an issue, and introducing parking space sharing, as it makes it possible to ensure that neither private nor public parking sites are left with unused space."
"At the same time it makes it possible to exploit areas that otherwise would have been assigned for a specific usage, as real time information about vacancy opens the door for temporarily assigning the parking space for other purposes."
"The situation today is that city managers and agencies, municipalities and counties, governments, site owners and other of the key actors referred to in “Table 4: Key actors in smart parking ecosystem” are experiencing pressure from commuters, residents and their own departments to reduce congestion and improve the conditions of those who are dependent on cars or are living in cities."
"The mobility sector affects all city users; commuters, business owners, blue light agencies and other departments that are triggered in emergency situations."
"Smart mobility solutions, of which smart parking is a part, is considered being a way of solving some of these challenges."
"By allowing people to receive relevant data, the user is enabled to make more choices that are informed."
"This provides them the option of deciding how to ride, when and where to ride."
"It opens for integration from different domains, and facilitates efficient movement of goods and people, thus ensuring logistics supporting the city."
These are often owners of the parking sites and are responsible for assigning budgets and managing the criteria that governs cities and infrastructure.
The departments that will benefit the most are located in these governmental bodies.
"They spend many resources on transporting people and goods, and health care personnel and blue light agencies represent a large part of their budget."
Solutions that will assist in reducing the pressure on the operational agencies will have a large impact and therefore gain a lot of interest.
Personnel responsible for managing mobility solutions within cities.
These are the key buyers in the smart mobility domain.
"City Managements are coming congestion, improve the quality of life of those living and working in cities."
These are companies involved in data collection and interpretation to provide traffic management solutions to City Management.
These are the key sellers and potentially the innovators and integrators in the smart mobility domain.
"The products produced by companies operating in this sector aim to optimise parking, improve safety and reduce congestion and emissions."
Companies who manufacture technology related to traffic and parking management solutions.
These are the innovators within the smart mobility domain.
Their products are primarily aimed at companies involved with Transport Information Integration and with City Management.
Provide tailored mobility solutions to city inhabitants.
"These are a small, but growing player in the industry offering services to commuters in need of parking space."
"Their smart mobility products are aimed at making transport more sustainable, greener and safer."
They design and manage the procurement processes and install the infrastructure network.
"These companies advise commuters, city management and transport information integration companies."
"The goals of these companies are to design and build mobility solutions that are optimally designed, incorporate best practises to reduce congestion, improve quality of life, lower emission and optimise use of urban areas and mass transport."
"Companies involved in this sector provide services such as beds, food, fuel, transportation to commuters."
"Commuters are informed of available services before, during or after their commute, through the use of smart technology which recognises their route or current location via GPS."
"Commuters are targeted by tailored advertising techniques depending on their mode of transport, location or smart phones setup of companies or services which could strike a chord with commuters in that location."
Revenues provided by advertising companies could greatly reduce the cost of development and installation of smart transport solutions for city management.
Companies whose technology will be used to relay data to transport information from advertising companies.
"Additional means of communication (data to and from measuring devices, transport information integrators and advertising companies) will be required."
Sensors that can detect occupancy of a parking space needs to send real time data.
A gateway will have to be able to transmit the information further into the network.
Information must be accessible to interested parties through relevant platforms.
"Additionally other sources of feedback, most notably smart light and monitors displaying information will improve usability factors and reduce risks for occupying the wrong parking space, or drive in the wrong direction."
"Real time transactions and security and privacy issues related to initial authorisation, authentication and access will have to be integrated in the smart parking system."
"This opens for other challenges that needs to be addressed; Who are responsible for handling authorisation and access, who will be liable for parking/damages or theft when occupying parking space."
Who will handle payment or other kind of transactions that function as transferring value.
How to handle long term and short- term ownership/rental of parking space – and customisation that may take place without consent from other owners.
"How to handle booking and verification, rating and other activities that directly may influence the worth of a given parking space."
"This may be considered even more important for underground parking facilities, where the entire facility may be affected by choices that are made in regards to just one parking space."
Finally – the core part of smart parking is based on optimizing the usage of areas in and around the parking facility.
"Not just based on available space, but also on specifications that ranges from disabilities to time slot, from location of entrances to nearby services."
Smart parking will offer cross-domain support through interoperability supported through the VICINITY platform.
"An extensible core information model, i.e. core ontology, should be used for all information elements to be interpreted, being agnostic of their specific contexts and communication standards."
Domain-specific information elements have to be interpreted using specific model extensions of the core model.
All information elements should have enough associated metadata to become properly annotated and understood using the corresponding information models.
All APIs should provide semantic descriptors of all information elements they expose by leveraging their own metadata.
Level of Review: This material has been technically reviewed by expert reviewer(s).
"This document is created under the project-level agreement (PLA) (PLA FY09_G1M.02-02v1) for “New ATM [air traffic management] Requirements—Future Communications” and addresses concepts of use (ConUse), system requirements, and architecture for the proposed L-band (960 to 1164 MHz) terrestrial en route communications system."
NAS-level and similar level international concept of operations (ConOps) driving this ConUse and its associated requirements include the RTCA “National Airspace System Concept of Operations and Vision for the Future of Aviation” (Ref.
"At the next lower layer, the European Organisation for the Safety of Air Navigation (EUROCONTROL) “Operating Concept of the Mobile Aviation Communication Infrastructure Supporting ATM Beyond 2015” (Ref."
"On a similar level to this ConUse, but with a different scope and intended for different services, are the operating concepts and requirements presented in the “Data Communications Safety and Performance Requirements (SPR)” (Ref."
"A process recommended in the “NAS System Engineering Manual” (SEM, Ref."
The following subsections summarize the steps taken in developing the ConUse.
The Next Generation Air/Ground Communications (NEXCOM) system requirements document (Ref.
"The resulting operational problems, if not addressed, could lead to service degradation and could limit introduction of new or expanded services."
"These, in turn, could potentially compromise safety of operation and increase operating costs."
"Saturation of the very high frequency (VHF) spectrum is the problem specifically mitigated by the introduction of a new L-band system (L–DACS), while the other operational problems will likely be mitigated to a degree dependent on the particular technology implemented with the L–DACS."
It is important to note that the FAA’s Data Communications Program (Data Comm) FPR document recognizes that “the scope of the mission shortfalls identified herein [is] broader than will be addressed solely by a data communications capability” (Ref.
"Because of the limitations and constraints of implementing data communications using VDL Mode 2 over a congested aeronautical VHF band, FAA Data Comm Program will focus on implementing the certain critical air traffic services."
This provides opportunities for L–DACS systems to augment Data Comm by enabling communications of other critical and essential air traffic services to address the shortfalls listed.
The Data Communications Networks Services (DCNS) A/G data communications system being developed under the Data Comm Program is expected to precede L–DACS implementation.
"Even though each of the shortfalls listed are meant to be addressed to some extent by the Data Comm using VDL Mode 2, there are opportunities to overcome these shortfalls to a greater extent during the later program segments of Data Comm (e.g., late Segment 2 and Segment 3) using link technologies such as L–DACS with greater bandwidth capabilities, which could augment the benefits already attained through VDL Mode 2 Data Comm program segment implementations (i.e., Segments 1 and 2) by providing a broader scope of services."
L–DACS will be designed specifically for data communication.
It may also target one or more unmanned aircraft system (UAS) communications services.
"Additional interference research and testing will determine if any operational constraints are to be imposed, such as limiting the number of users, time of the day, duration, etc."
"Data Communications Segment 3 requirements, including full four-dimensional trajectory-based operations (TBO), the L–DACS is also envisioned to support other future communications applications including mobile SWIM and UAS safety-critical data communications, UAS command and control, and monitoring of UAS onboard sense-and-avoid and automation capabilities."
COCR services previously identified as potential applications (Ref.
"As such, some ATC services are included in the table for the airport domain."
"As d throughout this report, the services are considered candidates for L–DACS if not implemented by the Data Comm program."
"Services provided on airport surface only (e.g., Software Loading, SWLOAD) as well as those likely to be provided in the ENR and TMA domains are included in the table."
"Some of the services listed would be mostly provided the ground, while others may be applicable to wheels-on- and off-the-ground scenarios."
A key NAS operational concepts source driving the L–DACS ConUse is the RTCA NAS ConOps.
"When discussing an impact of introducing the new L-band system, it should be emphasized that the proposed L–DACS is designed to augment current operations and is not intended to replace any of the existing services."
The proposed system is expected to further increase safety and efficiency of current operations.
An introduction of the proposed L-band system should require no changes to the existing L-band services operating in the same band by utilizing inlay technology and/or other interference mitigation techniques.
A “middle-out” approach was adopted to identify high-level requirements applicable to L–DACS.
"In parallel with that process, a bottom-up assessment included existing requirements provided in relevant documents such as the NAS SR–1000, the COCR, the Data Comm performance requirements, and documents associated with specific potential applications identified in Task 6."
"It further identifies services that are not planned to be implemented by the Data Comm program through Segment 3, and identifies them as possible candidates for implementation via C-band and/or L-band DACS."
"It must be stressed that both C-band and L-band DACS are being developed for the FCI to accommodate safety and regularity of flight services and designed to operate over aviation-protected spectrum, so any COCR ATS service could be could be implemented via one or the other of these links (as appropriate)."
The system shall enable G/A communication for fixed-to-mobile users.
The system shall enable G/A communication for mobile-to-mobile users.
The system shall enable A/G communication for fixed-to-mobile users.
The system shall enable A/G communication for mobile-to-mobile users.
The system shall support addressed communication for delivery of information to individual users.
The system shall support addressed communication for delivery of information to multiple users.
The system shall support broadcast communication for delivery of information to multiple users.
The system shall support delivery of real-time information in a timely manner.
"The system shall support multiple QoS offerings, such as priority and preemption capabilities, and so on."
The system shall support authentication of users (security).
The system shall support controlled access to NAS information (security).
The system shall provide support of FAA ground users.
The system shall provide support of FAA airborne users.
The system shall provide support of non-FAA ground users.
The system shall provide support of non-FAA airborne users.
The verbiage is consistent with that used in the NAS SR–1000 as opposed to some of the newer requirements documents.
"Users may include aircraft, airline operation centers, service providers, FAA users, and other government agencies."
Concepts identified in the document are found applicable for the proposed L–DACS even though it is likely to be implemented beyond 2020–2025.
The identified NAS ConOps were then traced to the desired functionality of the proposed network.
"These functions are grouped into appropriate functional hierarchies, and functional requirements are derived."
The table presents the mapping of NAS ConOps to L–DACS functional requirements and proposed capabilities.
This encompasses a top-down approach to the development of functional requirements.
Mapping the proposed services to the desired system capabilities and functional architectures presents combined functional requirements from the top-down and bottom-up approaches.
An L–DACS physical architecture can be derived from and represents a technical solution to the functional architecture and requirements.
"The ground infrastructure comprises a number of L–DACS ground radio stations, each providing a cell-like coverage service volume, and which are geographically situated to provide overlapping coverage (using different frequencies) to achieve seamless service volume handovers."
Each ground radio station would be connected to a G/G network through a ground network interface (number 1 in Figure ES–2).
The components would be responsible for providing the functions identified in Appendix B and meeting L–DACS functional and performance requirements identified in Section 4 of this document.
Most of the identified high-level functional and performance requirements cannot be readily allocated to the components shown in Figure ES–2.
More specifically defined ConUse and associated scenarios would make it more appropriate to further decompose the requirements and allow allocation of specific requirements to specific architecture components.
NASA/ITT provided system engineering evaluation of candidate technologies for the future communications infrastructure (FCI) to be used in air traffic management (ATM).
"Specific recommendations for data communications technologies in very high frequency (VHF), C, L, and satellite bands, and a set of follow-on research and implementation actions have been endorsed by the FAA, EUROCONTROL, and the International Civil Aviation Organization (ICAO)."
"In the United States, the recommendations from AP–17 are reflected in the FAA’s “Next Generation Air Transportation System Integrated Work Plan” (Ref."
Follow- on research and technology development recommended by ITT and NASA Glenn and endorsed by the FAA was included in the FAA’s NextGen Implementation Plan 2009.
"The plan was officially released at the NextGen Web site (http://www.faa.gov/about/initiatives/nextgen/) on January 30, 2009."
"On February 27, 2009, the FAA approved a project-level agreement (PLA) (PLA FY09_G1M.02- FAA’s solution-set work plan; this includes development of concepts of use (ConUse), requirements, and architecture for both a new C-band airport surface wireless communications system and a new L-band terrestrial en route communications system."
"Communications Segment 3 requirements, including full four-dimensional trajectory-based operations (TBO), the L-band terrestrial en route communications system is also envisioned to support other future communications applications including mobile System Wide Information Management (SWIM) and unmanned aircraft system (UAS) safety-critical data communications, UAS command and control, and monitoring of UAS onboard sense-and-avoid and automation capabilities."
"ATM Requirements—Future Communications, C-band and L-band Communications Standard Development.” Task 7 is separated into two distinct subtasks, each aligned with specific work elements and deliverable items identified in the FAA’s PLA and with the FAA FY09 and FY10 spending plans for these subtasks."
"Subtask 7–1 addresses C-band airport surface data communications standard development tasks that define ConUse requirements and architecture, describe supporting system analyses, and test development and demonstration plans, establishing operational capability."
"The purpose of the subtask 7–2, and the subject of this report, is to define the L-band terrestrial ConUse, systems performance requirements and architecture in a future L-band (960 to 1164 MHz) air/ground (A/G) communication system referred to as L-band digital aeronautical communications system (L–DACS)."
"The proposed L–DACS will be capable of providing ATM services, including the potential applications identified in the Aerospace Communications Systems Technical Support (ACSTS) Contract task 6, in continental airspace in the 2020+ timeframe."
Task 7–2 also includes an initial L-band system safety and security risk assessment (Ref.
Subtasks associated with interference analysis and testing were postponed due to FAA’s European partners schedule change.
"Aircraft components include radio equipment, antennas, and associated cabling."
"It should be d that while the figure essentially illustrates A/A and A/G communications provided by the proposed L-band system, it includes air traffic service provider (ATSP) end-systems only."
"ATSP is part of the broader air navigation service provider (ANSP) category that, in addition to ATSP, may encompass aeronautical information services providers, communication, navigation and surveillance providers; meteorological (office) service providers; and airport/aerodrome flight information service (AFIS) providers."
Section 2.0 presents the ConUse and requirements development processes.
Section 3.0 is devoted to the ConUse of the proposed L–DACS.
New system justification shows potential benefits of new systems and describes the desired changes.
Section 5.0 describes the synthesis process and introduces L–DACS physical architecture.
Section 7.0 summarizes the preliminary inputs to L–DACS design specification.
An overview of the requirements definition process and the results of previous analyses provide inputs to the design specification.
Appendix A defines acronyms and abbreviations used in this report.
Appendix B summarizes RTCA NAS ConOps applicable to the proposed L–DACS.
Appendix C presents hierarchical diagrams of L–DACS functional requirements.
Appendix D contains N2 diagrams illustrating L–DACS functional requirements.
Appendix E describes spectrum requirements for UAS communications.
Appendix F discusses spectrum applicability for UAS applications.
Multiple documents related to ConUse and ConOps of the future data communication systems exist.
This section provides background information related to ConUse and requirements development to offer the appropriate frame of reference and to provide traceability to better define the scope of this report and its place in the family of concepts documents.
ConUse are part of a hierarchy of concepts documents that capture concepts related to the NAS.
"As defined in the FAA’s NAS System Engineering Manual (SEM), there are two general types of concepts documents associated with system engineering in the NAS: ConOps and ConUse."
"A ConOps is “a description of what is expected from the system, including its various modes of operation and time- critical parameters,” whereas a ConUse is “an extension of a higher level ConOps with an emphasis on a particular NAS system and its operating environment,” (Ref."
These three levels can be summarized as follows (from Ref.
NAS-level ConOps are a high-level narrative of the user community’s desired change with some performance indicators.
The document indicates from the user’s perspective the desired end state for respective systems in the NAS.
It often uses various operational scenarios to illustrate the desired operational concept.
Service-level ConOps provide conceptual insight into a particular service of the NAS.
"It is more detailed and substantial, but it is still expresses the user’s needs regarding a specific system within the NAS."
NAS-level and similar international ConOps driving this ConUse and its associated requirements include the RTCA’s “National Airspace System: Concept of Operations and Vision for the Future of Aviation” (Ref.
"At the next lower layer, EUROCONTROL’s “Operating Concept of the Mobile Aviation Communication Infrastructure Supporting ATM beyond 2015” (Ref."
"On a similar level to this ConUse, but with a different scope and intended for different services, are the operating concepts and requirements presented in “Data Communications Safety and Performance Requirements” (Ref."
"L-band (960 to 1164 MHz) communications system named the L-band Digital Aeronautical Communications System (L–DACS), providing services similar in scope to those described in the “FCI Aeronautical Data Services Definition Task Report” (Ref."
This follows from the previous FCS technology evaluation studies (Ref.
"Because many, if not most, NAS systems are not new, but rather, evolutionary improvements of existing NAS systems, a top-down process is not always appropriate."
"This is a combination of a top-down process, which takes into account new concepts and missions needs, and a bottom-up approach, which takes into account existing requirements and concepts."
"As shown in the figure, operational concepts and requirements of higher-level concepts documents flow down to this document, providing high-level guidance and direction in the form of required functions and flows for the services of interest, namely A/G and A/A communications services."
"In addition to this top-down process, a bottom-up process of identifying and evaluating specific concepts and requirements developed for other communications systems, such as Data Comm, Next Generation Air/Ground Communication (NEXCOM), and Link2000+, along with appropriate NAS System Requirements (SR–1000), was employed for this document."
"A process recommended in the NAS system engineering manual (SEM, Ref."
The following sections describe the findings for each of the steps shown in the figure.
This section defines the operational needs for the L–DACS by describing current and planned A/G communications systems and their associated problems and capability shortfalls.
"Though not a current system at this time, the planned data communications networks services (DCNS) A/G data communications system being developed under the FAA’s Data Comm Program is discussed here because its initial implementation is expected to precede L–DACS."
"Data Comm should mitigate many of the current A/G operational problems and shortcomings, while still leaving room for L–DACS to provide additional gains over current shortcomings."
The current A/G Communications System for ATC consists of voice-based networks that use DSB–AM radios and operate in the 117.975 to 137 Megahertz (MHz) VHF band for civil aircraft and the 225 to 400 MHz UHF band for military aircraft.
The radios operate with the same frequency used for controller-to-pilot (uplink) and pilot-to-controller (downlink) transmissions in a simplex “push-to-talk” mode.
"In the event of a control facility power loss, engine generators provide back- up power."
"In the event of equipment failure, A/G communications are provided by Backup Emergency Communications (BUEC) in the Enroute, Emergency Communications System (ECS) in the large TRACONS and portable transceivers in the smaller TRACONS and Air Traffic Control Towers (ATCT)."
The current A/G communications system architecture is roughly the same for all operational environments.
The specific equipment used in the A/G communications string can differ among the various facilities.
"Different control facility types have different voice switches, with each type of switch having a unique interface."
Appendix A of the NEXCOM system requirements document (Ref.
"Communications enables the NAS to exchange information with users, specialists, ATC facilities, and other Government agencies."
This information is transported over land lines and wireless connectivity utilizing government and commercial assets.
"Communications defines how data is moved across the NAS to accomplish flight planning, control functions and navigation services for ground and space based systems."
This enabler provides end-to-end service to pilots to include disseminating and coordinating the flight plan and defines how controllers provide service throughout the flight while coordinating with other facilities and government agencies.
The communications enabler supports collaboration between users and specialists for traffic synchronization and flow services.
Communications support the exchange of navigation and surveillance information across the NAS.
"Information includes electronic signals emanating from ILS, VOR and space based systems and aircraft transmitted beacon code data."
An “x” at a row-column intersection in the table indicates that the particular function in that row is needed to provide the NAS service capability in that column.
Of particular interest for this report are the functions that can be enabled by A/G communications to provide specific NAS service capabilities.
"For example, A/G communications is used to implement some of the functionality needed to manage flight plans in support of the flight planning service capability."
This A/G communications-specific mapping is indicated by the blue boxes in the table.
TO NATIONAL AIRSPACE SERVICE (NAS) SERVICE CAPABILITIES (REF.
"Based on the need to support the NAS critical services, A/G voice communications latency and availability performance requirements are fairly stringent."
"Typically, this has resulted in requirements for 0.99999 availability and an end-to-end latency of 250 msec3 for the most critical voice communications services."
"Voice communications is used for all phases of flight, that is, from gate to gate."
The users of the current VHF A/G communications system include the following (Ref.
NAS service capabilities and performance requirements listed in Section 3.2.2.
"Currently, they are characterized by “high availability, low end-to-end latencies, the ability to convey human feelings, flexibility of dialogue, provision of a party-line, and use for non-routine, time critical, or emergency situations” (Ref."
"Some of these characteristics actually offer an advantage to voice communications as compared to data communications; however, there are several disadvantages of voice communications that motivate the need for data communications for many applications."
This is usually not a problem for A/G communications in continental airspace with manned aircraft.
"However, this imposes a constraint to the routine operation of UAS in the NAS."
"Even though the UAS operate under a Certificate of Authorization to allow flight in the NAS, UAS often currently operate in beyond line of sight conditions using non protected frequency bands (i.e., not AM(R)S or aeronautical mobile satellite (route) service (AMS(R)S frequency bands)."
Other operational constraints for UAS are described in Section 6.0.
"The resulting operational problems, if not addressed, could lead to service degradation and limit introduction of new or expanded services."
"Though the FAA Data Comm Program employing very high frequency digital link (VDL) Mode 2 technology is expected to mitigate these shortcomings to a considerable degree (as described below), saturation of spectrum is highlighted in red as the problem specifically mitigated by the introduction of a new L-band system (L–DACS)."
In addition it is likely that L–DACS will provide additional relief to the technology limitations of voice communications by providing broadband service capabilities not possible with VDL Mode 2.
"Unfortunately, as shown in Figure 8, the current A/G communications system lacks data communications capability for ATS."
"In moving towards NextGen, this shortcoming will become more acute and could lead to several significant shortfalls in safety, capacity, efficiency, and productivity."
"As part of the investment analysis process for Data Comm, a fairly comprehensive list of these shortfalls was developed."
These are repeated in Table 2 to specifically identify the shortfalls that the Data Comm intends to address.
"Because of the limitations and constraints of implementing data communications using VDL Mode 2 over a congested aeronautical VHF band, Data Comm will focus on implementing the most critical ATS services not requiring extensive amounts of bandwidth."
"This provides opportunities for L– DACS systems to augment Data Comm by enabling communications of other critical and essential ATS services, including those requiring greater bandwidth, to address the shortfalls listed in Table 2."
Peak communication workload demands on the radar controller take a larger portion of the controller’s available cognitive resources.
"Situations conducive to producing errors, confusion, and read-back and hear-back errors arising from voice congestion and voice communication quality."
Inability to implement a coherent “sector resource management” concept for the sector team where air/ground communication workload can be shared.
Alternate means to enable air/ground communication support for contingency plans when the primary voice communication capability is not available.
"For example, when a catastrophic event results in the loss of air/ground voice communication at an air route traffic control center (ARTCC) or during transient events such as a “stuck microphone” in the cockpit."
"The capability to rapidly and accurately communicate complex clearances containing multiple latitude/longitude-defined route elements, such as those associated with high-altitude airspace design; arrival and approach procedure names; and, speed, altitude, and heading instructions and preferences."
The ability to more effectively manage inter- and intra-facility sector air/ground voice communication transfer.
The ability to efficiently communicate air traffic instructions such as altimeter settings and aircraft beacon codes.
"The ability to disseminate efficiently, airspace congestion and weather advisories; and NAS infrastructure status information."
The ability to efficiently communicate complete departure clearances and revisions necessitated by traffic management initiatives.
The ability to provide for the maximum efficient use of the airspace and strategic plans by adjusting individual flights to reduce contention for resources and assure no resource is allowed to remain idle in the face of demand.
"Limited ability to use four-dimensional trajectories associated with flight objects and the airspace plan to identify areas of congestion, and the potential need for flow control initiatives to mitigate severe congestion."
"Lack of the ability to support airspace user operational requirements, utility, performance, and other flight operations preferences."
Avionics and airframe manufacturers need consistent global communication capabilities requirements.
Lack of the ability to exchange user preferred trajectories in real time.
"There are limited decision support tools to communicate and ensure user preferred routing, integrated sequencing, and spacing of arrivals and departures in Terminal Radar Approach Control (TRACON) airspace."
"Absence of synchronization between onboard avionics, such as Flight Management Systems, with ground Flight Data Processing Systems."
"Lack of synchronization between airborne and ground-based ATC increases controller and flight crew workload, imposes additional communications requirements, and introduces risks of operational errors and incidents."
"Providing for synchronization between aircraft flight management systems and ground-based ATC data processing systems provides increased predictability for flights and will allow aircraft operators to reduce costs, optimize flight routes, improve utility, and reduce dependency on voice communications."
"Misaligned communications infrastructure and service delivery to meet anticipated growth in the number of sectors and areas of specialization that must be supported for a given airspace combined with the high cost for hiring additional/maintaining current controller staff, leads to smaller and smaller sectors thus increasing flight crew/controller workloads and increased cost."
"Currently, air/ground communication capabilities are not integrated with other aspects of the automation environment."
Instructions to and requests from airspace users must be independently exchanged via voice air/ground communications and then manually updated in automation systems such as the flight data processor leading to system errors and less efficient movement of aircraft through the airspace.
"Inability to handle multiple, simultaneous traffic management initiated trajectory changes is limited to single voice transmissions that are prone to miscommunications and may lead to system errors."
Inability to automate many repetitive and time-consuming tasks precludes labor resources from focusing on more productive tasks.
"The current communication system lacks the capabilities inherent in modern, network-based communications and therefore limits more efficient dynamic resource management."
Further discussion of shortfalls related to UAS operations in the NAS is provided in Section 6.
"Referring to Table 1, these A/A could be provided in the NAS environment to address the NAS–SR–1000-defined separation assurance capability, most specifically by way of the Control Aircraft function."
The applicable A/A services defined in the COCR include the following (Ref.
"Ground automation uses the WAKE parameters (e.g., aircraft type, weight, and flap and speed settings) and other environmental data to determine the required minimum separation between a pair of aircraft to avoid a wake vortex encounter."
The WAKE service uses A/A and G/A broadcast communications.
The SURV service uses Automatic Dependent Surveillance (ADS) positional information provided by equipped aircraft for separation or monitoring purposes.
"The information can be provided via broadcast, (i.e., ADS–Broadcast (ADS-B)), or via addressed contracts, (i.e., ADS–Contract (ADS-C))."
"ADS-B can be A/A and/or G/A, while ADS-C is A/G only."
The ITP service requires both the ACL and SURV services.
"The ITP service is initiated by issuing an air traffic control clearance (ACL) instruction to one aircraft to perform a climb, descent, or station-keep relative to a target aircraft."
The aircraft performing the ITP instruction receives the SURV data from the target aircraft and displays the position information on the cockpit display of traffic information (CDTI).
The flight crew receiving the ITP instruction identifies the target aircraft using the CDTI and assumes separation responsibility with the target aircraft during the procedure.
The ITP service uses both A/G addressed (ACL) communications and A/G and A/A broadcast (SURV) communications.
The M&S service requires both the ACL and SURV services.
The M&S service is initiated by a controller issuing an ACL instruction to one aircraft to perform a merging and spacing maneuver relative to a target aircraft.
The aircraft performing the M&S instruction receives the SURV data from the target aircraft and displays position information on the CDTI.
The flight crew receiving the M&S instruction assumes separation responsibility with the target aircraft during the procedure.
The M&S service uses both A/G addressed (ACL) communications and A/G and A/A broadcast (SURV) communications.
The C&P service requires both the ACL and SURV services.
The C&P service is initiated by a controller issuing an ACL instruction to one aircraft to perform a crossing and passing maneuver relative to a target aircraft.
The aircraft performing the C&P instruction then receives the SURV data from the target aircraft and displays the position information on the CDTI.
The flight crew receiving the C&P instruction assumes separation responsibility with the target aircraft during the procedure.
The C&P service uses both A/G addressed (ACL) communications and A/G and A/A broadcast (SURV) communications.
The PAIRAPP service requires both the ACL and SURV services.
The PAIRAPP service is initiated by an ACL instruction to a pair of aircraft to perform a simultaneous approach.
The flight crews assume separation responsibility with the partner aircraft during the procedure.
The PAIRAPP service uses both A/G addressed (ACL) communications and A/G and A/A broadcast (SURV) communications.
"AIRSEP requires automated airborne algorithms that detect or estimate the probability of conflicts with other flight trajectories, airspace, or weather restrictions along the intended route of flight."
The AIRSEP service uses addressed and/or broadcast communications.
A/A communications is also currently used in the oceanic domain to provide voice communications in a relay fashion when aircraft are beyond line of sight (BLOS) of VHF ground stations providing ATS services.
"This need and/or shortcomings and the associated mitigations are outside the scope of the L- band communications system, which is intended for operation in continental airspace."
"Likewise, the joint EUROCONTROL/FAA Facility Review Committee conducted for AP–17 concluded that “in the longer term, a paradigm shift will occur in the operating concept and the prime mode of communication exchanges will be based in data exchanges rather than voice communications as it is today” (Ref."
"With the transformed role of the flight crew and flight deck in NextGen, data communications are critical to ensuring that data is available for flight deck automation (i.e., avionics to support flight crew decision making)."
"In certain defined airspace, data communications are the primary means of communicating clearances, routine communications, and 4DT agreements between the ANSP and flight deck."
Voice communications are used to communicate with lesser-equipped aircraft in appropriate airspace.
This allows greater flexibility for developing and using airspace/traffic assignments in all airspace.
"Communications paths, including both voice and data, are controlled by an intelligent network."
Communications between the ANSP and the flight deck are established when the flight is activated and are maintained continuously and seamlessly.
This capability is linked to the flight data management function so that the system automatically manages who has authority to interact with the flight deck based on the type of agreement being negotiated or information being exchanged.
Labor-intensive transfers of control and communication are automated.
"Data communications are central to TBO [(trajectory based operations)], including the use of trajectory analysis and separation assurance, and aircraft separation assurance applications that require flight crew situational awareness of the 4DTs and short-term intent of surrounding aircraft."
"In addition, as indicated above, there is increased sharing of improved common data between the flight deck, operator, and ANSP."
"In classic airspace where data communications will be available but not required, information exchange can take place with data communications for participating aircraft to provide an operational advantage."
"Common data includes ATC clearances, current and forecast weather, hazardous weather warnings, notices to airmen (NOTAMs), updated charts, current charting, special aircraft data, and other required data."
"Data communications also include weather observations made by the aircraft that are automatically provided to ANSPs, weather service providers, and flight operators for inclusion in weather analysis and forecasts."
Each of these data communications functions are managed by required communications performance (RCP) standards.
"This is shown in Table 3, which illustrates a projected allocation between voice and data communications during this period."
"As suggested by the table, for the en route domain, data link would become the primary means for most of the exchanges, with voice communication used for emergency messages and tactical clearances."
"In the TMA domain and on the airport surface, voice would remain the primary mode of communications for low delay and high availability pilot-ATC exchanges, with a data link used as a primary service for other messages and data-intensive services such as graphical weather."
"In all domains, voice communication would remain a backup for any data service."
In that timeframe tactical data exchanges are to be used as backup either to voice or to the strategic data clearance service.
"Because of spectrum constraints in the aeronautical L-band, L–DACS should be built as a broadband system, potentially accommodating a wide array of applications and services that would otherwise be difficult, inefficient, or even impossible to implement."
"Thus, an L–DACS rollout is expected in Europe prior to the United States."
"In the United States, frequency management options, such as the use of 8.33-kHz voice channel spacing in the VHF aeronautical band, may be considered prior to the introduction of an L-band system."
Data Comm is planned to be implemented in three segments (Ref.
The second segment will introduce conformance management and initial 4–D agreements.
"An L–DACS implementation in the United States might follow or overlap Segment 2 (VDL Mode 2 implementation) and enable additional services and operational capabilities not covered by VDL Mode 2 for Data Comm.4 Figure 9 depicts the planned capabilities for Data Comm, and for comparison also includes the European planned deployment of data communications capabilities."
"Those operational capabilities and the associated services shown in the figure for Segment 3, for example, the services needed to provide widespread 4–D agreements and widespread delegated separation, might benefit from a higher performance technology implementation like L–DACS."
"In addition to potentially augmenting the critical data communications services provided by VDL Mode 2 for Data Comm, L–DACS also could enable new noncritical services and UAS communications services."
"Contrary to the European plan to transition many safety critical services to the FCI (e.g., AeroMACS5), the U.S. is currently looking at FCI to augment, not to replace, the VDL Mode 2 data link enabling the FAA Data Comm services."
"Specific ConOps for both the ground users (e.g., ATC controllers) and airborne users (e.g. pilots) would have to be developed to appropriately segment the two systems to operate cooperatively and in parallel and without adding to existing workloads."
A/G voice communications as the primary A/G link in an ATC operational environment.
This additional mode of communications will contribute to improvements in airspace use and capacity.
An L–DACS could further reduce congestion on VHF voice channels and increase A/G communications capacity by offering spectrum for additional services not offered by Data Comm.
"In addition, L–DACS offers a viable alternative for the implementation of one or more of the communications links for UAS ATS communications, command/control, and/or sense-and-avoid systems."
"With Data Comm and L–DACS, the overall A/G information exchange could become more dynamic and efficient, potentially reducing operational errors and improving safety."
"Furthermore, it is assumed that the critical services proposed for implementation by the Data Comm program as an addition and/or replacement of voice communication will be in place by the time an L–DACS is implemented."
No operational changes are expected for the L-band incumbent systems.
It will also target one or more UAS communications services.
"Additional interference research and testing will determine if any operational constraints are to be imposed, such as limiting the number of users, the time of the day, duration, and other parameters."
"The economic feasibility of an L–DACS, from the perspective of an ground infrastructure provider, was evaluated at a top level during the FCS Phase II project (Ref."
The initial economic analysis showed that a positive business case for an L-band system implementation could be achieved with a payback period of approximately four years (Ref.
"However, although the first order of magnitude cost estimate yielded positive results, the assumptions made during the analysis should be revisited at a later stage, when more details of a planned implementation are known."
"The analysis assumptions included consideration of coverage, system requirements, research and development, and operations and maintenance costs."
"Consistent with the need to overcome the specific current communications systems problems and shortfalls discussed earlier, two additional primary drivers for a future radio system (FRS) are: (1) to provide an appropriate communications infrastructure to support future air traffic growth and (2) to provide a consistent global solution to support the goal of seamless air traffic management (Ref."
Increase flexibility in the terminal environment (excerpts from Ref.
"Aircraft and vehicles are identified and tracked to provide a full comprehensive picture of the surface environment to ANSP, equipped aircraft, and flight operations centers (FOCs)."
Surveillance and traffic broadcast services improve situational awareness in the cockpit with more accurate and timely digital traffic data provided directly to aircraft avionics for display to the pilot.
"ANSP is used to exchange clearances, amendments, and requests."
Initiate trajectory-based operations (excerpts from Ref.
Airborne and ground automation provide the capability to exchange flight planning information and negotiate flight trajectory contract amendments in near real-time.
"OI 104126—Trajectory-Based Management—Gate-To-Gate: All aircraft operating in high density airspace are managed by Four Dimensional Trajectory (4DT) in En Route climb, cruise, descent, and airport surface phases of flight to dramatically reduce the uncertainty of an aircraft's future flight path in terms of predicted spatial position (latitude, longitude, and altitude) and times along points in its path."
"Integrating separation assurance and traffic management time constraints (e.g., runway times of arrival, gate times of arrival), this end state of 4DT-based capability calculates and negotiates 4DTs, allows tactical adjustment of individual aircraft trajectories within a flow, resolves conflicts, and performs conformance monitoring by Air Navigation Service Providers (ANSPs) to more efficiently manage complexity, ensure separation assurance, and enhance capacity and throughput of high- density airspace to accommodate increased levels of demand."
"This will be enabled by the trajectory exchange through data communications, as well as many new surface automation and 3D (x, y, and time) trajectory operations."
Increase arrivals and departures at high-density airports (excerpts from Ref.
Arrival and departure flows are planned and executed based on a comprehensive view of real time airport operations.
"Automation provides optimal departure staging and arrival sequencing based on aircraft wake, wake conditions and airborne performance characteristics."
Data communications provides required navigation performance routes to the flight deck.
Enhanced surveillance and new procedures enable the ANSP to delegate some responsibility for maintaining aircraft-to-aircraft separation to flight crews.
Improved display avionics and broadcast positional data provide detailed traffic situational awareness to the flight deck.
Broadcast surveillance sources and improved avionics capabilities provide ANSP and the flight deck with accurate position and trajectory data and therefore increased situational awareness.
"Aircraft that are equipped to receive the broadcasts and have the associated displays, avionics, and crew training will perform delegated separation when authorized by the controller."
"This Operational Improvement involves more complex delegated separation responsibilities than those performed using a cockpit display to cross, merge, or pass another aircraft."
"Using advanced airborne technologies with conflict detection and alerting, aircraft in ANSP-managed En Route and transition airspace are delegated separation responsibilities to perform more complex operations, possibly maintaining separation from more than one other aircraft."
OI 104117—Improved Management of Arrival/Surface/Departure Flow Operations: This Operational Improvement (OI) integrates advanced Arrival/Departure flow management with advanced Surface operation functions to improve overall airport capacity and efficiency.
Air Navigation Service Provider (ANSP) automation uses arrival and departure-scheduling tools and four dimensional trajectory (4DT) agreements to flow traffic at high-density airports.
"Automation incorporates Traffic Management Initiatives (TMIs), current conditions (e.g., weather), airport configuration, user provided gate assignments, requested runway, aircraft wake characteristics, and flight performance profiles."
"ANSP, flight planners, and airport operators monitor airport operational efficiency and make collaborative real-time adjustments to schedules and sequencing of aircraft to optimize throughput."
"Metroplex traffic flow is more efficiently managed through arrival/departure and surface scheduling automation, integrated with all available constraint information, including weather impacts, optimizing traffic throughput by eliminating potential gaps in unused capacity, thereby increasing regional/metroplex capacity."
"Data communications is a key element of super-density operations, allowing the Air Navigation Service Provider (ANSP) to maximize access for all traffic, while adhering to the principle of giving advantage to those aircraft with advanced capabilities."
"OI 104206—Full Surface Traffic Management with Conformance Monitoring: Efficiency and safety of surface traffic management is increased, with corresponding reduction in environmental impacts, through the use of improved surveillance, automation, onboard displays, and data link of taxi instructions."
"Clearances are developed, delivered, monitored and provided in graphical or textual format that is used by the flight deck display to support taxi, takeoff and departure flows in all conditions."
"At high-density airports clearances and amendments, requests, NAS status, airport flows, weather information, and surface movement instructions are issued via data communications."
Surface decision support and management systems use ground and airborne surveillance and a scheduling and sequencing system to develop and maintain schedules of departing aircraft within a defined time horizon.
"Information is sent to participating aircraft and the air navigation service provider via data communications or voice and adjustments are made to push back times, taxi instructions, etc."
ANSP automation uses departure-scheduling tools to flow surface traffic at high-density airports.
Automation provides surface sequencing and staging lists for departures and average departure delay (current and predicted).
ANSP automated decision support tools integrate surveillance data.
"This includes weather data, departure queues, aircraft flight plan information, runway configuration, expected departure times, and gate assignments."
Improve collaborative air traffic management (excerpts from Ref.
"Constraint information that impacts the proposed route of flight is incorporated into air navigation service provider (ANSP) automation, and is available to users."
"Examples of constraint information include special use airspace status, SIGMETS [data link significant meteorological information], infrastructure outages, and significant congestion events."
OI 103305—On-Demand NAS Information: National Airspace System (NAS) and aeronautical information will be available to users on demand.
"NAS and aeronautical information is consistent across applications and locations, and available to authorized subscribers and equipped aircraft."
Proprietary and security sensitive information is not shared with unauthorized agencies/individuals.
"OI 105207—Full Collaborative Decision Making: Timely, effective, and informed decision- making based on shared situational awareness is achieved through advanced communication and information sharing systems."
"Decision-makers request information when needed, publish information as appropriate, and use subscription services to automatically receive desired information through the net-centric infrastructure service."
"OI 103119—Initial Integration of Weather Information into NAS Automation and Decision Making: Advances in weather information content and dissemination provide users and/or their decision support with the ability to identify specific weather impacts on operations (e.g., trajectory management and impacts on specific airframes, arrival/departure planning) to ensure continued safe and efficient flight."
"The 4-D Weather Single Authoritative Source (4-D Wx SAS)) will support enhanced volumetric extractions, by time frame of interest, of weather information by NAS users to quickly filter the enhanced weather content to the region of interest for impact analysis."
This will streamline the process by which the user—with or without decision support ATM tools—conducts system-wide risk management in planning for both individual flight trajectories and flows.
"OI 103123—Full Integration of Weather Information into NAS Automation and Decision Making: Further advances in weather information content/dissemination and a NAS-wide increase in the direct integration of weather into decision support tools will enable users and service providers to more precisely identify specific weather impacts on operations (e.g., trajectory management and impacts on specific airframes, arrival/departure planning) to ensure continued safe and efficient flight."
"While communication on the airport surface is more likely to be conducted over AeroMACS in the mid- to long-term, it could also be enabled by L–DACS."
"As such, OIs related to surface communications are included in the list above."
"Changes will occur in both volume and demand characteristics with improved aircraft capabilities to support airborne self-separation and spacing, and manage tasks to precisely navigate and execute 4DTs."
Aircraft operations are also expected to change to support sophisticated flight planning and operations management.
"At the same time, “it is a challenging environment for aeronautical communications due to the aeronautical channel characteristics and the current usage of the band” (Ref."
"These challenges include the following d in the AP–17 Future Communications Study (FCS): “Estimated RMS delay spreads for this channel, on the order of 1.4 µs, can lead to frequency selective fading performance for some technologies."
"Interference to and from existing aeronautical L-band systems for a proposed communication technology requires detailed examination, including validation measurements and testing” (Ref."
The aeronautical L-band spectrum provides an opportunity to support the objectives for a future global communication system; however no technology evaluated for the Future Communication System (as defined) for supporting data communication in this band fully addresses all requirements and limitations of the operating environment.
Initial co-channel interference testing indicates potential interference of evaluated candidate technology waveforms to existing navigation systems.
"Further evaluation, including consideration of duty cycle effects on interference, is required to determine collocation feasibility (with on-tune channels, off-tune channels or cleared spectrum)."
"Each technology was identified as having some technical, cost or risk concerns that require modification of the technology specification for applicability and/or willingness to assume moderate levels of cost/risk."
Both civil and military users could utilize the system.
Growing requirements to use UAS in civilian airspace using AM(R)S and AMS(R)S frequency allocations adds a new layer of requirements and adds different type of users to an aeronautical system.
"The introduction of an L-band system is expected to increase communications system capacity, thus allowing the addition of new services and expanding the user base."
The proposed introduction of an L-band system will increase the overall capacity of the system and open up opportunities for addition of data services not provided under the Data Comm.
"Many of those, for example, services associated with the Airborne SWIM program, will provide for the wider system use."
"Not only would more users be expected to take advantage of the new data communications capabilities, the types of users allowed to participate would change as well."
"An introduction of a new frequency band, such as an L-band, in addition to the VHF frequencies supporting the existing voice and data communications services, will alleviate long-term capacity problems."
"The continued migration from a NAS based on a ground infrastructure and voice communication to a system that encompasses both ground and airborne components and utilizes the exchange of digital data as the primary type of communication, will “support the human in doing what they do best—choosing alternatives and making decisions, while the technology accomplishes what it can do best—the acquisition, compilation, evaluation and exchange of information” (Ref."
Users will become key participants in the planning of traffic flow management and will utilize a comprehensive information exchange process to improve flight operations planning according to capacity and traffic conditions to minimize congestion and delays.
Flight planning and emergency alerting services: Users will have interactive flight planning capabilities with an immediate access to real-time data.
User-preferred routing will become available to properly equipped aircraft for both domestic and international flights.
Users will have improved real-time planning with continuous update of the flight profile.
"Users will utilize data, such as ATC clearances, current and forecast weather, NOTAMs and hazardous weather warnings, updated charts, current weather, special use airspace status, and other required data."
Oceanic: A/G communication via L–DACS will not be provided in oceanic airspace.
"Operational aspects of aeronautical communications are changing with an increased emphasis on safety and cost reduction achieved via increased automation, efficiency, delays reduction, and other improvements."
A key NAS ConOps source driving the L–DACS ConUse is the RTCA NAS ConOps (Ref.
Operational scenarios can illustrate how proposed system capabilities could be used in an operational environment.
"These scenarios also would be generally applicable to an L–DACS, implementation."
The following are examples of the operational scenarios from Segment 3 of Data Comm that are potentially applicable to L–DACS (Ref.
Typical exchanges via data communications for basic equipped departing aircraft include altitude and direct routing assignments.
The aircraft follows the previously negotiated 4-D trajectory.
Trajectory negotiations conducted pre-departure typically leave some conflicts unresolved such that maximum use of the airspace resource can be utilized.
The voice frequency and data communications eligibility transfers are conducted automatically without the need for flight crew interaction.
Communications with the first en route controller is conducted through data communications.
Routine clearances with aircraft are communicated via data communications while time critical clearances continue to be communicated by voice.
"Some of the aircraft operating in this normal (not High Performance (HP)) airspace are equipped with full 4-D trajectory-capable integrated data communications, while other aircraft have less capable data communications or lack ATC data capabilities and thus rely exclusively on voice."
"Only aircraft capable of communicating and conducting 4-D trajectory operations via data communications may enter the High Performance Airspace (HPA), which may initially be established at higher en route altitudes."
Aircraft not properly equipped continue to operate in normal (non-HPA) airspace.
"The HPA entry, 4-D trajectory, and exit previously loaded into the flight management system during the pre-departure phase are updated to reflect any changes made by ATC, and to reflect the current timing and actual position of the aircraft."
"The aircraft downlinks the revised requested profile, which is probed for conflicts by automation, then presented to the controller, who will typically approve and send the HPA clearance to the aircraft."
"If the automation determines a conflict will exist within the probed window of time, the automation will suggest revised constraints for controller approval and uplink to the aircraft."
"If the controller determines the conflict-free routing is sub-optimal, the controller may revise the constraints and uplink them."
"Since the controller remains responsible for separation, the output of decision support tools are reviewed by the controller when a conflict is predicted."
A proposed resolution will be sent to the aircraft via data communications upon the controllers review and acceptance.
The controller assesses any proposed trajectory changes generated by traffic management initiatives.
"If the proposed trajectory is predicted to cause a conflict, the controller takes the necessary action to alleviate the conflict."
Upon determination of a conflict-free trajectory the controller sends the new trajectory to the flight crew via data communications.
The flight crew checks whether the aircraft is capable of complying with the proposal through the flight management system.
In this scenario the flight crew responds with an alternative trajectory.
The ground automation confirms the proposal is conflict free and provides a new trajectory agreement to the controller for transmission to the aircraft.
"To prevent mistakes on re-entry of the trajectory clearance information, the data communications airborne system and the flight management system navigation function are interfaced, allowing direct transfer of clearance data upon flight crew approval."
"Data communications supports aircraft clearances to use the appropriate services to self- separate e.g., Crossing and Passing, Sequencing and Merging or In-Trail Procedures."
Separation responsibility is delegated to the flight crew for these functions.
"The flight crew requests relevant information for the weather, airport field conditions and local notices to airmen for the destination airport through data communications."
Selected aircraft parameters are monitored by data communications-enabled conformance management capability which decreases controller and flight crew workload and improves surveillance performance.
"As the aircraft approaches the Top of Descent position, the appropriate controller provides scheduled time of arrival information to the flight crew via data communications."
"The flight crew then downlinks a route request to the en route controller, through data communications, which is composed of a tailored 4-D trajectory based on the aircraft’s performance."
The controller coordinates the request with the arrival TRACON airspace controller via automation.
The en route controller responds to the flight crew via data communications with a message containing the confirmed clearance.
"In conjunction with the ground automation handoff, which is done automatically unless the controller takes an extra action to reject it, data communications provides the next frequency to the flight crew, and transfers the data communications eligibility to the next sector or Center."
The data communications system automatically validates the aircraft’s Mode-C reported altitude and confirms the assigned altitude for the receiving controller.
The flight crew contacts the TRACON controller via data communications.
The data communications system automatically validates the aircraft’s Mode-C and confirms the assigned altitude and ATIS code for the receiving controller.
"The TRACON controller replies with the initial information on approach expectations, potential airport information changes, and initial clearances."
Aircraft continue to employ continuous descent profiles from the en route Top of Descent constraint.
"Arrival at the final constraint, which is typically the final approach fix, terminates trajectory based operations."
"When necessary due to the traffic density, aircraft use the appropriate data communications services (e.g., Merging and Spacing (M&S) or Paired Approach) to perform delegated separation in the final approach phase from traffic landing on the same or closely spaced parallel runways."
A data communications clearance to execute the approach is issued.
An instruction to monitor the tower voice communication frequency is subsequently issued via data communications.
Data communications manages the data communications eligibility transfer.
Reference 12 classifies all of the COCR ATS data services as safety critical.
"Furthermore, it identifies services that are not expected to be implemented by Data Comm through Segment 3, and identifies them as possible candidates for implementation via C-band and/or L–DACS."
It must be stressed that both C-band and L–DACS are being developed for the FCI to accommodate safety and regularity of flight services.
"These are designed to operate over aviation-protected spectrum, so any COCR ATS service could be allowed to be implemented via one or the other of these links (as appropriate)."
Additional data services that may be provided via FCI may be identified as NextGen and Single European Sky ATM Research (SESAR) progress.
"Some of the services listed would be mostly provided the ground, while others may be applicable to wheels on- and off-the-ground scenarios."
These services were not mentioned by the COCR but recommended based on industry feedback during data link standardization activities.
"Although the services are already implemented in new aircraft, they are highly customizable."
"As d in the document, the following list does not claim to be exhaustive and is awaiting feedback from Airbus and major airlines."
"Air-to-ground cabin video streaming for security/surveillance (potential Real time of summary transmission of failures/monitored CABIN/IFE Transmission of telemedicine data to ground (sick passenger) Ordering and provisioning of fuel from cockpit when on ground De-icing service ordering and management from cockpit when on ground DEICING aThis service may be specific to some airline operators only, as the technical trend is rather to integrate these functions in avionics, as for business jets for example, instead of using data links."
CVM and VQAR involve transmission of large amounts of data (up to several tens of Mbytes).
"The remaining services listed above are similar to the AOC services defined in COCR v.2.0 in terms of the required message sizes, data rates, and phase of flight usage."
The AOC services in Table 5 may be mapped to the flight regularity category (Ref.
"Services with large bandwidth requirements may be more suitable to provide via FCI (e.g., L–DACS and AeroMACS), and services involving smaller traffic volumes may be more appropriate for a VDL-2 based system."
Section 6.0 contains more detail on UAS-related services.
"SWIM, an FAA technology program designed to facilitate sharing of ATM system information (airport operational status, weather information, flight data, status of special-use airspace, and NAS restrictions), can be implemented via G/G, A/G, and A/A communications infrastructure components."
Each of these components would enable efficient data exchange between authorized users in the respective domain.
An L–DACS could provide means for A/A and A/G data transfers.
L-band) fits in the overall FAA Information Exchange Model.
These later services would be suitable targets for an L–DACS implementation.
Services would be offered from individual providers as well as centralized providers.
Copyright Thales Air Systems; used with permission.
Joint Planning and Development Office (JPDO) Next Generation Air Transportation System (NextGen) ATM-Weather Integration Plan (Ref.
"OIs 104117, 102406, 104207,104208, communications and automation technologies as the primary means of accomplishing its goals” (Ref."
The proposed L–DACS offers communications links to fulfill the demand for such communication technology.
Updated information would be provided to filers if conditions along trajectory change with a user being able to submit alternative flight plans if needed.
"After filing a flight plan and up until departure, weather and nonweather constrains that impact the plan as well as FAA mitigation strategies would be provided to the user."
"The] evaluation capability will provide the user with feedback that is based on consistent information to that of the ANSP, thereby increasing common situational awareness."
"The feedback will include current and predicted information for a flight along its complete flight path (i.e., full route) throughout the flight’s life cycle."
"The feedback will include weather information, probabilistic information, TMIs (including delay information), airspace information (e.g., High Performance Airspace [HPA]/Mixed Performance Airspace [MPA], RNAV routes), required aircraft performance characteristics (e.g., RNP, RNAV requirements), active routes, restrictions (e.g., Letters of Agreement (LOAs), SOPs, SAA, terminal status information (e.g., airport conditions, runway closures, wind, arrival rates, RVR, airport (current and planned) configurations, surface information, and other NAS status information and changes along the path of the evaluated route or filed route."
"In addition, the nature (e.g., fully restricted or conditional access), the time, and the impact (e.g., distance, delay) associated with any restriction or constraint will be provided."
"It is expected that the evaluation feedback will evolve as changes in airspace, and new information systems become integrated and available (Ref."
L–DACS could provide communications links to enable these services.
L–DACS is likely to overlap with SWIM Segments 3 and 4 when air/airborne SWIM is introduced.
Airport (APT): airport surface/immediate vicinity of the airport.
En route (ENR): airspace that surrounds the TMA domain.
"The messages are grouped according to the information type, as defined by the function identifications (IDs) provided in Section 7.0."
"Trajectory intent exchange (air-to-air self-separation, AIRSEP), addressed and/or broadcast communications."
"Conflict negotiation (AIRSEP), addressed and/or broadcast communications."
The scenarios are a subset of those provided in COCR Version 2.0 (Ref.
Refer to Section 6 for ConUse and operational scenarios applicable to UAS.
"The flight information service (FIS) system response provides all relevant information for the weather, Automatic Terminal Information Service (ATIS), and field conditions, plus the local Notices to Airmen (NOTAMs)."
"For data-link-equipped aircraft preparing to taxi, the current graphical picture of the ground operational environment is uplinked and loaded using the data link surface information guidance (D–SIG) service."
"The system access parameters (SAP) service is initiated by the air traffic service unit (ATSU) automation system, and the downlinked information is provided to the various ground components (e.g., for smoothing of trackers) or on request for display of parameters to controllers."
The ATSU automation system monitors the aircraft behavior in accordance with the given clearances.
The tracking system issues warnings to the executive controller in case of noncompliance.
The executive controller intervenes if the situation requires action.
The tracking system uses the automatic dependent surveillance (ADS) and radar data to monitor whether the aircraft performance is in accordance with the ground-predicted trajectory and updates the trajectory where necessary.
The ATSU automation system confirms/sets the exit/entry conditions with the sectors in the en route phase.
"At each entry into a subsequent ATSU, FLIPCY is performed to verify the flight management system route against what is held in the ATSU flight data processing system."
This information is sent to the aircraft via the data link significant meteorological information (D–SIGMET) service.
A new network connection is established between the aircraft and the remote domain ground system before the connection with the en route domain ground system is released.
The planning controller analyses interactions with other aircraft that are reported to him/her by the conflict probe system.
The planning controller probes “what-if” solutions for interactions.
"The conflict probe system may offer alternatives to the existing route, the planning controller assesses these alternatives, and the alternatives are provided via the dynamic route availability (DYNAV) service for flight crew assessment."
The planning controller enters the flight-crew-selected alternative and updates the flight trajectory in the ATSU automation system.
The flight crew flies the aircraft according to the instructions given.
"The ATSU automation system recognizes the aircraft’s position relative to exiting the ATSU, compiles a data link operational en route information service (D–ORIS) report specific to the remaining portion of the area to be over-flown, and sends it to the aircraft."
The system updates arrival manager (AMAN) with changes to the arrival sequence.
"If required, the conflict probe system calculates a conflict-free alternative trajectory for the flight to comply with the AMAN constraints."
The planning controller of the receiving sector checks the PPD service information to see if the conflict probe system-provided trajectory could be improved with these preferences.
The planning controller accepts the proposal and coordinates the sending of the ACL instruction with the Executive Controller.
"Based on the equipage and flight crew qualification information contained in the flight plan and data obtained via SAP and PPD, the Executive Controller determines which aircraft may execute a spacing application and issues merging and spacing clearances to those aircraft via ACL (ACL is expected to be supported by Data Comm)."
The ATSU automation generates a D–SIG of the arrival airport surface.
A middle-out approach was adopted to identify the high-level requirements applicable to L–DACS.
"In this approach, the top-down functional requirements were derived from the ConUse and the associated functional capabilities."
"In parallel with that process, a bottom-up assessment of existing requirements in relevant documents such as the NAS SR1000 (Ref."
"Thus, the top-down approach employs the classic “clean-sheet” system engineering process, and the bottom-up approach addresses how L–DACS fits into the existing environment."
Functions identified in the NAS SR–1000 document (Ref.
The boxes deservices potentially enabled by A/G communication with the blue boxes representing voice and/or data communication and green boxes representing data communication only.
TO NATIONAL AIRSPACE SYSTEM (NAS) SERVICE CAPABILITIES (REF.
NAS requirements specified in the NAS SR–1000 document (Ref.
The NAS shall disseminate the status of special use airspace to users.
The NAS shall disseminate weather information to users to support flight planning.
The NAS shall disseminate aeronautical information to users to support flight planning.
The NAS shall disseminate flight information to users.
The NAS shall disseminate flight plan information to users via external data interfaces.
The NAS shall disseminate flight data summaries to users.
The NAS shall disseminate flight plan clearances to users.
The NAS shall disseminate recommended collision avoidance maneuvers to users.
The NAS shall respond to requests for assistance from in-flight users.
The NAS shall respond to emergency transmission received via radio communications.
The NAS shall respond to emergency transmissions received via data link.
The NAS shall continuously monitor air-to-ground communications utilizing designated frequencies for detection of emergency transmissions.
The NAS shall accept airspace reservations from search and rescue aircraft.
The NAS shall disseminate essential information on missing aircraft.
The NAS shall disseminate current flight activity information in restricted areas.
The NAS shall disseminate current flight activity information in warning areas.
The NAS shall disseminate weather advisories via direct specialist to pilot communications.
The NAS shall disseminate graphical weather information to airborne users.
The NAS shall disseminate weather information to users continuously.
The NAS shall disseminate current weather effect along the users proposed flight path.
The NAS shall disseminate forecast weather in effect along the users proposed flight path.
The NAS shall disseminate intensity levels of weather by route of flight to users.
The NAS shall disseminate intensity levels of weather by geographic area to users.
The NAS shall disseminate weather advisories to users in response to a request.
The NAS shall display intensity levels of weather by geographic area to users.
The NAS shall display intensity levels of weather by route of flight to users.
The NAS shall provide weather advisories to aircraft in flight.
The NAS shall disseminate weather information to airborne users for pictorial display.
The NAS shall coordinate navigation guidance information reception requirements between en route and terminal area navigation systems to minimize equipment costs to users.
The NAS shall disseminate correction values for navigational aids to users.
The NAS shall disseminate traffic advisories upon user request.
The NAS shall disseminate advisories to aircraft approaching special use airspace.
The NAS shall provide traffic advisories to aircraft on the surface.
The NAS shall disseminate airway usage information to users.
The NAS shall disseminate route usage information to users.
The NAS shall disseminate aeronautical information to users via external data interfaces.
The NAS shall disseminate aeronautical information per user request.
The NAS shall disseminate aeronautical information upon user request continuously.
The NAS shall disseminate the status of supplemental navigation systems to users.
The NAS shall disseminate status of supplemental navigation systems to users.
The NAS shall disseminate flow control information to users via external data interfaces.
The NAS shall disseminate derived restrictions to the user.
The NAS shall disseminate alternate courses of action relative to flight restrictions to users.
"The NAS shall disseminate terrain information compliant with terrain, ground and obstacle information accuracy requirements, to users upon request."
"The NAS shall disseminate manmade obstacle information compliant with terrain, ground and obstacle information accuracy requirements, to users upon request."
"The NAS shall disseminate ground information compliant with terrain, ground and obstacle information accuracy requirements, to users upon request."
The NAS shall disseminate filtered terrain information to users.
The NAS shall disseminate filtered ground information to users.
The NAS shall disseminate filtered manmade obstacle information to users.
The NAS shall disseminate military air traffic control plans related to national emergencies.
The NAS shall disseminate interfacility traffic flow plans.
The NAS shall disseminate derived alternative courses of action to the user.
The NAS shall determine flight restrictions for specific aircraft.
The NAS shall disseminate flight restrictions to users.
The NAS shall process derived alternatives to the user.
The NAS shall disseminate reports on equipment performance.
The NAS shall disseminate reports on maintenance activities.
The NAS shall disseminate reports on equipment repair activities.
These services are typically provided via satellite communication but could be provided via a ground-based system.
The following is a summary of NAS infrastructure (communications) requirements found applicable to the proposed L–DACS as documented in the NAS SR–1000 (Ref.
The list supports the high-level functional requirements presented in the document.
The NAS shall automate communications capabilities to reduce specialist and user workload.
The NAS shall provide A/G communications continuously.
"This section presents a top-down determination of functional requirements through: (1) a functional analysis based on prior work, and (2) a functional analysis based on the ConUse defined in Section 3.0, and an analysis of appropriate NAS–SR–1000 requirements."
A functional architecture can interpreted as a hierarchical arrangement of functions and interfaces that represents the complete system from a performance and behavioral perspective (Ref.
"For its top-down functional analysis, this report leverages prior functional analysis work to characterize aeronautical A/G and A/G communication."
Appendix C presents a hierarchical decomposition of functions as diagrams and in an outline format derived from Reference 8.
Functional architectures can be presented in several different ways.
"These two techniques are illustrated in Figure 22 and Figure 23, respectively."
N2 charts were selected to document the L-band functional architecture defined in Appendix C for this high-level architecture and requirements document.
L–DACS applicable NAS ConOps can be traced to the desired functionality of the proposed network.
These functions are grouped into appropriate functional hierarchies and functional requirements are derived.
Note that these are high-level NAS requirements that do not specify how they should be implemented.
The NAS shall disseminate hazardous weather avoidance recommendations to users within 1 minute of request.
The NAS shall communicate aircraft actions to users within 1 minute of implementing a weather avoidance plan.
The NAS shall alert participating aircraft to predicted conflicts with obstructions within 10 seconds of prediction.
The NAS shall alert participating aircraft to predicted conflicts with special use airspace within 10 seconds of prediction.
The NAS shall notify users of non-adherence to ATC clearance within 10 seconds of the detection of the deviation.
The NAS shall alert appropriately equipped users to the collision danger within 10 seconds after the prediction is made.
The NAS shall disseminate a requested summary of hazardous weather for any airspace in the continental United States within a mean response time 3.0 seconds of the request.
The NAS shall notify users affected by the presence of hazardous weather within 2 minutes of acquisition.
The NAS shall update hazardous weather broadcasts at least once every 30 minutes.
The NAS shall disseminate automated weather observations once per minute to designated interfaces.
The NAS shall disseminate terminal area hazardous weather information to users within one minute of detection.
The NAS shall disseminate a requested summary of hazardous weather for any airspace in the continental United States within a 99th percentile response time of 5.0 seconds of the request.
The NAS shall disseminate a requested summary of hazardous weather for any airspace in the continental United States within a maximum response time of 10.0 seconds of the request.
The NAS shall disseminate the results of Traffic Management Coordinator capacity projection requests within 99th percentile response time of 5.0 seconds of the request.
The NAS shall disseminate the results of Traffic Management Coordinator capacity projection requests within a maximum response time of 10.0 seconds of the request.
The NAS shall disseminate the results of Traffic Management Coordinator demand projection requests within the 99th percentile response time of 5.0 seconds of the request.
The NAS shall disseminate current flight activity information in military special use airspace within 1 minute of request.
"The NAS shall alert users within 10 seconds, of failures to navigation guidance that affect operations."
"The NAS shall alert users within 10 seconds, of failures to portions of navigation guidance that affect operations."
The NAS shall assure ground-air transmission time for data messages not exceed 6 seconds.
The NAS shall strive to restore critical system service to users/specialists within 6 seconds of failure.
The NAS shall strive to restore essential system service to users/specialists within 10 minutes of failure.
"An operational performance assessment (OPA) begins with required communication performance (RCP) and allocates these requirements to humans and technical components (e.g., equipment)."
The term required communication technical performance (RCTP) refers to the allocation to the technical components.
The performance requirements resulted from the OPA conducted as part of the COCR.
"That OPA determined the performance a system or service must achieve and led to determination of the availability, integrity, and transaction time requirements."
"Performance requirements were driven by operational needs and safety requirements as well as other assessments (e.g., information security) to determine overall communication performance requirements."
The more stringent of the safety objectives and operational requirements for each parameter were used to determine the communication performance requirements.
"The operational requirements were driven by the type of exchange (e.g., trajectory change and general information) and the domain in which the service was offered."
Values in Table 15 are based on COCR ATS FRS performance requirements (Ref.
"For example, the WAKE service is a driving service for defining the latency requirements in the airport, TMA, and en route domains."
A channel plan will be developed driven by frequency availability to support broadband services.
Interference studies proposed to be performed in the near future and the subsequent final technology selection will allow defining the channel plan.
The proposed system should provide seamless operations around the globe.
The NAS shall secure and protect national radio spectrum for the FAA and the U.S.
The NAS shall coordinate national spectrum allocation programs.
The NAS shall establish national frequency allocation programs.
The NAS shall coordinate national spectrum management assistance programs.
The NAS shall disseminate en route navigational guidance such that ambiguities in guidance information have a minimal impact on NAS operations.
The system shall be capable of operation with appropriately equipped aircraft of all types and all flight regimes including at rest.
"The new system shall satisfy any data communications requirements for use in any authorized category of communications service including air traffic services, ATS, aeronautical (airline) operational control, and aeronautical administrative communication."
The avionics equipment shall communicate with any compatible ground system.
The new system shall be capable of implementation and operation anywhere in the world.
The system shall comply with AM(R)S spectrum allocation requirements.
The system shall comply with the U.S. ATS and AOC service rules and regulations.
The system shall comply with the U.S. Federal aviation regulations.
The system shall support the requirements for message priority capability.
TABLE 19.—MAPPING OF ITU PRIORITY LEVELS TO COCR SERVICES (REF.
These are additional AOC services not specified in the COCR and therefore not addressed in the ITU Informational Paper ACP– WGF 19/IP01 as all other services.
"A fundamental safety requirement is that a new system shall not cause a degradation in safety when compared with the existing A/G (or A/A, as applicable) communications system."
Preliminary safety and security analysis and the associated requirements are covered in a separate document (Ref.
The L–DACS architecture can be characterized at many levels.
"In accordance with U.S. Government policy, all Government agencies, including the FAA, have developed an enterprise architecture (EA)."
"Of most relevance to this report is the NAS EA, which relates to activities that support operational air traffic services."
"The NAS EA contains architecture products and views that describe the current NAS “portfolio” of infrastructure and services, the 2025 far-term and 2018 mid-term target architectures, and roadmaps to reach the target architectures."
Some examples of the NAS EA views have been depicted in Section 3.0 of this report.
System elements are presented depicting their functionality.
"A/G communications is shown as an enabler of various NAS services facilitating surveillance, weather, flight management, and other data exchange."
"The L–DACS architecture, as it matures, may be incorporated into the NAS EA."
The high-level L–DACS architecture presented in this document might serve as a high-level entry point for EA incorporation.
"It should be d, however, that the FCS technology assessments leading to candidate technologies recommendations were conducted before formal system requirements, ConUse, and architecture were developed."
"As such, the development of L–DACS candidate technologies: L–DACS1 and L–DACS2, to a certain extent, might dictate a reverse-engineering approach to be taken for developing the proposed system architecture to assure traceability in the technology selection process."
It is recommended that this approach be considered as part of future U.S. and European coordination activities in the L–DACS technology downselection process.
At least one iteration of that process has been completed and is reflected in the FCS technology assessment reports.
"Another aspect of synthesis—“translating the requirements, as set in context by the functional architecture, into the design architecture, consisting of the physical architecture with its associated technical requirements” (Ref."
It represents “a hierarchical arrangement of hardware and/or software components along with associated interfaces depicting the physical definition of the system.
Lower level Functional Analysis work is constrained by a higher level physical architecture” (Ref.
"The ground infrastructure comprises a number of L–DACS ground radio stations, each providing a cell- like coverage service volume, and which are geographically situated to provide overlapping coverage (using different frequencies) to achieve seamless service volume handovers."
Each ground radio station would be connected to some G/G network through some ground network interface (GNI) (no.
"The components shown in the figure, with the exception of the ground station infrastructure (e.g., power, heating, ventilation, and air conditioning (HVAC), and antenna towers), would be responsible for providing the functions identified earlier and meeting L–DACS functional and performance requirements identified in Section 4.0."
This architecture is necessarily presented at a high level because the L–DACS ConUse so far are very broad in scope.
Most of the high-level functional and performance requirements identified in Section 4.0 cannot be readily allocated to the components shown in Figure 26 and Figure 27.
The main attributes of the current UAS would apply to the proposed system as well when services are provided over the L–DACS and as such are detailed below.
Most current UAS are equipped with line-of-site (LOS) control data links.
"However, such systems will still require LOS control data links."
The level of reliance on the LOS system is reflected in the level of control data link redundancy and low latency adopted by different UAS.
Most pilot in-the-loop takeoff and landing UAS use dual redundant data links and have low pilot-control-input-to-pilot-observable-response latencies since the pilot is actively maneuvering the aircraft in real time.
"Conversely, pilot on-the-loop systems often only have single-thread LOS data links and higher latencies because the pilot is not in real-time control of the takeoff or landing maneuvers."
Dual redundant LOS control data links offer the advantage of having two sets of data link equipment significantly improving the overall mean time between failures (MTBF) of the data link.
The two links can also offer improved data link availability.
"For example, if one of the links is temporarily suffering degradation, because of interference or propagation-related effects, then the other link in a different frequency band could take over the delivery of telecommands and telemetry, because interference and propagation effects are not correlated for the two links."
Some current UAS are equipped with BLOS UA control systems.
"While most takeoff and landing activity is controlled using the LOS systems, at a manufacturer-specific altitude or range, the UAS is switched from LOS to BLOS control and is usually flown this way for the bulk of the distant flight activity."
The pilot using the LOS system to control the aircraft does not necessarily have to be the same pilot controlling the aircraft using the BLOS system.
A LOS system will again be used for landing but not necessarily the same one that was used for takeoff.
This allows the UA to make landings at distant locations and also allows for pilot relief.
"To enhance link availability when using satellite communications, current UAS that fly BLOS missions often utilize two or three different satellite communications systems, all operating in parallel."
"Typically, the flight computer on the aircraft and the computer in the control station simultaneously monitor all links and choose, on a real- time basis, the best link as appropriate."
This link choice can also be manually controlled by the pilot.
The proposed L–DACS will not offer BLOS communication; these links will remain satellite-based.
Not all current UA carry voice communication equipment.
Current UA that are equipped only for LOS flights often have their VHF voice transceivers located in their control stations.
"This is adequate when the control-station based VHF transceiver can maintain voice communication with the controlling ATC entity; however, for BLOS operation this is unacceptable."
"In current BLOS UAS, the voice traffic is carried (along with the telecommands and telemetry) as part of the overall data link between the control station and the aircraft."
Most of the VHF voice equipment currently used for both LOS and BLOS systems is standard equipment covered by current technical standard orders (TSOs).
"However, the method for monitoring the voice traffic between the pilot and the VHF equipment, when it is carried by the aircraft flying a BLOS mission, is not specifically covered by current regulations."
It should be d that while the proposed L–DACS could support voice communication only data communication was planned over the L-band for manned aircraft.
"Typically, given the statistical nature of the situation, the data links will return to full functionality."
"The amount of time a particular UA can operate without its data links is dependent on its design and level of autonomy, but after a certain amount of time without a data link all systems must declare that the link is lost."
The vast majority of UA have built-in procedures to accommodate lost link situations.
"Again, the level of autonomy plays a major part in what the UA does after losing its link, but in most cases the aircraft will fly a preplanned maneuver trying to reestablish any data link that might be available while making its way to a precoordinated location where it can be picked up again by the LOS system located at that facility."
Transponder- equipped UA may set their transponders to squawk certain codes as part of their lost link procedure.
Lost link procedures will need to be developed for the proposed L-band system.
Current UAS Spectrum Usage includes a wide range of frequency bands for control of the UA.
Systems operate on frequencies ranging from VHF (72 MHz) up to Ka-band (27 to 40 GHz).
"The factors driving the choice of frequency are related to limiting the size, weight and power of the airborne data link equipment—particularly antennas and power amplifiers—as well as data rates required."
Many BLOS systems share the control link and the payload return link on one common carrier so the wide bandwidth needs of the payload return link may drive this choice more than the lower data-rate needs of the control link.
Spectrum provision for CC is essential for the safe operation of UA and their integration in the NAS.
Appendix E discusses UAS spectrum requirements for the proposed L–DACS.
Appendix F contains the details of the L–DACS applicability to UAS applications.
"They include aerodynamic control messages, power plant control messages, and messages associated with changing the status of the avionics (e.g., frequency of the VHF ATC radio) or aircraft (e.g., raise and lower the landing gear)."
The first type of information relates to the flight characteristics of the UA.
"This data includes items such as position, flight trajectory, altimeter setting, altitude, heading, speed, route clearance, and arrival time."
The pilot uses this data to maintain full awareness of the flight of the UA and to determine the changes needed to ensure safe flight.
The second type of information relates to the health and status of UA.
"Health and status data provides critical information about the condition of the subsystems, sensors, and hardware of the UA."
The pilot at the control station uses this information to maintain full awareness of the ability of the UA to function and to diagnose problems.
The pilot can then handle potential or actual problems by taking preventive measures or corrective actions to ensure continued functioning and thus safe flight.
The third type of information relates to situation awareness data.
This type of data describes the operational environment of a UA.
Examples of this data are weather conditions and terrain information.
It seems likely that the messages associated with those services will need to be relayed to and from the pilot via the UA.
The types of messages discussed above apply to the proposed L-band system.
"As d earlier, voice communication is not currently considered for the manned aircraft applications and therefore was not the focus of prior FCSs."
The capacity of the CC links used on current UAS is proprietary to the link manufacturer.
"However, a survey of publicly available literature indicates that data rates ranging from 1200 bps to 200 kbps are successfully used today to control UA."
"Currently, UAS use in the NAS is restricted to operating under a certificate of authorization, providing it a special waiver for conducting a flight in the NAS."
ATC separation assurance—Air traffic control is responsible for safe separation of all aircraft.
"Classes A, B, and, if the UAS is operated in accordance with instrument flight rules (IFR), Class C."
Segregated—A defined volume of airspace reserved for exclusive use of a particular user.
"Need for Change and Impact on Existing Unmanned Aircract System Operations Application of UAS is anticipated to increase over the next decade and beyond, ranging from small local surveillance aircraft to large, unmanned, transoceanic freight carriers."
These systems offer low-cost alternatives to manned aircraft applications and present numerous applications opportunities.
"At the same time, the volume and variety of systems pose new challenges to the airspace management and ATC infrastructure."
Challenges associated with the addition of unmanned aircraft vary from those similar to manned aircraft to UAS specific.
"Various performance characteristics and different moving patterns—manned aircraft typically go from one location to another, UAS may stay over one location for an extensive period of time—may affect existing NAS operations."
"This, in turn, would affect departure and arrival and ATC procedures including A/G and A/A communication."
A relatively high rating was assigned to a lower part of the L-band (960 to 1024 MHz).
"Control and contingency functions cut across the boundaries of all three basic functions (aviate, navigate, and communicate)."
"The control functions involve data and information exchange between the UA and control segments of UAS, networking, data bus protocols, and related issues covering internal data and information exchange within a UAS segment."
Contingency functions involve procedures or programmed operation that provide for a predictable behavior in the event of system failure such as loss of control link.
The proposed communication system should be designed and implemented to support a seamless integration of UAS operations into current ATC procedures while maintaining the required safety-of- flight levels.
"For communicating with ATC, the UA will use the same equipment as a manned aircraft."
The link will provide a two-way communication between the CS and the UA.
The uplink will be used to send commands to the aircraft for navigation purposes.
This is the command link that would probably necessitate low data rates.
The downlink will be used to send the flight status of the UA to the remote pilot.
It is anticipated that in some flight conditions or in specific airspaces it could be necessary to downlink video streams.
Such a requirement could lead to data rates of several hundreds of kbps per UA.
Control communications will have to be compliant with ICAO standards to be further specified on this function.
The system will support a two-way communication between the remote pilot and the UA.
The downlink from the UAV to the CS or remote pilot will provide an indication that the function operates as desired.
The necessity to send video streams must be considered avoiding duplication between command and control and sense-and-avoid video downlinks.
Payload applications such as the downlinking of surveillance data for non-safety purposes were excluded from the scope and not considered in estimating nationwide CC bandwidth requirements or evaluating candidate spectral bands.
Both commercial and Government applications could be provided over the L-band system.
Example operational scenarios for each type of application are presented in Table 20.
"Earth science and geographic missions (e.g., mapping and surveying or aerial photography) and biological and environmental missions (e.g., animal monitoring, crop spraying, volcano monitoring, biomass surveys, livestock monitoring, or tree fertilization) Coastline inspection, preventive border surveillance, drug control, anti-terrorism operations, strike events, search-and-rescue of people in distress, public interest missions (e.g., remote weather monitoring, avalanche prediction and control, hurricane monitoring, forest fires prevention surveillance, insurance claims during Famine relief, medical support, aid delivery."
A follow on research is documented in the Preliminary Draft New Report ITU-R M.[UAS-BANDS- EXIST-ALLOC]: Frequency band study to support control links for unmanned aircraft systems (UAS) (Ref.
The document s the highly favorable physical properties of the L-band for UAS control links.
Negligible rain losses and low free-space losses should permit reliable long-range LOS communication between relatively low-power radios using omnidirectional and medium-gain antennas.
"In additional to propagation characteristics, smaller UA whose size, weight, and power (SWAP) budgets do not allow the use of satellite terminals would also benefit from a small size of omnidirectional antennas suitable for airborne use in this band."
It appears feasible for UAS CNPC [Control and non-payload communications] to share 12 or more megahertz of spectrum in this band without depriving existing systems of needed spectrum.
"Such an allocation would not be sufficient to meet all the spectral needs of UAS CNPC, but it would furnish small UA with badly needed access to protected spectrum and would provide UA of all types with the band diversity that is essential for reliable pilot-to-UA communications."
It is recommended that larger UAs be equipped with a terrestrial link capability wherever possible.
"Latency will be of the utmost importance when establishing a safety case for the operation of UAs, particularly in non-segregated airspace."
Current air traffic management relies heavily on voice communications although information via data links is being progressively implemented.
Hence new operational requirements for the future data link environment will also need to be developed (Ref.
"In the future, in some parts of the world, the number of these vehicles may represent a large portion of an Air Traffic Service Unit’s (ATSU’s) traffic load."
"When providing ATS to a UAS, this may involve the relay of communication and execution instructions to and from a remote pilot; however, operational performance requirements between an ATSU and an UAS remain the same as those between an ATSU and any manned aircraft."
It should also be d that UAS vary widely in their design and capabilities.
A human pilot is always in control of an UA while it is operating.
UAS complies with ATC procedures and instructions while in ATC.
Prevention procedures are in place for unauthorized assumption of control.
Security of the control and communication links between the UA and control station is provided.
UAS communication link is compatible with other communication systems.
A notional system architecture consisting of three segments and the associated internal and external interfaces are shown in Figure 30.
The detailed description as well as notional diagrams of each segment can be found in RTCA DO–304 (Ref.
L-band communications system research and development.
"Due to changes in the proposed European partners’ schedule, some of the activities planned to be completed and detailed in this document were not included in this task."
"Specifically, further interference analysis and the development of a joint interference testing program have been postponed until corresponding European L-band activities resume."
"Additionally, refinement of the upper layers of the L–DACS1 protocol stack has been postponed."
"Inputs to Design Specifications are limited to the outputs from the previous analyses presented in the ConUse, System Performance Requirements and Architecture sections of this document and the L-band System Engineering Preliminary Safety and Security Risk Assessment and Mitigation (Phase I deliverable 7–2D, Ref."
EUROCONTROL/FAA Teleconferences were held on a regular basis as part of the Task 7 scope.
"Updates to the L-band system research and development schedule, as appropriate, are included in this document."
The proposed band is to be used for an L–DACS for terrestrial en route communications as part of the FCI.
"This assignment assumes a co-allocation on a noninterfering basis with Aeronautical Radio Navigation Systems (ARNS) in the same band, primarily distance measuring equipment (DME)."
"Consequently, further interference studies and technology analysis are required to assure compliance with this requirement."
"Because of fewer VHF spectrum depletion concerns in the United States than in Europe for A/G communications, L–DACS development in the United States was determined to be a lower priority compared with the other future communications components, with L-band technology mainly considered to support far-term applications."
"Because system capacity and spectrum saturation in the VHF aeronautical communications band appears to be a more pressing issue in Europe, the need for an L-band system is more prevalent in that region."
"As such, FAA has assumed a support role to the EUROCONTROL efforts in respect to the L-band activities."
"The first FY2009 NextGen milestone activity d above will be met with the deliverables provided under Task 7, including this document, by developing L–DACS ConUse, requirements, and architecture for potential domestic en route applications in the NextGen timeframes."
This document will serve as part of the second milestone activity.
Its full execution will be postponed and will depend on the EUROCONTROL L-band system development plan and schedule.
Several L-band technologies were identified as candidates to support future en route communication due to favorable propagation characteristics and because of spectrum congestion in the VHF band.
Technology selection remains one of the primary goals in L-band system development.
None of the considered technologies were fully recommended primarily due to concerns about the operational compatibility (spectrum interference) with existing systems in the L-band and/or because of lack of sufficient technical maturity.
The assessment of the candidate technologies did lead to the identification of desirable technology features to be used as a basis for the development of a spectrally compatible L-band data link solution.
"Considering these features and the most promising candidates, two options for the L-band Digital Aeronautical Communication System (L–DACS) were identified."
These options need further consideration before final selection of a single data link technology.
"The first option for L–DACS is a frequency division duplex (FDD) configuration utilizing OFDM modulation techniques, reservation based access control and advanced network protocols."
This solution is a derivative of the B–AMC and TIA–902 (P34) technologies.
"The second L– DACS option is a time division duplex (TDD) configuration utilizing a binary modulation derivative of the implemented UAT system (CPFSK family) and of existing commercial (e.g., GSM) systems and custom protocols for lower layers providing high quality-of-service management capability."
This solution is a derivative of the LDL and AMACS technologies.
The following table depicts the key characteristics of the two options.
The L–DACS1 option represents the state of the art in the commercial developments employing modern modulation techniques and may lead to utilisation/adaptation of commercial products and standards.
"The L–DACS2 option capitalises on experience from aviation specific systems and standards such as the VDL3, VDL4 and UAT."
"In addition to the air/ground capability, some of the assessed technologies could also support additional features such as air/air (point to point and/or broadcast) communications and digital voice."
However the support of these capabilities needs further investigation.
The L band data link investigations were primarily based on simulations and analytical investigations.
Therefore there is the need to validate the theoretical findings and confirm expected performances using real equipment (Ref.
"In line with the AP–17, follow-on activities to further characterize the proposed L–DACS options, validate their performance, and lead to a single technology recommendation for the L-band (Ref."
The SESAR Definition Phase recommended expediting the development and validation of the L band selected technology by developing initial prototypes to support feasibility assessment.
"Furthermore, it recommended making final technology selection in coordination with other regions by 2010, to allow the development of the technical specifications for inclusion in ICAO SARPs and Manuals."
"To complete the selection of the L–DACS, the detailed specifications for L–DACS1 and L–DACS2 were to be developed in 2009 along with interference scenarios, compatibility criteria, and a testing plan."
"These activities were proposed to be followed by SESAR joint undertaking (JU) prototype development, testing, and evaluation in to assess the overall performance of L–DACS1 and L–DACS2 systems."
The selection of the most appropriate system could then be considered in a global framework involving ICAO.
"At this time, one or more prototypes for L–DACS systems are still being developed."
"As d above, FAA schedule and activities have been adjusted accordingly."
It is proposed to allow moving from airspace based to trajectory-based operations.
The COCR identifies two phases of implementation of operational service capabilities.
Initial steps under this phase are currently being implemented.
During the second phase data communications is to become the primary means of A/G communication supporting increased automation in the aircraft and on the ground.
The L-band system is proposed to be introduced during the second phase of FRS implementation.
It should support A/G as well as A/A communications.
A/A communications would be considered a second stage following the A/G communications implementation.
"Mobile-to-mobile communications applies to aircraft in the air (second stage, shown in green)."
No mobile-to-mobile services are currently identified involving aircraft on the ground.
An L-band communications system is proposed to support UAS.
Mobile-to-mobile UAS to be implemented at the later stage (shown in green).
Mobile-to-mobile (A/A) communications could be broadcast or addressed.
Addressed communications implementation may require further development of various network layers.
Fixed-to-fixed communication is not supported by the proposed system.
"However, transition issues need to be identified early in the system development process to assure they are properly addressed by the time of system deployment."
"Because the system will be implemented after many other NextGen components are already in place (e.g., DataComm and C-band aeronautical mobile airport communications system, or AeroMACS), it will have an advantage of benefiting from the work and lessons learned during prior transitions."
As d in the NextGen Task Force Midterm report (Ref.
The NextGen Task Force is focusing on the difficult transition issues that must be addressed to achieve the goals of improving the performance of the NAS while transitioning to NextGen.
"This will require us to address policies, procedures, operational approval processes, certification, regulatory guidance, training, criteria and standards—along with technology."
"Most importantly, we must put ourselves in a position to clearly demonstrate improvements in capacity, efficiency and access in the next 3 to 5 years so the operator community will have the confidence and the commitment to make the business case for the technology investments needed for beyond 2015."
"We have a plan; now it is time to begin the really difficult work of execution, which is much more difficult than planning because it requires commitment to action."
A final selection of services chosen as applications for the new system will greatly influence transition time and process.
"When implemented, the system will provide a long-term capacity solution and will allow the introduction of new communications services."
A gradual transition to the new band and services will lead to mixed equipage aircraft cooperating for extensive periods of time.
A special consideration is given to the transition of UAS operations.
One aspect of the way ahead is to consider that not all UAS CC links need to operate in the same frequency bands or use the same technologies.
All that is required is sufficient connectivity to allow individual UAs to operate in their desired airspace.
Thus an evolutionary process is possible without mandating migration of existing UAS operations to the new bands and transmission systems as they become available.
"If an evolutionary process is chosen, some communications technologies could be made available for UAS operations quickly while others are being developed."
"It is important to note that with an evolutionary process, the short-term solutions will possibly have limited capacity so expansion of UAS operations beyond a limited capacity will require the introduction of the next solution."
A/A communications is shown as being provided on L-band only.
UAS- related services are assumed and shown as provided on L-band.
L-band and C-band systems are “connected” through the ground network only.
L-band systems will not access C-band sensors or otherwise communicate with the C-band fixed assets directly.
Transition issues will include but not be limited to the controllers adjusting communications procedures from voice to a mixed voice/data to potentially data-only communications for some information transfers.
"With respect to voice vs. data communications, it should be d, that voice communications are likely to remain as a backup in case of data communications failures and “voice-based procedures will remain as an alternative form of communications depending on the dynamics of the situation” (Ref."
"Additionally, as d earlier, the second stage of L-band implementation may include digital voice-based services."
Key system engineering processes are completed to serve as inputs to synthesis.
"Then, synthesis products are used to drive design specifications and lead to systems that satisfy the requirements."
Each of the elements in the chart are not a one-step task but rather an iterative process undergoing multiple iterations before producing an output that could be used by a proceeding process.
"Additionally, as shown in Figure 35, processes are interrelated and loop back to verify and fine-tune the results."
Manual (SEM) requirements and architecture definition process (Ref.
The FCI aeronautical data services definition task produced a list of services identified as potential applications for an L-band system.
An L-band system can be viewed as part of the FRS providing a subset of services described in the COCR.
"As such, many of the requirements identified in the COCR would apply to the proposed L–DACS."
Preliminary safety and security risk analyses (typically performed as part of the specialty engineering process shown in the Figure 35) define system design specifications required to provide a necessary level of safety and system security.
Initial prototype design specifications for L–DACS1 and L–DACS2 were developed in Europe and are part of the iterative system development process.
Interference scenarios have been defined to support future testing.
Matching these specifications to system requirements and continuing the interference testing process will be part of requirements management and final technology selection.
The final technology selection will be based on several technology assessment studies conducted to date.
AM(R)S spectrum21 is currently at or near saturation in high-traffic areas.
As stated in the Spectrum Issues and the WRC–07 FAA Preparation presentation at the 2007 ICNS Conference (Ref.
That is the band that L–DACS is designed by EUROCONTROL in which to operate.
The attributes of L-band selected to provide en route communications include (Ref.
Allocations designated as “(route)” or “(R)” for ATC and AOC.
WRC Conference Preparatory Committee Methods (CPMs): 960- to 1024- or 960- to 1164-MHz with no change to the current allocation always being a (usually unstated) CPM.
The current U.S. WRC proposal supports 960- to 1024-MHz with regulatory protections for existing uses.
"Several civil and military systems operate, or will operate, in parts of the 960- to 1215-MHz band, as shown in Figure 36."
Detailed compatibility analyses are required between the proposed L-band system and the incumbents.
Option 1: B–AMC utilizing spectrum between successive DME channels deploying the proposed system as an inlay in the L-band (960 to 1164 MHz).
B–AMC frequency planning is required to implement the system utilizing channels between successive DME channels.
Option 2: assigning frequencies to B–AMC channels in areas where they are not used locally by DME.
"A combination of selecting B–AMC channels with a certain frequency offset from nearby DME systems, and ensuring that a minimum separation distance is maintained to allow avoiding causing interference to DME, SSR, and UAT."
The report s that insufficient information is available to determine whether it is technically feasible to implement this option.
"When selecting appropriate centre frequencies for the B–AMC system, all interferers with the power level below –100 dBm can be neglected."
"Moreover, the interference situation in each channel can be simplified to one representative interferer with representative power and duty cycle, hence facilitating the ranking of different candidate centre frequencies with respect to interference condition."
The conducted studies highlighted the need for interference testing.
"Though interference depends on many factors, the document defines general procedures that should apply to any L-band frequency range."
"The document describes creating a DME interference simulator, discusses the methodology for generating interference scenarios taking into account DME ground stations, and investigates interference originating from aircraft interrogating these stations."
Examples of interference scenarios for B–AMC reverse and/or forward links are given as appropriate.
"Interference from other L-band systems is addressed by modeling JTIDS, UAT, and SSR pulses."
DME systems and a B–AMC system providing a future A/G communication service in the L-band while assessing relevant system design issues.
The DME and B–AMC coexistence study report draws the following conclusions and makes recommendations to EUROCONTROL (Ref.
"As it is not clear whether benefits of OFDM on the reverse link overweigh the need for a highly linear airborne power amplifier, it is recommended to examine methods to reduce peak-to-mean ratio of OFDM in the reverse link (e.g., by using a single carrier FDMA or a similar technique)."
Interference link budgets indicate that coexistence of B–AMC and DME systems is possible with a guard band of one DME channel between them.
"It is recommended to investigate whether key FCS system parameters could be selected in line with a commercial OFDM standard (e.g., WiMAX) to an extent that would facilitate partial reuse of COTS solutions."
"Without a guard band, and disregarding the effects of terrain, existing DME stations in Europe could cause up to –75 dBm peak and –87 dBm mean interference into a B–AMC receiver at a 9000-m altitude, assuming optimal frequency planning."
"It is recommended to assess whether it is possible to have the required guard band between DME and B–AMC through frequency coordination, taking into account the DME deployment in Europe and the effects of terrain."
The draft B–AMC frequency plan addresses interference and compatibility issues (Ref.
The draft frequency planning approach described in this report is restricted to the scenarios involving only B–AMC and DME systems.
"As the En-Route coverage is the most demanding case with respect to the usage of spectral resources, this case has been investigated in detail—TMA and airport planning have been delegated to the future work."
The document specifies basic frequency planning rules according to B–AMC Deployment Option 2—inlay deployment with a 0.5-MHz frequency offset between B–AMC and existing DME channels and presents an initial draft frequency plan for the deployment of B–AMC within Europe (Ref.
"Within the initial planning exercise, large 120 nm En-Route B–AMC cells have been considered, with ground B–AMC TX power of +38 dBm."
"As expected, simultaneously considering the interference from the B–AMC GS [ground station] towards airborne DME receivers and the interference from DME GSs towards airborne B–AMC receivers have imposed strong restrictions upon the pool of available B–AMC frequencies."
"In the consequence, for some B–AMC cells an appropriate B–AMC inlay frequency could not be found (at least not without re-arranging DME allocations)."
The B–AMC en route system can be operated as a cellular system with different cell sizes.
"Taking into account the dense distribution of DME and TACAN stations in Europe, as an overall conclusion the obtained preliminary results are quite positive."
"However, detailed evaluation of the B–AMC interference situation is required, covering all interference scenarios mentioned in subchapter 3.1.3 [of Draft B–AMC Frequency Plan report] and considering appropriate reuse distances."
Investigating other interference cases that could not be considered in this report (A/A and A/G) and their impact upon frequency planning should be included as a topic for future work.
All the studies described in this section were conducted for B–AMC/L–DACS1 systems.
"Common assumptions, metrics, and interference criteria for both candidate technologies should be established and followed to enable an objective comparison between them."
"In June 2010, the Preliminary Report on Interference Mitigation Techniques."
"Specifically, it considers the aircraft L-band cosite interference scenario, while leaving evaluation of other interference scenarios as subject of the follow-on Task 1b activity."
"For instance, cross polarization used with signal canceller, pulse blanking, or array of dual- polarized antennas may be good choices, which have to be more thoroughly studied in T1b."
"L–DACS on the incumbent L-band systems, current European L–DACS interference mitigation are focused exclusively on the impact of the incumbent L-band system transmissions on L–DACS receiving systems."
It is recommended that further evaluation on the impact of L–DACS transmissions on the incumbent L-band system receiving systems be performed when the L–DACS design has sufficiently matured.
EUROCONTROL has funded studies to provide the specifications for the L–DACS.
"Deliverable D3 Edition 1.2, EGIS AVIA, June 18, 2009 (Ref."
System specification studies capture the parameters relevant for the prototype development.
"Both, ground and airborne, as well as cosite23 scenarios will be investigated."
"Specification, Multilink Operational Concept and L–DACS Evaluation Criteria will be provided to the S. for review and comment."
A detailed plan of the P15.2.4 is expected in February 2011 with the full project activities to follow.
"Continued research, development and testing activities closely coordinated between EUROCONTROL and FAA will allow realization of desired system capabilities while adhering to the strictest safety and security requirements."
The following list identifies acronyms and abbreviations used throughout this document.
Section 4 of Reference 1 is devoted to surface operations.
It is assumed that the L–DACS could enable transfer of data and information from ground locations to an aircraft prior to landing to facilitate movement on the surface.
Traffic information collected by surveillance systems is transmitted to properly equipped aircraft.
Thus equipped users have position information of appropriate aircraft available to support flight deck decisions.
Enhanced CNS systems and automation in aircraft complement automation aids on the ground permitting more autonomous operations.
This improved autonomy combined with greater ability to share information permits workload to be distributed between service provider and operator in a balance appropriate for the operations being conducted.
"Accurate airport environmental information, including traffic, permits appropriately equipped aircraft to navigate on the airport surface with almost no forward visibilitya."
The proliferation of CDTI avionics and supporting ground infrastructure takes place in this time frame.
The ground system that receives aircraft position reports also broadcasts traffic information and a complete set of graphical and text weather products.
Safety is enhanced by situation displays that depict airborne and surface traffic as well as aerodrome information.
"In addition, ground-based surveillance data is shared with users as a safety enhancement for preventing incursions."
"Pilot situational awareness increases through the introduction of CDTI, as well as better weather and navigation information, increases safety and efficiency of approaches and departures and leads to better runway utilization."
"Virtually all aircraft are equipped to provide position and intent information, and to receive position and intent data from other aircraft."
"En route surveillance is accomplished through a combination of primary radar, beacon interrogation, and broadcasts of aircraft position and speed."
"As more sources of position data become available, more traffic is under some form of improved surveillance."
"An increasing number of aircraft are equipped with satellite based navigation, digital communications, and the capability to automatically transmit position data."
"In addition to this pool of common information, SWIM provides context-sensitive information to NAS elements that require the information."
"The system serves as an avenue for greater exchange of electronic data and information between users and service providers including… Dynamic information including but not limited to current and forecast weather, radar summaries, hazardous condition warnings, information on updated airport and airspace capacity constraints temporary flight restrictions (TFR), and special use airspace (SUA)."
"There are continued advancements in the scope and accuracy of the weather information available to the service provider and use throughout the NAS, including automatic simultaneous broadcast of hazardous weather alerts for wind shear, turbulence, microburst, gust fronts; and areas of precipitation, lightning, icing, and low cloud ceilings and visibility."
SWIM provides access to this information to all service providers and to participating aircraft via data link.
Improved weather information integrated into DSSs and disseminated via data link reduces encounters with hazardous weather.
"TFM service providers monitor traffic, weather, and infrastructure…Improved information exchange among users and service providers enables shared insight about weather, demand, and capacity constraints which enhances the users understanding of NAS status and TFM initiatives."
The National Weather Service tracks and projects weather systems using constantly updated data.
"Using this data fused with the automatically received data from airborne platforms, flow managers have accurate information to use in developing TFM initiatives."
"Users have access to an increasing amount of NAS information including airport status and acceptance rate, composite weather information developed collaboratively by the FAA and users to assure a common projection of future weather."
"A common geographical information system (GIS) format is used to store all NAS information including terrain, obstacle, weather, and navigation, surveillance and communication coverage information."
This information is available via SWIM to all service providers and users.
Data-link-equipped users load the flight plan directly into the flight management system (FMS).
The user obtains a complete weather briefing for the proposed route via the FOC computer.
"In addition, system-wide information is obtained via the FOC SWIM interface."
"Greater use of electronic flight planning, navigation database updates and weather briefing services via SWIM results in the routine transfer of preflight planning data to the flight deck."
"Dynamic safety-critical (e.g., turbulence, icing) and other flight plan is data linked directly to aircraft for use during flight."
There is a wider use of information automatically down-linked from the flight deck.
The information (incorporated into SWIM) includes current flight conditions and aircraft performance characteristics.
"Information uses include better weather prediction, creation of normalized turbulence maps, and improved safety analysis."
The introduction of data-linked meteorological information improves overall situational awareness.
"Properly equipped aircraft receive graphical weather information via data link, including current observations, pilot reports, hazardous phenomena in both graphic and text format, and winds aloft information."
"Clearances, airport information, and weather conditions (e.g., current, forecast, hazardous) are provided over data link to more users at more airports."
"The system provides access to airport environmental information, arrival, departure, and taxi schedules, airborne and surface surveillance information, flight information, ATIS and other weather information, and TFM initiatives."
Hazardous weather alerts are automatically and simultaneously broadcast to aircraft via data link and service providers via SWIM.
Many users continue to use Aircraft Communications Addressing and Reporting System (ACARS) as a source of data linked information.
ATIS and other weather information are received via data link or by voice.
"The ground system that receives aircraft position reports also broadcasts traffic information and a complete suite of graphical and text products, including precipitation/lightning, icing, low ceiling/visibility maps, surface hazards, and wind shear and turbulence information, as well as site-specific weather reports and forecasts."
Safety is enhanced through the use of situation displays that depict airborne and surface traffic as well as aerodrome information.
SWIM and ACARS enhance the service provider’s ability to provide data products such as NOTAMs and meteorological information to the airport vicinity.
"Although weather information and advisories continue to be available via traditional means, there is increased use of automation to collect and package the information and increased use of data link to disseminate routine and hazardous weather and traffic information."
"SWIM provides access to weather and information via data link to flight crews, allowing them to develop near-real-time picture of the surrounding environment."
SWIM and data link also expedite the service provider’s task of providing data products such as NOTAMs and meteorological information for the airport vicinity when changed or needed y the user.
Automatic exchange of information between aircraft and ground-based DSSs improves the accuracy and coordination of arrival profiles.
Aircraft wind and weather information is shared with the service provider and users.
Accurate weather information is available to service providers.
"In addition, automatic broadcast of hazardous weather alerts for wind shear, microburst, gust fronts are delivered simultaneously and presented graphically to the user and service provider."
"This [increased pilot situation awareness through CDTI] coupled with better weather and navigation information, increases the safety and efficiency of approaches and departures, resulting in better runway utilization."
"Data link and flight deck displays enable pilots to monitor current meteorological data, automated hazardous weather alerts, and surrounding traffic, thus reducing the number of verbal miscommunications of this routine information."
"Improved weather data and displays, including increasingly accurate information on weather severity and location, minimize disruption in departure and arrival traffic."
Real time weather information and maps are available via SWIM on the flight deck.
"When operationally advantageous and mutually agreed upon, flight deck separation is authorized by ATC."
Most [DoD] aircraft are equipped with satellite-based navigation aids and many have data link capability and onboard collision avoidance avionics.
The service provider has improved capabilities to assist pilots in avoiding hazardous weather.
"Enhanced weather data and weather alerts are depicted on service provider displays, and are immediately available, via SWIM, to the user."
These displays improve the service provider’s ability to coordinate with pilots and with other service providers to ensure the avoidance of hazardous weather.
"These services include certain ATC clearances, current and forecast weather, NOTAMs and hazardous weather warnings, updated charts, current weather, SUA status, and other required data that are up-linked (or data-loaded) to the aircraft to facilitate better planning."
There is improved weather information available to service provider pilots.
"This information, available from common weather sources, increases the service provider’s effectiveness in controlling aircraft in airspace that contains hazardous weather and in providing weather advisories to pilots."
The high-altitude airspace permits aircraft operations along user-preferred profiles from entry through cruise to final exit.
Entry to and exit from the airspace are based on preferred profiles for climb and descent.
"Within that airspace, aircraft operate closer to their optimum altitudes by increasing the available flight levels using 1000-ft rather than 2000-ft separation."
"Terminal-area procedures are expanded to provide increased efficiency, flexibility, predictability, and airspace accessibility."
"When the projected demand for volumes of airspace is at or near capacity and after collaboration between users and TFM, there are temporary route structures with transition points for moving to and from user trajectories."
A SWIM system is developed to distribute timely and consistent information….
The flight planning system accommodates all uses of the airspace as the flight profile evolves to include real time SUA operations scheduling information.
"By integrating all airspace management systems, the NAS achieves the technical goal of providing in a timely manner the airspace necessary to execute the flight profile."
"The ATM system manages airspace based on each user's needs, including proximity to the user’s base of operations."
"As a result, more airspace, including special use, is made available to more users with increased efficiency."
Collaboration via DSSs and intelligent agents supports negotiation of revised flight trajectories in real time.
"Flow-constrained areas are managed by allocating access, collaborative rerouting, and realigning sectors and associated resources."
"Users have access to an increasing amount of NAS information, including airport status and acceptance rate and composite weather information developed collaboratively by the FAA and users to ensure a common projection of future weather."
Improved individual support capabilities use investigative operations and develop individual strategies to mitigate demand-capacity imbalances and their effect on the individual user fleets.
Sharing strategies with the ATCSCC allows service providers to evaluate conditions based on user intention rather than published schedules.
"Working with the service providers, users better manage en route congestion by collaboratively evaluating the situation, developing re-routes around the area, and providing a more refined allocation of flights to the reroutes."
"With the increasing ability to maintain common situation awareness, users plan flight profiles that consider known constraints and provide the best advantage to their operations."
These alternative profiles are tested on a continuing basis as trial plans that are selected if conditions do not develop as foreseen.
The users and service providers collaborate by modifying/exchanging these alternatives throughout the course of the flight.
The systems interactively re-plan each flight against both current constraints and any ancillary problems that arise through the execution of the initiative.
"For airborne flights, new profiles that do not require a tactical change to trajectory are provided to the flight deck for approval and execution and are included into the NAS as profile updates."
"For flights that have nearer-term tactical changes, the new profile is provided to the flight deck and service provider as trial plans and are implemented when appropriate."
"Elements of SWIM are used to obtain and distribute flight-specific data and aeronautical information, including international coordination of planned flight trajectory."
"Real-time trajectory updates reflect more realistic departure times, resulting in more accurate traffic load predictions, and increased flexibility due to the imposition of fewer restrictions."
"As the information available through SWIM increases, a more collaborative role for users evolves based on the access to accurate real-time NAS information for improved flight planning."
"Examples of this information include current and predicted SUA status, infrastructure status, traffic density, and prevailing TFM initiatives."
Decision support suites are available for both interactive preflight planning with the service provider as well as changes by the pilot and/or dispatcher during the course of the flight.
"There is real-time sharing of system demand and the virtual ATM information, enabling service providers to collaboratively interact with the user and to mutually develop solutions to problems."
Flight plan information is incorporated into the flight profile.
This profile can be as simple as the user’s preferred path or as detailed as a time-based trajectory that includes the user’s preferred path and preferred climb and descent profiles.
The climb and descent profiles may include extended periods of continuous change.
"This is similar in nature to a discretionary clearance (climb or descent) but is part of the flight planning process and, ultimately, the approved flight profile."
This negotiated profile is available both to the user and to service providers across the NAS.
"To generate the flight profile, users access current and predicted weather, traffic density, restrictions, and SUA status information."
"When the profile is filed, it is automatically checked against various conditions and constraints."
Potential problems are displayed automatically to the user for reconciliation.
"Upon filing, the flight profile created at the initiation of planning is updated, as are all affected projections of NAS demand."
"At the completion of the planning process, the user supplies the service provider with both the flight profile that best balances the NAS constraints and the user’s preferred flight profile."
"This information, including any subsequent changes, is available electronically to all service providers until the termination of the flight."
"Interactive flight planning capabilities with immediate access to real-time data are fully implemented and are available throughout the flight to the flight deck, FOC, and service provider."
User-preferred routing is available to all properly equipped aircraft for both domestic and international flights.
"Controlled times of arrival (CTA) are the primary method for regulating flows in the planning, tactical, and strategic timeframes."
"The flight profile evolves with changes to operations to allow greater flexibility in user preferences, including the planning and filing of parabolic flight profiles."
The TFM information network enables a two-way exchange of real-time information.
"Using flight plan information, flow managers determine when either airport or airspace demand is predicted to exceed capacity, thereby warranting some type of flow management initiative."
NAS users receive information about projected areas of concern and revise their plans on a real-time basis.
Data link-equipped users load the flight plan directly into the aircraft Flight Management System (FMS).
"In addition, system-wide information is obtained through the FOC SWIM interface."
"SWIM ensures a continuously updated information base of NAS items, including service constraints and infrastructure status."
The flight planner uses this data to prepare a flight profile by performing a probe for the user-preferred route against the known system constraints.
User DSSs using information available via SWIM analyze the route that most closely balances user preferences and constraints.
The use of CTAs continues to expand across NAS resources.
"As conditions change during the planning phase or during the flight, the user is notified, and he/she is able to interactively determine the impact of the changes on the flight and modify the flight profile as desired."
"The status of active and proposed flights, as well as real-time updates to reflect more realistic departure times (e.g., the latest planned departure times) are available to users."
SWIM and SYSCO facilitate more effective collaborative decision making (CDM) between the FOC and service provider.
Most aircraft are equipped with advanced navigation and some form of data link communications.
"Properly equipped aircraft can also access the NAS status information, and pilots can participate in the collaboration to develop new flight profiles while airborne."
These proposed flight profile changes are coordinated electronically with the service provider.
Users without an FOC capability access the same flight data used by all other system users and service providers via appropriate devices.
They are able to enter a command and be transferred to a service provider for clarification of the information.
"Depending on the user’s equipment, this dialog is by voice or through electronic messaging."
"For users equipped with data link, the capability exists to load a flight profile directly into the aircraft FMS."
Other users can store the flight profile information on disk and upload it into the aircraft’s avionics for use.
Shared access to all commercial space operations schedules is provided via SWIM.
SWIM enables domestic and international users and service providers to access flight profiles and associated SUA data.
SWIM and Omni-SYSCO support an interactive flight planning capability for all properly equipped users to aid in filing user-preferred departure-to-destination flight profiles.
"SWIM information improves the user’s ability to create a flight profile, which facilitates the automatic generation of a flight profile containing either the user’s preferred flight path or a more detailed time-based trajectory within the known ATM system constraints."
Potential problems are automatically displayed to the planner for reconciliation.
"Upon filing, the flight profile is updated, as necessary, along with all affected projections of NAS demand."
"As conditions change, SWIM (in concert with SYSCO) allows the planner to access information used to determine the impact of the changes on the flight."
Intelligent agents are introduced in this period to identify the best alternatives in light of ATM system changes and user preferences.
SWIM information is available to all users and service providers until the termination of the flight.
Information such as runway preferences and aircraft weight or information to support flight following can be added during the planning phase or during flight.
Taxi routes and positions of other aircraft are data linked and displayed in appropriately equipped aircraft.
The receipt of taxi routes over data link relieves communication frequency congestion.
"Pilot situational awareness and safety are enhanced with an integrated display of the aircraft’s position, taxi route, and hazards."
Access to real-time data for surface movement DSSs makes for an increasingly integrated NAS.
"The system provides access to airport environmental information; arrival, departure, and taxi schedules; airborne and surface surveillance information; flight information; ATIS and other weather information; and TFM initiatives."
"On taxi out, the flight’s time-based trajectory is updated in SWIM, and projections are made based on prevailing traffic conditions."
This continuous updating of the flight profile improves real-time planning for both the user and the service provider.
The service provider’s ability to plan surface movement improves as timely traffic information becomes available.
Both the initial values and subsequent adjustments are incorporated into the surface management information system to ensure consistency and an integrated approach across systems.
Shared access to SWIM supports an automated exchange of gate and runway preference data to stakeholders.
"The user’s runway assignment preference is available within SWIM, and is used in conjunction with departure and arrival DSSs and integrated surface management capabilities to coordinate an optimal assignment and sequence."
Service providers also update the NAS about the available capacity of airport and surrounding airspace resources and the current status of SUA.
This facilitates more effective collaboration with FOCs and improved formulation of TFM agreements.
Flights routinely operate on user-preferred trajectories with fewer aircraft constrained to a fixed route structure.
The requirement to operate on structured routes only exists in high density areas to avoid terrain and active SUA and to facilitate the transition between areas with differing separation standards.
"Demand and capacity imbalances are resolved, in collaboration with the users, via voluntary changes in trajectories or through the establishment of temporary routes and transition points."
User-preferred trajectories are accommodated earlier in the flight and continue closer to the destination.
The status of active and proposed flights and NAS infrastructure is available to NAS users and service providers.
This allows users to collaborate with ATM in deciding TFM initiatives.
The FOC monitors the status of the NAS and relays status information to pilots.
"FOC and aircraft provide preference information, which the service provider considers when making in-flight route changes."
There is increased collaboration between the FOC and ATM as the FOC interactively probes proposed route changes.
Modified routes are developed collaboratively between the FOC and the service provider and then data linked to the aircraft and downstream ATC facilities.
"In addition, working with TFM specialists, the FOC helps to define and implement TFM initiatives to relieve airspace congestion."
"Collaboration supports determining when, where, and how transitional route structures are established in the airspace to meet a short-term problem."
"As required navigation performance (RNP)/RNAV capabilities increase, the low-altitude airspace structure remains largely unchanged."
Widespread area navigation equipage and expanded surveillance coverage with new technology provide increased access to airports and airspace in all weather conditions.
There are temporary route structures with transition points for moving to and from user trajectories.
Traffic information collected by surveillance systems is transmitted to properly equipped aircraft to support flight deck decisions.
"Tools and procedures are in place for frequent evaluation (up to several times a day) of the airspace structure and anticipated traffic flows, with adjustments made accordingly."
"Enhanced CNS systems and automation in aircraft complement automation aids on the ground, permitting more autonomous operations."
"This improved autonomy, combined with greater ability to share information, permits the workload to be distributed between the service provider and user in a balance appropriate for the operations being conducted."
"Seamless communications and coordination, coupled with information accessible through SWIM, allow real-time reassignment of airspace between facilities to meet contingencies such as equipment outages."
"Users have access to an increasing amount of NAS information including airport status and Working with the service providers, users better manage en route congestion by collaboratively evaluating the situations, developing reroutes around the flow constrained areas, and providing a more refined allocation of flights to the reroutes."
"Information about arrival capacity allocations, reroute programs and other restrictions is automatically recorded, as is information from local facilities…."
"Elements of SWM are used to obtain and distribute flight-specific data and aeronautical information, including international coordination of flight trajectory."
"There is real time sharing of system demand and the virtual ATM information… User flight planning systems account for system constraints such as flow restrictions, hazardous weather, SUA and infrastructure outages."
"A National Airspace System common reference (NASCR) and index that incorporates a common Geographical Information System (GIS) format is used to store all NAS information including terrain, obstacle, weather, and navigation, surveillance and communication coverage information."
DoD and FAA service providers maintain and have access to a continuously updated database of airspace and flow restrictions.
"Using this data, the DoD flight planner prepares a proposed flight profile, performing a probe for active or scheduled SUAs, weather, and airspace and flow restrictions."
Space vehicle flight profiles describe user needs and take into account flow conditions and constraints.
Airport layouts on moving maps and corresponding standardized airport signage provide flight crews with increased situation awareness and reduce runway incursions.
"Moving map displays enhance pilot familiarity with the airport, leading to better planning and increased safety."
"The surface management information system facilitates coordination between decision makers at all levels of the airport operation—service provider, flight crews, FOC, ramp, airport operator, and airport emergency centers."
"This data sharing allows service providers to coordinate local operations with airline ramp and airport operators, thus improving overall airport operations."
"Using data link, pilots receive ATIS-type messages with Runway Visual Range (RVR), braking action and surface condition reports, current precipitation, runway availability, and wake turbulence and wind shear advisories."
Airport maps are electronically available to properly equipped users.
The ground system that receives aircraft position reports also broadcasts radar-derived traffic information and a complete set of graphical and text products…Safety is enhanced by situation displays that depict airborne and surface traffic as well aerodrome information.
SWIM and ACARS enhance the service provider’s ability to provide data products such as NOTAMs and meteorological information for the airport vicinity.
Status information concerning the NAS infrastructure components that support arrival/departure operations is shared with all stakeholders.
Arriving aircraft receive expanded airport information through data link for display on the flight deck.
"The information includes RVR, braking action and surface condition reports, and runway availability as well as wake turbulence and wind shear advisories."
"All communication frequencies needed for operation in the airport vicinity are available for display to the flight deck, with any changes from the published list uplinked over data link."
Pilots conduct approaches using independent navigation systems and begin monitoring the approach path on a moving map display.
Seamless data link is available for most pilot and service provider communications.
Some emergency communications are automatically sent to both pilot and the service provider to further increase safety by eliminating the time necessary for a human to relay the message.
Examples of such messages are wind shear alerts (generated either by airborne or ground equipment) and airborne and surface collision resolution advisories.
Changes in airspace structures and route definitions in addition to the positions and predicted time- based trajectories are updated and registered within the NASCR for easy access via SWIM.
Properly equipped aircraft receive an increased number of services via data link.
"These services includes certain ATC clearances, current and forecast weather, NOTAMs and hazardous weather warnings, updated charts, SUA status, and other required data that are up-linked (or data-loaded) to the aircraft to facilitate better planning."
"For properly equipped aircraft, updates to navigation terrain and obstacle databases are provided over data link."
"Airspace sectorization changes dynamically based on weather, demand, and user preferences."
These changes are accomplished through automated coordination (SYSCO) with all affected domestic and international service providers.
"By taking advantage of advanced information and communications capabilities, airspace design and underlying sector configurations are no longer constrained by the current geographic boundaries, particularly in high altitude."
This increased flexibility permits changes to the configuration of air traffic facilities.
This improved autonomy combined with greater ability to share information permits the workload to be distributed between service provider and user in a balance appropriate for the operations being conducted.
There are continued improvements in the collection and processing of NAS infrastructure data.
These data are used to prioritize and schedule NAS infrastructure activities.
"All NAS resources are registered in the NAS Common Reference System (NASCR), and monitored and managed through SWIM."
Infrastructure operations are performed from a national perspective.
Infrastructure maintenance is performed from the viewpoint of customer requirements for the services with an understanding of the effects of the activities on service delivery to NAS infrastructure users.
"TFM service providers monitor traffic, weather, and infrastructure."
"Because NAS users have increased flexibility in planning routes and schedules, and because the NAS relies less on routine restrictions and fixed routes, managing NAS resources becomes more dynamic and adaptive."
"NAS infrastructure assets are assigned and reassigned dynamically to mitigate infrastructure problems as well as in response to changes to in sectorization, traffic demand, and airspace assignment."
SWIM provides access to all NAS management and resource information.
"Working with service providers, users better manage flight operations by collaboratively evaluating the situation, developing reroutes around the flow constrained areas, and providing a more refined allocation of flights to the reroutes."
"In coordination with the National Operations Control Center (NOCC), infrastructure management (IM) service providers monitor NAS infrastructure performance and determine needed actions."
"Service providers perform remote management and monitoring of systems, while others perform onsite maintenance for fault correction, preventive maintenance, and equipment installation and removal."
NAS infrastructure assets are assigned and reassigned dynamically to mitigate infrastructure problems as well as to respond to changes to in sectorization and airspace assignment.
The redundancy in the NAS is applied expeditiously to maintain flow and reduce operational impact.
"User flight planning systems account for system constraints such as flow restrictions, hazardous weather, SUA, and infrastructure outages."
"Data from SWIM allows service providers to monitor traffic demand, NAS infrastructure status, and other conditions in order to allocate resources, including changes in staffing."
"With the completion of the National Airspace Redesign, airspace is restructured to meet future traffic requirements."
Static restrictions due to fixed sector boundaries are reduced or eliminated.
"The airspace structure is frequently evaluated and adjusted in anticipation of expected traffic flows, or in response to weather and NAS infrastructure changes."
"Additionally, airspace boundaries are adjusted dynamically without respect to facilities, for transient events or circumstances for limited periods of time."
System Safety Hazard Analysis and Security Threat Analysis document (Ref.
Following is the same hierarchical decomposition presented in the outline style.
Section 6 (Conclusions) of the proposed changes to Annex 16 of 5B/296-E in Reference 44.
It has to be d that the video requirements is not yet decided as mandatory by the civil aviation authorities.
"The assessment of these spectrum requirements have been based on assumptions described in the PDN report ITU-R M [UAS-SPEC] (cells/spots radius, frequency reuse factor, etc.)."
"Regarding sharing studies on WRC–11 Agenda item 1.3 in specific bands, these assumptions, and therefore the spectrum requirements, could be refined."
"The detail of those requirements is shown in Figure 72, Figure 73, and Figure 74."
"Both satellite systems, particularly the regional-beam one, are clearly much more bandwidth-intensive than the terrestrial system."
A hybrid system consisting of terrestrial and satellite components would have an aggregate bandwidth requirement somewhere between the “pure terrestrial” and “pure satellite” extremes.
"That hybrid bandwidth requirement would depend on the allocation of functions between the terrestrial and satellite components of the system, and on whether the satellite component has a spot-beam or regional-beam architecture."
The assumed spot-beam system has a beam footprint of 391 km (243 m) in radius.
The rationale for this relatively high rating is as follows.
The band is highly attractive for future UAS control use from a regulatory standpoint.
Its current worldwide spectrum allocation is internationally standardized and consistent from region to region.
Opportunities for finding bandwidth for AM(R)S in the 960- to 1024-MHz band depend primarily on exploiting certain characteristics of the distance measuring equipment (DME) and tactical air navigation (TACAN) transmitters that are its principal current users.
"First, in the 979- to 1024-MHz part of the band, all of those transmitters are at fixed ground locations."
This would facilitate geographical frequency coordination between those DME/TACAN assignments and a future AM(R)S communications system.
"Second, a transmitted DME signal occupies a bandwidth narrower than its nominal 1-MHz channel width."
"If DME receivers are sufficiently selective, there may exist between adjacent DME channels a gap that could be utilized for AM(R)S (or UAS control and communications (CC))."
"Even if that is not the case for all DME receivers, many geographical areas have numerous unused DME channels that might be usable in their entirety by AM(R)S or UAS CC without radiofrequency interference to or from DME."
Consequently the band has been awarded a neutral rating in the “Potentially Available Bandwidth” category.
"The band scores relatively well for link range, capacity, latency, and availability."
Cosite compatibility on aircraft is a major concern in this band.
"A 960- to 1024-MHz UA-borne communications transmitter would pose an interference risk to a collocated DME or universal access transceiver (UAT) receiver and, most notably, to any collocated air traffic control radar beacon system (ATCRBS) or Mode S receiver operating at 1030 MHz."
Present-day manned aircraft typically protect their onboard L-band (960 to 1215 MHz) devices from mutual cosite interference by means of a suppression bus that blanks the receivers each time a collocated in-band transmitter emits a pulse.
"If the transmitter has too high a duty cycle, this pulse-blanking method could unacceptably degrade receiver performance."
"If future airborne UA control transmitters operate in the 960- to 1024-MHz band, they may have to employ some combination of power control, radiofrequency filtering, and/or low-duty-cycle operation to avoid interfering with collocated DME, UAT, and 1030-MHz receivers."
"The problem is likely to be more severe when the UA control transmitter operates near the upper end of the 960- to 1024- MHz band, where radiofrequency filtering would afford the least protection to the 1030-MHz receivers."
This cosite criterion is the only one for which the 960- to 1024-MHz band has received an unfavorable rating during the evaluation.
"However, it should be d that the need for airborne transmissions in this band could be “finessed,” possibly at the cost of an additional airborne antenna, if a split-band UAS CC system is developed."
"C-band, for example, might offer the opportunity for greater downlink bandwidth (thereby matching the projected asymmetry in uplink and downlink data rates), and the UAS community might willingly forgo microwave landing system (MLS)."
"Furthermore, a C-band downlink could more easily support ground-based sectorized, multi-beam, or “smart” antennas designed to achieve high gain on the downlink, thereby allowing lower airborne transmit power and an overall reduction in background noise level for other users of the spectrum."
"New 960- to 1024-MHz ground radios would have to be installed, but they could cover most of the National Airspace System from the existing ground sites used by very high frequency (VHF)/ultrahigh frequency (UHF) air traffic control air-to-ground radios, so the band has been given a neutral rating under both of the “cost” criteria in the matrix."
"The band’s inherent security is deemed to be no worse than average for terrestrial air-to-ground radio links, so a neutral rating has been given for that criterion as well."
National Airspace System: Concept of Operations and Vision for the Future of Aviation.
Concept of Operations for the Next Generation Air Transportation System.
"EUROCONTROL/FAA Future Communications Study Operational Concepts and Requirements Team, ACP/1–IP/5, May 2007."
Data Communications Safety and Performance Requirements (SPR).
Final Program Requirements for Data Communications.
National Airspace System: System Engineering Manual.
"Administration ATO Operations Planning, June 6, 2006."
"Activities, Eurocontrol/CND/CoE/CN/CO, DLK Users Forum, Attachment 4, July 20, 2010."
"Integrated Work Plan (IWP).Version 1.0, 2009. http://www.jpdo.gov/iwp/IWP_V1.0_No_Appendices.pdf Accessed March 21, 2011."
"B (Functional View), NAS Architecture 6, June 2008."
"Presented by ATO–W, Telecommunications Services Group (TSG), NAS Enterprise Architecture Conference, June 24, 2009."
"Final Conclusions and Recommendations Report, DASC2007–4B6, 2007."
"Flexibility in the Terminal Environment, 2010. https://nasea.faa.gov/products/roadmap/main/display/16/tab/solutionSet/ Accessed March 21, 2011."
"Trajectory Based Operations, 2010. https://nasea.faa.gov/products/roadmap/main/display/14/tab/solutionSet/ Accessed March 21, 2011."
"Thales Air Systems, ICNS 2007 Conference, Herndon, May 2007."
"Digital Data Communications Including Compatibility With Digital Voice Techniques, RTCA DO–224B, 2005."
"SC203-CC011_UAS Spectrum_vO_15May09, UAS Spectrum, RTCA, 2009."
"Preliminary Draft New Report ITU–R M [UAS–SPEC], Document No."
To Support Control Links for Unmanned Aircraft Systems (UAS).
"CoE/CN/COM Unit, DLK Users Forum, Brussels, Belgium, Sept. 2009."
"The public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information."
"This document is being provided as part of ITT’s NASA Glenn Research Center Aerospace Communication Systems Technical Support (ACSTS) contract NNC05CA85C, Task 7: “New ATM Requirements--Future Communications, C-band and L-band Communications Standard Development.” Task 7 was motivated by the five year technology assessment performed for the Federal Aviation Administration (FAA) under the joint FAA-EUROCONTROL cooperative research Action Plan (AP-17), also known as the Future Communications Study (FCS)."
"It was based on direction provided by the FAA project-level agreement (PLA FY09_G1M.02-02v1) for “New ATM Requirements-- Future Communications.” Task 7 was separated into two distinct subtasks, each aligned with specific work elements and deliverable items."
"Subtask 7-1 addressed C-band airport surface data communications standards development, systems engineering, test bed development, and tests/demonstrations to establish operational capability for what is now referred to as the Aeronautical Mobile Airport Communications System (AeroMACS)."
"Subtask 7-2, which is the subject of this report, focused on preliminary systems engineering and support of joint FAA/EUROCONTROL development and evaluation of a future L-band (960 to 1164 MHz) air/ground (A/G) communication system known as the L-band digital aeronautical communications system (L-DACS), which was defined during the FCS."
The proposed L-DACS will be capable of providing ATM services in continental airspace in the 2020+ timeframe.
"Phase I featured development of Concepts of Use, high level functional analyses, performance of initial L-band system safety and security risk assessments, and development of high level requirements and architectures."
"It also included the aforementioned support of joint L-DACS development and evaluation, including inputs to L-DACS design specifications."
"Phase II provided a refinement of the systems engineering activities performed during Phase I, along with continued joint FAA/EUROCONTROL L-DACS development and evaluation support."
Level of Review: This material has been technically reviewed by technical management.
The Space Telecommunications Radio System (STRS) Architecture Requirements Document provides the basis for the development of an open architecture for NASA Software Defined Radios (SDRs) for space use.
The STRS project is currently under the direction of the Space Communication and Navigation (SCaN) Program.
The Top-Level Customer Guidelines are provided by NASA Headquarters.
The goals and objectives are derived from the Top-Level Customer Guidelines.
"They provide broad, fundamental direction and purpose."
Level 1 requirements are derived from the goals and objectives and are verifiable but are not intended to be verified directly.
They will be decomposed into further requirements (Level 2 requirements) which will be verified.
The Level 1 requirements are considered verified after all of the decomposed (Level 2) requirements are verified.
Section 3 describes the Top-Level Customer guidelines.
Section 5 describes the derived system requirements that identify the architecture consideration for this study.
Section 6 provides the list abbreviations and acronyms related to the document.
Guidelines were provided by NASA Headquarters and are stated below without modification.
The goals and objectives clarify and expand on the Top-Level Customer Guidelines.
"The architecture will not be usable if excessive burden (such as Size, Weight, and Power (SWaP) and complexity) is needed for a single mission to realize the multi-mission benefits."
It also should be usable with the computing elements capable of operating in the space environment.
"This includes the capability to eliminate or mitigate long and short term radiation effects, perform in a vacuum, and operate in extreme temperatures."
The radio should also survive the effects of launch including Near Strike Lightning (NSL) to the extent that full performance can be restored.
The capabilities of elements that can operate in this environment lag behind the capabilities of ground environment elements.
The architecture is expected to apply to the majority of missions with the realization that a few missions should be allowed waivers to develop a non-fully STRS conformant radio.
Rationale: NASA HQ has given us the challenge to lower cost and risk and decrease the development time of software defined radios.
Complex reliable software can become very costly in terms of dollars and development time.
"With standard functions and interfaces defined by the architecture, code is more easily reused."
Rationale: Managing the complexity of the design through a common architecture and reducing the amount of interdependence on other systems will enhance reliability.
Common qualification processes and procedures will allow for improved testing methods as flaws in previous procedures are discovered and new methods are developed.
"Rationale: Technology advances will continue to provide greater processing power and memory and require less size, weight, and power."
"The architecture should also be able to accommodate the current and future evolution to advanced SDR concepts such as Ideal Software Radios (direct digital sampling at the antenna port) and Cognitive Radios, and should be extendable to interface with optical communication systems."
Rationale: Future missions may have requirements for operations or capabilities that have not currently been considered.
"For example, a higher level of security support may be required and the architecture should adapt to accommodate this new need."
The existing communication infrastructure typically needs to be operational for many years.
"As radio technology evolves, it is usually not feasible to upgrade all existing assets in order to operate over the air with new systems."
Rationale: Space radio vendors are building and deploying software defined radios.
"Given the limited number of radios that will be procured by NASA, aligning with current approaches to the extent possible is necessary."
Leveraging their software and hardware development and products to the extent reasonable may reduce NASA’s costs and risks.
Deviating from current practices would increase design cost and schedule and decrease reliability.
Reusing all or part of the code for this limited number of waveforms will decrease development time and cost and increase reliability.
STRS Architecture Requirements support a NASA perspective that often spans multiple missions.
These requirements address how the various mission classes are expected to use the architecture.
"The following sections list the Level 1 requirements, which were derived from the Goals/Objectives."
"These requirements are intended to address the STRS Architecture, not a specific implementation."
"An implementation may not require all aspects of the architecture; therefore, all requirements may not apply to each STRS-compliant software defined radio."
The architecture specification will evolve depending on available technology and capabilities.
Some requirements may not apply to near term applications.
Layering promotes waveform application portability to alternate platforms that conform to the architecture.
The STRS Architecture shall utilize an Open System Architecture approach.
A useful architecture partitions functions and components such that a) functions are assigned to components clearly and b) physical interfaces among components correspond to logical interfaces among functions.
"When functions, interfaces, components, and/or design rules are defined and published, the architecture is open."
Open architectures facilitates interoperability among commercial and Government developers and minimizes the operational impact of upgrading hardware and software components.
The STRS Architecture shall allow the radio to be flexible in physical form factor.
"The radio will need to be configured into different physical form factors to meet mission size, weight, and power requirements."
These form factors will require the ability to be sized based on the hardware required to implement the waveform functions.
The architecture is specified as platform independent and scalable to address mission requirements.
Rationale: This capability will allow the radio units to maintain communication and operational status during the reload process.
The upgrade can then be implemented upon the next boot or startup.
Reprogrammability provides the ability to correct latent software defects or implement new capabilities.
The STRS Architecture shall allow the radio to control external hardware in real-time.
Rationale: This capability will allow the radio to set and modify parameters to external hardware.
"For instance, tuning external RF hardware within specified frequency bands to avoid external interference sources and changing the output level of the power amplifier."
This potentially eliminates additional front- end hardware sets.
The STRS Architecture shall allow the radio to use standard spacecraft interfaces.
The radio will be employed on platforms using standard spacecraft interfaces for power.
"The radio will need to exchange voice, video, and data with spacecraft systems using the common spacecraft software and hardware interfaces."
Utilization of common spacecraft busses also enables the radio and other devices on the spacecraft bus to share excess resources such as processing power.
The STRS Architecture shall allow the radio to operate more than one waveform.
"Rationale: Missions typically require communications using more than one waveform, such as a mission that requires different waveforms during different phases or a mission that must use both GPS and TDRS."
"By having a single radio be capable of running more than one waveform, this can reduce the number of radios for a mission."
The STRS Architecture shall allow the radio to operate multiple waveforms simultaneously.
"The radio could also be used for simultaneous GPS reception, thus eliminating the need for a separate receiver."
"NASA missions typically need to use low frequency bands for telemetry, and high frequency bands for science data."
"Future NASA missions will probably need significantly larger science data transfers from space, requiring even higher frequency bands to be implemented."
"It is envisioned that future NASA missions will utilize optical communications, for direct to Earth and for inter-satellite links."
"As a result, the STRS baseband unit should be capable of interfacing to optical communications hardware."
Longer duration missions especially may need to adapt to using different frequency bands.
"For the foreseeable future, the frequency band will probably be determined by the pre-launch installed RF components in order to reduce weight, power, and complexity."
"Rationale: For example, this allows for the case where a mission requires that high criticality data be sent using a different channel than lower criticality data."
Multiple simultaneous channels can also allow for increased throughput or redundancy.
"This will increase reliability and availability by increasing understanding of the nature of a problem leading to a faster recovery, as well as supplying additional information to assist in improving future designs and procedures."
This is not a BIT but a behavior based on operational activity.
The radio detects a problem and then may issue BITs to attempt to determine if the signal loss is due to hardware or external factors.
The radio must be able to return to full operation (restores back to last radio configuration/parameters/operational settings prior to fault condition) without need for external equipment or procedures.
"A radio may recover from an internal error without the need to reboot or power cycle, however that is not a requirement of the architecture."
"Integrating the communication and tracking system into a single radio reduces the overall required RF spectrum, mass, power, and volume allocations."
Special considerations will be required in the design and implementation of the radio to implement the integrated system.
Protocol (IP) including a network infrastructure comprised of dispersed network elements using various communications transport capabilities.
CCSDS and IP are in common use in many existing systems and have been used in several NASA missions.
New delay tolerant protocols are being considered and the architecture must adapt to support these and other future protocols.
The STRS Architecture shall allow the radio to use secure transmission.
The radio may not need to perform its communications functions at all times.
"This optimization can include changes to the modulation and coding schemes (e.g., use a lower coding rate in favorable link conditions)."
This capability makes it possible to “fine-tune” the communication link much more accurately than an operator could perform a similar function.
"Briones, Janette, C.; Johnson, Sandra, K.; VanDerAar, Lisa, B."
The main objective of this document is to evaluate the goals and objectives and high level (Level 1) requirements that have bearing on the design of the architecture.
"The goals and objectives will provide broad, fundamental direction and purpose."
The high level requirements (Level 1) intend to guide the broader and longer term aspects aspects of the SDR Architecture and provide guidance for the development of level 2 requirements.
This document provides definition of technology human interface requirements for Collision Avoidance (CA).
"This was performed through a review of CA-related, HSI requirements documents, standards, and recommended practices."
"Technology concepts in use by the Access 5 CA work package were considered... Beginning with the HSI high-level functional requirement for CA, and CA technology elements, HSI requirements for the interface to the pilot were identified."
"Results of the analysis describe (1) the information required by the pilot to have knowledge CA system status, and (2) the control capability needed by the pilot to obtain CA information and affect an avoidance maneuver."
"Fundamentally, these requirements provide the candidate CA technology concepts with the necessary human-related elements to make them compatible with human capabilities and limitations."
"The results of the analysis describe how CA operations and functions should interface with the pilot to provide the necessary CA functionality to the UA-pilot system .Requirements and guidelines for CA are partitioned into four categories: General, (2) Alerting, (3) Guidance, and (4) Cockpit Display of Traffic Information."
Each requirement is stated and is supported with a rationale and associated reference(s).
It represents the Human Systems Integration functions and performance requirements limited to enroute operations above FL430.
Operations below FL430 and terminal operations have not been addressed in this document.
The following document was prepared by a collaborative team through the d work package.
"Access 5 is a NASA-led project tasked to recommend the policies, procedures, and functional requirements that will ensure High Altitude Long-Endurance (HALE) Unmanned Aircraft Systems (UAS) operate as safely as other routine users of the National Airspace System (NAS)."
"Four phases or “STEPS” are planned to systematically develop the necessary technology, policies and regulations to enable manufacturers to apply for Federal Aviation Administration (FAA) certification and approval needed to operate their civil UAS in the NAS."
"Current (FY05) effort limits focus to UASs that operate above 43,000 feet (STEP ."
"In order for UAS to be integrated into the NAS, it is necessary to identify the human systems integration requirements that ensure safe operations in the NAS."
"As a result, the Human System Integration (HSI) Work Package was established within the overall Access 5 program to address this objective."
"In FY05, several HSI products were developed to contribute to overall program objectives."
This product involves definition of technology interface requirements for Collision Avoidance (CA).
Technology concepts in use by the CA WP were assessed also.
Technology concepts in use by the CA WP were assessed.
"Beginning with the HSI high-level functional requirement for CA, and CA technology elements, HSI requirements for the interface to the pilot were identified."
The results of the analysis describe how CA operations and functions should interface with the pilot to provide the necessary CA functionality to the UA-pilot system.
"Requirements and guidelines for CA are partitioned into four categories: (1) General, (2) Alerting, (3) Guidance, and (4) Cockpit Display of Traffic Information."
The purpose of this document is to define HSI technology interface requirements for Collision Avoidance (CA).
"Research of human capabilities and limitations known for CA was performed through a review of HSI requirements documents, standards, and recommended practices."
"Step 1, which limits scope to CA only for flight above FL430 and excludes requirements for coordinated maneuvers."
The pilot may deviate only in response required for collision avoidance.
"Research and documentation of human capabilities and limitations requirements documents, standards, and recommended practices."
The technology concepts in use by the CA WP were assessed.
These include a plan view map display that depicts the ownship and proximate traffic icons; a vertical speed indicator that provides aural alerting system.
"Fundamentally, these requirements provide the candidate technology concepts with the necessary capabilities and limitations."
The HSI FRD describes the highest level functional requirement for convey information to the pilot to avoid cooperative aircraft.”2 Technology interface requirements in this document fall under this requirement.
Technology interface requirements are a necessary element of the Performance requirements.
"They represent high-level, requirements for (1) pilot control of a CA system and (2) information required by the pilot to understand vehicle operation."
"Step 1: Functional Requirements Document, Preliminary Draft."
"Human Factors Design Guide Update, Report Number DOT/FAA/CT-96/01."
"Human Interface Criteria for Collision Avoidance Systems in Transport Aircraft, Aerospace Recommended Practice (ARP) 4153."
"CA system, its modes shall be displayed to the pilot15."
"Johnson, W., Bilimoria, K.., Thomas, L., Lee, H., and Battiste, V. Comparison of Pilot and Automation Generated Conflict Resolutions."
"AIAA Guidance, Navigation, and Control Conference and Exhibit."
"In order to accomplish this, the aircraft’s location (in all information to accurately anticipate conflict situations."
The requirements described in this document represent a high level definition for pilot information and control capability.
The FL430 will require only minor additions to Step 1 results.
"Cooperative Collision Avoidance Functional Requirements for Step 1 – HALE UAS Flight Above FL430, Revision 3."
"Step 1: Human System Integration (HSI) Functional Requirements Document Step 1: Functional Requirements Document, Preliminary Draft."
"Society of Automotive Engineers, Warrendale, PA. November, 1988."
"Human Interface Criteria for Cockpit Display of Traffic Information, Aerospace Recommended Practice (ARP) 5365."
"Society of Automotive Engineers, Warrendale, PA. January, 1999."
"Federal Aviation Administration, Washington, D.C. February, 2002."
"Human Factors Issues Associated With Cockpit Display of Traffic Information (CDTI), Aerospace Resource Document (ARD) 50083."
"Society of Automotive Engineers, Warrendale, PA. December 1999."
"Johnson, W., Bilimoria, K., Thomas, L., Lee, H., and Battiste, V. Comparison of Pilot and Automation Generated Conflict Resolutions."
"Aircraft Flight Manual Supplemental Signature Approvals of TCAS II Aircraft Flight Manual Supplements Previously Approved under Type Certification (TC) or Supplemental Type Certification (STC), Order 8300.1, FSAW 01-02A."
"Federal Aviation Administration, Washington, D.C. May, 2001."
Airworthiness Approval of Traffic Alert and Collision Avoidance Systems (TCAS II)’ AND MODE S TRANSPONDERS.
"Federal Aviation Administration, Washington, D.C. March, 1993."
"The Effects of Traffic Load, Dimensionality, and Vertical Profile Orientation."
"Prepared for NASA Ames Research Center, Moffett Field, CA."
"Initial Evaluation of CDTI/ADS-B for Commercial Carriers: CAA’s Ohio Valley Operational Evaluation, Paper No."
"Gempler, K. and Wickens, C. Display of Predictor Reliability on a Cockpit Display of Traffic Information."
"Prepared for Rockwell International, Cedar Rapids, IA."
"Pilot Maneuver Choice and Safety in a Simulated Free Flight Scenario, Technical Report ARL-00-1/FAA-00-1."
"Human Factor Considerations in the Design of Multifunction Display Systems for Civil Aircraft, Aerospace Recommended Practice (ARP) 4153."
"Society of Automotive Engineers, Warrendale, PA. March, 2003."
"Federal Aviation Administration, Washington, C. November, 2000."
The Effect of Symbology Location and Format on Attentional Deployment within a Cockpit Display of Traffic Information.
"Proceedings of the Human Factors and Ergonomics Society 43rd Annual Meeting, Houston, Texas."
Minimum Aviation System Performance Standards for Aircraft Surveillance Applications.
"Minimum Operational Performance Standards for Universal Access Transceiver (UAT) Automatic Dependent Surveillance – Broadcast (ADS-B), DO-282A."
"TCAS I Training and Operational Procedures, Order 8400.1, HBAT 95-17."
"Federal Aviation Administration, Washington, D.C. December, 1995."
TCAS Transition Program (TTP) Industry Alert Bulletin.
"TCAS Transition Program (TTP) Newsletter, Issue #V7-3."
"TCAS Transition Program (TTP) Newsletter, Issue #V7-1."
"Federal Aviation Administration, Washington, D.C. February, 2000."
The document provides the Human System Integration(HSI) high-level functional C3 HSI requirements for the interface to the pilot.
"Description includes (1) the information required by the pilot to have knowledge C3 system status, and (2) the control capability needed by the pilot to obtain C3 information."
"Fundamentally, these requirements provide the candidate C3 technology concepts with the necessary human-related elements to make them compatible with human capabilities and limitations."
The results of the analysis describe how C3 operations and functions should interface with the pilot to provide the necessary C3 functionality to the UA-pilot system.
"Requirements and guidelines for C3 are partitioned into three categories: (1) Pilot-Air Traffic Control (ATC) Voice Communications (2) Pilot-ATC Data Communications, and (3) command and control of the unmanned aircraft (UA)."
This was performed through a recommended practices.
Technology concepts in use by the C3 WP were assessed also.
"Research of human capabilities and limitations known for C3 was performed through a review of Human-System Integration (HSI) requirements documents, standards, and recommended practices."
Technology concepts in use by the C3 WP were assessed.
"Beginning with the HSI high-level functional requirement for C3, and C3 technology elements, HSI requirements for the interface to the pilot were identified."
"Results of the analysis describe (1) the information required by the pilot to have knowledge C3 system status, and (2) the control capability needed by the pilot to obtain C3 information."
The purpose of this document is to define HSI technology interface requirements for C3.
FAA Human Factors Design Guide; other key research papers.
The technology concepts in use by the C3 WP were assessed.
"These include voice communication between the UA pilot at the ACS and the air traffic controller for line of sight (LOS) and beyond line of sight (BLOS) (using communications satellite(s) and UA as a relay node), and data transmission using digital uplink and downlink for communication between the pilot at the ACS and the UA."
Technology interface requirements in this document fall under this requirement.
Technology interface requirements are a necessary element of the HSI functional decomposition analysis of C3 Functional and Performance requirements.
The results of the analysis describe how C3 operations and functions should interface with the pilot system.
"They represent high-level, requirements for (1) pilot control of a understand vehicle operation."
"Neither shall it adversely affect pilot functions, the pilot or controller begins to speak until the audio signal is received by the listener."
The pilot shall have capability to operate the radio at the ACS.
This includes capability to turn the radio select radio modes.
"Federal Aviation Administration, Atlantic City, NJ."
The pilot shall have capability to control the aircraft transponder at the ACS.
"This includes capability to function, and select transponder modes."
The pilot shall have control capability at the of the vehicle flight path or trajectory.
"Unfavorable interactions include anomalous aircraft- oscillatory APC events (e.g., divergence)."
National Research Council - Committee on the Effects of Aircraft-Pilot Coupling on Flight Safety.
"Federal Aviation Administration, Washington, D.C. June, 2003."
"HALE ROA ATC Communications Step 1 Requirements Document, Version 2.0."
HALE UAS ATC Communications Functional Requirements.
HALE UAS Command and Control Communications Functional Requirements.
"Access 5 Technology Demonstration Command, Control, and Communication Test Objectives."
"Access 5 Command, Control, and Communications (C3) Work Package Step 1 Flight Demo Data Analysis Plan."
Aviation Safety and Pilot Control – Understanding and Preventing Unfavorable Pilot-Vehicle Interactions.
HSI001 Step 1 Human Systems integration Functional requirements document.
Air Transport Association Information Transfer Subcommittee.
"The Effect of Voice Communications Latency in High Density, Communications- Intensive Airspace."
"Unmanned Aerial Vehicles Human Factors Guidelines Final Report, CDRL AB04."
"George Mason University, Fairfax, VA. August and October, 1997."
This document involves definition of technology interface requirements for Hazardous Weather Avoidance.
Technology concepts in use by the Access 5 Weather Management Work Package were considered.
"Beginning with the Human System Integration (HIS) high-level functional requirement for Hazardous Weather Avoidance, and Hazardous Weather Avoidance technology elements, HSI requirements for the interface to the pilot were identified."
"Results of the analysis describe (1) the information required by the pilot to have knowledge of hazardous weather, and the control capability needed by the pilot to obtain hazardous weather information."
"Fundamentally, these requirements provide the candidate Hazardous Weather Avoidance technology concepts with the necessary human-related elements to make them compatible with human capabilities and limitations."
The results of the analysis describe how Hazardous Weather Avoidance operations and functions should interface with the pilot to provide the necessary Weather Management functionality to the UA-pilot system.
"Requirements and guidelines for Hazardous Weather Avoidance are partitioned into four categories: (1) Planning En Route (2) Encountering Hazardous Weather En Route, (3) Planning to Destination, and (4) Diversion Planning Alternate Airport."
"This was performed through a review of weather-related, HSI requirements documents, standards, and recommended practices."
Technology concepts in use by the Weather Management WP were assessed also.
"Beginning with the HSI high-level functional requirement for Hazardous Weather Avoidance, and Hazardous Weather Avoidance technology elements, HSI requirements for the interface to the pilot were identified."
"Results of the analysis describe (1) the information required by the pilot to have knowledge of hazardous weather, and (2) the control capability needed by the pilot to obtain hazardous weather information."
"Fundamentally, these requirements provide the candidate Hazardous Weather Avoidance technology concepts with the necessary human- related elements to make them compatible with human capabilities and limitations."
The purpose of this document is to define HSI technology interface requirements for Weather Management.
"Research of human capabilities and limitations known for Hazardous Weather Avoidance was performed through a review of HSI requirements documents, standards, and recommended practices."
Technology concepts in use by the Weather Management WP were assessed.
Some vehicles will tolerate higher or lower levels of the hazardous weather than others.
AIRMETs concern weather of less severity than that covered by SIGMETs or Convective SIGMETs.
"AIRMETs cover moderate icing, moderate turbulence, sustained winds of 30 knots or more at the surface, widespread areas of ceilings less than 1,000 feet and/or visibility less than 3 miles, and extensive mountain obscurement."
"SIGMET advisories cover severe and extreme turbulence, severe icing, and widespread dust or sandstorms that reduce visibility to less than 3 miles."
Preliminary messages issued in order to alert users that a Severe Weather Watch Bulletin (WW) is being issued.
"The messages are unscheduled and issued as required by the National Severe Storm Forecast Center at Kansas City, Missouri."
"Convective SIGMETs are issued for tornadoes, lines of thunderstorms, embedded thunderstorms of any intensity level, areas of thunderstorms greater than or equal to VIP level 4 with an area coverage of 4/10 (40%) or more, and hail 3/4 inch or greater."
HIWAS has been adopted as a national program and will be implemented throughout the conterminous U.S. as resources permit.
"In those areas where HIWAS is commissioned, ARTCC, Terminal ATC, and AFSS/FSS facilities have discontinued the broadcast of in-flight advisories as described in the preceding paragraph."
HIWAS is an additional source of hazardous weather information which makes these data available on a continuous basis.
"It is not, however, a replacement for preflight or in-flight briefings or real-time weather updates from Flight Watch (EFAS)."
Weather Service Unit meteorologists for ATC use to alert pilots of existing or anticipated adverse weather conditions within the next 2 hours.
In substantially alter the information contained in government- commercial provider is EWINS qualified.
Aeronautical Information Manual; FAA regulatory and advisory material; FAA Human Factors Design Guide; other key research papers.
The Human System Interface shall convey information to the pilot to requirements in this document fall under this requirement.
Technology interface requirements are a necessary element of functionality to the UA-pilot system.
"They represent high-level, requirements for (1) pilot control of a the pilot to understand current and forecast hazardous weather."
"Avoidance are partitioned into four categories: (1) Planning En Planning to Destination, and (4) Diversion Planning Alternate Airport."
FAR 91.167 Fuel requirements for flight in IFR conditions.
"Future work is required to continue this analysis to the level appropriate level of guidance without restricting the flexibility of analogous information requirement would read, “(For the top- provided at the ACS to indicate to the pilot the tank or function selected.” Once this level of detail is developed for each top- requirements definition effort for Step 1 will be complete."
"Federal Aviation Administration, Washington, C. February 17, 2005."
"Novacek, Paul F., Burgess, Malcolm A., Heck, Michael L., and Stokes, Alan F. (December 2001)."
The effect of ownship information and NEXRAD resolution on pilot decision making in the use of a cockpit weather information display.
"S. Department Of Transportation, Federal Aviation Administration (February Office."
"Air Traffic publication 7110.10R, Flight Services, August 5, 2004."
"Air Traffic Order 7210.3T, Facility Operation and Administration, August 5, 2004."
"Air Traffic Aeronautical Information Manual, August 5, 2004."
"FAA Advisory Circular, AC 00-45E, Aviation Weather Services, Revised December 1999."
"FAA Advisory Circular, AC 90-99, High Altitude Airspace Redesign Phase 1, September 22, 2003."
"FAA Advisory Circular, AC 00-62, Internet Communications of Aviation Weather and NOTAMs."
"National Airspace System Weather Functional Analysis, FAA Workgroup Report, February 12, 2004."
This document involves definition of technology interface requirements for Contingency Management.
"This was performed through a review of Contingency Management-related, HSI requirements documents, standards, and recommended practices."
Technology concepts in use by the Contingency Management Work Package were considered.
"Beginning with HSI high-level functional requirements for Contingency Management, and Contingency Management technology elements, HSI requirements for the interface to the pilot were identified."
"Results of the analysis describe (1) the information required by the pilot to have knowledge of system failures and associated contingency procedures, and (2) the control capability needed by the pilot to obtain system status and procedure information."
"Fundamentally, these requirements provide the candidate Contingency Management technology concepts with the necessary human-related elements to make them compatible with human capabilities and limitations."
The results of the analysis describe how Contingency Management operations and functions should interface with the pilot to provide the necessary Contingency Management functionality to the UA-pilot system.
Requirements and guidelines for Contingency Management are partitioned into four categories: Health and Status and (2) Contingency Management.
This was performed through a review of Contingency recommended practices.
Technology concepts in use by the Contingency Management WP were assessed also.
Management technology concepts with the necessary human-related elements to make them compatible with human capabilities and limitations.
The results of the analysis describe how Contingency Management operations and functions Management functionality to the UA-pilot system.
Requirements and guidelines for Contingency Management are partitioned into four categories: (1) Health and Status and (2) Contingency Management.
The purpose of this document is to define HSI technology interface requirements for Contingency Management.
"Management was performed through a review of HSI requirements documents, standards, and recommended practices."
Technology concepts in use by the Contingency Management WP were assessed.
Beginning with the HSI high-level functional requirement for Contingency requirements for the interface to the pilot were identified.
"Results of the analysis describe (1) the information required by the pilot to have knowledge of Contingency Management, and (2) the control capability needed by the pilot to requirements provide the candidate Contingency Management technology concepts with the necessary human-related elements to make them compatible with human capabilities and limitations."
The results of the analysis describe how Contingency Management operations and functions should interface with the pilot to provide the necessary Contingency Management functionality to the UA- pilot system.
The HSI FRD describes the highest level functional requirement Interface shall enable the pilot to manage contingencies.”2 In status of the UAS.”3 Technology interface requirements in this document fall under these requirements.
Technology interface requirements are a necessary element of provide the necessary Contingency Management functionality to the UA-pilot system.
"They represent high-level, requirements for (1) pilot control of a Management."
"Society of Automotive Engineers, March, 2003. para."
"Contingency Management Requirements Document, Revision D. March 2005."
"This report documents the work conducted under the NASA Advanced Transport Operating System task contract, Contract NAS1-18027, Task Assignment 15."
"It describes the development of a system requirements definition fw the flight control system of a commercial-type research aimaft of Langley Research Center's Advanced Transport Operating System program, the Transport Systems Research Vehicle, also known as the NASA 515."
"The objective of this work was to develop a definition of the 'kinsport Systems Research Vehicle flight control system requirements able to facilitate the research and development of alternate, more advanced software and possibly hardware architectures for modem transport aircraft flight control systems."
"The NASA 515 is a highly modified Boeing 737-100 aircraft designed specifically to investigate advanced navigation, guidance, control, and display concepts."
"In the experimental configuration, the aircraft is flown from a research flight deck (mounted in the aft cabin of the aircraft) whose entire flight control system is under software control."
"Therefore, alternate software implementations can readily be investigated."
"For the purposes of this report, the Transport Systems Research Vehicle flight control system is defined to be the baseline software for the NASA 515 research flight deck, including all navigation, guidance, and control functions, and primary pilot displays."
"At the beginning of this study, the system was built around two digital Norden PDP-11/70 computers, termed Norden #1 and Norden #2."
"Since that time, the system was modified and the Norden computers were replaced with DEC MicroVax computers."
For this report the system will be described for the Norden computer configuration.
"Norden #1 is the host to a Speny microprocessor display system which provides the Primary Flight, Navigation, and Engine Display formats; hence it is also referred to as the Displays host computer."
"Norden #2 hosts the guidance, navigation, and control software; hence it is also referred to as the Flight Managemenmight Control host computer."
The scope of the requirements definition contained herein is limited to a portion of the Flight Managemenmight Control computer functionality.
Included is a discussion of the tasks required to increase the scope of the requirements defmition and recommendations for follow-on research.
There is a strong requirement for a new generation of avionics systems with a more integrated hardware and software structure.
Future cockpits will incorporate a wide range of enhancements.
"Heavy application of artificial intelligence techniques can be expected to encompass the entim spectrum of crew station technologies: from data fusion to optimized display resource management, to real-time onboard maintenance and fault reporting, and even to the optimization of pilot physiological needs."
There is a significant challenge to integrate symbolic and numeric computation k a real-time enhnment as well as to effectively allocate functions between man and avionics.
"In addition, advances in the development of distributed and parallel processing systems necessitate the careful allocation of processing tasks among the system’s computing resources in order to realize the increased system performance, reliability, and flexibility that these architectures offer."
"Consequently, an effective systems engineering analysis is required to first identify the system requirements."
"A good requirements analysis addresses a system’s true requirements, that is, those essential features or capabilities that a system must possess in order to fulfill its purpose, regardless of how the system is implemented."
Development of the best architecture for the application starts with a good essential requirements specification.
"The objective of this work was to analyze the NASA Transport Systems Research Vehicle (TSRV) flight control system (FCS) and develop a system specification that would offer high visibility of the essential system requirements in order to facilitate the future development of alternate, more advanced software and hardware architectures."
"Neither the original (i.e., essential) TSRV FCS requirements nor the evolution of the baseline software are well documented, thus the “essence” of the system was backed out of the existing implementation."
The available documentation consists only of a somewhat cryptic software description document and a listing of the source code.
"Consequently, the specification produced is more influenced by the particular design preferences than would be a “top down” analysis for the development of an all new system."
"Furthermore, because the analysis was of an existing system, the scope of the requirements were limited to only those features actually implemented in the code."
"However, a good systems analysis should specify the (essential) requirements in such a way that they may be easily modified and/or extended to include new features."
The systems analysis approach used was based on the Object Oriented Analysis (OOA) methodology developed by Boeing.
"In short, the Boeing OOA approach unifies traditional systems analysis methods of information modeling, process modeling (e.g., Yourdon-DeMarco Structured Analysis), and behavior modeling (e.g., Ward-Mellor Real-Time Extensions) into a single more powerful method which synergistically combines the strengths of all three methods."
A Computer Aided Software Engineering (CASE) tool is extremely useful for the OOA methodology.
The Cadre Technologies Inc. teamwork tool was used teamwork to the OOA methodology.
"Furthermore, for this report, the teamwork data representing the TSRV FCS requirements analysis were reformatted into a single, unified, object-oriented specification."
"This section contains symbols and abbreviations used throughout this report, including those used in the requirements specification of Section 6."
"These are defmed in the object class descriptions found in 6.1 (see also 6.4, lndex of Identifiers)."
"The system of interest is the flight control system (FCS) for the research flight deck of NASA’s Transport System Research Vehicle (TSRV), a highly modified Boeing 737-100 commercial jet airplane, also referred to as the “NASA 5 15”."
Hardware and software descriptions are included below only to provide a general overview of the system.
Other references should be consulted for a more detailed understanding.
"The TSRV is used as part of NASA’s Advanced Transport Operating System (ATOPS) program established to investigate advanced navigation, guidance, control, and display concepts."
In the full-up test configuration it is flown from a second flight deck mounted in the cabin of the aircraft and referred to in this report as the Aft Flight Deck (AFD).
The AFD contains the basic controls required to fly the airplane and uses the advanced controls and displays in a completely realistic environment.
"The AFD pilots have essentially complete control of the airplane, although the AFD control authorities are limited and the forward flight deck (FFD) crew can take over control at any time."
"The AFD features programmable electronic Primary Right Displays, Navigation Displays, and Engine Displays, a Navigation Control and Display Unit (NCDU), a glare-shield mounted Advanced Guidance and Control System (AGCS) Mode Select Panel (MSP), and Panel Mounted Controllers (PMCs) that take the place of conventional column and wheel controls."
"Also, a Data Acquisition System @AS) provides real-time data recording and data display for inflight and postflight evaluation."
"The system is built around two Norden digital flight computers (militarized versions of the general purpose PDP-l1/70 computer), designated Norden #1 and Norden #2."
"Both computers are interfaced to the AFD and an extensive m y of sensors by a Digital Autonomous Terminal Access Communication (DATAC) system, a high-speed Norden #2, the Flight Management/Flight Controls (FIM/FC) host computer, receives sensor information and switch/button settings from the Sensor Interface Unit (SIU) across the DATAC bus."
"Norden #1, the Displays host computer, interprets input information from Norden #2 as well as from the sensors to create data blocks that are sent to a microprocessor-based Sperry Color Display System which provides the primary Right, Navigation, and Engine Display formats."
The Sperry system communicates with the displays host through a Direct Memory Access @MA) channel.
The information from the host is by Intel 80186 microprocessors which generate data usable by S units @Us) for the creation and positioning of display symbology.
There are twelve individual pieces of hardware involved in the standard Sperry display configuration.
"Included are eight color display units (ded PED, NAV, or ENG in Figure 4.1), three display electronic units (DEUs), and one bus interface unit (SIU)."
Each DEU has four microprocessors containing programs which perform VO functions and create data in formats acceptable to the DUs.
Note that one of the microprocessors contained in DEU #2 is a weather (WX) radar processor which feeds weather radar to each DEU.
"For the purposes of this report, the TSRV FCS is defined by the “baseline” software for the TSRV research flight deck including all navigation, guidance, and control functions, and primary pilot displays."
"It is comprised of the software contained in the Displays host computer (Norden #l), the FM/FC host computer (Norden #2), and the Sperry Color Display System."
The baseline software available for analysis on this project was a 1989 source code listing provided by NASA on a magnetic tape.
"This source code is best described by Reference [7], a software description document, also provided by NASA."
The software described in Reference [7] is delivery 4.1 (D4.1) of the baseline FM/FC system which was released in July 1987.
It should be d that these resources represent various portions of the software current on different dates.
"Consequently, some inconsistencies were found during the analysis."
"In these instances, the most logical and/or expedient resolution of the conflict was made; no attempt was made to document these conflicts or their resolution."
"This report addresses only part of the development of a complex, integrated system: the analysis and specification of its requirements."
The role of “systems analysis” in the life-cycle of a system may be best understood in the proper context.
"Initially, a problem generally exists as ideas about what the issues are as well as even preconceived notions of the solution; or at best, as a partial list of requirements."
"It is necessary to move from this nebulous condition to a more precise set of requirements, or better yet, a well-defined model of the requirements."
"This model should be a complete, consistent, and coherent specification of the essentiaf requirements of the system."
AnaZysis is the process which identifies the “essence” of a system.
The concept of essence helps distinguish between the true requirements of a system and those things which are really implementation oriented and/or technology dependent.
"In the analysis stage, the specification of the system should not be influenced by past design solutions -- “We’ve always done it that way” -- or by current technology constraints such as processor speeds or memory limitations."
"It is important to clearly define what the system needs to do, not how it shall do it."
"Following the analysis phase is the design phase, where real-world constraints as well as design preferences are imposed upon the system’s essential requirements specification."
The result is a technology dependent model of a solution to the problem.
"It represents one answer to the question, “How can the In the final phase of development, the design requirements are implemented in the form of hardware, software, etc."
"In the case of the TSRV FCS, the systems analysis process started from a specification of the system “as built”."
"Therefore, in a “reverse engineering” sense, the requirements were backed out of the existing implementation."
"Nevertheless, the goal was the same: to produce a specification of the essential system requirements."
The analysis of the TSRV FCS was carried out using a Boeing-developed Object Oriented Analysis (OOA) methodology.
"The Boeing OOA method unifies traditional systems analysis methods of information modeling, process modeling (e.g., Yourdon-DeMarco Structured Analysis), and behavior modeling (e.g., Ward-Mellor Real-Time Extensions) into a single mure powerful method which synergistically combines the strengths of all three methods."
"See References [8], [lo], [ll], and [12] for background information."
OOA is an alternative to “structured analysis” as a requirements specification language.
"It unifies elements of information, behavior, and processing on an atomic level (object level), whereas structured analysis provides three hierarchical system level views which are not necessarily consistent and require parallel maintenance."
OOA provides a method to rigorously define the requirements of any complex system in such a way that the analyst can readily identify any missing or contradictory requirements.
"The result is a complete, consistent, and simplified description of a system’s essential requirements."
"Furthermore, OOA provides a solid foundation for partitioning systems into “objects” and results in a system definition which allows a smooth transition into design."
"Object oriented specifications map very easily into object-oriented design and object-oriented programming (using languages such as Ada, Objective Cy and Smalltalk), but also may be readily translated into other design schemes such as a standard hierarchical structured design."
OOA’s partitioning methodology and design flexibility are a few of the features which make it particularly suited to the goal of defining alternate architectures for an existing complex system.
"OOA partitions a system into objects, or object classes."
The goals of OOA are to assist in the “discovery” of the object classes in a system and the relationships between those object classes; and 2) to provide a mechanism to document those object classes so that they can be verified and later communicated to designers and programmers.
The “products” of OOA and the relationships between them are depicted in Figure 5.2.
The products are the deliverable results of applying OOA to a specific system.
"In other words, they are the graphic and textual models that are produced by the process of analysis."
The products of OOA describe the system at two conceptual levels of detail: clars level models and system level models.
Class level models provide the detailed internal views of single object classes.
"System level models, on the other hand, describe the way object classes fit together to make the system as a whole."
The system level models are not concerned with the internal details of the object classes.
"Likewise, the internal “schematic” of each object class must not concern itself with any other object class directly (i.e., knowledge of the internal workings of another object class is not allowed)."
These rules support the principle of information hiding.
An object class can be thought of as a template that represents the generic form of all objects which belong to that class.
"Object classes can be described by the data they carry, the processes they perform, and the behavior they exhibit."
"Therefore, each object class template is comprised of three class level models: a Data Model; 2) a Process Model; and 3) a Behavior Model."
"In order for an object to be a member of a given class, it must conform to the class’ template: that is, it must be &scribed by the prescribed data, it must do the prescribed work (processing), and it must exhibit the prescribed behavior."
The data aspect of an object class is described textually by a set of Attributes.
"Each attribute represents a single meaningful fact that is pertinent to, and necessary for, all instances of that class."
The set of attributes for an object class defines the information that is relevant for that class.
"The Process Model captures the functionality of an object class,."
The model defines the set of P rocesses that operate upon or manipulate objects within that class.
A Process Model is described both graphically and textually.
The graphical portion is in the form of the familiar dataflow diagram notation.
A rigorous specification of the work performed by the processes is also necessary.
The Structured Analysis “minispec” is a convenient mechanism for describing the details of a process.
The behavior aspect of an object class is described by a finite state automaton.
This can be thought of as a collection of States and Transitions which respond to certain Events.
"A state is a phase, stage, mode, or condition of being."
"The states for an object class are distinguished by ongoing processing, recognized events, and the responses to those events."
"An event is a circumstance, occurrence, or happening which may cause a change in the state of an object."
There are two system level models that show how the population of object classes in the system are interconnected.
"The Object Class Relationship Model (OCRM) and the Object Class Communication Model (OCCM) depict how the object classes interrelate and interact, respectively."
This model describes the gxistence relationships among object classes.
"On the other hand, the OCCM depicts the glvnamic communication which takes human pilot (object) may -- at some time -- send the following commands (in place between objects during the life of the system."
"A rough example is: ""the the form of data &fined in the appropriate Data Model) to the autopilot (object): number of communications that take place in a system render a single communication diagram of the whole system unreadable, multiple communication diagrams can be developed each focusing on a related subset of the communications in the system."
"It should be d that a complete understanding of the internals (data, behavior, processing) of every object class is generally not required, and sometimes may not be possible."
"This gives rise to a special type of object class, an external object class."
All that need be known about them is that they are the sources and/or destinations of named events and data for the system.
The external object classes are identified in the analysis because they are significant in the overall understanding of the system.
"Later, these classes may be represented in the design phase by VO interface routines."
"In the analysis phase, every object class must either be described by data, process, and behavior models, or be designated as an external object class."
"A strategy serves the purpose of guiding the analyst toward the goal of completing the analysis, and different strategies may be appropriate in different situations."
The analysis strategy used here was necessarily oriented toward the OOA methodology.
The strategy was to develop the OOA models (see 5.3) of the system requirements using an information centered approach.
"With this strategy, the analyst focuses frrst on the information aspect of a system in order to discover as many of the object classes as possible."
The result of this activity is a fmt approximation of the OCRM along with Data Models for each of the object classes found so far.
"Note that at this stage, those objects with little or no data (i.e., those which are more process and/or behavior intensive) have not necessariiy been discovered: the list and definitions of the object classes are likely to be incomplete at this juncture."
"As subsequent phases of analysis (e.g., behavior and process modeling) are pedomed, new object classes may be discovered, or a few existing ones may be combined or split up."
"This is to be expected given a ""bottom up"" strategy of discovering object classes; the existence and completeness of an object class cannot truly and finally be validated until its Data, Process and Behavior Models are all &fined."
"Next, the analyst models the behavior aspect of the system by developing a Behavior Model for each object class."
"Additional behavior requirements not expressed by the Behavior Models for the known object classes may hint at the existence of hidden (i.e., as yet undiscovered) object classes that need to be exposed or at the need to re-partition some of the existing object classes."
The next step involves modeling the processing aspect of the system by developing a Process Model for each object class.
"The approach is to examine every state and every transition defined in the Behavior A4 1 for every object class and ask the question, “Is anything svpposed to happen in this state or on this transition?’ Processes are then created to represent the work required and those processes are coupled with the appropriate states or transitions."
"Again, additional processing requirements may expose new object classes."
"In this strategy, the development of the communication model is a relatively mechanical process as no new information should be discovered."
The task should be a simple matter of connecting the outputs of each object class to the appropriate inputs of the others.
The description of this strategy implies a relatively step-by-step approach.
"Nevertheless, it was a useful strategy, particularly for an analysis of an existing functional implementation where the existence and partitioning of objects was not obvious."
"A CASE tool can be thought of as a database management application which includes graphics objects and freeform text entities in its database schema, includes editors for the manipulation of these, and provides appropriate navigation throughout the database."
The Cadre Technologies Inc. teamwork family of tools (Reference [13]) was used as it was readily available at Boeing.
The teamwork CASE tool family automates standard structured methodologies using interactive computer graphics and multi-user workstation power.
"Using teamwork the analyst can examine the system being developed from multiple viewpoints -- all within one integrated environment that monitors the entire project’s progress, rigorously checks for errors and produces automatic documentation."
"Teamwork’s checking facilities provide automatic verification of the models by checking for completeness of the models, checking for consistency between models, and helping to find syntax errors."
Teamwork analysis tools help create descriptions and smctured analysis of complex specifications.
They allow description in both functional and object- oriented analysis.
"However, teamwork does not directly support an object oriented analysis approach."
"Consequently, various conventions were developed to adapt teamwork to the OOA methodology."
Creative utilization of teamwork has allowed essential information not directly supported by teamwork to be recorded in the requirements specification (Section 6).
Details regarding these conventions are described in 5.6.
"Also, for the purposes of this report, a Boeing-developed teamwork database report writer was used to format the TSRV FCS requirements analysis into a single, unified, object-oriented specification (Section 6)."
"When reviewing the requirements specification given in Section 6, it may be helpful to know beforehand some details regarding the conventions that have been followed."
This sub-section documents the conventions present in the printed reports and diagrams that comprise the requirements specification.
"It does not attempt to explain all of the rationale behind various conventions, but rather is intended to be a concise resource for the reader of the specification."
"For this reason, notation that has been published and is generally known is not explained."
"Furthermore, familiarity with the concepts of OOA is assumed (see , while knowledge of teamwork (see 5.5) is not."
Teamwork did not directly support the Boeing OOA methodology.
"Although special application of the standard notation and conventions were defined by the tool developer to support Project Technology’s Real-Time Object Oriented Analysis (see Reference [12]), these conventions were lacking in various respects."
"For example, one naming convention that required object class names to contain parentheses and spaces made it difficult to navigate within the software and eliminated any chance of producing an error report."
"Consequently, various conventions were developed to adapt teamwork to the Boeing OOA methodology."
Reference [ 141 contains additional background on some of the basic problems as well as solutions associated with using off-the- shelf CASE tools for Object Oriented Analysis.
"Any convention typically satisfies a number of demands simultaneously, though perhaps not all of them ideally."
"A compromise is often required among content, readability, ease of use, and teamwork’s “happiness” with the idea."
"The conventions outlined below maximize content but avoid sabotaging the automation offered by teamwork (such as error reports, listings, on-line navigation among elements in the specification)."
"At the same time, this supplementary-to-teamwork information is captured in a rigorous fashion, amenable to mechanical (i.e,, automated) syntax checking and cross- referencing."
Some of the conventions are conventions required by teamwork.
"Others are Boeing-developed, and have enabled the recording of essential information in an OOA specification that is not directly supported -- and therefore not expected -- by teamwork."
The following paragraphs are &signed to allow the reader of the specification to extract important information at a glance.
"Words are generally capitalized and separated by an underscore (‘-’); exceptions are allowed for small words such as “is”, “or”, etc."
"Names always begin with a letter and contain only letters, numbers, underscores and dashes."
The dash (‘-’) is used only when explicitly required by these conventions; it is not used otherwise.
"A given name is generally made up of two or more parts, separated by the reserved dash character."
"One of these parts will be the basic mme of the thing in question; that is, the ‘common’ word or phrase which is used in the analysis to uniquely identify the thing."
"The other parts, preceding and/or following this basic name, will embody useful or even necessary information."
"Teamwork, however, considers the name of the thing to be the full string of characters, and is thus unaffected by the augmentation."
"The full string of characters is sometimes r e f e d to as the official name, or as simply the name of the object."
Object names always begin with capital letters followed by a double dash.
"Attribute, derived attribute names and event names always begin with lower case letters, followed by “- 1-”, “-2-”, and “-3-”, respectively."
Relationship names always begin with the form ‘RnnA’ or ‘RnnB’ followed by a single dash.
"Every object class has a name, a description, and the following models: a Data Model andlor a Behavior Model and/or a Process Model."
An object class’ Several conventions were followed regarding the representation of object class templates in the specification.
"These include some which relate to the building of a name for a class, the format of its description, primary identifier, and aliases, and its appearance on system level diagrams."
These whole-object conventions are explained in detail in 5.6.2.
"Conventions for the various parts of an object class tempIate (i.e., those associated with the parts of the class level models) are documented in 5.6.3, 5.6.4, and 5.6.5."
"Refer also to 5.6.1, General Conventions for All Names."
The official object name consists of two parts: the object id and the basic name; these are separated by a pair of dashes.
"The object id is always present, always unique, generally mnemonic, and always entered in all capital letters."
"It is typically made from the first letters of the object’s name (“FP” for “Flight Plan”, “WFP” for “Waypoint on a Flight Plan”), though not always (“WPT” for “Waypoint”)."
"This id is always two or more characters, and always begins with a letter."
"The baric name is always in the singular, naming a typical instance of the object class."
"The description is always present, indented from the left margin."
The precise kind of object class being defined is given in italics within parentheses immediately prior to the body of the description.
"The following entries for object class kind may appear: regular object class; anonymous object class; external object class; external, anonymous object class; anonymous object class, no attributes; external, anonymous object class, no attributes."
Any non-anonymous object class must have one or more identifiers.
"The chosen primary identifier is introduced with the key phrase ""primary identifier""."
"When several attributes form the primary id, each attribute is separated by a plus sign (""+""), and should appear on a line of its own; the last attribute may be followed by a period (""."")."
"Comment blocks, if present, are delineated with a begin and end asterisk (""*',)."
Non-primary identifiers are indicated via attribute naming conventions.
"If so, these are indicated using the format shown above."
"Please note that the attribute list which appears inside the rectangle of a given object class on the Object Class Relationship Diagram (OCRD) is enclosed in a comment block -- it has been entered manually, and teamwork has not checked for agreement between this list and the list which is part of the object’s definition."
"It may help to know this in case a subsequent change is required, or an inconsistency should arise."
"Please note that just the object id appears within the object class rectangles on Object Class Communication Diagrams (OCCDs), to conserve diagram space."
"Also note that, by convention, a pair of asterisks following such an object id indicates that the context of the object class is not fully defined on that particular diagram; that is, there may be some data and/or events not shown on the diagram which this object class consumes or provides."
"Several conventions were followed regarding the representation of attributes, derived attributes, events and processes in the analysis."
"These include some which relate to the building of a name for one, the fonnat of its definition, and its appearance on diagrams."
The notion of a cornon domain also aided in concise representation.
An attribute’s ofsicial name contains within it various flags and indicators (see Conventions for ADCEP Names).
Its definition captures two things: the domain of values which the attribute can take on; and the precise meaning of those values for this attribute.
The former is captured via a domain specification; the latter via an English description (see Conventional Format for ADCEP Definitions).
"Common domains are created whenever two or more attributes share a common domain of values, due to an essential similarity (not a coincidence)."
"This is done to follow the guideline, “Document each fact in just one place.” In these cases, the group of similar attributes simply reference the common domain definition by its name, rather than repeat the shared domain specification."
"Like attributes, every common domain has a nume and a definition."
Attributes which reference other definitions are said to have nonprimitive definitions.
"Attributes come by nonprimitive definitions in three ways: by referencing common domains as described above, by being referential attributes, or by being compound attributes."
An attribute which directly is said to have a primitive definirion.
"A common domain usually has a primitive Wnition (i.e., usually contains its ."
"However, some common domains are compound domains, and these have nonprimitive definitions."
Compound domains reference other common domains (never attributes).
"Derived attributes are identical to (regular) attributes except in an information modeling (data normalization) sense: they represent not stored data, but data derived from a process."
"The process which derives a particular derived attribute may be explicitly defined for clarity or use in the Behavior Model, but is often left as an implied, always-available process."
"Like attributes and common domains, every derived attribute has a name and a definition which consists of a description and a domain specification (which may be primitive, nonprimitive, or compound)."
The description of an event captures the precise meaning of the event when it occurs.
Every process has a name and a description (also known as a minispec).
"The description of a process captures what the process must accomplish, not how it will be accomplished: it is not algorithmic."
"Attributes, derived attributes, common domains, events and processes are quite similar in regards to the conventions followed for them."
"An ADCEP is “an attribute / derived attribute / common domain / event / process”, i.e., either an attribute or a derived attribute or a common domain or an event or a process."
"The official ADCEP name consists of at least two parts: first (except for process names), the object id of the object class which is the source of the ADCEP in question (or, in the case of a common domain, the characters “domn” stand in the place of the object id); next, the basic name of the ADCEP; next, zero or more referential attribute tags; finally, zero or more identifier tags."
It is a consequence of the above naming convention that a global dictionary immediately after listing the object class.
"Also, all common domains will be defined in a contiguous block."
"This considerably improves the readability and usefulness of such a printout, and aids the analysis process."
The object id (and “domn”) is always entered in all lower case letters.
This simply improves readability by markedly distinguishing an ADCEP name from an object class name (entered in all capital letters).
The basic name of the ADGEP signifies the meaning of the values in the domain of the ADCEP.
The meaning may be moE precisely defined within the ADCEP’s definition.
Referential attributes will include one or more referential attribute ~ g s .
"These tags will be of the form ‘RnnA’ or ‘RnnB’, and serve to (a) flag an attribute as referential; and (b) indicate which relationship(s) are referenced, that is, from which related object class the attribute was borrowed."
"For example, the reader immediately knows that the attribute “wfp-l-Flight-- Plan-Name-RO1 A” is a referential attribute, because it has the ‘R’ tag “ROl A”."
"Specifically, the reader sees that relationship “RO1” is referenced, and that the object class connected to line “ROl A” is the object class from which the attribute comes."
"Therefore, the reader knows that the attribute “wfp-1-Flight-Plan-Name-ROlA” is in an essential sense equivalent to one of the attributes from the object class “FP--Flight-Plan”."
Exactly which attribute has been borrowed from the object class cannot be discerned from the attribute name itself; it is documented via the attribute’s definition (see Conventional Format for ADCEP Definitions).
"These tags name the identifier (primary, secondary, tedary, ...) of which an attribute is a part."
"For example, the attribute “wpt-1-Latitude-idO2” forms part of a secondary identifier for the “WPT--Waypoint” object class."
"An ADCEP definition captures two things: the domain of values which the the meaning is often clear from the name of the ADCEP, a more precise description is usually helpful."
The domain of values is described in essenzid (technology indepen&nt) terms; how these values might be stored in memory or on disk is of no concern in analysis.
An ADCEP definition consists of a well-structured body of text.
The six examples below illustrate some of the various kinds of definitions.
They are followed by the details of the exact structure.
Every definition begins with the ADCEP name in bold print on a line by itself.
"The precise kind of ADCEP being defined is given in italics within parentheses on the next line, indented 0.125 inches."
"An ADCEP definition usually has a description, indented 0.5 inches from the ADCEP name, and consisting of free-form English text."
"Except for events and processes, the description captures the precise meaning of the information recorded by the ADCEP."
"This description is commonly a brief, incomplete sentence like those of a normal dictionary entry, which assumes the reader foxmat is to begin the description with “This...”; the word mfers to the ADCEP might be implemented."
The description for an ADCEP may be omitted where obvious from the name.
The ADCEP’s domain specification (if any) is enclosed in a rectangle indented from both margins about 1 inch.
There are two kinds of domain specifications: primitive and nonprimitive.
"The ADCEP itself is said to have either a primitive or nonprimitive definition, accordingly."
A nonprimitive definition references other ADCEPs in its domain spec@cation.
"Generally, just a single ADCEP is referenced; occasionally, two or more may be referenced."
Teamwork checks referenced ADCEPs when validating a nonprimitive definition.
"When two or more ADCEPs are referenced, this indicates that the ADCEP is actually composed of two or more meaningful parts, each with its own domain."
"Reference to this ADCEP is, strictly speaking, a shorthand for reference to its parts (the true, atomic ADCEPs)."
"Such an ADCEP is called a Compound ADCEP -- specifically, a compound attribute, compound derived attribute, compound domain, and so on."
Referential attributes are always defrned in this way.
"Common domains are created whenever two or more ADCEPs share a common domain of values, due to an essential similarity (not a coincidence)."
A primitive definition is one that does not reference other ADCEPs; its domain (if any) is explicitly stated via a domain specification.
"The domain specification is not checked by teamwork, but does adhere to a rigorous syntax amenable to mechanical checking by auxiliary programs."
"The format of the domain specification varies, depending on the kind of domain being described: enumeration, subtype indication, string, numeric, or integer."
"However, all formats begin by indicating which of these five domain specifications follows (‘Type”)."
Enumerable domains are defined simply by listing the valid values.
"An attribute in a supertype which names the subtype object class is called a subtype indication, and its domain of valid values is, by definition, the object ids of the subtype object classes."
"An ADCEP whose domain of valid values is strings of characters may be defined by a maximum size, minimum size, legal characters and/or format (if any)."
The description of a string ADCEP may have to include an English description of its required format in order to be precise.
"Numeric ADCEPs are described by range and accuracy, as in the following examples."
Such material was not uncovered during the analysis process.
"The attributes of an object class are listed inside the object class rectangIe on the OCRD, below a line of dashes."
Several conventions were followed zegarding the representation of behavior via State Transition Diagrams (STDs).
These include conventions which relate to the construction of state and transition labels and are explained in detail below.
Line 2 consists of a separator line to improve readability; note that this line is enclosed in a comment block which begins after the state name.
"Below this appear the enabled processes, in the usual “E.” notation."
An id number for the state appears in the lower left comer.
Words are separated with spaces rather than underscores (“-”).
A transition is a change from one state to another state due to a particular event.
"The state from which a transition is drawn is referred to as the source stare; the state to where it goes, the next state."
The source state of a transition is said to “contain” that transition.
"Every transition has either an event bZock or a guard (or both), and may additionally have a response (ordered sequence of triggered processes and signalled events)."
Transition labels have been augmented in several ways in order to simplify otherwise busy STDs.
"A standard STD (i.e., a standard OOA STD) modified according to these conventions will generally have fewer transition lines and/or fewer state boxes."
"Please , however, that the meaning of both diagrams is the same (Le., the behavior specified is identical): the purpose of these conventions is to increase readability only."
The transformation from an augmented to a standard version of a given STD is mechanical.
A slash (“/”) and a separator line follow the event block whenever a guard and/or response follow.
"The guard, when present, is always preceded and followed by a separator line, and always appears before the response (if any)."
"The response, when present, always appears last, below a separator line."
Conventions relating to transition event blocks and guards are described below.
No special conventions were adopted for the response on a transition.
An event block consists of a list of everu names and/or boolean expressions.
Each item must be separated by the key word “.or.”.
A transition which has a boolean expression in its event block is referred to as an evaluated transition.
"When more than one item is listed, the transition is taken to be a shorthand for a set of transitions (one for each item) which share the same source state, next state, guard and response."
A step in the construction of the standard version of an STD is to replace such a transition with just that set.
"The event name carries the usual meaning: when an object of the class is in the source state, and the named event occurs, then the transition will be taken (unless the transition’s guard is false -- see below)."
A boolean expression is a series of one or more relational expressions separated by “.or.yy and/or “.and.”.
"Each relational expression compares an attribute or derived attribute of an object to that of another (or to a constant) via using “.not.”, and may consist simply of an attribute or derived attribute name, so long as its domain is boolean."
The boolean expression becoming true while the object is in the source state is treated as an event in the usual sense.
"Upon entry into a state which contains one or more evaZuuted transitions, each of the boolean expressions must be evaluated (in any order), and the associated transition taken immediately if the guard evaluates to true; none of the enabled processes associated with the state shall begin until after all of these boolean expressions have been evaluated as false."
"This stipulation is extremely important, especially in light of the infinite speed with which an essential (technology independent) process is said to execute."
"It is possible to create non-deterministic state models using evaluated transitions; however, it is also possible to create non-deterministic state models using standad OOA state models in which states contain multiple processes that evaluate criteria and signal events (refer to the paragraph below)."
"It is up to the analyst, as usual, to ensure the correctness of the state model, which may or may not mean ensuring that the model is deterministic."
All transitions going into the original state would be redirected to the specially-created state.
"When one of the events occurs, or when one of the boolean expressions evaluates to true, it is said that an event in the event block has occurred."
"A transition containing a guard is r e f e d to as a guarded event transition, and cannot be taken unless the guard evaluates to true at the time an event in the event block occurs."
"If the guard evaluates to false, then the transition is not taken: the event in the event block is ignored."
It is pennissable for a guard to appear on a transition which has no event block.
"However, in this case, the guard is treated as an event block consisting of single boolean expression."
See Conventions for Transition Event Blocks for more on boolean expressions.
"As with evaluated transitions, the evaluation of the boolean eqwession can be relegated to a specially-created process which signals one of two specially- created events."
"Any guarded event transition would be modified by removing its original response and changing its next state destination to a specially-created “temporary evaluation” state which would enable the specially-created process, and would contain two transitions: one going back into the source state of the original guarded event transition, with null response (for the “false” event), and one going ahead into the original next state of the original guarded event transition, with response equal to that of the original."
Part of the specification of a process may be to generate particular events when certain conditions are met.
"In this case, the process is shown to produce the event by means of a dotted arrow notation."
"Other than this, no special conventions were adopted for Process Model diagrams."
Several conventions were followed regarding the representation of relationships in the analysis.
"These include some which relate to the building of a name for a relationship, its definition, and its appearance on diagrams."
"Throughout the discussion of these conventions, please refer to Figure 5.3, which shows an annotated example &om the OCRD."
"Every relationship has an id, two names, two statements of multiplicity, and a relationship itself."
"Each name (as well as each statement of multiplicity) is defined from the viewpoint of one of the object classes, so that one can refer to the subject and object of the name (or statement of multiplicity), in the grammatical sense of these words."
"The relationship’s definition documents the precise details of a relationship, expanding on the meanings signified by the relationship as it appears on the Object Class Relationship Diagram (OCRD)."
The official relationship name consists of two parts: the relationship name id and the basic name.
The relationship name id is always present; it uniquely identifies one of the two m e s for the relationship.
It is always formed by appending ‘A’ or ‘By to the relationship id.
"Each relationship is assigned a unique id of the form ‘Rnn’ (e.g., R01, R02, R23, R46), referred to as the relationship id."
This id is the only way teamwork will refer to the relationship.
Keep this in mind when reading teamwork-generated reports and listings.
Teamwork uses this id (and only this id) to alphabetize.
The basic name of the relationship is always a verb or verb phrase.
It signifies the meaning of an association between members of the two object classes from the viewpoint of a generic member of the subject object class.
The precise meaning attached to the association is documented in the relationship definition (see Conventions for Relationship Definitions).
"These verb phrases might use the word “may” to underscore the conditionality of the relationship, though not always."
"The statement of multiplicity follows a straight-forward, teamwork-imposed syntax."
"It documents half of what is conventionally called the ‘multiplicity of the relationship’: the minimum and maximum number of objects in a class (the object object class) which might be associated, at any one time, with an object of the subject object class, defined from the viewpoint of a generic member of the subject object class."
"The other half of the ‘multiplicity of the relationship’ is documented in the other statement of multiplicity, in which the two object classes have reversed grammatical roles."
"For an example, refer to Rendering an English Definition From OGRD Relationships."
A textual plain-English relationship definition need not be given unless the definition will illuminate subtle aspects of reality or policy not obvious from the relationship as documented on the Object Class Relationship Diagram (OCRD).
"As shown in Figure 5.3, most aspects of a relationship are documented on the OCRD; only the definition is absent."
"The definition serves to clarify the terse, Recall that a relationship name is either a verb or a verb phrase."
"As shown in the figure, each name appears next to the object class which is the object of the verb phrase (in the grammatical sense), as is customary when using two names."
"For example, the relationship name which is derived from the viewpoint of a “WPT-Waypoint” is placed next to the object class rectangle for “FP-- Flight-Plan”; the former object class is the subject object class, the latter the object object class."
"The Statement of multiplicity which appears next to each relationship name follows a self-evident, teamwork-imposed syntax."
"The statement of multiplicity appears adjacent to the object object class, and is defined from the viewpoint of a generic member of the subject object class."
"As shown, the relationship name and statement of multiplicity appear together, generally on a single line."
The Elationship name is enclosed in a comment block; teamwork does not perform any checking of this name.
"However, teamwork does inspect and expect statements of multiplicity."
The relationship id appears inside the relationship diamond.
"It generally helps the rr=ader of an OCRD gain an understanding of the meaning of a relationship by reading all parts together in two sentences, as follows."
Read the name of one of the object classes; an object class is always named in the singular.
Read the relationship name (verb phrase) which is next to the other object class.
"Read the name of the other object class, treating it as the object of the verb (in the grammatical sense), switching to the plural form for one-to-many and many-to-many relationships."
Repeat this process from the other direction (starting with the other object class).
This section contains the actual requirements specification for the TSRV flight control system (see Section 4 for a system description).
"Although strictly speaking it is self-contained, any specification is best understood in the proper context."
A key to a good understanding of the specification is an understanding of the typographical conventions used in it.
"Qf course, it is also imperative to understand the concepts of Object Oriented Analysis (OOA)."
The scope of the requirements definition contained herein is limited to the Flight ManagemenVFlight Control computer functionality.
"Within the scope of the system analyzed, some requirements were identified but not thoroughly analyzed."
"In this analysis, such requirements were captured by identifying special placeholder object classes."
Such an object class is termed a “pseudo external object class”: treated as external until such time as this aspect of the system can be analyzed further.
"For the interim, this object class provides a source and sink for closely related events and data: those known to be required by objects already defined in the analysis."
Further analysis may reveal that this single placeholder must become several object classes.
"Also, several of these pseudo external object classes might be split andjoined."
The requirements specification is divided into four sub-sections.
"The requirements contained in the class level models are laid alphabetical &r. out in a format geared for maximum readability, although 5.3 and 5.6 may be useful in understanding the various products of OOA and the conventions used for the various pieces of a specification, respectively."
The layout of these level products of OOA are descxibed below.
"Each object class is defined within its own paragraph, 6.1.11 (where ‘n’ is a number): its Data Model, Behavior Model, and Rocess Mo&l are documented."
The title to paragraph 6.1.n consists of the official mme of the object class.
Immediately following this title is the object class description.
"If the object class has a Behavior and/or Process Model, the Behavior Model Diagram and/or Process Model Diagram appear after Definitions."
"Summary consists of a summary of the object class: all attributes, derived attributes, events and processes are listed here without being defined."
"Also included is the primary identifier of the object class, along with any aliases by which the class is known."
"If the object class has a Behavior or Process Model, su zh is indicated."
Definitions contains all of the textual definitions relevant to the object class.
"It defines the attributes, derived attributes, events and processes (in this order)."
"Thus the Data Model is completely contained in Definitions (and is summarized in Summary), while just the textual def~tions associated with the Behavior Model and Process Model appear."
These diagrams document essential information; they are not mere summaries of information present e1sewheI.e in the specification.
"However, every item referenced on these diagrams is defined textually in Definitions of the source object class specification."
"With respect to the STD, signalled events, mggered processes and enabled processes are listed in Summary, and defined in Definitions."
"Consumed events are defined in the source object class specification, as are attributes and derived attributes appearing in boolean expressions."
The meaning of a state is taken to be self- evident from (and identical to) the context given in the STD; a textual description is not given.
"With respect to the DFD, signalled events, processes, and “outflow” attributes and derived attributes are listed in Summary, and defined in Definitions."
Consumed (“inflow”) attributes and derived attributes a~ defined in the source object class specifcation.
This event corresponds to a command from the AAMC to the DEFMC.
This event corresponds to a command from the AAMC to the VCWS.
"This process makes the selected attitude (pitch, bank, yaw) of the aircraft equal to the instantaneous actual attitude."
"This process commands the Effector-Controller to maintain the selected attitude (pitch, bank, yaw) of the aircraft, while at the same time allowing the Aft Flight Deck Crew to modify this selected attitude via control inputs."
"The AFCSE enables and disables the Automatic Flight Control System (AFCS), taking input only from the Forward Flight Deck Crew."
This event is signaled at the moment the AFCSE enables the AFD.
This event is signaled at the moment the AFCSE disables the FFD.
This event is signaled at the moment the AFCSE enables the FFD.
The Aft-Flight-Deck-Crew of the research pilots who fly the aircaft in the aft flight deck.
The control input which indicates the desired Bank Angle of the aircraft.
This event corresponds to a request to decrease the maintained or preselected airspeed.
"This event corresponds to a request to release control of the aircraft’s airspeed; i.e., a request to disengage the AIRSPDHMC."
"This event corresponds to a request to hold the current or preselected airspeed; i.e., a request to engage the AIRSPDHMC."
This event corresponds to a request to increase the maintained or preselected airspeed.
This event corresponds to a request to decrease the maintained or preselected altitude.
"This event corresponds to a request to hold the current or preselected altitude; Le., a request to engage the ALTHMC."
This event corresponds to a request to increase the maintained or preselected altitude.
"This event cornsponds to a quest to disengage the “Attitude Hold with Control Wheel Steering (CWS)” mode; Le., a request to disengage the ACWS Mode Controller."
This event corresponds to a quest to disable the automatic flight modes (the “Auto” Modes).
This event conesponds to a request to enable the automatic flight modes (the “Auto” Modes).
This event corresponds to a request to release automatic control of the throttle.
"This event corresponds to a request to engage the default mode of autopilot control, which might be the ACWS mode or the Manual Electric mode."
This event corresponds to a request to decrease the maintained or preselected flight path angle.
This event comesponds to a request to disengage the FTAHMC.
This event corresponds to a request to hold the current or preselected flight path angle.
This event corresponds to a request to increase the maintained or preselected flight path angle.
This event corresponds to a request to decrease the maintained or preselected ground track angle.
"This event corresponds to a request to release control of the aircraft's ground track angle; i.e., a request to disengage the GTAHMC."
"This event corresponds to a request to hold the current or preselected ground track angle; i.e., a request to engage the GTAHMC."
This event corresponds to a request to increase the maintained or preselected ground track angle.
"This event corresponds to a request to disengage the “Horizontal Path Guidance” mode; Le., a request to disengage the Horizontal Path Guide."
"This event corresponds to a request to engage the “Horizontal Path Guidance” mode, i.e., a request to engage the Horizontal Path Guide."
"This event corresponds to a request to disengage the “Time Path Guidance” mode; i.e., a request to disengage the Time Path Guide."
"This event cornsponds to a request to engage the “Time Path Guidance” mode; i.e., a request to engage the Time Path Guide."
"This event corresponds to a request to disengage the “Velecity Vector Hold with Control Wheel Steering (CWS)” mode; Le., a request to disengage the VCWS Mode Controller."
"This event corresponds to a request to engage the “Velocity Vector Hold with Control Wheel Steering (CWS)” mode; i.e., a request to engage the VCWS Mode Controller."
"This event corresponds to a request to disengage the “Vertical Path Guidance” mode; i.e., a request to disengage the Vertical Path Guide."
"This event corresponds to a request to engage the “Vertical Path Guidance” mode; i.e., a request to engage the Vertical Path Guide."
This is the current sensed position of the aileron.
This is the commanded airspeed which shall be attained.
This process displays the Actual-Airspeed of the aircraft.
This is the pilot-indicated airspeed which shall be maintained while the Airspeed-Hold_Mode_Controller is engaged.
This process makes the Selected-Airspeed attribute equal to the instantaneous Actual-Airspeed.
This process increases the current Selected-Airspeed by 5 knots.
This process decreases the current Selected-Airspeed by 5 knots.
This process makes visible the current state of this object.
Airspeed of the aircraft to match the Selected Airspeed.
"The Altitude-Hold-Mode-Controller, when engaged, generates steering commands so as to capam and hold a pilot-selected altitude."
It issues a vertical acceleration steering command.
This is the pilot-indicated altitude which shall be captured and held when the Altitude-Hold-Mode-ConController is engaged.
This is arithmetic difference between the actual and the select altitudes.
This is the commanded vertical acceleration of the aimaft which shall be attained.
"This event corresponds to a determination that the Altitude Hold Mode Controller must disengage, that is, release control of the aircraft."
This event corresponds to a determination that the Altitude Hold Mode Controller can successfully capture the Selected Altitude.
This process displays the Actual-Altitude of the aircraft.
This process displays the Selected-Altitude of the aircraft.
This process makes the Selected-Altitude attribute equal to the instantaneous Actual-Altitude.
This process increases the current Selected-Altitude by 50 feet.
This process decreases the current Selected-Altitude by 50 feet.
This process generates a vertical acceleration steering command so as to smoothly change the actual altitude of the aircraft to match the pilot- selected altitude.
This process monitors the difference between the Actual-Altitude of the aircraft and the Selected-Altitude.
"At the moment the difference is small compared to the vertical speed of the aircraft, this process signals the Engagement-Criteria-Satisfied event, so that the selected altitude may be captured."
"At the moment the difference exceeds the maximum expected during altitude hold, the Disengagement-Criteria-Triggered event is signalled by this process, so that the Capture-and-Hold process can be disengaged."
"That is, the definition here follows the ordinary usage."
This indicates whether the aircraft is allowed to land at the Airport under normal conditions.
This item determines how the airport is displayed to the human pilot.
This is the longitude of the official “location” of the airport as defined by a single point on the Earth’s surface.
It captures the information relevant to such an “ATC-Waypoint-onan-Airway-Route” is a somewhat artificial term created for clear from context).
"For that matter, the term “Waypoint” may refer to an ATCWFT or even an ATCWAR."
"Also, several of these pseudo external object classes might be split and joined."
The AUTOMC enables the engagement of the various “automatic flight modes”.
"A WFP of this type allows more than the usual, simple specification of an altitude or planned time of arrival; rather, altitude and airspeed constraints on a flight leg are recorded."
This constraint must be continually met during the whole of waypoint acquisition.
It applies to the cwfp-l-Airspeed-Value-for-Wpt-Acq.
This defines the airspeed for the aircraft for the whole of waypoint acquisition.
The attribute cwfp- 1 -Airspeed-Constrain t-for-Wpt-Acq defines what the aircraft must do with this value.
This constraint must be met just by the time the aircraft is actually at the waypoint.
This defines the altitude for the aircraft just when actually at the waypoint.
The attribute cwfp- 1-Altitude-Constraint-at-Wpt defines what the air& must do with this value.
Indicates the distance to the tangent point of the standard rate turn arc which is used to transition smoothly from the current leg to the next.
The Default Mode Controller controls the engagement and disengagement of the designated “default mode” (which is chosen by the AFD).
This event corresponds to a determination that the ACWS must disengage.
This event corresponds to a determination that the MANEL must disengage.
This event corresponds to a determination that the ACWS should engage.
This event cornsponds to a determination that the MANEL should engage.
This event cornsponds to the self-disengagement of the DEFMC.
The event is generated to let other objects in the system react as they will.
"The pmeeding WFT is known as the “inbound waypoint” of the dme arc, while this WFP is known as the “outbound waypoint”."
This is why the method of acquiring this WFP is said to be via a dme arc: that is the path in space between the two WFPs.
This attribute names the center of the circle used for the DME Arc acquisition.
"Note that in this analysis, where there may typically exist multiple coupled surfaces (e.g, upper and lower rudders), the surfaces are taken together as (logically) a single effector."
"For the interim, this object class provides a source and sink for closely related events and data."
The Elevator is one of the aerodynamic control effectors used to control the motion of the aircraft.
All elevator surfaces are taken together here to be (logically) a single effector.
This is the current sensed position of the elevator.
The Engine is one of the control effectors used to control the motion of the aircraft.
All the engines are taken together as a single entity.
The Forward-Flight-Deck-Crew consists of the safety pilots who fly the aircaft in the forward flight deck.
The control input which indicates the desired Pitch Angle of the aircraft.
The control input which indicates the desired Yaw Angle of the aircraft.
"The Forward-Flight_Deck_Control-Wheel-Steering-- Mode-Controller, while engaged, maintains the attitude of the aircraft by issuing commands to the Effector-Controller."
The FFDCWS allows the FFD-- Crew to change the attitude-being-maintained by I;esponding to wheeVcolumn inputs (or equivalent control inputs) while engaged.
"When fewer than four dimensions are specified, the remaining dimensions are unconstrained and are determined by the pilot or system “on the fly” during flight."
Different parts of the path may be specified in different numbers of dimensions.
"The path may contain so-called “discontinuities,” which arise due to modifications which delete part of the path."
"The AFD Crew specifies a Flight-Plan by listing an ordered sequence of Waypoints, possibly creating “pilot-defined” Waypoints in the process, but generally referencing pre-existing Waypoints."
"Whole strings of Waypoints may be specified in the creation process by referencing SIDs, STARs, Company Routes and/or Published Airway Routes (which themselves are ordered sequences of Waypoints)."
A list of Waypoints without additional information determines a two-dimensional Flight Plan.
"Additional constraints may be placed on individual Waypoints on the Flight Plan, such as specifying an Altitude (to form a 3-D Waypoint) and possibly a Planned Time of Arrival (to form a 4-D Waypoint); alternatively, SID/STAR-like constraints may be placed on a Waypoint (or such constraints copied from pre-existing SIDs and STARs may be modified)."
A “Flight Plan” as commonly thought of in the aviation community begins at a Runway at one Airport and ends at another Runway at another Airport.
"The intermediate stages that exist during creation and editing are also FP--Flight-Plans, strictly speaking (merely incomplete ones)."
This process allows the insertion and deletion of Waypoints in the provisional Flight Plan.
This process allows the pilot to insert whole strings of Waypoints into the provisional flight plan via reference to route entry/exit Waypoints.
"Any route known by the system can be used for this purpose: Published Airway Routes, Company Routes, as well as SXDs and STARS."
Deletion of a Waypoint in the middle of a Flight Plan shall create a “discontinuity” in the Flight Plan.
"This process allows two Waypoints in the provisional Flight Plan to be “joined,” wherein all Waypoints in between the two (if any) are deleted, and no discontinuity arises."
"The Flight-Path-Angle-Hold-Mode-Controller, engaged, generates steering commands so as to capture and hold a pilot-selected flight path angle."
It issues a vertical acceleration steering command to the Effector-Controller.
This process displays the Actual-Flight-Path-Angle of the aircraft.
This process displays the Selected-fight-Path-Angle.
This process makes the Selected-Flight-Path-Angle attribute equal to the instantaneous Actual-Flight-Path-Angle.
This process increases the current Selected-l?light-Path-Angle by 0.1 degrees.
This process decreases the current Selected-Night-Path-Angle by 0.1 degrees.
This process generates a vertical acceleration steering command so as to smoothly change the Actual Flight Path Angle of the aircraft to match the Selected Flight Path Angle.
It issues a bank angle steering command to the Effector-Controller.
This process displays the Actual-Ground-Track-Angle of the aircraft.
This process displays the Selected-Ground-Track-Angle of the aircraft.
This process increases the current Selected-Ground-Track-Angle by one degree.
This process decreases the current Selected-Ground-Track-Angle by one degree.
This process generates a bank angle steering command so as to smoothly change the Actual-Ground-Track-Angle of the aircraft to match the Selected-Ground-Track-Angle.
"The HPG, while engaged, generates steering commands that direct the ahraft to, and maintain it on, the horizontal projection of the Flight-Plan."
The HPG assumes the aircraft is near the leg between the first two waypoints of the flight plan.
This is the commanded bank angle which shall be attained.
"This event corresponds to a determination that the HPG must disengage, that is, release control of the aircraft."
This event corresponds to a determination that the HPG can successfully capture the horizontal component of the flight plan.
This event corresponds to the self-disengagement of the HPG.
The event is generated to let others in the system react as they will.
This event cornsponds to a determination that the aircraft is physically moving toward the capture envelope of the current Right Plan leg.
This event corresponds to a determination that the aircraft is physically moving away from the capture envelope of the c m n t Flight Plan leg.
This event corresponds to a determination that the “current leg” of the active flight plan is complete.
"This means that the first waypoint in the active flight plan should be deleted, and the aircraft should transition to the next leg."
This process determines whether the HPG can successfully capture the harimntal component of the flight plan.
"This process determines whether the HPG must disengage, that is, release control of the aircraft."
"This process determines whether the aircraft is progressing towards the first path of the active flight plan, raising a signal if so."
"This process steers the aircraft to, and maintains it on, the horizontal projection of the active flight plan."
The ILSGS object class represents the knowledge within the system that real ILS Ground Systems exist in the real world; members of the ILSGS object class represent the knowledge within the system of particular real-world ILS Ground Systems.
"In other words, this is NOT an external objezt class: the system does NOT communicate (directly) with physical, real-world ground-based equipment."
This is the name of the airport at which this ILS ground system is located.
This is the location above the surface of the Earth of the broadcast antenna.
"The ILS-On-Board-S ystem is an external, anonymous object class which can determine the deviation of the aircraft from the path defined via radio communication by a nearby ILS Ground System."
"The Manual-Electric-Mode_Controller, while engaged, provides mdimentaxy transformation of the AFD control inputs; the aimaft is essentially being flown manually."
This process provides rudimentary transformation of the AFD control inputs.
The MLSGS object class represents the knowledge within the system that real NLS Ground Systems exist in the real world.
This is the name of the airport at which this MLSGS is located.
"This is the location of the antenna which broadcasts distance information, specified relative to the Azimuth-Broadcast-Location."
This is the name of the runway which this MLSGS services.
"The MIS-Aircraft-S y stem is an external, anonymous object class which can determine the deviation of the aircraft Erom the path defined via radio communication by a nearby M L S Ground System."
"Every NAVAID is an example of an ATGWPT, that is, the NAVAID object class is subtype of the ATCWPT object class."
The navaid-Name is the official name designated by the FAA.
This is the height of the nav aid's broadcast antenna.
The par- 1-Number is the official designation of an official PAR Published-Airway-Routes are called out on air navigation charts.
"At the time of this writing, Published-Airway-Routes are divided into two categories (types): “low altitude routes” and “high altitude routes”, also known as “Victor Airways” and “Jet Airways” (respectively)."
"A short English description of the primary purpose for which this waypoint was created (e.g., “DIVE arc center”)."
"In this analysis, a Restricted-Area always takes the shape of a polygon, which is defined by its vertices (see Restricted-Area-Vertex)."
The id of the Restricted Area of which this is a vertex.
The position of this vertex in the sequential vertex list.
The line connecting this vertex with its successor defines one edge of the polygonal Restricted Area.
Numbering the vertices is necessary to unambiguously define the polygon.
The Rudder is one of the aerodynamic control effectors used to control the motion of the aircraft.
"A given strip of pavement (airstrip) plays the role, at different times, of two distinct Runways (e.g., 1OL and 28R)."
Thus the term “Runway” refers to one of the roles played by an airstrip rather than to the physical airstrip itself.
The name of the Airport at which this Runway is located.
The location on the surface of the earth over which the pilot must make his go-around decision.
"This is the official name of the Runway, which is determined by (1) its Magnetic-Heading, and (2) its position at the Airport relative to a runway parallel to it (if one exists)."
"In the format “nh”, ‘n’ is a sting of degrees; ‘h’ is either “L” OT “ R (for left-hand runway and right-hand runway, respectively)."
"If there is no parallel runway, then the ‘h’ is dropped."
Some of the data provided by the Sensor-Suite may be simply “passed through”.
The mapping from sensed data to SDF data is non-trivial.
The array of inputs from the sensor suite is not known at the time of this writing.
"This is the instantaneous longitudinal acceleration of the aircraft, where forward acceleration is positive."
"This is the instantaneous lateral acceleration of the aircraft, where acceleration towards the right wing is positive."
"This is the instantaneous ""vertical"" acceleration of the aircraft, where the vertical axis completes the right-hand coordinate system of the aircraft."
"The Sensor-Suite is a placeholder, an external object class used to provide a s plified source of sensed data until such time as this aspect of the system can be analyzed further."
The a m y of data provided by the Sensor-Suite (to the SDF) is not known; hence there are no definitions given for this object class of any &rived attributes.
"Rather, this object class serves merely to document the existence of some set of raw data, which can be used to derive the set of data provided by the SDF."
Note that external object classes which have already been modeled provide their own sensed data.
The SENS object class exists as a “catch-all” for sensed data which does not have a clear source at the time of this writing.
This is due to the fact that the system shall give maximum flexibility to the pilot as he or she constructs a Flight-Plan.
Maximum flexibility manifests itself as very generic behavior and processing for SIDs and STARs.
A Standard_Instrument_Departure_Procedun: is officially referred to as a SID.
A SDD is a published IF’R ATC departure procedure established by the FAA.
SIDs exist to reduce communication in the terminal area of an airport by providing a predefined transition route from a particular Runway to an appropriate en route structure.
"The ss-1-Name shall be the official, published SID name."
STAR is a published IFR ATC arrival procedure established by the FAA.
STARs exist to reduce communication in the terminal area of an airport by providing a predefined transition route from an en route structure to a particular Runway.
"The ss-1-Name shall be the official, published STAR name."
"Note that combining SIDs and STARs into a single SS object class did introduce a couple “wrinkles”: the introduction of the “Type” attribute, and the transitive dependence of “IAS Required“ on the key."
"However, the savings in terms of reduced complexity provided the impetus."
The Stabilizer is one of the aerodynamic control effectors used to control the motion of the aircraft.
"A Terrain Object known to the system can appear on a map display, for instance, or be used to validate a flight plan."
"The TPG, while engaged, generates steering commands that direct the aircraft to, and maintain it on, the time projection of the Flight-Plan."
The TPG assumes the aircraft is near the leg between the first two waypoints of the flight plan.
This is the commanded airspeed which the aircraft shall attain.
"This process steers the aircraft to, and maintains it on, the time projection of the active flight plan."
The VCWS allows the AFD-Crew to change the velocity-vector-being-maintained by responding to wheeYcolumn inputs (or equivalent control inputs) while engaged.
This process makes the selected velocity vector (flight path angle and ground track angle) of the aircraft equal to the instantaneous actual velocity vector.
"This process commands the Effector-Controller to maintain the selected velocity vector (flight path angle and ground track angle) of the aircraft, while at the same time allowing the Aft Flight Deck Crew to modify this selected velocity vector via control inputs."
"The VFG, while engaged, generates steering commands that direct the aircraft to, and maintain it on, the vertical projection of the Flight-Plan."
The VPG assumes the aircraft is near the leg between the first two waypoints of the flight plan.
This is the commanded vertical acceleration which shall be attained.
This event corresponds to a determination that the VPG can successfully capture the vertical component of the flight plan.
This event corresponds to the self-disengagement of the VPG.
This event corresponds to a determination that the aircraft is physically moving toward the vertical projection of the flight plan.
This event cornsponds to a determination that the aircraft is physically moving away from the vertical projection of the flight plan.
This process determines whether the VPG can successfully capture the vertical component of the flight plan.
"This process determines whether the VPG must disengage, that is, release control of the aircraft."
"This process determines whether the aircraft is progressing towards the first path of the active flight plan, raising a signal if not."
"This process steers the aircraft to, and maintains it on, the vertical projection of the active flight plan."
It captures the information relevant to such an association.
"The same Waypoint on a different Company Route may be assigned different data “Waypoint on a Company Route” is a somewhat artificial term created for the sake of clarity in this analysis; in general usage, the term “Waypoint” may refer to Waypoints, Waypoints on Company Routes, Waypoints on Flight Plans, or even Waypoints on SIDs or STARS (where the meaning is clear from the context)."
The id of the Company Route which the named Waypoint is on by means of this WCR.
The id of the Waypoint which is on the named Company Route by means of this WCR.
The id of the Flight-Plan which the named Waypoint is on by means of this WFP.
The manner in which the aircraft will move from the previous WFP to this WFP.
The id of the Waypoint which is on the named Flight-Plan by means of this WFP.
"As a vacuous object class, it's existence is justified only to complete the subtypes of WFP: it ensures that every WFP has a well-defined wfp-1-Type."
"A short English description of the location of the waypoint, typically the name of a nearby city."
This process allows the creation and deletion of Waypoints.
"If the Waypoint is &fined by the pilot via reference to existing Waypoint(s) (e+, SPO/30/30 or SPO/180/EAT/270), then the pilot-entered reference shall be used as the name."
"Likewise, if the Waypoint is defined by the pilot via latitude and longitude coordinates, then these coordinates shall be used as the name."
Note that pilots may not create ATC-- Named-Waypoints.
"The same Waypoint on a different SID or sake of clarity in this analysis; in general usage, the tenn “Waypoint” may refer from the context)."
"For that matter, the term Waypoint may refer to a Waypoint on a Flight Plan (see WFP)."
The attribute wss-1-Altitude-Constraint defines what the aircraft must do with this value.
The id of the SS which the named Waypoint is on by means of this wss.
The id of the Waypoint which is on the named SS by means of this wss.
See Section 5.6.2 for conventions of common domains.
This is the easvwest component of a distance from a point over the stward.
This is an X-Offset from the location of an Azimuth antenna.
This is a Y-Offset from the location of an Azimuth antenna.
This is a Y-Offset from the threshold of a runway at an airport.
This is a 2-Offset from the threshold of a runway at an airport.
This sub-section documents the system level models (see 5.3.2): the Object Class Relationship Model and the Object Class Communication Model.
"The existence relationships among object classes 511.e documented via the Object Class Relationship Diagram (OCRD) and, where further clarification is needed, with textual definitions."
"In the case of the TSRV flight control system, the OCRD suffices to specify the relationships."
Please note that a complete understanding of the relationships depicted in the OCRD depends on one’s understanding of the graphical conventions employed.
Only those object classes r e l a t e d t o other object classes a r e shown here.
"In the case of the TSRV flight control system, the approach was to develop multiple communication di each focusing on a related subset of the communications in the system."
"In order to maximize the scope of analysis on this project, the development of OCCDs was given a low priority, and only an example OCCD was generated."
The OCCD shown in Figure 6.2 specifies the communication among the objects relating to the higher level flight modes.
"This sub-section is intended to aid in determining where an identifier is defined or referenced Here “identifier” refers to the names of object classes, attributes, &rived attributes, events, processes and common domains."
This index includes entries for every significant piece of an identifier.
"For instance, the attribute “althmc-l-Selected-Altitude” appears in the index under its full name as well as “l-Selected-Altitude”, “Selected-Altitude” and “Altitude”."
A definition of a subset of the NASA Transport System Research Vehicle (TSRV) flight control system essential requirements was developed using the Boeing developed Object Oriented Analysis (OOA) requirements analysis methodology.
"The scope of the analysis was limited to the functionality included in the Flight ManagementfFlight Control (FM/FC) computer which hosts the navigation, guidance, and flight control software."
"In terms of depth, a significant portion of the essential requirements for the FM/FC software was specified with Data, Behavior, and Process Models."
Some requirements need further analysis to be fully specified.
Such requirements were captured via pseudo external object classes which serve as placeholders until they can be thoroughly analyzed.
Follow-on research activities might begin with extending the scope of the analysis in terms of both breadth and depth.
"In regards to depth, it would be beneficial to analyze the EM/FG software further to completely ferret out the essential requirements relating to portions of the flight control laws, the autoland capability, and the sensor data requirements."
This process may result in the specification of additional object classes and/or modifications of those already identified.
"In regards to breadth, additional analysis might address the quirements for the on-line simulated airplane capability, the interfaces to other research flight deck systems (e.g., the IC, HOLD, and RUN operating system modes), and the displays."
The specification of the display system requirements could be addressed in at least two ways.
One approach would be to perfom an analysis of the Displays host computer software functions similar to that of the analysis documented in this report.
The essential functionality could be integrated appropriately with the FM/FC functionality specified in this report or as extended per the abve recommendations.
"Alternatively, the requirements implemented in the displays host could be captured in a user interface document where the pilot(s) and the other inflight test personnel are viewed as “users” of the system."
"In this approach, the various pilot display formats and real-time data acquisition capabilities are considered to be a xesult of nonessential reformatting of the FM/FC essential data and could therefore be appropriately documented in a user interface document."
The goal of another potential follow-on activity might be to formulate a more rigorous mapping of the essential system requirements to the existing implementation.
This might take the farm of m m detailed Process Model mini- specs or merely some degree of cross-referencing of an essential system specification to the existing software documentation.
"Such a mapping might provide a better understanding of the current TSRV flight control system, however, a design focused specification could hinder innovative architecture development of a new system."
"Also, the complexity of an object-to-code mapping may limit its usefulness."
A final recommendation for future research addresses the development of alternate more advanced software architectures for modem transport flight control systems.
Architecture trade studies may be conducted on the system defined in this report or on any of its enhancements described above.
"In particular, artificial-intelligence based real-time architectures and related functions with expert systems, innovative integration of numeric and symbolic processing, the real-world technology-based requirements associated with failure modes and reliability issues, and the appropriate use of parallel and distributed processing."
"In summary, the essential system requirements specification presented here offers high visibility of the TSRV flight control system and may be readily extended to capture an increased set of existing system functionality and/or may be easily modified to accommodate new features, e.g., ones using expert system concepts."
"The Object Oriented Analysis methodology proved to be an effective approach to distill the essential requirements of a complex, integrated system and the information centered strategy was a useful one for backing out the requirements of an existing system."
"Frankovich, Major K., Pedersen, Ken, and Bemsteen, Stanley, ""Expert Dayton, OH, May 1985."
"Handelman, David A., and Stengel, Robert F., ""An Architecture For Conference, Minneapolis, MN, June 1987."
"Seward, Walter D., ""Task Allocation in a Distributed Computing System,"" Proc."
"Bruce, Kevin R., ""NASA B737 Flight Test Results of Total Energy Control System,"" Final Report, NASA CR-178285, January 1987."
"Goodwin, A.E., ""NASA 515 Flight Control System Description,"" D6- ""Advanced Transport Operating System Software Upgrade: Flight Managemenmight Controls Software Description,"" Computer Sciences Corporation, NASA CR-181936, January 1988."
"McMenamin, Stephen M., and Palmer, John F., Essential Svste ms Analvsis, Yourdon Press, 1984."
"Analysis: Building on the Structured Techniques,"" Proc."
"The Educational Foundation of the Data Processing Management Association), Washington D.C., November 29-30,1990."
"DeMarco, Tom, Structu red Analvsis and Svste m SD - ecification, Yourdon Press, 1979."
"Ward, Paul T., and Mellor, Stephen J., Struc tured Development for Real-Time Svste mg,"" Volumes 1 through 3, Yourdon Press, 1985."
"Shlaer, Sally, and Mellor, Stephen J., Obieet 0 riented Analvsis: Modeling the World in Da@ , Prentice Hall, 1988."
"Tockey, Steve, ""Using Off-the-shelf CASE Tools to Build Object Oriented Analysis Specifications,"" hoc."
"Structu red Develapment Forum, San Diego, CA, May 1-3,1990."
"The objective of this work is to analyze the baseline flight control system of the Transport Systems &search Vehicle (TSRV) and develop a system specification that offers high visibility of the essential system requirements in order to facilitate the future development of alternate, more advanced software architcctures."
"The flight control system is defined to be the baseline software for the TSRV research flight deck, including all navigation, guidance, and control functions, and primary pilot displays."
The C&ject Oriented Analysis (OOA) methodology developed by Boeing is used to develop a system requirements definition.
The scope of the mpkments definition contained herein is limited to a portion of the Flight Management/Hight Control computer functionality.
"The development of a partial system requirements definition is documented, and includes a discussion of the tasks required to increase the scope of the requirements definition and rrcomrnendations for follow-on research."
The Report Documentation Page (RDP) is used in announcing and cataloging reports.
"It is important that this information be consistent with the rest of the report, particularly the cover and title page."
Instructions for filling in each block of the form follow.
It is important to stay within the lines to meet optical scanning requirements.
"Symbols (circles, squares, and triangles) indicate the considered satellite product."
Empty symbols indicate clear sky conditions and filled symbols indicate cloudy conditions.
The color of the symbols is representative of the station environment.
The size of each symbol gives an idea of the bias (in absolute value).
"TsIR is for the ISCCP estimate, TsMW1 is for our retrieval, and TsMW2 stands for the retrieval from [RD-42]."
White triangles represent the LST-VI pairs from where the dry edge has been estimated.
"Far left, ideal LST-VI space; middle-left, sub-optimal space due to noise in the dry edge definition (low R2); images on the right side, non-valid LST-VI triangles caused by lack of enough points for the dry edge computation (middle -right) or in the LST-VI space (far-right)."
In-situ LST have been derived for the period 2004-2013 and are already available at the time of writing this report.
The ESA DUE GlobTemperature Technical Specification for land surface temperature (LST) provides the framework for the project.
"It scopes the user needs and thus the development of GlobTemperature output datasets, tools and documentation to firstly evaluate these outputs and then to deliver them to the user community."
"A quantified set of Technical Specifications have been determined to both guide the Project, and to facilitate an assessment of its success."
The process for deriving these specifications can be summarised.
"We took as input the set of User Requirements from the Requirements Baseline Document, and through analysis determined how the Project could meet each one and the most effective way of doing so."
"This brief overview of how these requirements could be achieved was expanded upon in more detail in Sections 4.2, 5, 6, and 8."
From these detailed accounts it has been possible to quantify a set of Technical Requirements which together fulfil the User Requirements.
"Moreover, both the User Requirements and the subsequent Technical Specifications have been mapped onto the suite of GlobTemperature deliverables ensuring full traceability of how the requirements will be met by the Project."
"Develop Climate Data Record of over 10-years for (A)ATSR in harmonised format with low bias, high precision, and high stability."
As default datafiles to be disseminated with mandatory variables only.
"The Technical Specification Document for the ESA DUE GlobTemperature project provides the framework for the project to follow in terms of the provision of user needs; the development of GlobTemperature output datasets, tools and documentation; the approach to assessing the success of the delivered output products through the mechanism of the User Case Studies; and the quality of these products through the application of a robust and traceable validation and intercomparison procedure."
It will also consolidate a physical nomenclature to describe land surface temperature (LST).
"More specifically, a summary of the user requirements and implications for LST; a determination and justification for the GlobTemperature product portfolio including a trade-off analysis, specifications of the products and web portal specifications; validation protocols and high level summaries of current results; and work plans for the user case studies."
The backbone of the Technical Specification is to provide traceability from the User Requirements through to the delivered suite of GlobTemperature products.
This document will be iterated with the International Land Surface Temperature and Emissivity Working Group (ILSTE-WG) with feedback obtained following user consultation; with further releases therefore scheduled.
"Furthermore, it is expected that these aspects will directly contribute to all documents produced within the framework of GlobTemperature: the physical nomenclature (Section 2.1) will form part of the LST White paper (DEL-28) [AD-6]; the validation and intercomparison protocols (Section 5) will link such activities with the ILSTE-WG and with the LST White Paper [AD-6] - the protocols themselves appear both here (Section 5.1 and Appendix B – Detailed categorisation of the LST Validation GlobTemperature products."
The User Case Study work plans provide the framework for which to channel resources in evaluating the value of the GlobTemperature products to user applications (Section .
This document will additionally provide high-level summaries for the evolving GlobTemperature presentation pack for internal and more importantly for external use.
The title of each main chapter is shown in Figure 1.
An essential point is that the Technical Specifications Document has some important interactions which are also shown in the figure.
"It is of particular note that a summary of the Requirements Baseline Document [AD-3] is an input to this document, as is the validation and inter-comparison protocol."
The algorithm trade-off analysis summary (Section 6.3) GlobTemperature developments to provide recommendations for retrievals in GlobTemperature products; a full algorithm trade-off analysis is presented in [AD-5].
Physical nomenclature definitions (Section 2.1) will be iterated with the ILSTE-WG whose role will be also be defined.
"Definitions include, amongst others, the following key parameters in land surface temperature: LST; land surface air temperature (LSAT); skin temperature; soil temperature; radiometric temperature; thermodynamic temperature; angular anisotropy; emissivity; biome; fractional vegetation cover; land cover class; satellite zenith angle; solar zenith angle."
"Finally, the document concludes with a set of targets for GlobTemperature which include data set availabilities, publications, users, and international meetings and conferences."
This is a living document in that further versions will include updates to the Technical Specifications based on feedback obtained throughout the life cycle of the Project.
Such feedback will be collated following meetings of the International LST & Emissivity Working Group (ILSTE-WG) and the User Consultation Meetings (UCMs) thus providing a mechanism over which the Project will evolve to meet the requirements of the user community.
"Section 8.5 provides in tabulated form the necessary traceability from the User Requirements [AD-3] to the list of enumerated Technical Specifications, and thence through to the GlobTemperature deliverables."
"Joint Commitee for Guides in Metrology, Evaluation of Measurement Data - Guide to the Expression of Uncertainty in Measurement."
"Privette, and P. Guillevic, Modeling the observed angular anisotropy of land surface temperature in a savanna."
"IEEE Transactions on Geoscience and Remote Sensing, 2006."
"Vinnikov, K.Y., et al., Angular anisotropy of satellite observations of land surface temperature."
"Schneider, P., et al., Land Surface Temperature Validation Protocol (Report to European Space Agency)."
The surface temperatures of Earth: steps towards integrated understanding of variability and change.
"Schaepman-Strub, G., et al., Reflectance quantities in optical remote sensing—definitions and case studies."
"AMS, American Meteorological Society Glossary of Meteorology [Available online at http://glossary.ametsoc.org/wiki/”term”]."
"Wan, Z. and J. Dozier, A generalized split-window algorithm for retrieving land surface temperature from space."
"IEEE Transactions on Geoscience and Remote Sensing, 1996."
"CEOS, Committee on Earth Observation Satellites (http://www.ceos.org/)."
"Pinheiro, A., C. Prigent, and W. Rossow, International Workshop on the Retrieval and Use http://rain.atmos.colostate.edu/GDAP/reports/NCDC-LSTWorkshopReport_final.pdf, 2008."
"Ghent, D., LST User Exploitation Document: A review of the applications of current satellite-derived Land Surface Temperature (LST) products and a synthesis of user requirements (Report to European Space Agency)."
"Remedios, J.J. and N. Humpage, Sentinel Convoy for Land Applications: Workshop Report."
"Ghent, D., et al., Advancing the AATSR land surface temperature retrieval with higher resolution auxiliary datasets: Part B – validation."
"Galve, Temperature-based and radiance-based validations of the V5 MODIS land surface temperature product."
"Journal of Geophysical Research- Atmospheres, 2009."
"Olesen, and A. Bork-Unkelbach, Validation of temperature derived from MSG/SEVIRI with in situ measurements at Gobabeb, Namibia."
"CF Conventions, NetCDF CF Metadata Conventions (http://cfconventions.org/)."
"Llewellyn-Jones, D., et al., AATSR: Global-change and surface-temperature measurements from Envisat."
"Esa Bulletin-European Space Agency, 2001(105): p. 11-21."
"Sobrino, ENVISAT/AATSR derived land surface temperature over a heterogeneous region."
"Coll, C., et al., Ground measurements for the validation of land surface temperatures derived from AATSR and MODIS data."
"Noyes, E.J., Technical Assistance for the Validation of AATSR Land Surface Temperature Products, Final Report - February 2006 (Report to European Space Agency)."
"Ghent, D., et al., Advancing the AATSR land surface temperature retrieval with higher resolution auxiliary datasets: Part A – product specification."
"Arino, O., et al., GlobCover: ESA service for Global land cover from MERIS."
"Igarss: 2007 Ieee International Geoscience and Remote Sensing Symposium, Vols 1-12: Sensing and Understanding Our Planet."
"Baret, F., et al., GEOV1: LAI and FAPAR essential climate variables and FCOVER global time series capitalizing over existing products."
"Veal, K.L., et al., Final Report on progress towards a Surface Temperature Dataset for the Polar Regions from ATSR (Report to Department of Energy and Climate Change)."
The detection of cloud-free snow-covered areas using AATSR measurements.
"Bulgin, C.E., et al., Cloud Clearing Techniques over Land for Land Surface Temperature Retrieval from the Advanced Along Track Scanning Radiometer."
"Marsham, J.H., Lake Temperatures - thermal remote sensing and assimilation into a lake model."
"Merchant, Surface water temperature observations of large lakes by optimal estimation."
"Saunders, R., et al., RTTOV8 - Science and Validation Report."
"University of Edinburgh, School of GeoSciences / European Space Agency."
"Lehner, B. and P. Doll, Development and validation of a global database of lakes, reservoirs and wetlands."
"Bulletin of the American Meteorological Society, 2011(93): p. S18-S19."
"Aires, F., et al., A new neural network approach including first-guess for retrieval of atmospheric water vapor, cloud liquid water path, surface temperature and emissivities over land from satellite microwave observations."
"Rossow, Land surface microwave emissivities over the globe for a decade."
"Bulletin of the American Meteorological Society, 2007."
"Rossow, Land surface skin temperatures from a combined analysis of microwave and infrared satellite observations for an all-weather evaluation of the differences between air and skin temperatures."
"Catherinot, J., et al., Evaluation of ""all weather"" microwave-derived land surface Atmospheres, 2011."
"Holmes, T.R.H., et al., Land surface temperature from Ka band (37 GHz) passive microwave observations."
"Journal of Geophysical Research: Atmospheres, 2009."
"Moncet, J.L., et al., Land surface microwave emissivities derived from AMSR-E and MODIS measurements with advanced quality control."
"Journal of Geophysical Research- Atmospheres, 2011."
"Schmetz, J., et al., An introduction to Meteosat Second generation (MSG)."
"Bulletin of the American Meteorological Society, 2002a."
"Schmetz, J., et al., Radiometric performance of SEVIRI."
"Bulletin of the American Meteorological Society, 2002b."
The Satellite Application Facility on Land Surface Analysis.
"Freitas, S.C., et al., Quantifying the Uncertainty of Land Surface Temperature Retrievals From SEVIRI/Meteosat."
"Trigo, I.F., et al., An assessment of remotely sensed land surface temperature."
"DaCamara, Emissivity Maps to Retrieve Land-Surface Temperature from MSG/SEVIRI."
"Verger, A., et al., Prototyping of Land-SAF leaf area index algorithm with VEGETATION and MODIS data over Europe."
"Borbas, E.E., et al., A Global infrared Land Surface Emissivity Database and its validation."
"Symposium on Integrated Observing and Assimilation Systems for Atmosphere, Oceans, and Land Surface, 11th, San Antonio, TX, 14-18 January 2007."
"American Meteorological Society, Boston, MA, 2007, Paper P2.7, 2007."
"Freitas, S.C., et al., Land surface temperature from multiple geostationary satellites."
"The operational IASI Level 2 processor, in Atmospheric Remote Sensing: Earth's Surface, Troposphere, Stratosphere and Mesosphere - I, J.P. Burrows and K.U."
"Zhou, D.K., et al., Global Land Surface Emissivity Retrieved From Satellite Ultraspectral IR Measurements."
"IEEE Transactions on Geoscience and Remote Sensing, 2011."
"August, T., et al., IASI on Metop-A: Operational Level 2 retrievals after five years in orbit."
"Journal of Quantitative Spectroscopy & Radiative Transfer, 2012."
"Hoyer, Arctic surface temperatures from Metop AVHRR compared to in situ ocean and land data."
Thermal-based techniques for land cover change detection using a new dynamic MODIS multispectral emissivity product (MOD21).
"EUMETCast, (http://www.eumetsat.int/home/main/dataaccess/eumetcast/index.htm)."
"S3_L2_ADF, Sentinel-3 Level-2 Auxiliary Data File Project."
"Li, Radiance-based validation of the V5 MODIS land-surface temperature product."
"Ghent, D., Land Surface Temperature Validation and Algorithm Verification (Report to European Space Agency)."
"Veal, K.L., et al., A time series of mean global skin-SST anomaly using data from ATSR-2 and AATSR."
"Hulley, Validation of six satellite-retrieved land surface emissivity Environment, 2012."
"Hook, Intercomparison of versions 4, 4.1 and 5 of the MODIS Land Surface Temperature and Emissivity products and validation with measurements of sand samples from the Namib desert, Namibia."
"Jimenez-Munoz, J.C., et al., Temperature and Emissivity Separation From MSG/SEVIRI Data."
"Geoscience and Remote Sensing, IEEE Transactions on, 2014."
"Wang, K., et al., Estimation of surface long wave radiation and broadband emissivity using temperature/emissivity products."
"Journal of Geophysical Research: Atmospheres, 2005."
"Cheng, J. and S. Liang, Estimating the broadband longwave emissivity of global bare soil from the MODIS shortwave albedo product."
"Journal of Geophysical Research: Atmospheres, 2014."
"Seemann, S.W., et al., Development of a global infrared land surface emissivity database for application to clear sky sounding retrievals from multispectral satellite radiance measurements."
"Journal of Applied Meteorology and Climatology, 2008."
"Parkes, I.M., et al., AATSR Validation Implementation Plan Part 1 - AATSR Validation Principles and Definitions ( No."
"Schneider, P., et al., SLTSR and SLSTR LST Validation Site Requirements (UL-NILU-ESA-LST- VSR Issue 1 Revision 0)."
Thermal Infrared Emissivity for Some Natural Surfaces from Experimental Measurements.
"Fox, CEOS comparison of IR brightness temperature measurements in support of satellite validation."
Part I: Laboratory and ocean surface temperature comparison of radiation thermometers.
"Schädlich, S., F. Göttsche, and F.-S. Olesen, Influence of land surface parameters and atmosphere on METEOSAT brightness temperatures and generation of land surface temperature maps by temporally and spatially interpolating atmospheric correction."
"Long, SURFRAD—A National Surface Radiation Budget Network for Atmospheric Research."
"Bulletin of the American Meteorological Society, 2000."
"Li, S., et al., Evaluation of 10 year AQUA/MODIS land surface temperature with SURFRAD observations."
"Yunyue, Y., et al., Validation of GOES-R Satellite Land Surface Temperature Algorithm Using SURFRAD Ground Measurements and Statistical Estimates of Error Properties."
"Geoscience and Remote Sensing, IEEE Transactions on, 2012."
The Atmospheric Radiation Measurement (ARM) Program: Programmatic Background and Design of the Cloud and Radiation Test Bed.
"Bulletin of the American Meteorological Society, 1994."
"Xu, H., et al., Evaluation of GOES-R Land Surface Temperature Algorithm Using SEVIRI Satellite Retrievals With In Situ Measurements."
"IEEE Transactions on Geoscience and Remote Sensing, 2013."
"Wang, K. and S. Liang, Evaluation of ASTER and MODIS land surface temperature and emissivity products using long-term surface longwave radiation observations at SURFRAD sites."
"Hook, S.J., et al., Retrieval of Lake Bulk and Skin Temperatures Using Along-Track Scanning Radiometer (ATSR-2) Data: A Case Study Using Lake Tahoe, California."
"Journal of Atmospheric and Oceanic Technology, 2003."
"Thermal Infrared Data From ASTER and MODIS on the Terra Spacecraft Using the Lake Tahoe, CA/NV, USA, Automated Validation Site."
"Cook, C., G. Orlob, and D. Huston, Simulation of wind-driven circulation in the Salton Sea: implications for indigenous ecosystems."
"Sellers, A global climatology of albedo, roughness length and stomatal-resistance for atmospheric general-circulation models as represented by the Simple Biosphere model (SiB)."
"Randel, D.L., et al., A new global water vapor dataset."
"Bulletin of the American Meteorological Society, 1996."
The ERA-Interim reanalysis: configuration and performance of the data assimilation system.
"Quarterly Journal of the Royal Meteorological Society, 2011."
"Li, A physics-based algorithm for retrieving land-surface emissivity and temperature from EOS/MODIS data."
"IEEE Transactions on Geoscience and Remote Sensing, 1997."
"Sommer, Simultaneous land surface temperature-emissivity retrieval in the infrared split window."
"Galve, J.A., et al., An atmospheric radiosounding database for generating land surface temperature algorithms."
"IEEE Transactions on Geoscience and Remote Sensing, 2008."
"Collard, A., E. Pavelin, and P. Weston, NWP-SAF Met Office 1D-Var Product Specification, l. EUMETSAT, Editor 2012."
"Saunders, R. and B. Conway, NWP-SAF 1D-Var Overview, U. EUMETSAT, Editor 2004."
"SEN4LST Teams, SEN4LST Validation Report (SEN4LST_DL4)."
"Cresswell, M.P., et al., Estimating surface air temperatures, from Meteosat land surface temperatures, using an empirical solar zenith angle model."
"Cristobal, J., M. Ninyerola, and X. Pons, Modeling air temperature through a combination of remote sensing and GIS data."
"Kilibarda, M., et al., Spatio-temporal interpolation of daily temperatures for global land areas at 1 km resolution."
"Vancutsem, C., et al., Evaluation of MODIS land surface temperature data to estimate air temperature in different ecosystems over Africa."
"Jimenez, C., et al., Global intercomparison of 12 land surface heat flux estimates."
"Mueller, B., et al., Evaluation of global observations-based evapotranspiration datasets and IPCC AR4 simulations."
The Surface Energy Balance System (SEBS) for estimation of turbulent heat fluxes.
"McCabe, M., et al., Global scale estimation of land surface heat fluxes from space: product assessment and intercomparison."
Remote Sensing of Energy fluxes and Soil Moisture Content.
"Bleck, R., An oceanic general circulation model framed in hybrid isopycnic-Cartesian coordinates."
The HYCOM (HYbrid Coordinate Ocean Model) data assimilative system.
"Hunke, E.C., Viscous-plastic sea ice dynamics with the EVP model: Linearization issues."
"Rothrock, Modeling global sea ice with a thickness and enthalpy distribution model in generalized curvilinear coordinates."
"Schmugge, T., Remote Sensing of Surface Soil Moisture."
"Wang, K., Z. Li, and M. Cribb, Estimation of evaporative fraction from a combination of day and night land surface temperatures and NDVI: A new method to determine the Priestley– Taylor parameter."
"Minacapilli, M., M. Iovino, and F. Blanda, High resolution remote estimation of soil surface water content by a thermal inertia approach."
Modelling and model verification of the spectral reflectance of soils under varying moisture conditions.
"Ceccato, P., et al., Detecting vegetation leaf water content using reflectance in the optical domain."
"Moran, M.S., et al., Estimating soil moisture at the watershed scale with satellite-based radar and land surface models."
"Sandholt, I., K. Rasmussen, and J. Andersen, A simple interpretation of the surface temperature/vegetation index space for assessment of surface moisture status."
"Gillies, and T.J. Schmugge, An interpretation of methodologies for indirect measurement of soil water content."
"Carlson, T.N., E.M. Perry, and T.J. Schmugge, Remote estimation of soil moisture availability and fractional vegetation cover for agricultural fields."
"Sun, L., et al., Monitoring surface soil moisture status based on remotely sensed surface temperature and vegetation index information."
"Moran, M.S., et al., Estimating crop water deficit using the relation between surface-air temperature and spectral vegetation index."
"Price, J.C., Using spatial context in satellite data to infer regional scale evapotranspiration."
"Geoscience and Remote Sensing, IEEE Transactions on, 1990."
"Stisen, S., et al., Estimation of diurnal air temperature using MSG SEVIRI data in West Africa."
"Hassan, Q., et al., A Wetness Index Using Terrain-Corrected Surface Temperature and Normalized Difference Vegetation Index Derived from Standard MODIS Products: An Evaluation of Its Use in a Humid Forest-Dominated Region of Eastern Canada."
"Merlin, O., et al., Disaggregation of SMOS Soil Moisture in Southeastern Australia."
"Stisen, S., et al., Combining the triangle method with thermal inertia to estimate regional evapotranspiration — Applied to MSG-SEVIRI data in the Senegal River basin."
The thermal inertia approach to mapping of soil moisture and geology.
"Proud, S.R., et al., A comparison of the effectiveness of 6S and SMAC in correcting for atmospheric interference of Meteosat Second Generation images."
"Journal of Geophysical Research: Atmospheres, 2010."
"Rahman, H. and G. Dedieu, SMAC: a simplified method for the atmospheric correction of satellite measurements in the solar spectrum."
"Schaaf, C.B., et al., First operational BRDF, albedo nadir reflectance products from MODIS."
The Normalization of Surface Anisotropy Effects Present in SEVIRI Reflectances by Using the MODIS BRDF Method.
"Fensholt, R. and I. Sandholt, Derivation of a shortwave infrared water stress index from MODIS near-and shortwave infrared data in a semiarid environment."
"Verbesselt, J., et al., Detecting trend and seasonal changes in satellite image time series."
"MyOcean, Ocean Monitoring and Forecasting http://www.myocean.eu/."
"ISCCP, International Satellite Cloud Climatology Project http://isccp.giss.nasa.gov/."
"CEOS-LPV, Land Product Validation (LPV) sub-group of the CEOS Working Group on Calibration and Validation (WGCV) http://lpvs.gsfc.nasa.gov/."
"GHRSST, Group for High Resolution Sea Surface Temperature https://www.ghrsst.org/."
"ESA DUE, ESA Data User Elements Programme http://due.esrin.esa.int/."
"ESA CCI, ESA Climate Change Initiative Programme http://www.esa-cci.org/."
"AVHRR Polar Pathfinder, Advanced Very High Resolution Radiometer (AVHRR) Polar Pathfinder http://nsidc.org/."
The MODIS Snow and Sea Ice Global Mapping Project http://modis-snow-ice.gsfc.nasa.gov/.
"IPCC, Intergovernmental Panel on Climate Change http://www.ipcc.ch/."
"WMO, World Meteorological Organization http://www.wmo.int/pages/index_en.html."
"GEWEX, Global Energy and Water Exchanges Project http://www.gewex.org/."
"OSI-SAF, EUMETSAT Ocean & Sea Ice Satellite Application Facility http://www.osi-saf.org/."
"NOAA-NCDC, National Oceanic and Atmospheric Administration - National Climatic Data Center http://www.ncdc.noaa.gov/."
Validation of Operational Land Surface Temperature Products with Three Years of Continuous In-Situ Measurements.
Validation of Land Surface Temperatures Obtained from Meteorological Satellite Conference.
"Hall, D., et al., Comparison of satellite-derived and in-situ observations of ice and snow surface temperatures over Greenland."
"Quarterly Journal of the Royal Meteorological Society, 2005."
A key aspect of GlobTemperature is to standardise terminology and data for ease of use by the user community.
Section 2.1 details a first attempt at defining a common nomenclature for LST science.
"The governance of such standardisation is to be overseen by an international group of LST experts, users of LST, and representatives of the space agencies (Section 0)."
This group will provide an independent source of advice and appraisal for LST documentations and data.
"A variety of definitions exists for terms associated with the retrieval, validation and exploitation of land, lake and ice surface temperatures."
No single resource exists which attempts to draw together all the applicable terms with community agreed definitions.
The objective is for developers and users alike to utilise this nomenclature as a reference independent of satellite / airborne / ground instrumentation and retrieval methodology.
"As a baseline, the definitions are first collated from the growing source of literature on LST."
"For LST validation, for instance, several definitions are adopted from [RD-1], which is the standard for Metrology nomenclature."
"In order to achieve community acceptance of the nomenclature presented here, the definitions are to be iterated with International LST & E Working Group (ILSTE-WG); this being a representative sample of the view of the wider data provider, LST expert, and user communities."
"Furthermore, liaison with the Land Product Validation (LPV) sub-group of the Committee on Earth Observation Satellites (CEOS) Working Group on Calibration and Validation (WGCV), both directly and through contacts within the ILSTE-WG aim to promote this nomenclature for inclusion in the first LPV “Best Practices Guide for LST”, which is still to be defined."
"While some of these terms may be more qualitative than the more precise mathematical terminology as presented in [RD-1], their use is now so embedded in the psyche of the LST data provider and user communities it is pertinent to provide a unified definition of these terms so as to ensure consistency within this field."
"Individuals who require a precise mathematical definition of thermal remote sensing properties, such as directional and hemispherical radiometric temperatures, or directional and hemispherical emissivities, are referred to [RD-2]."
Rather the objective here is to provide a nomenclature that both LST experts and LST users can identify and adopt to facilitate improved communication (addresses requirement REQ-28-TR).
GlobTemperature will provide a foundation for collaboration and international progress.
"To further advance these common themes, a new group has been founded with the support of GlobTemperature in its first three years."
"WG) is becoming a truly international initiative providing a unifying, collaborative element in the LST community bringing together users with producers and providers of data."
The ILSTE-WG has been founded jointly by a number of LST experts: representatives of NASA-JPL and members of the ESA GlobTemperature Team (specifically U. Leicester in the UK and IPMA in Portugal).
The ILSTE-WG Steering Committee has been formed with agency representatives and LST experts and the first meeting was held on 6th June 2014.
"The Steering Committee is responsible for agreeing the Terms of Reference of the Group, planning for the General Meetings, and providing the leadership."
"The structure of the ILSTE-WG is presented in Figure 2, which additionally s early-identified projects, which would benefit from the oversight of the ILSTE-WG."
"Further projects have been added to list, such as the ECOSTRESS Project run by NASA-JPL."
General Meetings take place bi-annually alternating between Europe GlobTemperature User Consultation Meetings) and North America (during a large conference such as AGU); with Steering Committee teleconferences taking place every three to six months.
To address these themes a number of task-orientated groups are being considered.
These would focus on such particular elements of LST and Emissivity work.
"Where feasible, individuals external to the GlobTemperature Project Team from the ILSTE-WG General membership are identified and approached to review specific deliverables (deliverable sections)."
In the interest of international buy-in and cooperation the ILSTE-WG will also be a focus for review on other related international LST projects.
"However, it must be stated that since the ILSTE-WG operates on a “best efforts” basis for most members the review of deliverables is entirely on the goodwill of international colleagues, and the maintenance and growth of the community takes priority."
Current membership is outlined in Appendix A – International LST & E Working Group Membership.
A primary purpose of the GlobTemperature Technical Specification is to document the strategy of delivering products which meet the requirements quantified following the User Requirements Survey.
A key aspect here is traceability from these User Requirements through to the GlobTemperature outputs.
In this section a brief overview of the User Requirements process is presented with the implementation detailed in Section 3.2.
"The Requirements Baseline Document version 0 (DEL-05) [AD-3] undertook the following forms of assessment of user requirements for LST: review of previous user requirements documents including the NASA white paper on LST and Emissivity Needs [RD-12], the LST User Exploitation document [RD-13] and the Sentinel Convoy for Land Applications report [RD-14]; an evaluation of user requirements from the questionnaires completed during the first User Consultation Meeting for GlobTemperature (UCM#1) [RD-15]; and the development, distribution and analysis of a new survey on user requirements completed by eighty respondents across the globe."
From this assessment a comprehensive list of user requirements for best practice in LST data provision was compiled.
The User Requirements defined from the results of the User Survey have been augmented with updates following mini-questionnaires carried out during breakout sessions.
The codes ‘TR’ and ‘BR’ in the requirement specification refer to ‘threshold’ and ‘breakthrough’ respectively; whereby threshold requirements indicate the limit beyond which data would be of no use for their application; and breakthrough requirements which indicate the level at which significant improvement to the given application would be achieved.
Where questions did not permit different levels to be specified then requirements were considered to be at the threshold level.
It is pertinent here to briefly summarise the methodology for determining these requirements.
To assess whether a GlobTemperature requirement could be quantified then three options were available.
"First, the responses were evaluated to see whether a ‘hard’ requirement could be issued on the basis of 75 % or more of participants agreeing on a particular option or where a particular specification would satisfy to whether a requirement based on a majority response could be issued."
This type of requirement is appropriate where respondents could only select a single response from a range of options.
"Finally, if this type of requirement could not be issued, a decision could be made to construct a ‘soft’ requirement."
This type of requirement was best suited to multiple choice questions where participants could select a range of options that they felt were applicable to their use of LST data.
If none of these types of requirement could be constructed then no requirement was issued.
"Once a requirement was identified then it was first checked against the outcomes of the first user consultation meeting (UCM#1) for agreement, differences or contradictions."
Agreement and differences that are a natural refinement of the requirement were d in the comments column of the requirements table.
"Where a contradiction occurred, the outcomes from both UCM#1 and the current survey were weighed to construct the final requirement, which was justified in the comments section of the requirements table along with a description of the discrepancy."
This process described related to threshold levels specified by respondents.
"Where the information was provided, the same process was reiterated with breakthrough level specifications."
"These were also included in the requirements table but are acknowledged as currently being more difficult to meet than the threshold requirements, primarily due to limitations in instrument capabilities rather than data production."
Provide LST data at a spatial resolution of 1 km or finer.
Provide LST data at a temporal resolution of day/night (12 hours) or less.
Provide an LST uncertainty budget split into a number of different components eg.
Provide LST data with a precision of 1 K or better.
Provide LST data with a stability of 0.3 K per decade or better.
Provide surface emissivity assumed in the LST retrieval as an ancillary data field.
Provide LST data with individual file sizes of 200 MB or less.
Provide LST data with timeliness for new observations of 24 hours.
Provide the timeliness specified in REQ-12-TR for 99 % of observations.
Provide dataset updates for reprocessing and algorithm development not more than once a month.
Provide LST users with email alerts about data availability and reprocessing.
Establish a single file specification covering all metadata requirements.
"Provide spatially averaged GEO, LEO or combined products in merged data at a resolution of 0.05 degrees or less."
"Provide temporally averaged GEO, LEO or combined products in merged data at a resolution of 3 hours or less."
Provide a detailed description of externally linked datasets within a data portal.
Provide links to product specification documents for LST products.
Provide gridded LST products with both regular latitude-longitude and equal area projections.
For averaged LST products timescales of day/night or 24 hours should be applied.
"Provide LST data at 0000, 0600, 1200, 1400 and 1800 local time."
Provide LST data at an hourly resolution for UTC times.
Establish a common nomenclature for the expression of error and uncertainty terms and provide information on the definition of terms.
"Provide uncertainty information as confidence intervals, estimated root mean square total error or estimated mean and standard deviation of total error."
Provide the 95 % confidence interval with confidence level information.
Provide detailed flags for quality checks and statistics of data comparison with reference to in-situ validation data.
"Provide information on 2 m air temperature, aerosol affected pixels, the diurnal cycle and data adjustment."
"Provide land cover type, fraction of vegetation cover, albedo assumed in the retrieval and NDVI with LST data."
Provide descriptions of dataset length and coverage and a link to the main provider web page for data accessed via a portal.
"Provide dataset validation reports, detailed descriptions of file content and dissemination options and interactive map services for LST data."
"Provide tools for data reading and sub-setting, data extraction on different grids, data compositing, generation of match-up datasets, data visualisation tools, data inter-comparison tools, data processing tools, data analysis tools, trend analysis and tools for visualisation and evaluation of data uncertainties and quality."
"Provide LST data from single sensors, instrument series and merged products."
Provide merged data both with and without gap filling.
Provide LST data at a spatial resolution of < 1 km.
Provide data at a temporal resolution of 3 hours or less.
Provide LST data with a precision of 0.1 K or better.
Provide LST data with a stability of 0.1 K per decade or better.
In each sub-section where the implementation of a requirement is described then this is clearly indicated to provide additional traceability.
"Level-3 single-sensor datasets for (A)ATSR, Metop-AVHRR, and MODIS will be provided for day/night (12 hours) at standard temporal resolutions."
Both the (A)ATSR single-sensor dataset and the (A)ATSR Climate Data Record will span over 10 years.
The proposed harmonised format distinguishes between the different components of the LST pixel uncertainty.
"Existing single-sensor datasets – AATSR [RD-16], MODIS [RD-17] and SEVIRI [RD-18] have been shown to produce LST data with a bias of ≤ 1 K. Each of these datasets will be disseminated via the GlobTemperature Data Portal in harmonised format."
"Furthermore, the objective of the (A)ATSR Climate Data Record is to reduce existing bias further."
Existing single-sensor datasets – MODIS [RD-17] have been shown to produce LST data with a precision of ≤ 1 K. Both these datasets will be disseminated via the GlobTemperature Data Portal in harmonised format.
"Furthermore, the objective of the (A)ATSR Climate Data Record is to further improve precision."
The (A)ATSR LST Climate Data Record aims to deliver a dataset with very high stability.
"Quantification of this currently remains unknown, although the 0.3 K is seen as a minimum goal (for SST the ARC product has a stability of better than 0.05 K per decade)."
The proposed harmonised format for Level-2 products specifies cloud-screening information as a mandatory component of the Quality Control flags.
The proposed harmonised format identifies surface emissivity assumed in the LST retrieval as an ancillary data field.
"For single-sensor datasets which explicitly exploit surface emissivity in their retrieval, such as MODIS, this will be provided as mandatory information."
The choice of netCDF-4 as the format preferred by the user community allows for high-level of internal compression of datafiles with no difference in read performance to uncompressed files.
"As such, all Level-2 and Level-3 will be able to be provided with individual file sizes less than 200 MB."
Access to LST data will be provided via dedicated FTP download from temporary user workspaces.
"These temporary user workspaces will be created when users place bulk orders for data via the Data Portal, with files deleted after a period of two weeks."
The aim for the demonstration NRT project is to provide the majority of data at the objective timeliness described in REQ-12-TR.
Once a dataset is released to the user community via the Data Portal any further evolution of the algorithm and re-processing will be subject to a minimum period of one month being enforced between releases.
In reality it is not foreseen that progressive releases of the same dataset will occur at such a high frequency as once a month.
Users are currently being informed of upcoming events and new releases of components of the GlobTemperature Website / Data Portal and continuation of this to data availability and reprocessing is straightforward.
The GlobTemperature User List is being maintained as new users are both identified externally and through registration via the GlobTemperature Website.
Standard metadata are an important component of the harmonised format.
Exact individual metadata will be iterated with the ILSTE-WG to ensure all metadata requirements are covered.
"The Tier-1 and Tier-2 Merged LST Products will provide spatially averaged GEO, LEO and combined products at 0.05°."
The Tier-1 combined GEO/LEO product will provide temporally averaged merged data at a resolution of 3 hours.
Each dataset disseminated or linked from the GlobTemperature Data Portal will also contain a dedicated page describing the product with a breakdown of the Metadata.
Each dataset disseminated or linked from the GlobTemperature Data Portal will also contain downloadable .pdf links of Product User Guides (PUGs) which will contain detailed descriptions of the Products and how to extract and exploit the data in the accompanying datafiles.
"Tier-1 Merged LST Products will be gap-filled, and Tier-2 Merged LEO and Merged GEO LST Products will be provided without gap-filling."
Single-sensor LST datasets will be provided as both level-2 (swath) and level-3 (gridded) products in the agreed harmonised format.
For global gridded datasets equal-angle (regular latitude-longitude) is more suitable for global user applications and if user demand is sufficient will be provided at a broad set of resolutions defined in Section 6.5.5 to successfully meet the wide range of user requirements.
For high latitude applications then equal area projections are more suitable and as such dedicated polar IST / LST datasets will be available in these projections.
For the single sensor datasets Level-3 products will be averaged by day and night.
"The Tier-1 combined GEO/LEO product will provide temporally averaged merged data at a resolution of 3 hours (at 0000, 0300, 0600, 0900, 1200, 1500, 1800, 2100 UTC)."
The single-sensor GEO datasets will also provide data at hourly resolutions or better meeting the requirement of data at the requested times.
The single-sensor GEO datasets will provide data at hourly resolutions or better.
All single-sensor LEO datasets will be provided globally in the agreed harmonised format.
"In addition, GlobTemperature merged LST and the (A)ATSR Climate Data Record will also be provided globally."
The common nomenclature detailed in Section 2.1 will be provided to the user community via the GlobTemperature Website.
The common nomenclature is to be agreed with the ILSTE-WG.
Uncertainty information is to be provided as mandatory in the harmonised format.
For Level-2 datasets this amounts to total uncertainty on a pixel basis.
In other words a single value per pixel that characterizes the dispersion of the values that could reasonably be attributed to the measurand.
Optional uncertainty information allows the Data Provider to break this down into its component elements.
"For higher-level products, as well as total grid cell uncertainty, the uncertainty information can be optionally disaggregated into random, synoptically correlated, and sampling components."
As stated for REQ-29-TR uncertainty information is to be provided as the value that characterizes the dispersion of the values that could reasonably be attributed to the measurand rather than as confidence levels.
Optional detailed cloud and confidence flags from Level-1b source data can also be provided for additional quality checks.
Statistics of data comparison with reference to in-situ validation data and for satellite-to-satellite comparisons will be provided in the Validation and Intercomparison Reports available via the GlobTemperature Website.
Such information will be averaged to Level-3 if available.
The GlobTemperature Merged LST Product will resolve the diurnal cycle.
Where data adjustment is performed this will be provided in the harmonised format as attribute comments.
"REQ-33-TR Where available, land cover type, fraction of vegetation cover, albedo assumed in the retrieval and NDVI will be provided with LST data."
All these fields are included in the harmonised format.
"AATSR for example includes land cover type, fraction of vegetation cover and NDVI as standard."
The proposed harmonised format for all LST products is netCDF-4.
The uncertainty estimates for all GlobTemperature LST output products will be validated in addition to the LST data following taking guidance from the SST approach.
The GlobTemperature Merged LST Product will be provided as both global and regional datasets.
All datasets disseminated via the GlobTemperature Data Portal will have a full list of metadata accompanying the dataset as a page of information on the Data Portal.
This will include descriptions of dataset length and coverage and a link to the main provider web page.
"For each disseminated dataset in the harmonised format the GlobTemperature Data Portal will provide links to dataset validation reports, detailed descriptions of metadata – with links to download Product User Guides - and information on the dissemination options."
"For LST data both FTP download, and interactive map services will be provided for acquiring LST data."
"Python tools, which are platform independent, will be provided to read the LST data in their harmonised formats; such tools will allow for sub-setting."
"The visualisation suite on the Data Portal will allow users to view data composited on different timescales, maps and time-series of data intercomparisons from the matchup database, and LST and LST anomalies."
"GlobTemperature LST output products will include single-sensor datasets in harmonised format, datasets of the (A)ATSR instrument series (Climate Data Record), and Multi-Sensor Merged LST."
"Tier-1 Merged LST Products will be gap-filled, and Tier-2 Merged LST Products will be provided without gap-filling."
The GlobTemperature Data Portal will link to an external data centre for VIIRS Land Surface Temperature Environmental Data Record which has a spatial resolution of ~0.75 km (Section of the GlobTemperature Project.
"However, the ASTER Global Emissivity Database (GED) contains climatology of mean LST at 100 m; a link to this this dataset will be provided from the GlobTemperature Data Portal (Section 4.2.12)."
"Furthermore, post-Project support of the Data Portal allows for the possibility of high resolution data being made available via this single LST portal."
The (A)ATSR LST Climate Data Record aims to deliver a dataset with very low bias.
The (A)ATSR LST Climate Data Record aims to deliver a dataset with very high precision.
"Question thirty-eight of the User Requirements Survey, as detailed in the Requirements Baseline Document [AD-3], asked participants in which file format they would like LST data to be provided."
"Respondents were only able to select one option; however, some indicated via the ‘other’ box that more than one file format was acceptable and information was been included in the responses where provided."
The favoured file format is CF-Compliant NetCDF with 33 of 68 respondents selecting this option.
The next nearest choice was HDF-EOS (which is standard format of MODIS products) with 16 participants expressing a preference for this format (Figure 3).
"NetCDF format is a self-describing, portable, scalable, appendable, sharable, archivable, and machine- independent data format."
"It is supported by all major data analysis and visualisation packages, such as for example IDL, Matlab, R, BEAM, Panoply, etc., and programming interfaces exist for a wide variety of other programming languages."
"As such, CF-compliant netCDF-4 is the proposed format for all GlobTemperature data products (addresses requirement REQ-34-TR)."
The exact description of the proposed format is presented in Section 6.5.
To ensure data file sizes remain manageable it is further proposed that all GlobTemperature data products are internally compressed to the highest level (level 9) possible (addresses requirement REQ-10-TR).
There is no detriment to the performance of reading these datafiles by implementing the highest-level of internal compression; the compression of the datafiles instead only impacts the initial writing of the datafiles and is thus borne internally by the Project rather than impacting the users.
"The distinct features of Level-2, Level-3, Level-4 and databases for multi-sensor validation and intercomparison necessitate minor enhancement to these grouped harmonised formats, but all based on core variables and common metadata."
Standard metadata are indeed an important component of the harmonised format (Section 6.5.3).
"A single file specification covering all metadata requirements will be implemented for GlobTemperature output datasets, with common naming conventions across Level- (addresses requirement REQ-16-TR)."
The CF (Climate and Forecast) metadata conventions are designed to promote the processing and sharing of files created in netCDF format.
"The conventions define metadata that provide a definitive description of what the data in each variable represents, and the spatial and temporal properties of the data."
"This enables users of data from different sources to decide which quantities are comparable, and facilitates (http://cfconventions.org/) [RD-19]."
"The finalised form of the CF-compliant netCDF-4 harmonised format is to be iterated with the ILSTE-WG, with user feedback provided through the User Consultation Meetings."
The User Requirements (Table 4) defined from the results of the User Survey have been augmented with updates following mini-questionnaires carried out during breakout sessions thus satisfying the technical requirement GT-TS-4; these updates are recorded in Table 6.
Provide LST NRT data with timeliness for new observations of 12 hours.
Provide LST long-term data record updates with a timeliness of 1 month for new observations.
Provide dataset updates for reprocessing and algorithm development not more than quarterly.
"Provide information on 2 m air temperature, aerosol affected pixels, the diurnal cycle and data adjustment, total column water vapour, wind speed and humidity."
"Provide tools for data reading and sub-setting, data extraction on different grids, data compositing, generation of match-up datasets, data visualisation tools, data inter-comparison tools, data processing tools, data analysis tools, trend analysis and tools for visualisation and evaluation of data uncertainties and quality, time series extraction."
Explore ways of sharing data reading and visualisation tools within the LST community.
Provide a data download tool with the ability to screen data as a function of cloud cover prior to download.
"Provide tiled data for L3, L4 and geostationary satellite products at 10 x 10 degree resolution."
Provide LST NRT data with timeliness for new observations of 6 hours.
Provide LST long-term data record updates with a timeliness of 48 hours for new observations.
In addition both MODIS single-sensor datasets for Terra and Aqua will also span over 10 years.
The SST CCI Project is deriving intercalibrated L1b AVHRR GAC data spanning 30 years.
"Although outside the original framework of GlobTemperature, the project will investigate the potential exploitation of this L1b data stream to develop a future 30+ year LST data record."
"The GlobTemperature NRT Merged LST demonstration product processed at IPMA’s operational chain, archived locally and made available via FTP through the GlobTemperature portal aims to provide timeliness for new data of less than 24 hours."
"The objective will be set to 12 hours, although final timeliness will be dictated by technical feasibility."
The only long-term datasets (over 10 years) being derived in GlobTemperature are for (A)ATSR and MODIS.
The GlobTemperature “value-added” MODIS products will be developed with new observations aimed at timeliness within 1 month.
Once a dataset is released to the user community via the Data Portal any further evolution of the algorithm and re-processing will be subject to a minimum period of quarterly being enforced between releases.
In reality it is not foreseen that progressive releases of the same dataset will occur at such a high frequency as quarterly.
"Where the information is available, Level-2 single-sensor datasets in harmonised format will provide information on 2 m air temperature, total column water vapour, wind speed and humidity; with aerosol affected pixels as a QC flag."
For time series extraction a tool will be developed tool that allows cloud filtering to provide data as both a plot and csv data file.
A repository will be set up to allow users to share data reader and visualisation tools within the community.
"A minimum set of required information will be requested of any user wanting to share their tools and the user must accept responsibility for ensuring the robustness, security and any licensing matters regarding the tools are satisfied."
Maintenance of the tools do not lie within the remit of the GlobTemperature consortium.
Cloud cover information provided within the QC flags of the GlobTemperature Products can be applied by the Data Portal facility prior to dissemination.
This would though increase the waiting time for users to acquire the final data.
All L3 and L4 data are provided as tiled datafiles with the nominal resolution chosen as 10° x 10°.
The Geostationary data within the Merged product is also to be provided as tiled datafiles at this same resolution.
The only GlobTemperature “operational” data product currently within scope is the NRT Merged Product demonstration.
Since this requires data from multiple input data streams with considerable processing requirements such timeliness is not considered feasible.
"However, once data from Sentinel-3 becomes available a NRT GlobTemperature LST Product for Sentinel-3 would be feasible within the remit of a CCN."
Although much of the feedback obtained during UCMs are of a qualitative nature and thus not necessarily suitable for deriving User Requirements – which then drive Technical Specifications – such feedback is nevertheless pertinent to the direction of the Project; and indeed in the methods employed to deliver the most appropriate products to maximise exploitation.
"As such, where possible the response to this user feedback has been enumerated as GT-UFs and addressed throughout the Technical Specifications."
There is an urgent need to better understand/characterise the relationships between i) observations of “all-sky” land surface air temperature (LSAT) and “clear-sky” thermal infrared (TIR) LST; and ii) TIR retrieved LST and microwave (MW) retrieved LST ensure including the “clear-sky” bias.
This needs to be communicated to the user community.
"Metadata and/or documentation describing the uncertainty metrics, how the uncertainty value is calculated and how the data is processed."
"While some users are more likely to adapt their existing tools, others would require the data provider to provide tools."
"It should be d, that this weighting towards this request may partially be a result of the large numbers of urban participants following on from the EarthTemp meeting."
There were numerous studies which highlighted the need for high quality LST data from polar- orbiting satellites with near daily global coverage spanning multiple years.
"In this regards the MODIS LST, NOAA-AVHRR GAC LST, and Metop-AVHRR LST data should be prioritised."
Cloud screening algorithms applied should be documented.
"Furthermore, filtering for cloud at the point of data download is seen as extremely relevant and was a tool that would be widely used."
"Overall quality should be moved up in the QC since more important than the day/night flag, with a bit tool/decoder to produce a mask on the QC inserted into the extraction tool."
It is suggested that daily files with global coverage would be useful with the possibility to download all the data as single zip-files.
Improved folder structure can decrease download time such as one folder per year if there is only one file per day.
Enable tiles to be aggregated into a single file when multiple are selected from an ROI selection.
It was acknowledged that there is a time penalty in aggregation - that seems to be okay to prevent users from having to do it.
We first describe the LST datasets currently being produced by the various space agencies.
For each satellite sensor dataset a description of the satellite sensor is provided followed by a summary of the LST dataset algorithm.
"This series consists of three instruments (ATSR-1, ATSR-2 and AATSR (Advanced Along-Track Scanning Radiometer) on board the European Space Agency (ESA) sun-synchronous, polar orbiting satellites ERS-1 launched in July 1991, ERS-2 launched in April 1995, and Envisat launched in March 2002, respectively."
All these instruments have used similar orbits and equator crossing times ensuring a high level of consistency - thus providing approximately 20 years of data.
Continuation of this data will be sustained with the launch of the Sea and Land Surface Temperature Radiometer (SLSTR) on board Sentinel-3.
"AATSR has good radiometric accuracy of less than 0.1 K, which is achieved using Stirling Cycle coolers to maintain the infrared detectors in an optimal thermal environment."
On board calibration was performed by utilising two blackbodies which were scanned once each scan cycle.
"For LST retrieval the quoted target accuracy is 2.5 K during the day, and 1 K at night [RD-20]."
"For ATSR-1 the radiometric accuracy gradually deteriorated over the lifetime of the instrument as the detector temperatures increased, whereas for ATSR-2 good radiometric accuracy of less than 0.1 K was achieved over its lifetime."
"However, no data were acquired from ATSR-2 between December 1995 and June 1996 due to the scan mirror anomaly; and the ERS-2 gyro failure in January 2001 affected the satellite's ability to maintain its normal stellar yaw-steering mode."
A distinguishing feature of the ATSRs was the dual-angle (DA) capability (nadir and forward at an angle of ~55° to nadir).
"However, only the nadir view is utilised in the standard ESA LST retrieval - this being a split-window (SW) algorithm in which 1 km LST is retrieved based on the infrared channels at 11 and land cover classes."
"With a swath width of 512km, AATSR is able to provide approximately 3-day global LST coverage with a repeat cycle of 35 days."
Potential exploitation of the DA view for LST has received little attention; although [RD-21] did assess both SW and DA over topographically flat and homogeneous rice fields and found DA algorithms to be less accurate.
In the case of the ESA standard (A)ATSR Level-2 LST (ESA_V3) product there are 13 land biome classes and one lake class at a spatial resolution of 0.5°.
The SiB/ISLSCP fractional vegetation cover product and the precipitable water auxiliary data from the NASA Water Vapour Project (NVAP) climatology also have a spatial resolution of 0.5°.
These latter two are composed of separate global datasets for each month of the year.
"Issues relating to the auxiliary biome and fractional vegetation data utilised by the product were identified from validation, with the conclusion being that the resolution of these data were not high enough for their intended purpose [RD-23, RD-24]."
"As such substantial development under the ESA Long Term Land Surface Temperature Validation Project led by the University of Leicester has produced a significantly improved product (UOL_LST_2P) for AATSR [RD-16, RD-25]."
The ESA_V3 auxiliary datasets have been superseded with near 1 km data.
"The new biome auxiliary data is a variant of the Globcover classification [RD-26], with the original 1/360° spatial resolution product having been re-gridded to 1/120°."
"In addition, the original Globcover bare soil class has been divided into six separate classes, taking the total number of land and inland water classes to 27."
"To incorporate these changes the Globcover nomenclature has been replaced, with the new classification system known as the ATSR LST Biome version-2 (ALB-2)."
In addition to the 27 land and inland water classes an additional biome class (ALB-2 class 0) is included for completeness and represents the ocean and large lakes – this corresponds to where the AATSR land- sea mask identifies a pixel as sea – whereby SST is retrieved rather than LST.
Inland and coastal water (ALB-2 class 26) represents the remaining water - classified as land by the land-sea mask.
Although the biome classification is invariant - being based on the 2006 Globcover product - on any given orbit every pixel including class 0 is assessed for snow and ice cover.
Where snow or ice is identified the pixel is reclassified as permanent ice (ALB-2 class 27) and LST is retrieved by applying the associated coefficients.
"Fractional vegetation cover is taken now from the Geoland-2 FCOVER dataset, which is available globally at the desired near 1-km resolution of 1/112° every 10-days from 1999 and acquired from a moving temporal window of approximately 30-day composites of observations [RD-27]."
The values of FCOVER are computed from leaf area index and other canopy structural variables available in the CYCLOPES (Carbon cYcle and Change in Land Observational Products from an Ensemble of Satellites) product using a neural network trained from the 1-D radiative transfer models SAIL and PROSPECT.
The 10-day AATSR fractional vegetation cover auxiliary dataset is created from the FCOVER dataset with missing values gap-filled from climatology.
"The standard ESA LST retrieval algorithm was implemented in version 5.58 of the AATSR Instrument Processing Facility (IPF) in March 2004, and in 2008 the archive was re-processed to include version 6.01 of the IPF."
These standard products have been consistently processed to Level-2 LST utilising this same algorithm.
UOL_LST_2P has been reprocessed from the L1b data following the ATSR 3rd reprocessing.
"For IST, prior knowledge of the surface type is required in order to allow selection of the most suitable retrieval algorithm."
The (A)ATSR IST dataset [RD-28] applies LST coefficients to retrievals over snow and ice.
These coefficients have been regressed from radiative transfer modelling of permanent snow and ice surfaces utilising associated atmospheric profile and emissivity data.
Where a surface is identified as transient snow/ice or sea-ice these IST coefficients are applied instead of the respective LST or SST coefficients.
The variability of surface type dictates a requirement for a dynamic mask that demarcates snow/ice- covered areas from snow/ice-free areas in addition to the usual requirements for a land-sea mask.
"Furthermore, it is the differentiation of ice from cloud over both land and water using the data available from the instrument channels that can be the most challenging feature of IST retrieval."
"For determination of the snow mask third-party ice extent data from OSTIA is used for sea-ice extent and over the land [RD-29] is used for daytime retrievals and IMS data for land-ice extent at night; the cloud mask is then an application of the UOL_V3 cloud clearing algorithm, which has been shown to perform well [RD-30]."
"Lake surface water temperature (LSWT) retrievals from ATSRs have been developed under the ESA project, ARC-Lake."
"Earlier work [RD-31] established that LSWT retrieval using standard ATSR SST retrieval coefficients is prone, for some lakes, to retrieval biases of 0.5K."
"Rather than specifying lake- specific retrieval coefficients and cloud clearing methods, which becomes less practical when considering all lakes resolvable by ATSR (> 1000), ARC-Lake uses optimal estimation (OE) retrieval and probabilistic (Bayesian) cloud screening techniques."
"This methodology is generic (i.e. applicable to all lakes) as variations in physical properties such as elevation, salinity, and atmospheric conditions are accounted for through the forward modelling of observed radiances."
"The ARC-Lake LSWT algorithm [RD-32] uses the radiative transfer model, RTTOV8.7 [RD-33], driven by the NWP profile for the state of the atmosphere from ECMWF, to simulate top-of-atmosphere brightness temperatures for ATSR."
Prior surface temperature fields (on a 1/120° grid) for the forward modelling are derived iteratively from ATSR observations using empirical orthogonal function techniques to fill in gaps in the observations (e.g. clouds).
"LSWT retrievals are performed at the ATSR level-1b pixel resolution using (where possible) dual-view 3-channel for night-time and dual-view 2- channel retrievals for day-time, before being averaged onto a 0.05° grid."
"Currently, day and night-time ARC-Lake v2.0 LSWT products are available for 258 of Earth’s largest lakes (mostly of area exceeding 500 km2) from 1991 to 2011 [RD-34]."
Lake locations have been defined using a land/water mask derived from a combination of a 1/120° global gridded binary mask (NAVOCEANO) and polygon data from the Global Lakes and Wetlands Database (GLWD) [RD-35].
"Improvements in coverage and LSWT retrieval biases from ARC-Lake, compared to LSWTs from operational SST retrievals has been demonstrated as has the potential use of ARC-Lake LSWTs in climate applications [RD-36]."
The Advanced Very High Resolution Radiometer (AVHRR/3) is an across track scanner that senses the Earth’s outgoing radiation from horizon to horizon: scan range of 55.37º and a swath width of about 1447 km.
It provides global observations in the visible and infrared bands detailed in Table 8.
"Although AVHRR/3 is a six-channel radiometer, only five channels are transmitted to the ground at any given time, since channels 3a and 3b do not operate simultaneously."
"For Metop satellites, channel 3a is operated during the daytime portion of the orbit and channel 3b during the night-time portion."
"The LSA SAF adopted a procedure for LST retrieval from AVHRR split-window channels similar to that described above for SEVIRI data, but taking into account AVHRR response functions."
Again emissivity estimates are based on the so-called Vegetation Cover Method and atmospheric correction takes into account hourly forecasts obtained from the operational global ECMWF model.
The AVHRR/Metop LST is first generated on a pixel-by-pixel basis.
"A daily composite is then generated from the former, where LST is re-projected onto a regular (0.01) grid to form two regular fields (65ºS – not operational yet at the LSA SAF system; the respective operational readiness review is planned for the 1st quarter of 2015."
The Special Sensor Microwave / Imager (SSM/I) sensors have been on board the Defense Meteorological Satellite Program (DMSP) polar satellites since 1987.
"They observe the Earth twice daily at 19.35, which is for vertical polarization only."
"The observing incident angle is close to 53°, and the elliptical fields of view decrease in size proportionally with frequency, from 43 x 69 to 13 x 15 km2."
The local times of their descending and ascending modes are early morning and late afternoon respectively.
There are up to 4 SSM/I instruments in space at the same time (with similar overpassing times).
"A methodology has been developed to estimate the LST, along with atmospheric water vapour, cloud liquid water, and surface emissivities over land, from passive microwave imagers [RD-37]."
"It is based on a neural network inversion, trained on a large data set of simulated radiances, using real atmospheric and surface information over the globe."
"It makes use of a first guess information about emissivity (pre- calculated directly from the satellite observations, [RD-38]), and coincident surface skin temperature (derived under clear sky condition from IR observations, through the ISCCP program, [RD-39])."
"The method has been applied to the Special Sensor Microwave/Imager measurements, and LST have been estimated with a spatial resolution of 0.25°x0.25°, at least twice daily, depending on the number of SSM/I instruments in space."
The theoretical RMS error of the LST over the globe is 1.3K in clear-sky conditions and 1.6K in cloudy conditions.
"In the absence of routine in situ surface skin measurements, retrieved LST values have been evaluated by comparison to the surface air temperature LSAT measured by the meteorological station network [RD-40]."
"The LST-LSAT difference shows all the expected variations with solar flux, soil characteristics, and cloudiness."
"After suppression of the variability associated to the diurnal solar flux variations, the LST and LSAT data sets show very good agreement in their synoptic variations, even for cloudy cases, with no bias and a global rms difference of 2.9 K. This value is an upper limit of the retrieval rms because it includes errors in the in situ data as well as errors related to imperfect time and space collocations between the satellite and in situ measurements."
Results have also been evaluated over snow and ice surfaces and the results were consistent with surface air temperature [RD-40].
"More recently, the microwave LST have been evaluated through a careful comparison with in situ measurements from the Coordinated Energy and water cycle Observations Project (CEOP) for 12 stations in different environments over a full annual cycle [RD-41]."
"Under clear sky conditions, the quality of our microwave neural network retrieval (TsMW1) is equivalent to the infrared ISCCP products, for most in situ stations, with errors ∼3 K as compared to in situ measurements."
"The performance of the microwave algorithm is similar under clear and cloudy conditions, confirming the potential of the microwaves under clouds."
"We showed that the LST accuracy does not depend upon the surface emissivity, as the variability of this parameter is accounted for in the processing."
"The Advanced Microwave Scanning Radiometer (AMSR) has similar characteristics to SSM/I, with the addition of low frequencies."
AMSR was developed by the Japan Aerospace Exploration Agency (JAXA) with close cooperation of U.S. and Japanese scientists.
"It was launched on board the Earth Observation Satellite Aqua, in May 2002 (AMSR-E)."
"AMSR-2, the AMSR-E follow-up, was launched on board the Japanese Global Change Observation Mission (GCOM) on May 2012."
"AMSR measures horizontally and vertically polarized radiances at 6.9, 10.65, 18.7, 23.8, 36.5, and 89.0 GHz."
It scans conically at a nominal 55° with a swath width of 1600 km.
Spatial resolution of the individual measurements varies from 5 km at 89 GHz to ~50 km at 6.9 and 10.65 GHz.
"Inversion procedure for the LST has been applied to AMSR-E, similar to SSM/I."
Note that the overpassing time of AMSR is around midnight and midday (1h30 and 13h30 local time for AMSR-E).
"The Spinning Enhanced Visible and Infrared Imager (SEVIRI) is the main sensor onboard Meteosat Second Generation (MSG), a series of 4 geostationary satellites to be operated by EUMETSAT."
"SEVIRI was designed to observe an earth disk with view zenith angles (SZA) ranging from 0o to 80o, with a temporal sampling of 15 minutes."
"The High Resolution Visible (HRV, Table 9) channel provides measurements with a 1km sampling distance at the sub-satellite point (SSP); for the remaining channels the spatial resolution is reduced to 3km at SSP."
"The nominal SSP is located at 0º longitude and therefore the MSG disk covers Africa, most of Europe and part of South America."
"Level 1.5 data are disseminated to users after being rectified to 0o longitude, which means the satellite viewing geometry varies slightly with the acquisition time (satellite zenith angles typically differ by less than 0.25o between consecutive observations)."
The EUMETSAT Satellite Applications Facility on Land Surface Analysis http://landsaf.meteo.pt) produces an LST product based on SEVIRI data.
"LST fields are available every 15 minutes, in near real time and off-line, covering the MSG disk centred at 0º longitude and with a spatial resolution of about 3km at the sub-satellite point."
"LST is obtained by correcting top-of-atmosphere (TOA) radiances for surface emissivity, atmospheric attenuation along the path and reflection of downward radiation."
The LST algorithm follows closely the generalized split window proposed by [RD- coefficients were calibrated for classes of viewing angle and total column water vapour (available from ECMWF as operational hourly forecasts).
"The split-window algorithm requires values of channel emissivity at the surface, which are estimated as a weighted average of that of bare ground and vegetation elements within each pixel [RD-49, RD-50]."
This method produces emissivity values that are generally in line with those retrieved independently for other sensors [RD-52].
The uncertainty of LST values is also estimated and distributed.
"This depends on a number of factors [RD-47]: (i) the retrieval conditions in terms of atmospheric water content and viewing geometry, since the total optical path will strongly influence the performance of the generalized split-window algorithm; (ii) input uncertainties, including sensor noise, errors in the estimation of surface emissivity and in atmospheric total water vapour obtained from ECMWF forecasts; and (iii) errors in the cloud mask used to identify clear sky pixels."
"For most regions within the MSG disk these values are below 2K and pixels with error bars higher than 4K, generally near the edge of the MSG disk, are masked out."
"Validation of SEVIRI LST relies on comparisons with other satellite products (e.g., MODIS) and with in- situ measurements."
"The latter generally reveal root mean differences between 1K and less than 2.5 K [RD-47, RD-50], depending on the surface (better agreement is generally found for sites located in homogeneous surfaces)."
The LSA SAF initiated the production of SEVIRI LST in February 2005.
The first retrievals covered the European area and were later extended to the whole disk in July 2005.
"Since then, the algorithm and input data were improved and therefore the LSA SAF team is planning a re-processing exercise to cover the full period of SEVIRI measurements (2003 onwards) with a single and most recent SEVIRI algorithm; the review to release the re-processed LST dataset is foreseen for the end of 2014."
"MODIS instruments are part of the payload of two sun-synchronous, near-polar orbiting satellites Terra (EOS AM-1) launched on 18 December 1999 and Aqua (EOS PM-1) launched on 4 May 2002, respectively."
Each instrument provides a pair of observations each day acquiring data in 36 spectral bands: for Terra-MODIS at approximately 10:30am (local solar time) in its descending mode; and at approximately 10:30pm (local solar time) in its ascending mode; for Aqua-MODIS at approximately descending mode.
"The large swath width of these instruments, 2330km, enables these satellites to view almost the entire surface of the Earth every day."
The spatial resolution of the thermal bands is 1 km; with both land surface temperature and land surface emissivity being core products from these instruments.
MOD11_L2 data is available from 5th March 2000 and MYD11_L2 data is available from 4th July 2002.
"The generalized split-window (SW) algorithm [RD-10], similar to the split-window method used for AVHRR data, is used to estimate LST as a linear function of clear-sky TOA brightness temperatures from bands 31 and 32 centred on 11μm and correction being made to account for the satellite viewing angle."
"MODIS LST data is accompanied by quality control flags, which include an indication of the presence of clouds."
Previous collections of the LST products have suffered from cloud- contamination; the latest operational version - collection 5 - though includes refinements to account for surface elevation in the cloud masking algorithm; the resultant accuracy is reported as better than 1.0 K [RD-53].
VIIRS is one of five instruments on board the sun-synchronous near-polar orbiting satellite Suomi NPP which was launched in October 2011 with an expected operational lifetime taking it into 2017.
"Observations correspond to approximately 13:30 (local solar time) in its ascending mode, and with a swath width of 3040 km it achieves global coverage every day with a repeat cycle of approximately 16 days."
It has a spatial resolution of ~375 m at nadir in the Imagery Bands and ~750 m at nadir in the Moderate Bands through a system of pixel aggregation techniques.
VIIRS controls pixel growth towards the edge of scan such that the pixel sizes are comparable to nadir.
The aim of NPP VIIRS is to extend and improve upon the heritage of AVHRR and MODIS while providing a bridge between MODIS and the operational JPSS VIIRS.
Land surface temperature is one of several products being produced from VIIRS.
VIIRS LST algorithms use brightness temperatures measured by VIIRS IR channels processed through physical regression methods to retrieve skin LSTs.
"The baseline LST algorithm is a two-band, thermal split window algorithm based on a single equation for each land cover type, with an additional dual split window algorithm based on four thermal BTs (two middle infrared and two thermal infrared) bands that can be used when conditions are optimal, i.e. the measurements are unaffected by sun glint, with different algorithms for day and night."
"The algorithms used in the VIIRS LST product do not require emissivity information, only knowledge of the land surface type - for which there are separate coefficients."
"The algorithms require that the input BT values have a measurement accuracy of 2.4 K and a measurement precision of 0.5 K, the latter of which may not be met for some land types [RD-54]."
The Geostationary Operational Environmental Satellites (GOES) Imager consists of a five channel radiometer covering visible and infrared bands of the spectrum (Table 10).
NOAA/NESDIS operates two GOES satellites: GOES-W positioned over 135W and GOES-E over 75W.
"The temporal sampling over the disk is not homogeneous: images over North America are available at least hourly, while South America is covered every 3 hours."
"IPMA have generated LST from GOES imager data for the period between 2010 and 2012, within the framework of FP7 GMES project Geoland2."
"From Jan 2013 onwards, IPMA is producing GOES LST in near real time, as part of Copernicus Global Land Initial Operations Service."
"The algorithm used for GOES LST takes into account the information in the available channels and considers two different formulations used for night-time and daytime, respectively: (i) two-channel algorithms, which derive LST from one window channel in the thermal infrared – around 11 μm – and another in the middle infrared – around 3.9 μm (TTIR1 and TMIR, respectively); this is used for night-time conditions, when TMIR is not contaminated by solar radiation reflected by the surface; (ii) mono-channel method that corrects the TOA brightness temperature of a single channel, TTIR1, for atmospheric attenuation and surface emissivity; this algorithm is used for daytime conditions."
"LST is estimated as a linear function of TTIR1 and TMIR (night) or of TTIR1 (day), using regression coefficients estimated for different classes of water vapour in the atmosphere, view angle and land cover types [RD-55]."
"GOES LST is estimated hourly on a pixel-pixel basis, together with an error bar which takes into account the algorithm expected uncertainty and propagation of input errors."
The Multi-functional Transport Satellites (MTSAT) series of geostationary satellites is operated by the Japan Meteorological Agency (JMA).
"The imager onboard MTSAT is very similar to that of GOES, with 1 visible (VIS) band and 4 in the infrared: (i) middle infra-red (MIR); (ii) water vapour (WV); and (iii) two split-window channels in the thermal infrared (TIR1 and TIR2)."
"MTSAT is centred at 140 East, providing hourly coverage of most of Asia and Australia."
The VIS data are available with a 1 km pixel sampling distance at nadir and 4 km for infrared channels.
"IPMA have generated LST from MTSAT imager data for the period between 2010 and 2012, within the framework of FP7 GMES project Geoland2."
"From Jan 2013 onwards, IPMA is producing MTSAT LST in near real time, as part of Copernicus Global Land Initial Operations Service."
"Although the sensor onboard MTSAT has two channels in the thermal infrared atmospheric window (split-window channels), only one of these is relayed via EUMETCast."
"Therefore, the algorithm implemented by IPMA to produce MTSAT LST is very similar to that described above for GOES."
The coefficients of the regressions used were calibrated for MTSAT imager response functions [RD-55].
The Infrared Atmospheric Sounding Interferometer (IASI) is a nadir viewing instrument flying operationally on MetOp satellites.
"IASI is composed of a Fourier Transform Spectrometer (FTS) with a spectral sampling of 0.25 cm-1, and a spectral range of 645 to 2760 cm-1."
"The IASI instrument utilises a step by step scanning mirror to achieve a swath width of 2200 km, and twice daily global coverage (>99 ."
The optical axis of the scanning mirror moves from 48.3o to +48.3o with respect to nadir.
As IASI moves forward in its orbit a scan line is made of 30 Effective Fields of View (EFOV).
"Each EFOV consists of a matrix of 2 x 2 IFOVs (Instantaneous Field of View), each with a diameter of 0.84± (11 mrad ≤d≤14:65 mrad) and with centres located at 15.3 mrad (0.88o) from the instrument optical axis."
"On the ground, the EFOV is 50 km by 50 km at nadir, and the distance between two EFOV is approximately 50 km."
"Each cell of the 2 x 2 matrix corresponds to a circular pixel of 12 km diameter at the sub-satellite point, and at the edge of the scan the across-track and along-track sizes of the individual pixel are 39km and 20 km respectively, with each of the 4 simultaneously imaged pixels utilising its own detector."
"There are currently two IASI instruments flying operationally, onboard MetOp-A and MetOp-B."
"IASI LST products are available at 12 km spatial resolution at the sub-satellite point, increasing to 39 km and 20 km at the swath edge in the across- and along-track directions, respectively."
"The IASI Level 2 Product Processing Facility (PPF) is located at EUMETSAT headquarters in Darmstadt, producing operational products from MetOp (currently MetOp-A and MetOp-B)."
There also in eight decentralised satellite application facilities hosted by EUMETSAT member states.
"The level 2 processing combines IASI data with concurrent measurements of the AVHRR, AMSU-A and MHS, which are flown together on MetOp, to aid cloud detection and the initialisation of the geophysical–parameters retrieval although IASI stand-alone processing is possible if other measurements are not available [RD-56]."
Version 5 of the PPF has a modular structure with IASI and auxiliary data first collocated in a pre-processing step.
"After configuration of the retrieval algorithm with coefficients and thresholds adapted to the time and location of the measurements, cloudiness is determined, followed by the geophysical parameters, including LST from cloud-free scenes."
The LST (and land surface emissivity) are currently taken from statistical retrievals [RD-57].
"A collection of statistical methods are applied first, which include EOF linear and ANN non-linear regressions."
"For the EOF analysis, principal component scores of the IASI radiances are computed and then input into the linear regression [RD-58]."
"GlobTemperature LST products include both single-sensor datasets, the multi-sensor merged LST datasets, and the (A)ATSR Climate Data Record."
All datasets are to be disseminated to the users via the GlobTemperature Data Portal (or linked to external sites in the case of some operational datasets produced by other space agencies) in harmonised format.
"Single-sensor LST datasets will be provided as both level-2 (swath) and level-3 (gridded) products in the agreed harmonised format, as will level-4 (merged) products whereby the optimum dissemination of higher level products is via 10° x 10° tiles (addresses requirements REQ-22-TR, REG-40-TR and REQ-44-TR)."
"The objective of data provision in GlobTemperature is to provide a one-stop-shop for all LST, IST, and LSWT data products."
Thus third-party datasets will also be available via the Data Portal.
"Since non- GlobTemperature funded international collaborators may be unlikely to be able to provide datasets in the agreed GlobTemperature harmonised format, the Data Portal will not restrict access to only datasets in harmonised formats."
For such third-party datasets the Data Portal will provide a link to the external data centre and will include a descriptive page on the product metadata.
"Although these datasets may be in non-harmonised format this is outweighed by the benefit to the user community of having a single point of access to all the major European and non-European LST, IST and LSWT datasets."
"For the single-sensor LST dataset from the ATSR (ATSR-1, ATSR-2, and AATSR) series, this will be provided via the GlobTemperature Data Portal in the harmonised format (Section 6.5.1 and Section available on both the ESA archive and the CEDA archive in the UK) will be employed here for the GlobTemperature single-sensor (A)ATSR LST Product."
"The harmonised format is slightly different, in terms of additional mandatory variables, from the format for UOL_LST_2P (although UOL_LST_2P was the baseline for the proposed harmonised format) since it is user-driven following the User Requirements Survey."
"As such, level-1b data available on the CEDA archive (ftp.ceda.ac.uk) following the 3rd ATSR re-processing will be processed to LST data in the harmonised format on the UK CEMS facility exploiting its new 20 Tb GlobTemperature workspace."
The level-2 harmonised format will use the latest probabilistic cloud clearing detection algorithm (UOL_V3) to generate a cloud masks which will be stored as a component of the Quality Control flag.
A further particular inclusion in the GlobTemperature (A)ATSR LST single-sensor dataset is the uncertainty budget breakdown (addresses requirement REQ-4-TR); an example is illustrated in Figure 5.
Version 2.0 of the GlobTemperature (A)ATSR LST product assigns these individual components to a 3- component model which categories the uncertainty in terms of: i) uncertainties from random effects; ii) uncertainties from locally correlated effects; and iii) uncertainties from large-scale systematic effects.
Such a categorisation is applicable across sensors and product levels.
"This is the approach, which will be implemented, where feasible, in new GlobTemperature products, and updated versions of existing GlobTemperature products."
Thus a consistent approach to providing uncertainty information is the objective.
A full description will be provided in the Product User Guide (PUG).
"The same algorithm and procedure will be applied to Level-1b data from each of the ATSR instruments independently, albeit with instrument specific response functions, retrieval coefficients and tuning parameters."
The homogenisation of the brightness temperatures for the instrument series will be carried out in the development of the (A)ATSR Climate Data Record (Section 4.2.14).
Level-3 datasets will be produced from these Level-2 datasets and be made available via the Data Portal.
"Furthermore, tools embedded within the Data Portal will permit easier ad hoc visualisation of the ATSR data by the users from these Level-3 datasets."
For ATSR the Arc-Lake product offers an optimum solution for Lake Surface Water Temperature (LSWT).
"Since this product is available at level-2, having been derived from the ATSR level-1b data at this pixel resolution, where available this product will supersede the level-2 retrievals described above for UOL_LST_2P."
Arc-Lake is derived (where possible) from dual-view 3-channel retrievals for night-time and dual-view 2-channel retrievals for day-time.
"For any lake pixels where Arc-Lake is not available, the UOL_LST_2P retrievals for the inland water biome are to be used."
The locations where Arc-Lake retrievals are derived are defined using the ARC-Lake land/water mask.
The Arc-Lake dataset will continually be extended within the framework of the Globolakes Project for additional smaller lakes thus extending the LSWT data available.
At each new LSWT release of GloboLakes the (A)ATSR GlobTemperature single-sensor dataset will be re-processed.
For Level-3 products the (A)ATSR LSWT data will be combined into a single dataset before being averaged onto a regular grid to quantify retrieval uncertainty and apply retrieval methods to other sensors.
ARC-Lake v2.0 data products are available from the Edinburgh DataShare repository [RD-34].
"For IST, the latest developments at ULeic in (A)ATSR IST retrievals over land and sea will be exploited and will supersede the UOL_LST_2P LST data in the GlobTemperature product."
This includes the application of alternative retrieval coefficients for sea-ice (this being classified as an additional biome) and the exploitation of additional auxiliary data for snow/ice masking.
"The cloud masking over snow/ice GlobTemperature single-sensor (A)ATSR LST product will encompass the optimum solutions for LST, LSWT and IST covering all land, lake, and sea-ice domains."
Unrestricted use for ArcLake data (part of contractor's background IP).
The single-sensor Metop-AVHRR LST product in harmonised format will apply as a baseline the LSA SAF split-window algorithm for SEVIRI adapted for the AVHRR response functions.
"Emissivity estimates will be based on the Vegetation Cover Method, as with SEVIRI, while the atmospheric correction is based on ECMWF hourly forecasts of total column water vapour."
The LSA SAF processing chain is not yet GlobTemperature harmonised format for dissemination via the GlobTemperature Data Portal.
"Near real time AVHRR/Metop level 1b data, i.e. geo-located radiances and respective navigation information, are available via EUMETCast (http://www.eumetsat.int/home/main/dataaccess/eumetcast/index.htm)."
Off line data are archived at EUMETSAT UMARF and at IPMA.
In the case that the LSA SAF processing chain takes longer to commission than the expected then the option exists to process the GlobTemperature single-sensor Metop-AVHRR LST dataset on the UK CEMS facility exploiting the core processing nodes and the dedicated GlobTemperature workspace.
The full Level-1b data are archived on the CEDA archive with direct read access from these core processing nodes.
Level-3 datasets will be produced from these Level-2 datasets and be made available via the Data Portal permitting swift user specified visualisation through embedded tools.
The derivation of the Level-3 products will follow the same mechanics as for (A)ATSR ensuring consistency across products in the GlobTemperature suite.
Background Intellectual Property Rights are applicable.
The LSA-002 product is considered “essential” in accordance with the WMO Resolution 40 (Cg-XII).
"This means that access to these SAF products is granted to all users without a licence, without charge and (http://www.eumetsat.int/website/wcm/idc/idcplg?IdcService=GET_FILE&dDocName=PDF_LEG_DATA_ POLICY&RevisionSelectionMethod=LatestReleased&Rendition=Web."
"For Metop-AVHRR IST, the Level-3 dataset derived by DMI [RD-59] will form a stand-alone IST dataset in harmonised format."
This consists of daily or 12 hourly merged and interpolated fields of IST produced using an optimal interpolation scheme developed for SST.
The algorithm uses spatially varying and empirically determined error covariances.
"Associated with each of the grid points is an error estimate, based upon the availability of the data."
The spatial resolution of the IST grid is 5 km and covering the Arctic Sea ice (Northward of 58° N).
Metop/AVHRR IST observations can be used without restrictions.
"DMI only have IPRs on the processing software that has been used to generate the data, but as long as they are not used for commercial purposes the data is available to the project without restriction."
The SSM/I-derived LST for 2003 will be provided to the GlobTemperature project.
The LST are calculated at the SSM/I overpassing times (close to 6am and 6pm).
It has been thoroughly evaluated by comparison with infrared estimates and with in situ measurements.
The data can be projected on another grid and a specific format if necessary.
"The SSM/I brightness temperature source data are publicly available, with no restriction to their use."
The resultant LST data will be produced exclusively for the GlobTemperature Project under the ESA defined conditions of use of the GlobTemperature output datasets.
The initial neural network inversion [RD-37] requires a large range of ancillary observations that are difficult to collect on near-real time.
"It was first developed to estimate the atmospheric parameters over land from microwave, and since the atmospheric signal is small as compared to the surface contribution caution was necessary."
"Based on the experience we have now with the retrieval of land surface parameters from microwave, the algorithm is to be revisited, limiting the number of ancillary inputs while maintaining the LST accuracy."
"Work from [RD-42] showed that simpler algorithms have some potential, even using a single frequency channel from SSM/I."
"This algorithm has been shown to yield realistic estimates of LST, for a large range of surfaces."
"It is based on the assumption that microwave surface emissivities are stable in space and time, and it shows limitations especially for surfaces with low emissivities."
"Our objective within GlobTemperature is to develop a LST retrieval algorithm, easily and broadly applicable to past and current microwave imagers."
"The algorithm will be based on measurements provided by microwave conical scanners, from 19 to 90 GHz."
"It will possibly require pre-calculated atlases of land surface emissivities, at the same frequencies."
"Within the framework of GlobTemperature, three-years of LST will be produced from AMSR-E observations (2008-2010), on an equal area grid of 0.25° at the equator, for clear and cloudy conditions, at the overpassing time of AMSR-E (1:30AM and 13:30 PM)."
"The results will be carefully compared to existing IR estimates under clear sky conditions, and to available in situ measurements."
"The AMSR-E brightness temperature source data are publicly available, with no restriction to their use."
"The single-sensor LST dataset from SEVIRI/MSG series, generated by the LSA SAF processing, will be provided via the GlobTemperature Data Portal in the harmonised format (Section 6.5.1)."
"SEVIRI LST is generated using a generalized split-window algorithm (Section 6.2) with explicit correction for surface emissivity based on the vegetation cover method [RD-47, RD-50]."
"The atmospheric correction takes into account the differential absorption in the two split-window channels, adjusted to the view angle and water vapour in the atmosphere (as provided by ECMWF hourly forecasts)."
The SEVIRI LST dataset is currently available from 2005 to present.
The LSA SAF will re-process the full SEVIRI archive (2004 – to present) maintaining a fixed algorithm (corresponding to that currently in operations) and using level 1.5 SEVIRI data re-processed at EUMETSAT.
"The harmonised format, in terms of additional mandatory variables, projection and metadata is user- driven following the User Requirements Survey."
The original level-2 SEVIRI data generated within the LSA SAF will be re-written following the harmonised format.
"Furthermore, tools embedded within the Data Portal will permit easier ad hoc visualisation of the SEVIRI LST data by the users."
"This means that access to these SAF products is granted to all users without a licence, without charge and (http://www.eumetsat.int/website/wcm/idc/idcplg?IdcService=GET_FILE&dDocName=PDF_LEG_DATA_ POLICY&RevisionSelectionMethod=LatestReleased&Rendition=Web)."
SEVIRI data in the GlobTemperature harmonised format will be provided at a temporal resolution of 1 hour or better (addresses requirements REQ-25-TR and REQ-26-TR).
The operational MODIS LST products (MOD11 / MYD11) for Terra / Aqua respectively are available from the Land Processes Distributed Active Archive Center (LP DAAC) [RD-60].
Many users are familiar with these operational products.
In GlobTemperature the dissemination of this data is to be improved upon via direct dissemination of a “value-added” product (MOGSV / MYGSV).
This will be an entirely new data product independent of the MOD11 / MYD11 data streams.
A key feature of the product is the provision of a full uncertainty budget from first principles consistent with the approach for (A)ASTR.
The operational Level-2 MODIS LST (MOD11_L2 / MYD11_L2) datafiles provide geolocation at tie-points every 5 pixels x 5 pixels.
For users requiring 1 km swath data they currently have two choices available for geolocation: i) to interpolate between tie-points; ii) to extract full resolution information from the MOD03 / MYD03 products.
This situation can be improved upon in GlobTemperature with the provision of Level-2 data in harmonised format.
Full resolution geolocation and satellite viewing angles will be extracted directly from the corresponding MOD03 / MYD03 products and output with LST data from the MOD11_L2 / MYD11_L2 products.
"In order to deliver uncertainty information from first principles consistent with other GlobTemperature products, such as (A)ATSR, it is necessary to derive new LST data from Level-1b radiances (MOD021KM / MYD021KM)."
"This involves the generation of new coefficients for the chosen algorithm, in this case existing the split-window algorithm used operationally for MODIS."
These new coefficients however enhance the retrieval across-track through increased classification into viewing angle and water vapour classes with subsequent bias-correction.
"Emissivity information is acquired from the Cooperative Institute for Meteorological Satellite Studies (CIMSS) and spatial / temporal interpolation of emissivity, water vapour, and retrieval coefficients is carried out."
"The uncertainty information adheres to a 3- component model, which identifies: i) uncertainty from random effects; ii) uncertainty from locally correlated effects; and iii) uncertainty from large-scale systematic effects."
"MODIS operational Level-3 products do not contain any information on uncertainty, nor do they contain Quality Control information on the full range of cloud detection flags (a notable absence is masking from thin cirrus)."
"Taking the GlobTemperature LST data in harmonised format this information is to be incorporated into the GlobTemperature MODIS Level-3 “value-added” products, allowing for easier inter-comparability with other GlobTemperature higher-level products."
"MODIS data and products acquired through the LP DAAC have no restrictions on subsequent use, sale, or redistribution (https://lpdaac.usgs.gov/products/modis_policies."
Level-1 data will be acquired from http://e4ftl01.cr.usgs.gov/MOLT/ (Terra) and http://e4ftl01.cr.usgs.gov/MOLA/ (Aqua) for subsequent harmonisation in GlobTemperature format for dissemination.
From 2014 onwards a new MODIS LST and Land Surface Emissivity (LSE) product (MOD21 / MYD21) retrieved up to four times per day will be available [RD-61].
This product is being generated by international collaborators at NASA-JPL and applies a physics based approach originally designed for ASTER LST retrievals but adapted to MODIS data - the Temperature Emissivity Separation (TES) algorithm.
"The method retrieves LST and LSE in MODIS bands 29, 31 and 32."
"Currently, users will be directed to the development dataset available from the NASA-JPL site: http://emissivity.jpl.nasa.gov/mod21."
An email contact address will be provided to allow users to contact the data providers directly for the most up-to-date information on the status of the product.
In this phase of access a significant amount of MOD21 data will be processed for validation and testing purposes.
Once MOD21 has been officially released then the GlobTemperature Data Portal will instead link to the LP DAAC https://lpdaac.usgs.gov/products/community_products_table site [RD-60].
User exploitation is then to comply with the individual conditions of use regarding distribution and acknowledgement.
A Web Page on the GlobTemperature Data Portal will provide accompanying details for the dataset (addresses requirement REQ-37-TR).
Individual band data and the LST Environmental Data Record (EDR) product is available to be (http://www.class.ncdc.noaa.gov/saa/products/search?datatype_family=VIIRS) GlobTemperature Data Portal will provide a link to this external data centre.
"The single-sensor LST dataset from the imager on the GOES-East series of satellites, generated by IPMA within the Copernicus – Global Land service, will be provided via the GlobTemperature Data Portal in the harmonised format (Section 6.5.1)."
"The current version of the algorithm makes an implicit correction for surface emissivity based on a land cover classification, while the atmospheric correction takes into account the view angle and water vapour in the atmosphere (as provided by ECMWF hourly forecasts)."
GOES-East LST is currently available from 2010 to present.
The original level-2 GOES data generated within the Copernicus – Global Land Service [RD-63] will be re-written following the harmonised format.
"Furthermore, tools embedded within the Data Portal will permit easier ad hoc visualisation of the GOES LST data by the users."
"Background Intellectual Property Rights are applicable; these data are subject to GMES/Copernicus data policy, which promotes full and open access to information produced by GMES/Copernicus services."
GOES data in the GlobTemperature harmonised format will be provided at a temporal resolution of 1 hour or better (addresses requirements REQ-25-TR and REQ-26-TR).
"The single-sensor LST dataset from the imager on the MTSAT series of satellites, generated by IPMA within the Copernicus – Global Land service, will be provided via the GlobTemperature Data Portal in the harmonised format (Section 6.5.1)."
"Given limitations on the availability of the full MTSAT channels, LST was generated using an algorithm to that applied to GOES-East data, i.e., based on MIR and TIR observations for night-time retrievals and on a single TIR channel for daytime, up to 2013."
"Once two split-window channels in the TIR region became available in near real time, LST continued to be generated using a split-window algorithm similar to that implemented for SEVIRI [RD-55]."
The processing of MTSAT LST at IPMA started in Jan 2010.
"A re-processing of the full archive at IPMA, from during the processing period."
The original level-2 MTSAT data generated within the Copernicus – Global Land Service will be re-written following the harmonised format.
"Furthermore, tools embedded within the Data Portal will permit easier ad hoc visualisation of the MTSAT LST data by the users."
MTSAT data in the GlobTemperature harmonised format will be provided at a temporal resolution of 1 hour or better (addresses requirements REQ-25-TR and REQ-26-TR).
"Near real time Metop-IASI level-1b data, i.e. geo-located radiances and respective navigation (http://www.eumetsat.int/home/main/dataaccess/eumetcast/index.htm) [RD-64]."
Off line data are archived at EUMETSAT UMARF and at NEODC.
Level-2 LST from IASI will be generated utilising work carried out on radiance inter-calibration of AATSR and IASI.
The spectral response functions (spectral filters) of the AATSR instrument for each of the 11 and 12µm channels can be used in conjunction with the IASI radiance spectra to create quasi-AATSR brightness temperatures for IASI.
"This process uses the integral of the IASI data with each spectral response function, with use of spectral-filter integrated Planck functions to generate the equivalent brightness temperature values."
IASI emissivities will be convolved to the AATSR spectral responses exploiting work being carried out at the Met Office on developing a global emissivity dataset from IASI; and the Generalised Split-Window (GSW) then applied to retrieve LST.
"The product will be output in harmonised format, with Level-3 averaged data additionally produced."
EUMETSAT radiances are available from http://eoportal.eumetsat.int/.
"Access to these data is granted to all users without charge, and against the signature of a licence agreement; they may not be (http://www.eumetsat.int/website/home/AboutUs/LegalInformation/DataPolicy/index.html)."
"The ATSR series is scheduled to continue with the Sea and Land Surface Temperature Radiometer (SLSTR) - which is based on the principles of AATSR - on board the Sentinel satellites 3-A and 3-B which comprise an element of the Global Monitoring for Environment and Security (GMES) / Copernicus programme, which responds to the requirements for an operational and near-real-time monitoring of the Earth surface over a period of 15 to 20 years."
These are currently projected for launch in early-2016 (3-A) and 18 months later (3-B).
"SLSTR is designed to retrieve global sea-surface temperatures to an accuracy of better than 0.3 K and global land surface temperature to an accuracy of less than 1 K. Like AATSR a dual view capability is maintained with SLSTR - the nadir swath being 1420 km, and the backward view being 750 km."
This will support a maximum revisit time of 4 days in dual view and 1 day in single view.
There are nine spectral channels including two additional bands optimised for fire monitoring and improved cloud detection.
The spatial resolution of SLSTR is 500m in the visible and shortwave infrared channels and 1 km in the thermal infrared channels.
The baseline retrieval for the operational ESA SLSTR LST product (SL_2_LST) is that which is described for the UOL_LST_2P retrieval for AATSR (Section 4.2.1).
In other words it consists of a split-window algorithm with classes of coefficients for each biome-diurnal (day/night) combination.
"Providing Sentinel 3-A launches on schedule and depending on the length of the commissioning phase, then the single-sensor dataset will be added to the GlobTemperature suite in the agreed harmonised format."
A further plan is review both the existing SL_L2_LST algorithm and any proposed synergy LST algorithms from the SEN4LST Project [RD-66].
A trade-off analysis will be performed for these and other potential algorithms with the selected algorithm processed to a Prototype GlobTemperature SLSTR LST GlobTemperature LST data from Sentinel-3 via the framework of a CCN.
Thermal Emission and Reflection Radiometer (ASTER) Global Emissivity Database (GED) uses all ASTER scenes acquired from 2000 to 2008 inclusive to calculate mean seasonal emissivity climatology.
"This dataset is currently available for Africa, Australia, and Eurasia, with South America expected to be completed by end of 2014."
"For North America, the North American ASTER Land Surface Emissivity Database (NAALSED) v3.0 is available which provides a mean seasonal emissivity dataset for summer (Jul-Aug-Sep) and winter (Jan-Feb-Mar) time periods using data from 2000 to 2012 inclusive."
ASTER-GED and NAALSED are produced in 1 x 1 degree tiles at ~100 m and ~1 km spatial resolutions.
"Products include emissivity (5 ASTER TIR bands), surface temperature, NDVI, land-water map, geolocation information, observation count, and the resampled ATSER Global Digital Elevation Map (https://lpdaac.usgs.gov/products/community_products_table) [RD-60] will be provided where users can use either reverb or Earth Explorer to acquire the data."
"The first step is to produce a daily merged LEO infra-red data set without any gap filling, with correction factors derived."
"The process is based on AATSR and MODIS data initially, with AATSR as the reference sensor for the system; AVHRR data will be added when available."
"The second step is to use the daily merged infra-red LEO data to derive correction factors for the GEO sensors, in comparison to expectations from the validation and intercomparison, once microwave data is available."
This can also be compared at this point for clear-sky data to achieve harmonisation of the sensors.
"Once the GEO data are merged, LEO data and GEO data can be merged; in areas not covered by GEO observations the following stage of the merging process is based on LEO-only data."
"This product will be gap-filled, with estimated clear-sky biases, and also under-cloud LST where possible (addresses requirements REQ-27-TR and REQ-36-TR)."
This product will be gap-filled with estimated clear-sky biases and also under-cloud LST where possible.
The expected spatial / temporal output grid of these Tier 1 products are 0.05° / 10-day composites for continental tiles and daily output for the GEO-only / LEO-only products (addresses requirement REQ-17- TR).
"As with all GlobTemperature output products, the merged products will be delivered according to the agreed GlobTemperature harmonised format (addresses requirement REQ-40-TR)."
"The exact specifications of the primary merged product will be iterated with the ILSTE-WG, and modified as a result of tests of the prototype."
The first critical step then is to understand the differences between the individual instruments.
"Both ATSR-2 and AATSR were both stable instruments; ATSR-1 was affected by elevated operating temperature, 3.7μm channel failure, plus elevated stratospheric aerosols following the Mount Pinatubo eruption."
"For SST inter-satellite differences have been shown to be ~0.1 K. As for SST, adjusting the resultant LSTs will not determine the cause of inter-instrument bias; homogenisation is more effective for BTs."
"For generation of retrieval coefficients one needs to account for (known) differences in satellite calibration, in terms of spectral response for example."
Since the ATSR’s are well-calibrated instruments corrections derived from cross-calibration are to be applied to the simulations in the coefficient generation process.
A statistical model of δLST will be generated from double differences (for example: (AATSRsim – AATSRobs) – (ATSR-2sim – ATSR2obs)) and applied so as to adjust to a common Local Equator Crossing Time (LECT).
The most suitable reference site is identified as Lake Tahoe (Section 5.2.5) which has provided continuous high-quality measurements since 1999.
"This activity will deliver long-term data record from an instrument series (addresses requirements REQ- definition exhibit low bias, high precision, and high stability (addresses requirements REQ-5-TR, REQ-6- TR and REQ-7-TR)."
The adoption of better cloud clearing detection as delivered through the CCRR will further enhance the quality of the LST data.
"GT-TS-14: Develop Climate Data Record of over 10-years for (A)ATSR in harmonised format with low bias, high precision, and high stability."
Currently LST is not classified by GCOS as an Essential Climate Variable (ECV); an objective of this deliverable is for LST to be re-assessed in the light of prospective advances in understanding.
The GlobTemperature Matchup Database (GT_MDB) encompasses datafiles for both in situ validation and multi-sensor intercomparisons.
Their individual requirements mean datafiles generated within the GT_MDB follow set variants of a single harmonised format with common core features (Section 6.5.3).
For in situ validation satellite data providers are to deliver gridded LST subsets in harmonised format centred on the validation station for comparison with the station measurements.
"The size of these subsets are determined by the characterisation of the surface for each individual stations, and may range from 5 x 5 pixels up to 50 x 50 pixels to ensure a sufficient coverage to capture the variability of the land around the validation site."
"The spatial resolution will be consistent with the equivalent GlobTemperature Level-2, Level-3 or -4 datasets in equal-angle grids."
All orbits overpassing a given site will be extracted as subsets for matching in the GT_MDB.
Similarly the validation scientist will deliver in situ measurements and thence datafiles of satellite matchups vs. in situ data in harmonised formats to the GT_MDB.
For intercomparisons the common proposed spatial resolution for re-gridding is 0.05º x 0.05º (compatible with both the merged LST products and the CDR).
For some intercomparisons though other resolutions may be required (as detailed in Section 5.3).
Both the mechanisms of intercomparison and the parameters for subsequent analysis may influence the results.
The differences between weighted polygon averages for example and nearest neighbour binning may be significant; as may the temporal matching – nearest observation within a given time thresholds verses temporal interpolation.
"Also one needs to identify the importance of analysis with respect to different parameters: viewing geometry, orography, emissivity, and land cover classification for example."
It is therefore important that all intercomparisons are carried out under a common framework.
The baseline protocol for the matchup process is described in Section 5.1.3.
This will be updated as the different mechanisms are better understood.
It is then critical that the protocol is adhered to so as to give confidence to the user that each GlobTemperature output product has undergone a standardised evaluation.
"An agreed process for intercomparison is particularly important since such a process is to be carried out by different individuals within the GlobTemperature Project Team, and it is important that results are consistent and comparable."
"Specifically, intercomparisons of satellite observations coincident with in situ validation sites are to be carried out by KIT under the framework of the Validation and Intercomparison Work Package; while global satellite vs. satellite intercomparisons to generate empirical corrections for developing the suite of Merged LST Products will be split between ULeic and IPMA."
All Satellite vs. Satellite matchups will be provided in the harmonised format for inclusion in the GT_MDB.
Once the protocol is finalised then the use of open source solutions for data extraction will also be considered (a recommended solution is GDAL (www.gdal.org)).
Parallel comparisons will be carried out between the GT_MDB developed tools and GDAL for consistency.
ACRI-ST have developed several generic tools based on GDAL libraries allowing the generation of maps from sensor data dedicated to the comparison of satellite sensors.
Such a solution will support the user requirement for transparency in product evaluation (addresses requirements REQ-31-TR and REQ-39-TR).
The project team will implement a processing chain to generate in near real time the merged LST products.
"Being a demonstrational service, the LST merged product will be generated at IPMA’s operational chain, archived locally and made available via FTP and through the GlobTemperature portal."
For the majority of observations the objective is to provide users with data within 24 hours of acquisition with the target being within 12 hours (addresses requirements REQ-12a-TR and REQ-13-TR); the maximum timeliness being 2 days.
"The merged LST product (GEO-only and later GEO+LEO) shall be available in the GlobTemperature harmonised format, disseminated together with an error budget estimated on a pixel- by-pixel basis."
"The order of dataset dissemination is governed by the guaranteed access to source datasets and both the need, and the complexity, of performing the conversion of datasets at the local facilities of the partners."
"Therefore, some staging of data is needed, and the solution to this has been built on the UK- CEMS facility with 20 Tb of dedicated storage on the “globtemperature” workspace and access to central processing facilities to simplify the development of output datasets through code and data sharing."
"Furthermore, while most data will be archived directly on the main GlobTemperature archive at ACRI-ST other data will be hosted on the CEDA archive or on the LandSAF archive with direct dissemination from these archives via the GlobTemperature Data Portal."
"The LST, IST and LSWT products to be produced within the framework of GlobTemperature, or externally linked to via the GlobTemperature Data Portal are summarised in Table 11, with the strategy for archiving and dissemination described in Table 12."
The validation and intercomparison protocols will link Task 4 of the Project with the ILSTE-WG and with the LST White Paper [AD-6].
"The approach GlobTemperature will take is to follow, as a baseline, the LST Validation Protocol [RD-5] developed for the ESA Long-term Land Surface Temperature Validation Project (as applied in [RD-68])."
This protocol is quickly gaining recognition within the LST community and has also been incorporated into the ESA Sentinel-3 Cal-Val Plan [RD-70] for LST Validation.
There is a wide variety of approaches to LST validation.
The different types of approaches are structured here within four different categories.
This is the traditional and most conclusive approach to validating LST.
It involves a direct comparison of satellite-derived LST with collocated and simultaneously acquired LST from ground-based radiometers.
"It is often more intensive than other approaches as a result of finding suitable sites, operating validation stations and obtaining the required ancillary information from additional measurements."
"The measurements must be continuous and frequent enough to allow a close temporal matching between satellite overpasses and in-situ data, i.e. in-situ data need to be available every 1-3 minutes, which will also allow daytime and night-time validation."
"Furthermore, ancillary data relating to the near surface atmosphere, e.g. air temperature and humidity, and land surface emissivity data should be collected."
"Ideally, the validation site is to be uniform at scales of several kilometres and covers at least 3x3 satellite pixels."
"Although cloud-free campaigns with low aerosol content provide “ideal” conditions, validation should also be performed under difficult conditions and the in-situ measurements have to be continuously available and represent the whole bandwidth of possible atmospheres."
"The in-situ instruments, e.g. radiometers or FTIR spectrometers, should be calibrated to as near an accuracy of ±0.1 K as possible given the restrictions of the instrument and be traceable to a NIST blackbody."
Measuring the down-welling sky radiance allows correcting for reflected radiance contained in the radiance measured over the target.
"In practise, this requires identical up-looking and down-looking sensors, e.g. as usually found in radiance balance sensors."
In-situ emissivities need to be determined with appropriate spatial and temporal sampling to be representative of LSE.
"However, in case of changes in surface moisture LSE may need to be retrieved several times per day."
"In-situ measurements and laboratory measurements were performed for two of KIT’s validation sites [RD-74, RD-75], but generally such measurements are not available."
"Depending on the surface type, the accuracy of in-situ LSE is usually between ±0.005 and ±0.015."
"Where no in-situ emissivity data are available, the use of in-situ emissivities derived from MOD21 LSE is recommended."
The fractional tree crown cover at the validation sites should be estimated and the emissivities of the relevant end-members should be acquired from literature.
"The standard approach to obtain BBE is via regression relationships with multi-spectral emissivities, g. MODIS or ASTER LSE."
"The regressions can directly be based on satellite emissivities [RD-76] or on spectral emissivities obtained from matching satellite-retrieved LSE with laboratory spectra [RD-77, RD-78]."
At night an upward viewing pyrgeometer can improve cloud-screening.
"This technique uses top-of-atmosphere (TOA) brightness temperatures (BTs), LSE data, and atmospheric profiles of air temperature & water vapour content in conjunction with a radiative transfer model to simulate ground LST."
Radiance-based validation offers a useful alternative to validation with in situ LST as it does not require in-situ measurements concurrent with the satellite overpass [RD-67].
"The technique starts with an initial input satellite-retrieved LST value for which it simulates TOA BTs with a radiative transfer model; as inputs the model requires the - assumed to be known – LSE and (nearly) concurrent atmospheric profiles of air temperature, water vapour, and - if available - aerosols."
Perturbations are then applied to the input LST value until the simulated TOA BTs bracket the BT observed by the satellite: the R-based LST (LSTR) is determined by interpolating between the bracketing LST.
"The difference, δLST, between the initial input LST and LSTR is the LST uncertainty."
"Radiance-based validation requires accurate knowledge about the vertical structure of the atmosphere, in particular about the vertical profiles of air temperature and water vapour, and LSE has to be known."
"For selecting locations where R-based validation is to be carried out, a key criterion is the spatial homogeneity and temporal stability of the surface in terms of emissivity."
"As for the atmospheric profiles, the most appropriate data for global analyses of LST products are outputs from global circulation models (GCM), in particular from atmospheric reanalyses interpolated to the time of the satellite observation."
"Therefore, vertical profiles of air temperature and water vapour should be obtained from GCMs within a specified time around the satellite measurements and within a specified radius of the target area."
"To assess whether the atmospheric profiles used in the radiative transfer simulations sufficiently represent the true atmospheric conditions observed during satellite retrievals the discrepancy δ(T11 – T12), which is the difference between the observed BT difference (T11 – T12)obs and the simulated BT difference (T11 – T12)sim, can be examined."
"When the result of this ‘double-differencing test’, which was first implemented by [RD-67], is close to zero, then the atmospheric profiles can be assumed to be representative of the real conditions."
"However, the accuracy of radiance-based validation still crucially depends on the accuracy of the input LSE, which must be known."
A wide variety of airborne and space borne instruments collect thermal infrared data and many provide operational LST products.
An inter-comparison of LST products from different satellite instruments is highly valuable for assessing relative algorithm performance and supplements in-situ and radiance- based validation by providing important information about the spatial distribution of LST deviations.
"Intercomparisons facilitate the evaluation of the LST products relative consistency, which is highly important for users needing to judge the relative merit of several products."
Intercomparisons are also mandatory when combining several products into a ‘best available product’.
"However, product intercomparisons on their own are not sufficient for comprehensive validation since the various products could be ‘consistent’ but nonetheless biased with respect to reference data, i.e. in-situ LST."
"This is achieved by re-gridding the data onto a common spatial grid by averaging all geo-referenced, cloud free pixels weighted by their respective fractional area overlap with the corresponding common grid cell."
The high temporal variability of LST ensures that intercomparison of different LST products is a challenging prospect.
"In order to minimise the impact on the intercomparison results, LST differences due to deviating observation times have to be minimised."
This can be achieved by limiting the data to close temporal matchups; or – for intercomparisons between LEO and GEO datasets - by interpolating the GEO measurements that temporally bracket the LEO overpass time.
Analysing time series of satellite data over temporally stable targets allows identification of potential calibration drift or other issues with the instrument or the input data that manifest themselves over time.
"Furthermore, problems associated with cloud contamination may be identified from artefacts evident in the time series."
Care must be taken in distinguishing between instrument-related issues such as calibration drift and real geophysical changes of the target site or the atmosphere.
Time series provided at small spatial scales are subject to less spatial averaging and therefore provide more specific information with respect to temporal validation than time series of a merged global product.
"While the latter is interesting independently, merged data sets tend to include a variety of instrumental issues and geophysical signals which are difficult to separate, and they are therefore less useful for validation purposes."
A precision assessment reflects the repeatability of a product.
This step is very important when analysing long time series or comparing different regions.
"Ideally, such an assessment should be based on a comparison with reference (in-situ) data with well-defined small uncertainties."
"However, due to the limited amount of such high quality reference data, precision is usually assessed by analysing the variability of LST products over surfaces known to be homogeneous and stable."
"In case such surfaces are not available, e.g. if there is a heterogeneous and dynamic vegetation cover in the target area, precision may also be quantified by evaluating the ‘smoothness’ of the time series of some geostatistical metric, g. variograms generally show significant variability (nugget) for pixels separated by very short distances."
The evaluation should also consider the frequency of valid data with additional details on data QA (such as the application of gap filling techniques).
Histograms of the data can be used to check if the distributions are plausible.
"It should be d that, while exhibiting certain similarities, these categories do not directly translate to the hierarchical validation classes as suggested previously for SST validation [RD-79] and by CEOS."
"While a Category A validation will generally be more complex and resource-demanding than a Category D validation, the categories given here can be quite complementary and a comprehensive LST validation will ideally entail elements from all four of them."
"Based on the complexity of the methodology and the expected accuracy of the validation, the four validation categories are further subdivided into several classes."
For each category a set of quality criteria is established.
A Class 1 validation must fulfil all these criteria.
"For each subsequent class, one of the listed criteria can be relaxed."
"Furthermore, the LST uncertainties themselves need to be validated to provide further confidence to users of LST datasets."
The protocol for this involves mapping the standard deviation of the satellite LST vs. in situ LST against the satellite uncertainty estimate and examining whether the uncertainty estimate falls within the predicted bounds (addresses requirement REQ-35-TR).
"Only few active validation sites dedicated to long-term LST validation exist, namely KIT’s four validation sites in Portugal and Africa and the site operated by the University of Valencia in Spain [RD-23]."
"However, the latter operates on a campaign basis and usually provides some measurements during the summer months."
"In order to increase the number of primary in-situ validation sites for the purpose of GlobTemperature, additional sites were selected based on a) their long-term operational availability and their category according to [RD-5]."
An overview of potentially useful validation sites is given in Table provide only a limited number of data points for past satellite sensor generations.
"The ideal instrument for validating satellite-derived LST is a narrow band, narrow FOV radiometer with the same spectral characteristics and view direction as the overpassing satellite sensor."
"In practise this is unfeasible, but many satellite sensors observe the surface close to nadir (or such measurements can be selected) and, therefore, can be validated with in-situ LST from well-chosen sufficiently isotropic sites, g. sites covered by grass or sand [RD-81, RD-82]."
"KIT’s validation stations and some ARM sites are equipped with narrowband infrared (IR) Heitronics KT-15 radiometers (self-calibrating, chopped radiometers, Heitronics Infrarot Messtechnik GmbH, Wiesbaden, Germany)."
The KT-15 measures IR radiance between 9.6 and 11.5µm and expresses the results as BTs with an absolute accuracy of ±0.3 K over a wide temperature range [RD-83].
"For radiometers measuring in the atmospheric window and for a small distance between the sensor and the surface (a few 10m), atmospheric attenuation of the surface-leaving IR radiance can be neglected."
"However, the measurements contain radiance emitted by the surface (i.e. the target signal) as well as reflected downwelling TIR radiance originating from the atmosphere."
"Where Tsfc is LST, ε is the channel-specific emissivity of the surface, B is the Planck function at the KT- with the KT-15’s response function [RD-18]."
"Depending on surface emissivity and on downwelling longwave radiance (e.g. a cold clear sky vs. a warm humid atmosphere), the reflection term in the above equation can cause differences of several degrees Celsius [RD-84]."
LST is obtained from KT-15 radiances by solving the above equation for B(Tsfc) and then solving the Planck function for Tsfc at the KT-15’s centre wavelength.
SURFRAD [RD-85] and other stations provide upwelling and downwelling broadband hemispherical IR radiances which are related to BT via the Stefan–Boltzmann law.
"Together with broadband emissivity (BBE), which can be obtained from regression relationships between BBE and MODIS multi-spectral LSE [RD-23, RD-76], LST can be obtained from the simplified radiative transfer equation at the land surface [RD-86, RD-87]."
"For meaningful comparisons with satellite-retrieved LST the land surface has to be near isotropic, since the in-situ sensors integrate over the entire lower hemisphere, whereas the satellite sensor is strongly directional (e.g. near nadir)."
"In order to avoid influence of the atmosphere on the broadband measurements (3-50µm), the distance between the in-situ sensor and the target has to be small, since the sensors also measure outside the atmospheric window."
"Key sources for ground-based validation data will be KIT’s well established LST validation sites (Figure 7) in Evora (Portugal), Dahra (Senegal, subtropics), Gobabeb (Namibia, Namib desert) and at farms RMZ/Heimat (Namibia, Kalahari); according to the [RD-5] specifications, these are - for the solid land surface - currently the only available class A2 ground based validation stations worldwide."
The core instruments of KIT’s validation stations are Heitronics KT-15.85 IIP infrared radiometers.
"Relevant end-members are observed under a view angle of 30°; using this view angle instead of the nadir view is justified by the fact that the angular emissivity variation of sand, grass, and gravel is negligible up to view angles of at least 30° [RD-81, RD-82]."
From 25m height the KT-15’s full view angle of 8.5° results in a FOV of about 14 m2.
"An additional KT-15 faces the sky at 53° with respect to zenith and measures the channel-specific downwelling longwave radiance, which is used to correct for the reflected component in the down-looking measurements."
"In addition to the dedicated LST sites in Table 14, in-situ LST obtained from non-dedicated, continuously operating SURFRAD stations [RD-85] and ARM (Atmospheric Radiation Measurements) stations [RD-88] will be used for product validation within the GlobTemperature project (Figure 8)."
"SURFRAD stations were successfully utilised to validate MODIS LST [RD-76, RD-86] and GOES-R LST [RD-87, RD-89]."
In-situ LST from ARM sites were applied to validate AATSR LST [RD-16].
The long-term maintenance of the SURFRAD stations (Table 15) and selected ARM stations (Table 16) ensures good opportunity for matchups of in-situ LST with satellite LST products.
"The SURFRAD (Surface Radiation) network was established in 1993 through the support of NOAA's Office of Global Programs and has been operational since 1995 [RD-85, RD-87]."
"Its primary objective is to support climate research with accurate, continuous, long-term measurements pertaining to the surface radiation budget over the United States [RD-90]."
"Six of the seven SURFRAD sites were identified as useful for validating spatially moderate to coarse LST products [RD-86, RD-87]; the seventh site - Sioux Falls, SD – is to too heterogeneous in terms of land cover, making the in-situ measurements un- representative on the scale of the satellite pixel."
"The U.S. Department of Energy's Atmospheric Radiation Measurement (ARM) site SGP CF1 (Central Facility), Lamont, Oklahoma (http://www.arm.gov/sites/sgp/C), has been identified as the most appropriate ARM site for LST validation (Table 16)."
Thermometers (IRT) Wintronics (Heitronics KT15) and it is located in a large area with cattle pasture and wheat fields.
"Due to the specific instrumentation at the sites, higher surface heterogeneity and/or small areas of the sites, many of the remaining ARM sites in Table 16 are less suitable for LST validation."
"Furthermore, the TWP sites are on the coast which complicates the validation of spatially coarse satellite LST."
"GlobTemperature will focus on the ‘Southern Great Plains Facility’ SGP-CF1 site and then consider the NSA-sites, which in winter are covered by snow (Figure 9)."
"The Alfred-Wegener-Institute (Bremerhaven, Germany) has been operating the Georg-von-Neumayer- Station on Antarctica since 1981 (Neumayer I: 1981-1992, Neumayer II: 1992-2009, Neumayer III: 2009- now) (Figure 10 and Table 17)."
Neumayer’s meteorological observatory is designed as a radiation and climate monitoring station.
Measurements of radiation are carried out on a large scale as part of a global observation network to detect long-term changes in the Earth's radiation budget and their impacts on climate.
"Since 1998 derived surface temperatures at 1 min interval are available from the Alfred Wegener Institute (AWI) in Bremen, Germany."
"These are obtained from broadband hemispherical longwave fluxes (PIR and CGR4 pyrgeometers from Eppley and Kipp+Zonen), which are part of Neumayer’s Baseline Surface Radiation Network (BSRN) station."
"The Lake Tahoe LST validation site (http://laketahoe.jpl.nasa.gov) is located at the border between California and Nevada (USA) and is operated by the Jet Propulsion Laboratory [RD-91, RD-92] (Figure 11 and Table 18)."
"The site consists of four fixed buoys (TB1 - TB4) equipped with highly accurate, self-calibrating radiometers (7.8 µm - 13.6 µm) for measuring the lake’s skin temperature."
The site has provided continuous data since 1999 at an interval of 2 minutes.
"Measurements performed at the buoys are: upward and downward long wave radiation, upward and downward shortwave radiation, wind speed & direction, air pressure, air temperature, relative humidity, net radiation, aerosol optical depth, total column water vapour, skin temperature (from radiometer) and water temperature measured 1cm below the surface."
Contact: Dr Simon J. Hook (Simon.J.Hook@jpl.nasa.gov).
"The salinity of Salton Sea is approximately 45 g/l, thirty percent greater than that of the ocean [RD-93]."
The Jet Propulsion Laboratory operates a platform in the sea which provides the same set of parameters as the Lake Tahoe Site (http://saltonsea.jpl.nasa.gov).
Data has been available since 2006 at an interval of 2 minutes.
A summary of which datasets are to have intercomparison matchups extracted and a brief description of the matchup specifications are given in Table 20.
Only feasible matchup combinations are listed; where the orbit characteristics of two sensors are not compatible for matching LST then no entry is made.
"Matchups are to be used both globally in the derivation of correction factors for the GEO/LEO merging, and within the framework of the Validation and Intercomparison activities centred on the validation sites."
For matchups between datasets with different spatial resolutions or different orbital tracks the standard spatial resolution for re-gridding is proposed as being 0.05º x 0.05º.
"As for temporal matching, for the most part the nearest temporal matchup – within a predefined project-wide threshold (7.5 minutes, which is half the temporal difference between temporally adjacent SEVIRI observations) – will be used."
For matchups between LEO and GEO satellites where the temporal frequency of the GEO observations are high the possibility of interpolating between bracketing GEO observations to the LEO overpass time may provide more representative matchups; only data from SEVIRI offers such potential.
"For analysis of matchups specific auxiliary is recommended, such as viewing geometry, orography, emissivity, and land cover classification."
Where available these should be supplied with the input satellite vs. satellite matchup datafiles (Section 6.5.3).
These matchups provide the raw material for temporal / spatial compositing for delivery of user required intercomparison information via Data Portal visualisation tools (addresses requirement REQ-39-TR).
This section sets out the scope of the GlobTemperature Products and their formats based on the inputs from the Requirements Baseline Document [AD-3].
"The GlobTemperature website, available at http://www.globtemperature.info aims at providing information about the project."
"In addition, the website also includes a restricted area dedicated to ESA and the partners of the project whose main objective is to share project documents."
The web portal aims at providing access to the LST data and the associated documents and tools.
It will be available on the sub-domain named “data” at http://data.globtemperature.info.
"This portal must be an open system, easy to use and must be consistent with the users’ needs."
"A catalogue of all the available data sets will be available online, presenting the main characteristics of the products."
"For each data set, the user will be able to consult a detailed version of the metadata."
"In particular, the access policy and the acknowledgements associated to the data set will be available on the interface."
This kind of information must be given by the provider of the data set when it is included in the GlobTemperature Archive of the data portal (information often included in the header of the products).
"It will be complemented with other useful information concerning the data sets, such as links to other websites, validation information or external online documents (addresses requirements REQ-19-TR, REQ-20-TR and REQ-38-TR)."
A registration procedure must be followed through a web form in order to gain access to project information and datasets.
A procedure will also be developed to allow the user to enter a new password in case of password lost (Figure 15).
The global GlobTemperature database will be separated in to parts (two different schemas in PostgreSQL).
The first will be dedicated to the data themselves.
It will host the metadata at the dataset level and at the product level.
"In particular, the logical structure of the GlobTemperature archive (location of the products on disk) is stored in this database."
The second will be dedicated to the management of users (information on registration) and requests (parameters of the request).
"For each order, the link between the registered user and the associated order will be stored in the database."
The schematic of the architecture is shown in Figure 18.
"In this schematic, a user accesses the system through a DATA Interface."
"This interface, representing the front-end, includes a form with all the parameters necessary to send a request to the system."
This request is then processed on the back-end by the DATA management system.
This component has a direct access to the data sets (physical on the local storage area or virtual in the case of external storage).
It is also in charge of the I/O actions on the User & Request database and on the product database.
"In response to the order received, the data is transferred from the archive to the Download area."
"The DATA management system also controls the access to the metadata, stored in the product database, from the DATA Interface."
The “Search” action generates a list of products corresponding to the criteria.
This interface will contain a form with the parameters needed to request products.
The list of parameters will be modified and completed during the project to be in accordance with the users ’needs and the characteristics of the datasets.
This though would not be suitable for downloading large quantities of products depending of the browser used.
"For the latter two options, bulk orders could be downloaded as one request."
"Other solutions will be introduced depending on the user’s need, particularly in the case of non- interactive mode, which is a good way to include automated actions in scripts."
These could include transfer of data products onto portable media provided by the user.
A script will be set up on the dissemination system to automatically delete any ordered products older than 15 days.
Extraction functionality can be added to the data portal.
It is a useful tool in the context of a dissemination system because users may work on a region of interest (ROI).
"In such a case, the specification of the coordinates can be done at the level of the interface and the extraction can be processed on the server side, before download."
"This kind of tool is included in the Hermes service, dedicated to the dissemination of level-3 ocean color data (GlobColour products)."
A screenshot of the service is shown in (Figure 24) (new version will be online soon).
The current version can be viewed at the http://hermes.acri.fr.
"On this interface, the coordinates of the ROI can be directly inserted in the form (North, South, East, West fields) or can be selected using an interactive mode (by drawing a rectangular area in a web mapping environment)."
One can note that a module of quicklook visualization is also provided on the Hermes interface (Figure percentage of validated pixels in a product.
Analysis tools will be provided on the data portal.
Graphs and maps showing various statistics and comparisons on the LST data sets will be available online.
These plots will be self-explanatory; they will include a legend and an acknowledgement to the data sources.
Detailed specifications will be appended in further versions in response to the users need and to recommendations of the International LST & E Working Group.
This section will provide access to projection and conversion tools.
A particularly useful tool is for all users to be able to read GlobTemperature data with minimal effort.
Thus a tool for reading the harmonized formats described in Section 6.5 would be beneficial.
"This requires any tool to be platform independent, with functionality for extracting subsets of data from the downloaded datafiles."
Additional detailed specifications will be appended in further versions in response to the users need and to recommendations of the International LST & E Working Group.
"The most commonly currently used tools are for data reading/sub-setting, data visualisation, data processing and data analysis, developed either internally or made available by external providers."
Many such tools already exist and are exploited by many users of LST data.
"As such, an optimum approach would be to allow users to share such tools, with GlobTemperature providing the facility to do this."
There are expected to be reservations in ensuring that the shared tools are error free; while some LST data users are likely to be unable to share tools due to copyright issues.
"Thus, to meet this need within the user community a tool repository area on the GlobTemperature Data Portal will be set up whereby users will be able to upload tools they are willing to share (addresses requirement REQ-42-TR)."
"While some basic tests can be carried out on the uploaded tools to detect viruses for example, responsibility for the integrity, security and licensing implications must reside with the user who uploaded the tool."
The user would also be responsible for providing the necessary information to install and exploit the tool.
"Furthermore, since many of these tools are likely to be written in a multitude of computer languages and delivered as a “black box” GlobTemperature is not able to support ongoing maintenance of such a suite of tools."
Any bugs would be reported to the user who uploaded the tool – whether they then are in a position to deliver a fix is outside the influence of the Project.
"A further tool, in high demand within the LST user community is the ability to screen data for cloud prior to downloading it."
The presence of the cloud bits within the QC flags enable easy filtering of cloud from the delivered data.
"Furthermore, this tool will be designed to operate as a function of selected cloud cover fraction for the area of interest to be downloaded."
The cloud-screening algorithm applied is to be documented (addresses requirement REQ-43-TR).
Cloud filtering will also be applied within the proposed time series extraction tool.
"This time series extraction tool will be able to cover an entire instrument mission, although it is initially proposed to operate on single grid-cell given the huge overhead of extracting and processing datafiles for the entire archive."
Output of the time series extraction will be both as a plot and a datafile (in .csv format) (addresses requirement REQ-39-TR).
Both the standard ESA (A)ATSR LST algorithm (ESA_V3_algm) [RD-22] and the enhanced ULeic LST algorithm (UOL_LST_algm) for AATSR (UOL_LST_2P) and SLSTR (SL_2_LST) use a nadir-only split-window approach with classes of coefficients for each combination of biome-diurnal (day/night) condition.
The fractional vegetation cover (f) and precipitable water (pw) are seasonally dependent whereas the biome (i) is invariant.
The retrieval parameters d and m are empirically determined from validation and control the behaviour of the algorithm for each zenith viewing angle (θ) across the nadir swath.
The parameter d resolves increases in atmospheric attenuation as the zenith viewing angle increases due to increased water vapour.
"The parameter m is supported by previous studies [RD-23, RD-24] which suggest a non-linear dependence term on the BT difference T11 - T12 would elicit improvement in the accuracy of the LST retrievals."
"The rationale here is that the BT difference increases with increasing atmospheric water vapour, since attenuation due to water vapour is greater at 12μm than at 11μm."
The nature of the algorithm means that land surface emissivity is implicitly dealt with.
For the ESA_V3_algm there are 13 land biome classes and one lake class [RD-94] at a spatial resolution of 0.5°.
"Validation of the standard AATSR LST product (ESA_V2 following the 2nd ATSR re-processing) [RD-23, RD- exploits 1 km BTs from the ATSRs to derive LST whereas the auxiliary data is at the much coarser spatial resolution of 0.5o; this restricts the capability to make the necessary corrections for land surface emissivity and atmospheric effects."
"These scale differences cause artefacts in the LST products which often appear as sharp, straight boundaries aligned with lines of latitude and longitude [RD-25]."
In some cases large biases and absent values in the retrieved data were attributed to inaccuracies in the auxiliary data; the conclusion being that the resolution of these auxiliary data are not fine enough for their intended purpose.
"The UOL_V3_algm incorporates higher resolution auxiliary data files (ADFs) [RD-16, RD-25]."
"In addition, the original Globcover bare soil class has been divided into six separate classes, taking the total number of land and inland water classes to classification system known as the ATSR LST Biome version-2 (ALB-2)."
Precipitable water is derived from the European Centre for Medium-Range Weather Forecasts (ECMWF) ERA-Interim reanalysis [RD-96].
"Each auxiliary data file is derived from 6-hourly monthly climatology corresponding to the 4 synoptic times - 00UTC, 06UTC, 12UTC and 18UTC - covering the 10-year period complement the use of higher resolution auxiliary data in the retrieval of LST from the AATSR instrument."
"Necessarily, this work has also established the requirement to optimise the parameterisation of the retrieval across the nadir swath."
"For the generation of the retrieval coefficients for each biome–diurnal (day/night) combination vertical atmospheric profiles of temperature, ozone, and water vapour, surface and near-surface conditions and the surface emissivities are input, in addition to specifying the spectral response functions of the instrument, into a radiative transfer model in order to simulate TOA BTs."
Retrieval coefficients are determined by minimizing the l2-norm of the model fitting error (ΔLST).
These algorithms do not take advantage of the dual angle capability of AATSR.
"The rationale being that the disadvantages, such as surface heterogeneity and non-simultaneity of the two views – significant over most land surfaces – outweigh any potential benefits [RD-22]."
"Indeed, over homogeneous surfaces [RD-21] have illustrated that a dual angle algorithm may retrieve LST with more accuracy, but performance degrades as the surface becomes increasingly heterogeneous."
The retrieval coefficients are determined by interpolation on a set of multi-dimensional look-up tables; these are obtained by linear regression of the simulation data generated by radiative transfer over a broad wide range of surface and atmospheric conditions.
"The look-up tables incorporate several improvements for the Split-Window LST algorithm such as view-angle dependence, water vapour dependence, and atmospheric lower boundary temperature dependence."
"In addition, a physics-based day/night algorithm [RD-97] is employed to retrieve both surface spectral emissivity and temperature at 5 km resolution."
"It achieves this by utilising seven MODIS TIR bands (20, rapidly than LSE."
"The SW approach has high accuracy over graybody surfaces, but a lower accuracy over semi-arid regions."
"The retrieval coefficients: 𝐴𝑗, 𝐵𝑗 (𝑗 = 1,2,3) and 𝐶 are dependent on water vapour and zenith view angle."
"The algorithm is dependent on a linearization of the TOA BTs with the surface temperature and the controlling factors are the surface emissivity, atmosphere and satellite view-angle."
"The coefficients are calculated using a regressive analysis technique, whereby simulated 𝑇10.8 and 𝑇12.0 are obtained from radiative transfer simulations performed over a wide variety of atmospheric profiles."
"When compared with an independent dataset of radiative transfer simulations the algorithm and it’s coefficients were found to be bias free, although random errors tended to increase with increasing water vapour content and at high view-angles [RD-50]."
For the operational LST product the water vapour database used is that provided by ECMWF ERA-Interim.
The channel surface emissivity is calculated from an average of bare-ground and fully vegetated emissivities weighted by the fractional vegetation cover (FV) and by the fraction of water within the pixel.
"In a similar fashion to the AATSR algorithm, the emissivity extremes are selected from a look-up- table in accordance to the land cover classification."
"In contrast, a new MODIS LST product (MOD21) being generated by international collaborators at NASA- JPL applies a physics based approach - the Temperature Emissivity Separation (TES) algorithm, which was originally designed for ASTER LST retrievals, but has been adapted to MODIS data to retrieve LST and LSE in MODIS bands 29, 31 and 32 [RD-61]."
One rationale for this development is to improve on the retrieval in semi-arid regions.
TES attempts to solve the ill-posed LST problem through the use of empirical methods to predict the minimum emissivity observed from a given spectral contrast.
"This relationship is referred to as the TES calibration curve, and can be adjusted for any sensor's spectral response function in the TIR."
"Although the AATSR instrument does not observe the surface with sufficient TIR channels to separate the LST and LSE explicitly, it is still possible to consider retrieval algorithms with an explicit emissivity term."
Much work has been carried out in the LST community on developing alternative algorithms for LST from (A)ATSR.
These include most notably the candidate algorithms developed for the SEN4LST Project [RD-66] amongst others [RD-99].
"Theory, is a technique developed to help solve problems which are either over- or under- constrained and there is some degree of uncertainty in the measurements or formulation."
"It has proved to be of great use in Earth Observation, specifically in resolving multispectral measurements to give multi-level atmospheric profiles."
"In comparison to SW techniques, OE methods ensure that more consideration of the true physics is considered."
"Generally this ensures that the retrieved state is more likely to reproduce the observation vector when used as input in a forward model, hence provides more confidence in the result."
"However, the cost is whether or not the extra computation required is operationally feasible in the context of a global dataset."
SAF provide three 1D-Var packages: a Met Office version; an ECMWF version; and an SSMIS version.
The Met Office 1D-Var package is a flexible stand-alone optimal estimation routine suitable for user adaptation [RD-100].
It was initially designed with the primary purpose of retrieving water vapour profiles using data from the IASI and AIRS instruments in conjunction with the RTTOV forward model.
It has been constructed such that it can be easily adapted to use a number of different radiative transfer models and satellite instruments [RD-101].
"In this project, the single-sensor data sets disseminated via the Data Portal will continue to be produced largely with the existing algorithms because of the nature of operational systems."
The innovation in understanding of algorithms will come in two ways.
"Firstly, in the merging work, the effects of algorithm bias is to be examined more closely by analysing more than one instrument data set with the same algorithm."
"This will provide information on which are the dominant sources of bias, which components are due to the algorithms, and which are due to “auxiliary” information, thus allowing a better understanding of the algorithms to develop."
"Secondly, an algorithm trade-off is being carried out prior to the derivation of an (A)ATSR Climate Data Record."
The results of this trade-off analysis will feed in to the algorithm trade-off and optimisation as part of the extension to SLSTR.
A number of algorithms are being assessed as potential candidates for the development of the (A)ATSR Climate Data Record; with these also pertinent for the Multi-Sensor Merged LST Product.
The Prototype Sentinel-3 LST Product will use these as inputs but additionally may consider other alternatives not previously suitable.
"The standard ESA ATSR LST algorithm (ESA_V3_algm) is not considered a potential candidate algorithm since studies [RD-16, RD-68] have illustrated the significant improvement in accuracy and precision of the UOL_V3_algm compared to the ESA_V3_algm."
"Nevertheless, the ESA_V3 LST Product will still be utilised for comparison purposes."
The comprehensive Climate Data Record Trade-off Analysis is being delivered as a separate report (LST CDR Algorithm Trade-Off Analysis (DEL-8)) [AD-5] and thus only summarised here.
For global production of a CDR several techniques may be employed to decouple surface emissivity and surface temperature.
"The most widely used are: the Day/Night method, which require acquisitions twice per day and assumes that day/night emissivity differences are negligible; the Temperature Independent Spectral Indices (TISI) method, which provides relative emissivity values; the Temperature and Emissivity Separation (TES) algorithm, which requires multispectral thermal infrared data (TIR); and methods based on retrieval from vegetation indices, such as the NDVI THresholds Method (NDVITHM) [RD-102]."
The additional thermal infrared (TIR) channels of MODIS permit a choice of algorithms to be exploited.
"For instruments without multispectral thermal infrared capabilities, such as (A)ATSR and AVHRR, we are primarily reduced to approaches based on vegetation indices or enhancements on this by incorporation of land cover classification."
"Emissivity retrieval from vegetation indices is based on a simple approach between emissivity and Fractional Vegetation Cover (FV) constrained by reference values of vegetation and soil emissivities from laboratory measurement, such as the ASTER spectral library [RD-103]."
Land cover information can be also used to categorise these emissivity values by land cover types.
"The final approach is to utilise a third-party emissivity product, such as the ASTER-GED or the CIMSS dataset."
For the Prototype Sentinel-3 LST Product similar arguments are applicable as for the LST CDR Algorithm Trade-Off Analysis (DEL-8) [AD-5].
"However, the SEN4LST Dual-Angle algorithm (S4L_DA_algm) is also a viable option since this is a single-sensor algorithm for an instrument with both nadir and oblique views."
A full analysis of the candidate algorithms will be carried out within the Sentinel LST Product Development Plan (DEL-23) activity.
"Finally, the optimal estimation / 1D-var approaches, which are a very different alternative to the coefficient based algorithms in that they provide fits to the observed radiances within the constraints of the system, may be considered during the merged LST NRT activities where climate accuracy and stability may be less important."
Further information on these approaches is expected to come from the study on assimilation of LST into NWP models (Section 7.5).
"The structure, format, and purpose of the ILSTE-WG has been developed as a joint effort between U. Leicester (representing the requirements of the GlobTemperature Project) but also IPMA (representing both GlobTemperature and EUMETSAT through the LSA SAF) and NASA-JPL."
The aim being to create a truly international group dedicated to the development of products and exploitation by users of LST and LSE data with multi-agency support.
This is particularly important in the post-GlobTemperature era where continuing development of this Group may be sustained by various inter-agency funding streams.
"The ILSTE-WG Steering Committee has been set up with key personnel representing different agencies involved in the satellite-retrieval of LST and LSE: ESA, NASA, NOAA and EUMETSAT."
"Furthermore, in addition to the invitation pack sent out to prospective members of the ILSTE-WG a tailored presentation has also been compiled for NASA Headquarters in order to gain high level support for the Group."
"Indeed, Simon Hook (ILSTE-WG Steering Committee member) and Jose Sobrino (ILSTE- WG general member) are leading the LST/Emissivity focus area within the LPV."
"A consistent approach to data validation, in line with CEOS-LPV Best Practices has been proposed from the LST Validation Protocol of [RD-5] and which is utilised here (Section ."
"The ILSTE-WG will manage Technical Advisory Groups to support the development and use of satellite LST information, to promote scientific insight and innovation, to identify best-practices, and to facilitate the transfer of new science into user's applications."
These groups will seek to develop partnerships with these identified international bodies.
"A further key aspect of the ILSTE-WG is to provide an independent source of advice and appraisal, as requested, for related projects run by supporting agencies."
In addition to the ESA DUE GlobTemperature Project another initial recognised project is the NASA MEaSUREs (Making Earth System Data Records for Use in Research Environments) for which key ILSTE-WG Steering Committee members are involved in.
"An objective of this project, in terms of LST and LSE, is to merge MODIS and GEO data."
Considerable prospects of cross-collaboration between projects are envisaged through the focal point of the ILSTE- WG.
"Data sharing and dissemination to users is also an important goal of the ILSTE-WG, and through early negotiation with NASA-JPL agreement has been sought and given for the GlobTemperature Data Portal to externally link with their datasets – MOD21 (Section 4.2.6) and ASTER GED (Section 4.2.12)."
Strong links have been developed with the Sentinel-3 Validation Teams in the Land domain.
This brings the benefit of community agreement to share both LST data and associated validation data.
"For example, data collected by our international partners at NASA JPL are to be made available to both the Sentinel-3 LST Validation Team and GlobTemperature from the well calibrated and established validation sites at Lake Tahoe and Salton Sea."
"This section describes the proposed harmonised format for all Level-2, -3 and -4 GlobTemperature data products."
Database (GT_MDB) are also proposed to conform to a harmonised format (Table 26 and Table 29).
Appendix C – Harmonised Format Examples provides example netCDF-4 outputs for selected example orbits.
"Where available in the source data for a given data stream optional fields will be supplied as mandatory in the corresponding output product, albeit in accompanying auxiliary datafiles (addresses requirement REQ-33-TR)."
To meet the user needs of a harmonised format (REQ-16-33: Establish a single file specification covering all metadata requirements) a distinction needs to be made between the tier of data this refers to.
"In other words, single-sensor level-2 swath datafiles are to conform to a one harmonised format – with respect to the variables, metadata, and filename conventions - and higher-level (single-sensor, and merged products) are to conform to a harmonised format more appropriate to gridded data."
"While both formats are to be netCDF-4 with common CF-compliant metadata (addresses requirement REQ-34-TR) and the majority of variables to be common, several differences due to the individual requirements of swath / gridded datasets are necessary."
"Data providers are tasked with ensuring their products meet CF compliance, and a CF compliance checker is available online at http://titania.badc.rl.ac.uk/cgi-bin/cf- checker.pl for confirmation."
"All output datasets will be delivered in consistent data format, with the objective to provide consistent standardised metadata across all LST products at both file and granule level and a common data format which is well established and internationally accepted by the user community."
"The choice on datafile format has been driven by the User Requirements, with detailed specifications influenced by the success of the standard formats of GHRSST."
"For example, the standard Level-3 resolution for single-sensor datasets, the merged LST products, and the (A)ATSR LST CDR has been chosen to be 0.05° equal-angle daily data (with day and night distinguished); experience from GHRSST and SST_CCI informs that this is optimal and allows aggregation to many of the coarser spatio-temporal scales."
Section 6.5.5 also specifies additional possible spatial / temporal resolutions which could be available from the Data Portal given sufficient user demand following feedback from User Consultations.
The final harmonised formats are necessarily subject to approval with ILSTE-WG.
"To facilitate optimum user uptake of the GlobTemperature products in harmonised format a set of tools will be developed in Python, which is open-source and platform independent software for reading and sub-setting the datafiles created in the harmonised formats."
Level-2 products can be defined as geophysical variables derived from Level-1b source data at approximately the same spatial resolution and location as the Level-1b data.
"Generally the projection is in a satellite projection with geographic information, although for more obscure satellite projections data may be re-projected onto an equal-angle grid of equivalent geospatial resolution."
These data form the fundamental basis for higher-level products (addresses requirement REQ-1-TR).
It is acknowledged that although the size of each datafile will be less than 200 Mb (addresses requirement REQ-10-TR) many users may only be able to successfully exploit datafiles considerably smaller.
"As such, the GlobTemperature single-sensor Level-2 harmonised format is proposed to only include essential variables as mandatory."
This will ensure the minimum datafile size for a given sensor is not restrictive to wide user uptake.
GT-TS-31: As default datafiles to be disseminated with mandatory variables only.
Optional fields are proposed to be included in accompanying datafiles.
Data Providers are to be tasked with providing all mandatory fields in their GlobTemperature primary LST datafiles (labelled LST).
"For optional fields, where information is available for the given sensor then these are to be provided as mandatory fields in the accompanying auxiliary datafiles (labelled AUX)."
"As standard, the Level-2 datafiles disseminated to the users will contain all the mandatory fields from the primary (LST) datafiles."
"For dissemination of auxiliary fields a proposed approach to be agreed with the ILSTE-WG following feedback obtained from the 2nd and 3rd User Consultation Meetings is to offer both dissemination of the full auxiliary (AUX) datafiles, and the addition of user selected fields to the primary (LST) datafiles including select meteorological data (addresses requirements REQ-8-TR, REQ-9- TR, REQ-29-TR and REQ-32-TR)."
Where emissivity data are explicit these can be provided in the AUX datafiles.
"Nonetheless, the approach to deriving emissivity for any given algorithm will be described in the accompanying Product User Guide (PUG)."
"In addition to the provision of netCDF datafiles, the option of disseminated the LST field alone will also be provided by way of GIS-compatible GeoTIFF format."
To achieve such user definition of output files the optimum solution is to utilise the open source netCDF Operator (NCO) tools (http://nco.sourceforge.net/).
These allow single command-line manipulation of netCDF-4 datafiles including the extraction and concatenation of variables.
"They allow preservation of metadata, chunking and compression options."
"NetCDF-4 incorporates in-built compression, where it is recommended that all data providers supply their products with the highest level of compression available (level 9), and customise the chunking of data for optimal storage."
"High compression will increase the time to write the files, whereas no impact can be detected on the subsequent reading of these files."
"Thus users will not be affected by reading highly compressed datafiles, while benefitting from much reduced datafile sizes."
Further necessary account is taken of file size in the scaling of variables.
Where possible floats should be scaled (using the add_offset and scale_factor attributes) and stored as short integers (which is a very efficient way of compressing the data of individual variables).
In GHRSST the geolocation in the L2P datafiles are stored as floats to 3 decimal places.
For LST the proposal is that these are stored to 4 decimal places.
Level-3 products can be defined as products on a defined spatial / temporal grid mapped from the Level- requirements for fields related to the sampling.
Level-4 products can be defined as datasets created from lower level data from multiple data streams that may or may not be gap-filled (addresses requirement REQ-2-TR).
These products will be disseminated in datafiles of 10° x 10° tiles to reduce the output size of individual datafiles (addresses requirements REQ-10-TR and REQ-44-TR).
"As for the single-sensor Level-2 swath data format many users may only be able to successfully exploit datafiles up to a certain size, considerably smaller than the 200 Mb from REQ-10-TR."
For higher spatial resolution global Level-3 (single-sensor averaged products) and Level-4 (multi-sensor merged products) size becomes a pertinent consideration.
"As such, optional fields are proposed to be included in accompanying datafiles similar to the structure for the Level-2 products."
This framework ensures all GlobTemperature higher level products are delivered in datafiles appropriate to the user community (addresses requirement REQ-10-TR).
"All information, such as observation time, will be preserved from Level-2 products to higher-level products."
"In addition, the number of pixels averaged and the number excluded due to cloud will also be provided."
The dissemination of optional variable and the compression of variables is proposed as per described in section 6.5.1.
Similar to the Level-2 and Level-3 format descriptions (Section 6.5.1 and Section 6.5.2 respectively) the datafiles have unique features in addition to the core requirements.
"Thus, core variables will be included in each output type in harmonised format with common metadata across all types."
Since matchup datafiles by design are gridded and localised the constraints of file size are not restrictive here.
"Moreover, the GT_MDB contains datafiles that are also internal to the database but nevertheless require definition so each data provider is able to adhere to a single format to expedite optimal matchup processing."
From the User Requirements REQ-39-TR requires tools for generation of match-up datasets and data inter-comparison tools.
To facilitate these requirements internal datafiles in harmonised format independent of the data source are required.
"Data Providers are to be tasked with providing all mandatory fields in their input satellite LST extractions over each validation site, and if exists accompanying optional fields."
This facilitates optimum knowledge of the different characteristics of individual LST datasets for understanding accuracy and precision with respect to in situ reference measurements.
"For any given site, the satellite input LST is to be provided on a fixed grid as designated by the validation scientist."
"All mandatory fields are to be filled for each validation site, and if exists accompanying optional fields."
This facilitates optimum knowledge of the site characteristics including instrument details for understanding accuracy and precision.
Taking the inputs described in Table 26 and Table 27 matchups between the satellite LST and coincident in situ measurements can be derived.
"Note that matchups between in situ and satellite data may not be at the same location; for example, at the Gobabeb station satellite LST are taken from a location on the homogeneous gravel plains about 10 km east of the station."
For satellite vs. satellite intercomparison matchups the proposed harmonised format is described in information to the users on multi-sensor matchups.
"For example, monthly composites can be derived based on the individual matchup data and stored on the Data Portal for visualisation tools to map intercomparisons over user-defined spatial and temporal extents."
"To facilitate detailed analysis of the differences between satellite LST data from matchups in terms of orography or land cover for example, a static / semi-dynamic (yearly updated) datafile is to be available to maintain such global information (Table 30)."
GT_MDB input satellite LST format and the GT_MDB in situ measurements format.
These will all be documented in the accompanying Product User Guide (PUG).
It is also the intention to assign Quality Flags to the LST products at a per-pixel level similar to those used for SST in the GHRSST convention to enable users to be more informed when filtering data.
This agreement for these Quality Flags needs to be made in consultation with the ILSTE-WG so as to set a community standard that can be adopted by other data providers.
These may be for example individual detailed cloud or confidence flags carried forward from the Level-1b source data.
They are to be described in the flag_meanings and flag_masks variable attributes.
"The Global metadata describe the whole file with regard to general information about conventions, data producer, contact information etc."
Examples for the information provided in each of the used attributes can be found in Appendix C – Harmonised Format Examples.
Refers to the metadata convention used in the file.
For the harmonised format the Climate and Forecasting (CF) metadata convention version number.
"Provides the start time of the product; this relates to an orbit, start of a day or start of a month."
Provides the start time of the total coverage of the data for the Product.
"Provides the end time of the product; this relates to an orbit, end of a day or end of a month."
Provides the end time of the total coverage of the data for the Product.
Provides the northernmost geographical extent of the data in the datafile.
Provides the southernmost geographical extent of the data in the datafile.
Provides the easternmost geographical extent of the data in the datafile.
Provides the westernmost geographical extent of the data in the datafile.
Each individual variable in the GlobTemperature harmonised format has its own metadata.
Text description of the units the data is stored in.
Some variables contain additional metadata attributes that are only relevant for the specific variable (Table 34).
Used for variables which describe a classification (eg: land flag meanings.
For each GlobTemperature product the variables and metadata will be documented within the Product User Guide (PUG).
"Furthermore, a recommended approach to utilisation of the individual variables will also be documented in the accompanying PUG (addresses requirement REQ-20-TR)."
For Level-3 single sensor datasets the proposed standard spatial resolution is 0.05° equal-angle and the temporal resolution daily; each average is resolved for day / night retrievals (addresses requirement REQ-24-TR).
For the Level-4 GlobTemperature merged LST product the proposed spatial / temporal resolutions are detailed in Section 4.2.12.
"Datasets created within GlobTemperature specifically for the high latitudes, such as IST datasets will be provided in harmonised format in equal-area projection (addresses requirement REQ-23-TR)."
The file length is thus consistent between the different types of datafiles ensuring maximum ease of use for the users of harmonised format products.
"Each User Case Study will be supported by firstly, a designated core partner most directly related to their interests in terms of science and data; and secondly, by University of Reading who will maintain an overview of progress and help each group benefit from interactions across the consortium."
Following feedback and interactions from the 2nd User Consultation Meeting this section will be updated with a further release of the User Case Study Work Plans prior to their commencement when a more complete picture of the available GlobTemperature output datasets is known and hence the work to be carried out can thus be more accurately organised.
These updated Work Plans will adhere to a common format to simplify management of the suite of User Case Studies.
"In this User Case Study, we will explore the issues involved in using LST retrievals to augment information from meteorological stations with a view to understanding the problem at different space and time scales and identifying core issues for generating a seamless product that can be used across different space and time scales."
"To do this, we will make use of state of the art understanding on the relationships between LST retrievals and air temperature measurements gained from the literature and other projects."
"We expect this study to highlight the core issues and to inform our strategy for the exploitation of LST retrievals in our future high resolution products for climate services, amongst other applications."
"Satellite observations of surface temperature represent area-averaged ‘skin’ temperatures (i.e. the temperature of the Earth’s surface) at scales of several tens of metres to kilometres, whereas meteorological stations record the ambient air temperature at a height of around 2m at a specific spatial point."
"Climate studies have traditionally utilised the latter, usually in a gridded or interpolated form, but are geographically limited where the spatial density of stations is low."
This issue is becoming increasingly apparent as users ask for data sets with higher spatial resolution and better geographical coverage.
"Satellite data can be used to augment station data sets, providing detailed spatial pattern information for surface temperature, and observations where in situ stations are absent."
"Surface temperatures from satellites may also be informative with respect to spatial and temporal discrepancies in the station records themselves, for example resolving a non-climatic temperature change that results from geographical relocation of a station."
"However, before any synergistic use of these different data sets can be properly developed, work must first be carried out to understand the relationships between these observation types, which although physically related, are fundamentally different."
"Moreover, the satellite data have a number of limitations that must be taken into consideration; for example, cloud contamination in infrared data, uncertainties in the temperature retrievals and geolocation."
"There are a number of studies documented in the literature where near-surface air temperature is estimated from satellite observations and nearly all of these adopt a statistical empirical approach to predict air temperatures from observed satellite variables and auxiliary data sets [RD-105, RD-106, RD- Europe within the framework of the European Reanalysis and Observations for Monitoring (EURO4M) project (see http://www.metoffice.gov.uk/hadobs/msg_tmaxmin/)."
"In particular, in coastal regions where the skin- air temperature relationship is particularly complex, the effects of satellite view angle, cloud contamination, and where spatial heterogeneity is high as a result of changing topography or land use."
"In this user case study we will determine the effect of spatial and temporal resolution on the accuracy of relationships between the different temperature data sets, as estimated in other studies."
"We will do this in selected regions where there is a high-density network of stations, for example in Germany, the Netherlands, the UK and parts of the US."
"This will also allow us to determine the impact of varying in situ network density, by withholding station data, as well as the effect of the resolution on which information is aggregated and the resolution of the satellite retrievals."
The work will make use of several of the satellite temperature products produced in GlobTemperature to fully understand the spatial aspects of the problem (e.g. ATSR vs SEVIRI vs station).
Uncertainty information provided in the GlobTemperature products will also be considered in the analysis.
This work will enable the identification of the core issues in combining satellite and station data for climate applications.
"A report will be written detailing the work undertaken, describing the issues found, with recommendations for future work."
This information will then also be included in a journal article for peer review presenting the user case study and discussing its implications.
"LST is one of the key parameters controlling the surface heat fluxes, and a key input for some of these ET models."
"Here we will demonstrate the production of LST-driven evapotranspiration (ET) by running the Surface Energy Balance System (SEBS) model, [RD-111] with one of the GlobTemperature generated products (Merged GEO v0.5) over 3 regional sites representative of different biomes and climate conditions."
"The produced ET will be evaluated with the available in situ measurements and the estimates from other ET methodologies produced by the WACMOS-ET project (http://wacmoset.estellus.eu/), being the objective of the evaluation to signal strength and limitations of using the GlobTemperature LST to derive an ET product, compared with the other existing approaches [RD-112]."
"The main result will be one year of daily GlobTemperature LST-driven ET produced over 3 regional sites spread over 3 different continents representing different land cover and climate conditions, together with an analysis of the quality of the produced ET by comparison with other estimates."
"This analysis will drive discussions on the potential to produce LST-driven ET by SEBS-like methodologies, taking into account the characteristics of the GlobTemperature LST estimates and the ancillary inputs required to run the model."
"Over Europe, an area in the Rietholzbach catchment in Switzerland, corresponds to a pre-alpine region, including a sub-catchment studied for more than 30 years, to try the ET estimation over a region with pasture and coniferous forest."
"Over Africa, a region with a climate dominated by the West-African monsoon around one of the savannah mesoscale sites of the African Monsoon Multidisciplinary Analysis (AMMA) Land Model Intercomparison Project Phase 2 (ALMIP-2, a GEWEX Global Land Atmosphere System Study (GLASS) initiative), to test the ET estimation over a grassland region."
"Over North America, a cultivated area around the Atmospheric Radiation Measurement (ARM) Southern Great Plains site is selected in North America, to have an example of ET estimation over agricultural fields."
"This case study will result in an early application of the GlobTemperature product into the expanding field of estimating ET from satellite measurements, and links the GlobTemperature project with another ESA project, WACMOS-ET, which is currently investigating the potential to develop global long-term ET products that may exploit existing and coming European EO assets (e.g., Envisat AATSR, MERIS, and the coming Sentinel series)."
This proposal aims at improving the sea ice description in the model using the remote sensed sea ice/snow surface temperatures from GlobTemperature with additional Metop_A observations.
This will be implemented by improving the surface boundary condition of the thermodynamic equation that is solved in the sea-ice model.
"A pre-processing of the L2P sea and ice surface temperature observations from GlobTemperature will be performed, where the GlobTemperature products are blended with IST observations from Metop_A, to produce a year of daily level 4 SST + IST fields, suitable to be ingested into the HYCOM-CICE model."
The one year with daily SST and IST level 4 fields will cover the area shown in Figure 26.
The data set will be constructed within the user case study and delivered to the project afterwards.
DMI has vertical temperature measurements derived from 8 ice mass balance buoys that were deployed in 2012.
These measurements with a thermistor every 2 cm through the ice will be used as a validation tool of the simulations.
The differences in the ice cover and ice volume between the two simulations will be analyzed and the sea-ice concentration will be compared to the remote sensed sea ice concentration.
"In addition the sea-ice surface temperatures derived from buoys, remote sensing and atmospheric forcing will be discussed and a discussion of the effect of assimilating the IST product direct into the ocean/sea-ice model will be given as well."
The results may also show spatial differences which highlights areas where the IST product is most useful.
This will be combined into a scientific peer-reviewed article.
"Ultimately, the assimilation of IST into the sea-ice model will reduce the error associated with the sea- ice thickness and the sea-ice cover in the operational forecasts, which is of obvious beneficial for commercial marine operators in the ice-covered seas."
"The experiments will start from month 12, initiated at PM2 and be carried in phase 2 of the project."
The ATSR IST observations from GlobTemperature and the 1 km IST observations from Metop_A will be ingested into the DMI L4 IST processing system.
"Daily gap free fields of IST will be produced for a year, with auxiliary information on the daily variability, to optimize the ingestion of the IST field into the HYCOM-CICE model."
The one year level 4 IST data will be validated against drifting buoy observations.
The daily IST fields will be available in Netcdf format to other partners within the GlobTemperature project after generation.
The IST observations will be assimilated into the operational Arctic model at DMI with a nudging scheme that corrects the incoming atmospheric heat flux as an additional term that converges the surface temperature of the ice/snow cover towards the observations.
This will enter into the upper boundary conditions of the thermodynamic equation solved by the sea ice model.
"The IST has a large diurnal variability that very likely exceeds the differences between observations and modeled IST, therefore and in addition to the daily observed IST maps from GlobTemperature the diurnal variations will be used to form a series of fields that includes these variations."
"The coupled ocean and sea ice model is a slightly modified version of HYCOM (HYbrid Coordinate Ocean Model) v2.2.55 [RD-113, RD-114] and CICE v4.0 (Community Ice COde) [RD-115, RD-116]."
"HYCOM explores a hybrid coordinate that is isopycnal in the open, stratified ocean, but smoothly reverts to a terrain-following coordinate in shallow coastal regions, and to z-level coordinates in the mixed layer and/or unstratified seas."
"CICE applies an elastic-viscous-plastic (EVP) sea ice rheology [RD-116, RD-117] and includes a multi- category ice thickness distribution."
The thermodynamics of CICE allows for a vertical temperature profile with a vertical resolution defined by the number of thermodynamic layers (currently 4).
This profile will be compared to the measurements obtained by the drifter buoys.
The difference in of the input (ice/snow surface temperature) will be evaluated both with regards to temporal and spatial differences.
The total sea-ice covered area from the two simulations will be compared to the total sea ice cover derived from OSISAF.
Due to the lack of remote sensed ice volume the sea ice volume will be compared to model results from modeled sea-ice volume found by PIOMAS [RD-118].
The temperature profiles from the buoys and the two simulations will be calculated and the differences will be analyzed.
"The recent retreating sea-ice cover has increased the commercial interest of these remote areas during the last decade due to potential new ship routes, increased tourist cruises and oil exploration."
"Consequently, the need for trustworthy forecasts of atmospheric and oceanographic conditions is highly needed for safely marine operations in ice-covered seas."
DMI is involved in many projects regarding ice management and marine safety in the Arctic.
These uses will thus directly benefit from improvements in the performance of the ocean and sea ice models.
Numerical weather prediction models (NWP) rely on observations for their data assimilation.
"The amount of data in the Arctic is sparse, thus the observational control of the NWP models in Arctic is limited, which allows larger variations of the results and likely larger error bars when compared to other regions."
Monitoring Soil Moisture (SM) is a key variable to determine the water fluxes between the land surface and the atmosphere.
Thermal Infra-Red (TIR) region of the electromagnetic spectrum.
"Additionally, if multiple observations of the land surface are taken at different times throughout the day they can be related to the soil thermal inertia [RD-120] and consequently to SM [RD-121]; and 3) In the optical domain (350-2500 nm), an increase of SM produces an overall decrease in albedo [RD-122] and specific absorption features in the Short-Wave Infrared Region (SWIR) [RD-123]."
"Each of these spectral regions has its own advantages and disadvantages for mapping SM [RD-124, RD- (1 to 2 orders of magnitude) to be compared with sensors in the optical or thermal infrared domain, due to the lower emitted energy in this region."
This is the case of Soil Moisture and Ocean Salinity (SMOS) (50 km) or the future Soil Moisture Active Passive (SMAP) (9km) missions dedicated to monitor SM.
"Regarding optical and TIR sensors, they are greatly affected by the atmosphere, but, on the positive side, they allow a higher spatial and/or temporal resolution."
Different methods have been proposed in the literature to combine thermal information with visible and near infrared data in order to estimate the root-zone SM.
"This is the case of the Temperature-Vegetation Dryness Index (TVDI) [RD-126] based on the triangle method, since it delimitates empirically the triangle formed when plotting many different cases of the Land Surface Temperature (LST) versus a Vegetation Index (VI) [RD-126, RD-127, RD-128, RD-129, RD-130]."
The triangle method was first used by [RD-131] based on the different thermal properties of soil and vegetation: for equal weather forcing conditions soil and vegetation temperatures differ and this fact explains why the LST-VI scatter plot shows a typical triangular shape [RD-126].
The different ranges of moisture availability and fractional vegetation cover within the LST-VI spatial window affects its shape [RD-127].
The upper boundary is called “dry edge” that represents dry soils and stressed vegetation where evapotranspiration (ET) does not occur and hence surface temperature is maximum.
The “wet edge” establishes the lower boundary that corresponds with wet soils and unstressed vegetation where ET occurs near its potential rate and thus surface temperature is minimum and close to the air temperature.
"Between the two edges, all intermediate conditions occur, and all SM conditions can consequently be represented within the LST-VI triangle space."
The dimensions of this spatial domain have to be large enough to collect a sufficient amount of LST-VI cases to adequately define the triangle shape; and 3) Factors like land cover type and topography should also be taken into account to ensure the applicability of the method [RD-133].
In this study case study we propose to produce long time series of TVDI using GlobTemperature datasets for SEVIRI (~4km) and AATSR (1km).
"LST data from SEVIRI and AATSR, produced by GlobTemperature, will be used."
"The area of interest will be West Africa (upper left coordinates 28.0°N, 27.0°W, lower right 3.0°N 26.0°E) as this area presents the optimal conditions for applying the triangle method."
"Particularly interesting is the Sahel region with semi-arid environments, a big sensitivity to drought spells as well as the availability of in situ soil moisture data in several sites."
"In addition, optical data for computing vegetation indices required in the triangle method will be acquired."
"SEVIRI level 1.5 data (0.6, 0.8 and 1.6 µm) is systematically received at the UoC-EUMETCAST processing system."
MERIS reduced resolution level 2 and AATSR data (1km) will be also acquired from the ESA’s MERCI online servers.
"Finally SMOS reprocessed L2 SM will be downloaded from am EOLI- SA/Category 1 access, currently granted at U. Copenhagen."
"In situ soil moisture data aimed for product validation will be utilized for currently operated sites in Senegal (U. Copenhagen), Namibia (KIT), and the AMMA supersites in Mali, Niger and Burkina Faso, the latest ones in collaboration with AGRHYMET thanks to a DANIDA (Denmark's development cooperation) funded project."
"In a first step, from the 15 minute SEVIRI LST, we will estimate the daily thermal inertia at SEVIRI scale as the morning temperature rise (δTs), expressed as the slope of the linear regression of all cloud-free LST observations between 6 and 12 UTC [RD-135]."
"The use of morning temperature rise (δTs) offers some advantages compared to absolute LST measurements; it offers more information than does the single observation of LST, and is less susceptible to systematic retrieval errors as it is a relative value."
Thermal inertia measures the resistance of a material to changes in temperature [RD-136].
A dry soil will present a higher value of δTs than a dry soil [RD-137].
"Finally, to ensure the quality of the δTs data, we will filter out the cases where the R2 of the linear fit of the temperature rise was lower than a given threshold."
Both real-time and archived optical data (since 2006 onwards) is corrected from atmospheric and BRDF effects at the UoC-EUMETCAST processing system.
"First, the 15-minute directional reflectances were atmospherically corrected using a modified version of the Simplified Method for Atmospheric Correction (SMAC) code [RD-139, RD-140]."
"As the atmospheric correction requires an estimate of the aerosol optical depth, water vapour, and ozone content, this information is fed into SMAC from the relevant MODIS atmosphere products on a daily basis (MOD08_D3/MYD08_D3)."
"Then, a semi-empirical Bidirectional Reflectance Distribution Function (BRDF) model, inherited from the MODIS BRDF model [RD-141] is fitted using all daytime observations in a 4-days period [RD-142]."
Modelled BRDF reflectances at local solar noon and observed at nadir were considered the NBAR and from those NDVI and SIWSI [RD-143] will be computed.
The Temperature Vegetation Dryness Index (TVDI) will be calculated from the thermal data and vegetation index data.
"The extension of the scene to be applied will be based on the conditions required for this method: it has to be large enough to represent a wide range of different soil moisture and vegetation fraction conditions, while small enough to ensure atmospheric forcing homogeneity."
Additional mask might be applied to guarantee that the method is applied to both a topographically homogeneous area and to surfaces of similar aerodynamic roughness.
"Once the triangles are calculated, results will be checked to remove those dates where the LST-VI triangle is not properly defined."
"The R2 value of the dry edge fitting, selecting only those dates where the triangles in which this value is higher than a certain threshold."
"Based on [RD-134], the TVDI values from AATSR and SEVIRI will be used as proxy for soil evaporative efficiency (SEE) at high spatial resolution (1-4 km)."
"Where 𝑆𝑀ℎ𝑖𝑟𝑒𝑠 is the high-resolution (1-4 km) SM product, downscaled from the original SMOS data efficiency (SEE), 𝑆𝐸𝐸ℎ𝑖𝑟𝑒𝑠 is the estimated SEE at high-resolution data, based on the TVDI, and 〈𝑆𝐸𝐸ℎ𝑖𝑟𝑒𝑠〉40𝑘𝑚 is its aggregated value at the SMOS scale."
The soil moisture data will be validated with in-situ measurements.
"Firstly, spatio-temporal trends in TVDI values will be compared with soil moisture and rainfall data."
"Secondly, the SMOS SM and its downscaled product will be also validated with soil moisture measurements."
"Due to the linear downscaling approach, bias in SMOS SM will also be transferred to the downscaled product, nevertheless, it is expected a higher agreement of the downscaled SM than with the original SMOS resolution."
"Finally, changes of soil moisture will be related to vegetation dynamics by trend analysis of vegetation indices (NDVI and SIWSI) and remotely sensed Leaf Area Index."
The aim of this work package is to assess the impact of assimilation of land surface temperature (LST) retrievals from satellite observations within a land data assimilation scheme that is coupled to a numerical weather prediction model.
"The assessment will include both the impact on variables at the land surface (such as soil moisture and soil temperature), but also the key atmospheric forecast variables such as near surface temperature."
The anticipated outcome of this study will be an assessment of the quality of the LST observations from satellite through comparisons with in situ data and NWP forecasts of LST.
Satellite LST observations will then be assimilated into the Met Office land data assimilation scheme and an assessment of the impact to both land surface analyses (soil moisture and temperature) and atmospheric forecasts will be made.
Because of the recent improvements to both the modelling of the land surface and assimilation at the Met Office the source of the satellite data will need to be from a recent observing period.
Consequently either the GlobTemperature near real time data will be used or Met Office derived LST observations from polar or geostationary platforms.
It is anticipated that this work will be performed during 2015.
Assessment of LST quality through comparisons with in situ and model forecasts.
In situ data such as the radiometer at the Met Office Cardington site would be used and converted to an equivalent LST measurement.
The GlobTemperature product will be validated against both the in situ data and against values of LST from the operational Met Office atmosphere model.
The in situ data is a more accurate reference but the model data gives global coverage.
The metrics examined will be standard error and bias.
Adaption of existing current Met Office land DA scheme to ingest new satellite LST observations.
This will include simple quality control informed from work package 1.
"Work is needed to adapt the current software (in Fortran 2003) to ingest the GlobTemperature product, including mapping the product to forecast model gridpoints, thus ensuring uniform coverage."
It is expected there will be significant biases between GlobTemperature and the model LST fields over some surface types (e.g. desert) and so bias correction is likely to be required.
This might need to be a function of both season and time of day.
CDF matching (cumulative distribution function) is the preferred option for calculating the biases.
"Outcome: Working software to ingest GlobTemperature data, perform QC and bias correct, meeting Met Office quality Standards, ready for use in a full NWP impact study."
Trials of assimilation of satellite LST within the Met Office Numerical Weather Prediction (NWP) system.
"A trial of the full NWP system of at least one month duration will be performed in which satellite derived LSTs are assimilated using the new software on top of observations, satellite derived soil moisture)."
The forecast lead time in this assessment will be from 1 to 5 days.
Outcome: a comprehensive report examining the results of the assimilation trial.
The outcome of this study will be an assessment of the impact of satellite LST within an NWP system and recommendations for the operational use of such data.
At operational NWP centres the use of land measurements has focused up to now on soil moisture and this study will be an important step forward in the use of satellite derived data.
The results found here will equally be applicable to reanalysis work and will help to inform use of satellite data in projects such as the EURO4M – EURRA reanalysis (of which the Met Office is a partner).
"Dissemination plans are provided in Table 12, and access information is provided in Section 6.1.3."
Once a dataset is released to the user community via the Data Portal evolution of the algorithm and further re-processing will be carefully managed.
A minimum period of three months will be enforced between releases.
"The demand for a re-processed release will be governed both by user feedback, including detailed application within the User Case Studies, and any issues as identified by the ongoing Validation and Intercomparison activities."
In reality it is not foreseen that progressive releases of the same dataset will occur at such a high frequency as quarterly (addresses requirement REQ-14-TR).
Users will be updated via email on release of new and re-processed datasets.
For current satellite data sources the timeliness of new observations will be 7 days once the final version of the given dataset has been released to the Data Portal for user dissemination (see Table 37).
It is the intention of the Project consortium to support the Data Portal post-project.
"The nature of this support is maintenance of the Data Portal architecture and functionality, and provision of existing data products."
"There is a strong user requirement to keep products current on the Data Portal and to add new products, which is beyond the current scope of the Project, but where feasible (further funding, follow-on work, or other projects allow for this) such products can be updated."
Each version of the Technical Specifications will include a list of publications directly related to the work carried out under the framework of the GlobTemperature Project.
It is expected that each User Case Study will generate publishable material in addition to an overall publication on the Project itself.
Additional publications will also be encouraged; it is expected that each scientific Work Package in this project will produce at least one such publication.
The publication of results in international peer- reviewed journals will be the responsibility of the lead Project Partner for each activity.
Each publication will explicitly acknowledge the support of the ESA DUE GlobTemperature project.
"Specifically, detailed user input into the specifications of the GlobTemperature Products; user involvement in testing the data (particularly through both the User Case Studies, and the Champion User setup); and a core programme in building the LST community globally, involving both data producers and users, through association with the EarthTemp network and the GlobTemperature UCMs will achieve a coherence and openness in facilitating the use of satellite LST data."
Provision of products which meet the needs of the user community is thus the very core of the GlobTemperature Project.
"As evident in the Baseline Requirements Document users of LST data are from a broad spectrum of disciplines, and vary in their capacity both to identify and access available datasets and to handle varied data formats."
"Guidance is frequently required by users of LST data about the suitability of different datasets for different applications, together with quantification as to why individual datasets differ amongst themselves."
The agreed common nomenclature (Section 2.1) for uncertainty and accuracy needs to be disseminated to the users so they are able to compare different datasets with knowledge that these are consistent in their information.
"The objective is to provide comprehensive user-friendly to support to the user community, and where necessary to educate the user community in the optimum exploitation of satellite LST / IST and LSWT products."
"This will be achieved via a mixture of personal communication via email / phone, information provided via the Website, GlobTemperature Newsletters [AD-4], peer-reviewed publications, GlobTemperature reports for public dissemination, conference / workshop presentations, and UCMs."
A schematic of the communication lines with the user community is shown in Figure 30.
"The strategy for user support also includes a commitment to sustained operation of GlobTemperature from all consortium members beyond the lifetime of the project; and particularly, from ACRI-ST who host the Website and Data Portal, the University of Leicester who lead the project, and IPMA who operate the NRT LST services of the LandSAF for EUMETSAT."
"GlobTemperature User Mailing List is constantly evolving and regular emails are sent out to the users informing them of upcoming events, GlobTemperature news, Website and Data Portal developments such as the availability datasets and their documentation, which is also supplemented for “Champion Users” with more personal email updates."
"This intensive level of communication with the users will continue throughout the Project lifetime and beyond, where for example notification of the availability of new datasets / re-processing of existing datasets will be announced in a timely manner (addresses requirement REQ-15-TR)."
The full GlobTemperature User Mailing List is available to all Project Partners via the GlobTemperature Website.
"Statistics on individual user exploitation of the datasets on the Data Portal will be maintained as will the User Registrations on the Website and Data Portal with additional information on other interactions logged in the mailing list, such as attendance at User Consultation Meetings, participation in the User Requirements Survey."
"Such level of detail, whereby types of users are categorised, is required to enable a more tailored approach to interacting with the user community."
These groups will seek to develop partnerships with international bodies identified above.
The ILSTE-WG in particular will cement relationships with the external activities / agencies listed in Table fostering formal links with these entities.
The ILSTE-WG will also be a key guiding hand facilitating improved communications with the LST data providers and the user community (Figure 31).
Conferences and workshops are an important forum for dissemination of user information through presentations to a wider audience.
A presentation pack is available on the GlobTemperature Website as a resource for Project Partners to utilise when preparing conference / workshop presentations.
It is anticipated that each Work Package will result in at least one presentation at a conference.
The User Requirements defined from the results of the User Survey have been augmented with updates following mini- questionnaires carried out during breakout sessions.
The Technical Specification and User Requirements can be linked to relevant GlobTemperature Deliverables.
"Internal management deliverables are not linked since they do not relate specifically to the enumerated User Requirements or Technical Specifications, but are listed for completeness."
The Technical Specifications have been updated following mini-questionnaires carried out during breakout sessions thus satisfying the technical requirement GT-TS-4; these updates are in response to the updates to the User Requirements (Table 6).
The updates to the Technical Specifications are summarised in Table 44.
"Develop Climate Data Record of 20-years for (A)ATSR in harmonised format with low bias, high precision, and high stability."
"Data Portal to provide visualisation tools and statistics for LST data, LST anomalies, validation information and intercomparison data."
Where possible a mechanism will be explored through the ILSTE-WG for data providers and users to share visualisation and analysis tools.
"Develop platform independent tools for reading and sub-setting datasets provided in the harmonised formats, and cloud filtered time series extraction."
Where possible a mechanism will be explored for data providers and users to share reading and sub-setting tools.
"User functionality to be provided to allow selection of optional variables from auxiliary datafiles, and Data Portal tools to allow sub-setting of data."
"In addition to updates to the Technical Specifications via the updates to the User Requirements following the UCMs, the project also captures the qualitative user feedback from these meetings."
This feedback should influence future developments within the Project.
"As such, a set of User Feedback specifications has been defined; with individual items addressed in the previous sections, and a summary presented in Table 45."
"Not all user feedback falls within the current scope of the Project, such as: the need for high spatial resolution data for urban studies in particular, but also for ET applications; continued updating of data products with new observations; and the provision of multi-year SSM/I data."
"Where these lie outside the scope of the project, they are nonetheless recorded in the GlobTemperature UCM Reports [AD-7], but not transformed into specifications."
The International LST & E Working Group (ILSTE-WG) core membership can be categorised as Steering Committee membership (Table 46) or General membership (Table 47).
It is envisaged that although initial membership has been with these individuals over the course of the Project (and beyond) membership will be more fluid with additional members becoming involved.
The structure and function of the ILSTE-WG may also evolve over the course of the Project (and beyond).
"Here we define six classes of in situ data, describing a wide range of possibilities with respect to the data quality and expected validation accuracy as well as complexity and expense of data acquisition."
"In addition to proper instrumentation and calibration, a key element in defining the different levels was the availability of multi-year time series of radiometer data, since long and consistent time series are becoming increasingly valuable, not only for allowing a significantly increased number of satellite vs. in situ matchups for better statistical analysis, but also for better identification of instrumental issues such as drift."
A class 1 in situ validation site completely fulfils all the criteria listed above.
"At the time of writing no such sites exist, primarily due to the lack of a comprehensive and documented uncertainty budget at the currently existing Class 2 sites."
"Class 2 in situ data are established long-term in situ validation sites, completely equipped with one or more highly accurate and calibrated radiometers, which provide continuous observations with no or only small data gaps."
The sites are either completely homogeneous over an area of ideally 3 x 3 pixels or alternatively heterogeneous with well-documented and measured heterogeneity.
"In addition to radiometers, these sites measure the standard meteorological parameters."
All instrumentation and procedures must be well documented and the site description must be available to the LST research community.
"The sites in this class only lack one of the criteria listed above, in most cases this is a comprehensive uncertainty budget."
In situ validation sites that fail to meet two of the criteria listed above are considered Class 3 sites.
"In addition to the lack of an uncertainty budget, such sites typically have long (multi-year) time series but are not continuous in the sense that measurements are only taken during certain times of the year."
"At this site, LST measurements have been carried out with calibrated radiometers for several years, however the sampling was limited to the summer months of each year."
In situ validation sites that fail to meet three of the criteria listed are considered Class 4 sites.
"This includes stations that have potential as Class 2 (or even Class 1) stations, but that currently only have relatively short time series which may have substantial gaps due to instrument failure or cloud conditions."
Furthermore this class contains station networks established for reasons other than LST validation as well as most validation campaigns that provide high-quality and reasonably well- documented data but only for a very short time period.
Class 5 in situ sites violate four of the listed criteria.
"An example of Class 5 in situ data includes measurements made by the United States Climate Reference Network (USCRN) (NOAA/NESDIS, 2007)."
This network provides continuous surface temperature data at 114 stations located within the continental United States and is planned to be operated for many decades in order to provide consistent datasets for climate research.
"However, while the stations provide data on infrared ground surface temperature, the calibration level of the instruments and thus the data quality is currently unknown."
"In addition, the data are currently only recorded at hourly intervals."
Further research needs to be undertaken to determine the feasibility of using USCRN data for LST validation.
"If the outcome of such an analysis is positive, it is likely that USCRN data can be classified in one of the higher classes in future."
Class 6 in situ observations violate at least five of the listed criteria.
"This lowest level of complexity and validation quality is generally provided by in situ measurements of LST proxies, such as air temperature."
"It has been shown that the air temperature and ground surface temperature are almost the same during certain hours of the night and that air temperature can thus be used as a surrogate dataset to validate LST as a first approximation if the satellite overpass occurs temporally close to those times (Prata, 2003)."
"While this technique obviously only allows for rough comparisons, air temperature is ubiquitously observed at a large number of meteorological stations worldwide, so this class potentially includes a multitude of stations that can be used for providing general guidance on LST quality at a global scale."
Such an approach has for example been used in Greenland [RD-166].
The accuracy classes for this category are established based upon the expected accuracy of both the radiative transfer code and the atmospheric profiles.
"Three classes have been defined, ranging from highest to lowest expected accuracy of the validation."
"A Class 1 radiance-based validation fulfils both of the criteria listed above, i.e. it uses line-by-line radiative transfer code in conjunction with atmospheric profiles of air temperature and water vapour observed directly at the validation site during the time of the satellite overpass."
The combination of a line-by-line radiative transfer code together with a radiosonde-based atmospheric profile provides the highest possible level of accuracy for this type of LST validation.
A Class 2 radiance-based validation is performed very similar to a Class 1 radiance-based validation; however one of the two classification criteria is not met.
"Therefore, a Class 2 radiance-based validation uses either a band-transmission radiative transfer model in conjunction with radiosonde-based atmospheric profiles observed directly at the validation site during the time of the satellite overpass or a line-by-line radiative transfer model in conjunction with atmospheric profiles obtained from a less accurate source such as from a reanalysis dataset."
A Class 3 radiance-based validation relaxes both of the classification criteria necessary for a Class 1 validation: It uses a broad-band radiative transfer model together with atmospheric profiles obtained from an atmospheric model.
"As such, this validation class is expected to provide the lowest level of validation accuracy; however it is still a very valuable validation method when no ground LST measurements are available."
Matchup times must be within a specified threshold – a recommendation being ±10 minutes.
A Class 1 inter-comparison is considered the most accurate type of inter-comparison.
Such an inter-comparison can for example be accomplished by using data from two instruments onboard of the same satellite platform or alternatively from similar instruments flying successively along a similar orbit (such as the A-Train group of satellites).
A Class 2 inter-comparison relaxes one of the criteria established above.
"As such, this accuracy class encompasses LST inter-comparisons of datasets that deviate in their respective matchup times by more than the recommended threshold."
A special case of Class 2 inter-comparisons are airborne LST observations.
"Aircraft equipped with radiometers are a powerful tool for validating both TOA radiances and LST derived from spaceborne instruments, as they provide much higher spatial detail than satellite data."
They further allow detailed observations of the atmospheric conditions.
The primary advantage of the airborne platform is that it allows coverage over a much larger area than could normally be achieved with field measurements and provides significantly more spatial detail than satellite observations can deliver.
"However, it is a requirement that the instrument is well calibrated."
Airborne TIR instruments are generally flown in dedicated validation campaigns and as such are specifically set up to match the satellite instrument to be validated in terms of overpass time and viewing angle.
"However, due to the episodic nature of such campaigns and the resulting lack of operational availability, data acquired in airborne LST campaigns does not fulfil one of the criteria listed above and thus is classified as a Class 2 inter-comparison."
"The third accuracy class within the inter-comparison category encompasses the inter-comparison of satellite-derived LST data with spatially distributed LST proxy data, such as reanalysis data as provided by the ECMWF [RD-96, RD-167] or NCEP [RD-168]."
"In contrast to the other three validation categories, no specific key criteria were defined for category D. While criteria such as the length of time series, the number and size of gaps in the time series, and the temporal sampling could be used to define classes, such requirements are highly dependent on the goal of the time series analysis and vary widely."
"Instead, accuracy classes for this category were established simply based on the geographical scale over which the time series are computed."
"This follows the idea that localized time series will be able to be interpreted more easily than global time series, as the latter usually combine a whole number of artificial and natural issues and thus make the identification of individual instrument problems or similar validation issues very challenging."
A Class 1 time series analysis is performed at the single pixel level (or an average over a small number of neighbouring pixels).
"Plotting and studying reasonably long time series of such a small area can be very valuable for identifying algorithm and instrument issues, such as increased noise or calibration drift."
A Class 2 time series analysis is performed at for a geographically invariant scene.
For most instruments on low earth orbit platforms this means areas at a scale on the order of a few hundred kilometres.
A Class 3 time series analysis is performed at the regional scale.
"This could be on the scale of a country, a continent, or a certain land cover type."
"While not as powerful as Class 1 and 2, this type of time series analysis can still provide valuable information about problems in the data."
For biome based retrieval algorithms this may uncover biome-specific retrieval issues.
A Class 4 time series analysis is computed at the global scale.
"While this type of analysis is not as useful for validation purposes as the other three classes, it can still provide interesting information."
"Furthermore, after establishing their accuracy, global time series are extremely relevant for global change research."
"USGS/Earth Resources Observation and Science (EROS) Center, Sioux Falls, South Dakota."
"This is the SoA of devices and actuators technologies, capabilities, drawbacks, innovative approaches and challenges that are closely related to DiYSE."
"Smart environment systems, for achieving its goals, must gather information about objects surroundings by means of sensors and must also be able to make such surroundings evolve to the desired conditions by means of actuators."
This document shows present sensors and actuators technologies capabilities related to DiYSE as well as the challenges and requirement specification that DiYSE must meet.
"The DiYSE project has three State of the Art (SOTA) documents covering the different tools, techniques, methods and environments that may be used to provide a DiYSE platform."
These documents present the same pool of elements from different points of view.
"Due to this SOTA partition, it will be needed to link some of the sections from one of the documents to other sections on some of the other two documents."
"In WP1 (Use cases and requirements), deliverable D1.1 will focus on which requirements will be covered by web technologies, mobile technologies, system platforms and toolsets, i.e. how the users will access the smart experiences by using these systems."
"This document will present the SOTA of current applications, systems platforms and business models relating to DiYSE."
"This includes Ambient Experience applications, features of toolsets and the business models and ecosystems that are working at this moment in similar proposals."
"The document also includes a PEST (Political, Economical, Social, Technological) analysis."
"It is important to know why people are motivated to produce and share services, devices, etc."
"In WP4 (Interactive Experience Creation), deliverable D4.1 analyses similar elements to D1.1, but from the user/developer point of view: how the users will use the elements of the DiYSE ecosystem."
The review of existing application creation approaches will identify technologies that may be supportive for the envisioned creation of applications and services in smart spaces.
Also the issue of actually do-it-yourself versus do-it-together (or have the community do it for you) and crowdsourcing will be addressed.
The document reviews how to create interactive experiences.
The objective of the whole Do-it-Yourself Smart Experiences (DiYSE) project is to enable people to transform their everyday environment into a highly personalized meaningful communication/interaction experience that can span the home and city domains.
"The project aims to create a marketplace for user-generated application components, in which non-technically-skilled people can participate, re-using components designed by savvy users."
"Within the DiYSE project, work package 2 aims at bridging the gap between software and the physical world."
It will do so by enabling end users to connect to the system all kind of input and output devices and smart objects.
"They will enable to gather raw data from the environment, process it and enrich it to deliver meaningful information about surrounding phenomena and more generally interact with the environment."
Work package 2 has the challenge of enabling non-technical users to customize their environment by installing and configuring themselves devices they can buy or easily assemble.
"We will produce software and documentation both for expert users wanting to assemble hardware and customize software to tailor it for their usage, and also for non-technical users wanting to reuse final hardware and software components."
The objective of this document is to study the state of the art on several technical challenges in heterogeneous Internet-of-things device interconnection and derive high-level requirements for the architecture design phase.
"Section 2 lays the context for non-technical users on the kind of devices we are addressing, the interactions they provide and the realistic scenarios where they can be used."
Section 4 deals with techniques and algorithms to extract meaningful information (such as identification or location) from raw data provided by devices and the way this information is delivered to applications.
"Section 5 zooms into a specific technology for the interaction with the environment, Wireless Sensor and Actuator Networks."
"In particular, we will identify the potential and the major challenges raised by its use in DiYSE applications, and analyze the associated requirements and state-of-the-art."
Section 6 provides a brief survey on the existing Do-it-Yourself hardware platforms and identifies the technical challenges that need to be addressed to simplify the exposure of DiY devices in the DiYSE platform.
This section aims at providing partners that are not involved in WP2 with information about the devices that may be available to the project and the kind of general functionalities that those provide.
"It will also identify a few representative scenarios involving devices, which will be used as guiding vectors for WP2 works."
"Data acquisition (or sensing): device is used to capture data from the physical world (e.g. : acceleration, temperature…) and provide information to the system."
"Identification: specific type of data acquisition providing the unique identity of an object (e.g. : using barcodes, smartcards, RFID tags, etc."
Sensors can sample data periodically (eg: sound recording) or trigger events when a given condition is met.
"For instance, IP cameras might be employed to read the lighting level, so that some component may ask “Is it dark?” and the reply would be true or false."
"They can also be used to recognise some objects (i.e. : a game where a child has to find a picture hidden in a room, and then show it to the camera so it can continue to the next step) and they can record and or analyse sound upon request (for example, recognise when someone is crying)."
Some IP cameras have integrated speakers that can be used to play sounds (waveforms).
These can be used to play a given sound when a certain message is received.
"Finally, there are cameras with a small LED light that might be used to provide information to the user."
There are several devices for locating and positioning people and objects.
"For instance, mobile phones can be used for locating purposes and GSM / GPS devices can be used for locating people indoor and outdoor too."
"In the later case, when GPS signal is lost, GSM and last GPS position are used to locate people, some commercial devices such as Navento [4] and Senda GPS [5] use this approach."
"Smart phones supported with GPS, Bluetooth, digital compass and WIFI technology provide a variety of techniques to perform user location."
"Laptops, netPCs may use WIFI connection to locate users."
"In the other hand, there are other kinds of devices such as RFid tags and magnetic tags that can be applied for locating purposes."
Finally QR-codes and others patterns can be also used to locate people and objects.
"When the presence and identity of people and objects matters but their exact location does not, then the identification process appears."
"There are a lot of devices and techniques in order to identify people and objects, the most frequently used being RFID tags."
Each tag provides information about the object or people who carry it.
Some examples of use can be found in parking or room access control systems.
Another kind of identification system uses visual recognition of some patterns.
QR-codes can be used to provide identification information too.
"In the other hand, wireless connection devices can provide identification information via the communication technology they use, i.e., Bluetooth, Zigbee, and WLAN can provide MAC addresses in order to identify devices or people who carry or wear them."
"Finally, smart and mobile phones can provide identification information depending on the cell they are connected at each time."
This section lists the high-level requirements for the integration of devices in the DiYSE platform and identifies for each of them the existing standards and technologies.
This subsection is devoted to overview the different communication technologies which could be used by devices in any of the proposed DiYSE scenarios.
"Despite on those scenarios most communication technologies are hard-wired (due in part to the lack of appropriate, reliable, and cost-effective wireless solutions), in this subsection we will only focus on wireless alternatives."
"The main advantages of a wireless solution are its ease of installation and deployment, the system flexibility, a dynamic network formation and the low cost which are mandatory issues for the proposed scenarios."
"Moreover, this subsection finishes with a survey of the most commonly used approaches to provide the coexistence and the interoperability of the related standards1."
"Generally Wireless Sensor Networks (WSNs) are originally standalone networks, where sensor readings are usually disseminated towards the sinks or gateways located in the boundaries."
"However, numerous WSN applications lead to the need of interconnecting WSNs to the external networks (e.g. Internet) to introduce WSN applications into different domains."
The interconnection of WSNs with Internet or other communication networks also relaxes the control and management tasks of WSNs under dynamic changes of the application environment (see Section 3.8).
"The IEEE 802.15.4 standard, designed specifically for remote monitoring and control applications, defines the characteristics of the physical and MAC layers for Low-Rate Wireless Personal Area Networks (LR-WPAN)."
"Several leading radio manufacturers have implemented IEEE 802.15.4, which specifies a wireless link for low-power personal area networks."
"It is widely used in embedded applications, such as environmental monitoring to improve agricultural yields, structural monitoring to track building and bridge integrity, industrial control to provide more sense points and control points at lower cost."
"These applications generally require numerous low-cost nodes communicating over multiple hops to cover a large geographical area, and they must operate unattended for years on modest batteries."
"Such requirements target a very different set of applications than do WPAN technologies such as Bluetooth, which eliminate wiring for headsets, game controllers, and personal devices."
"Accordingly, 802.15.4’s capabilities are more limited than other WPANs and WLANs – they have small frame sizes, low bandwidth, and low transmit power."
"Additionally, the microcontrollers typically coupled with LR- WPAN radios have limited memory and compute power."
"This stack specification builds upon the IEEE 802.15.4 standard, hence it only defines the network and security layer, handling star and peer-to-peer network topologies, and providing a framework for application programming in the application layer."
The 6LowPAN group has defined encapsulation and header compression mechanisms that allow IPv6 packets to be sent to and received from over IEEE 802.15.4 based networks [3].
"Because of the potential of direct compatibility with the existing Internet infrastructure, 6LowPAN can be viewed as a significant factor in future sensor networks."
It is also the most profound RFC [4] clearly breaking the OSI layered model and it exploits cross-layer information to minimise protocol overhead.
It uses information in the link and adaptation layers to compress network- and transport-layer headers.
The 6LowPAN may be connected to other IP networks through one or more border routers that forward IP datagrams between different media.
"Connectivity to other IP networks may be provided through any arbitrary link, including Ethernet, Wi-Fi, GPRS, or satellite as the next figure shows."
"It is an open-standard wireless networking technology developed by HART organizing, and self-healing mesh architecture and it currently operates in the 2.4 GHz ISM Band upon IEEE 802.15.4 standard but specifying new Data-link (including MAC), Network, Transport, and Application layers."
W-HART was defined specifically for the requirements of process field device networks and industrial automation and to interoperate with the widely existing HART technology [5].
"It is a proprietary mesh network standard developed by ZenySys and standardized by the Z-Wave alliance (including Intel and Cisco) which is intended for home automation, residential and light commercial environments."
"Some of its applications embedded in consumer electronics products are remote controls, smoke alarms or appliances."
The Z-Wave RF system operates in the sub Gigahertz frequency range (900 MHz) and it is optimized for low-overhead commands and reliable communication [6].
ONE-NET is an open-source standard which defines the physical and network layers for wireless networks.
"It was designed for low-cost, low-power control networks for applications such as home automation, security & monitoring, device control, and sensor networks."
"ONE-NET is not tied to any proprietary hardware or software, and can be implemented with a variety of low-cost off-the-shelf radio transceivers and micro controllers from a number of different manufacturers."
"ONE-NET is the only wireless control network that is based on the Open-Source philosophy (no royalties, freedom for use and modify, BSD license and Lots of design choices with open design standard)."
It operates in the 900 MHz band but additional frequencies are also possible [7].
It is a proprietary solution devised by Coronis System in 2001 but standardized as open by the Wavenis-OSA.
"Wavenis technology provides a platform to deploy Machine-to-Machine (M2M) applications such telemetry, industrial automation, home applications, etc."
Its main strengths are ultra-low power consumption and long-range small amounts of data communications without the needed of Line of Sight (LOS) using the 900Mhz and 433Mhz band [8].
"DASH7 (ISO 18000-7) is a new, trade alliance with the goal of increasing the market size for ultra-low-power wireless products."
"Like ZigBee Alliance, DASH7 partners affectively address interoperability as well as the development of improved functions into the standard."
"DASH7's range of more than 1 kilometer (433Mhz), multi-year battery life, and ability to penetrate walls and water make it preferable in several WSN applications."
"DASH7 can be used with a variety of devices, from stand-alone DASH7 ""tags"" that monitor goods to mobile phones that allow consumers to monitor the energy usage in their own home [9]."
"Mi-Wi and MiWi P2P are proprietary wireless protocols designed by Microchip Technology that uses small, low-power digital radios based on the IEEE 802.15.4 standard."
The technology aims to get low-data rate and short range distances by reducing the complexity of others WSN technologies (e.g. ZigBee) and reducing the footprint for constrained memory devices [10].
"INSTEON is a robust, redundant dual-mesh network that combines wireless radio frequency (RF) with the home's existing electrical wiring."
INSTEON is less susceptible than other single band networks to the kind of interference and noise commonly encountered within the home (900Mhz band).
It leverages the latest digital technology to create a true peer-to-peer mesh network.
"Because every INSTEON devices are flat, they do not require network supervision (network controllers and routing tables are not required)."
"On the power-line, INSTEON devices are compatible with legacy X102 [11]."
IEEE 802.15.1 (Bluetooth) is another wireless link technology that falls under the WPAN classification.
Bluetooth supports relatively high throughput for a limited number of nodes within a small range.
"The key features of Bluetooth technology are robustness, low power, and low cost."
The Bluetooth specification defines a uniform structure for a wide range of devices to connect and communicate with each other [12].
"Bluetooth technology has achieved global acceptance such that any Bluetooth enabled device, almost everywhere in the world, can connect to other Bluetooth enabled devices in proximity."
"Bluetooth enabled electronic devices connect and communicate wirelessly through short-range, ad hoc networks known as piconets."
Each device can simultaneously communicate with up to seven other devices within a single piconet.
Each device can also belong to several piconets simultaneously.
Piconets are established dynamically and automatically as Bluetooth enabled devices enter and leave radio proximity.
"Bluetooth technology operates in the unlicensed ISM band at 2.4 to 2.485 GHz, using a spread spectrum, frequency hopping and full-duplex signal."
It is a digital radio technology (intended to become an open standard of wireless communications) designed for ultra low power consumption (button cell batteries) within a short range (10 meters) based around low-cost transceiver microchips in each device.
"Wibree is not designed to replace Bluetooth, but rather to complement the technology in supported devices."
Wibree-enabled devices will be smaller and more energy-efficient than their Bluetooth counterparts.
It operates in the same ISM band with a bit rate of 1 Mbit/s as its “big brother”.
"It primarily uses power line wiring for signaling and control, where the signals involve brief radio frequency bursts representing digital information."
"UWB is defined as any radio technology having a spectrum that occupies a bandwidth greater than 20 percent of the center frequency, or a bandwidth of at least consumption for distances of less than 10 meters which can satisfy most of the multimedia applications such as audio and video delivery in home networking and it can also act as a wireless cable replacement of high speed serial bus such as USB where many devices are involved, low power is a must and high data rates are important (e.g. medical monitoring) [15]."
Since UWB operates at very high frequencies it has very high penetration loss which will significantly affect the performance and size of the network nodes.
"Although UWB was claimed very low power initially in the literature, the attempts of such technology in the integrated circuits have exhibited power consumption more than that of the conventional narrowband short range wireless chips."
A major drawback to date with UWB has been the standards issue.
In January 2006 the IEEE abandoned its efforts for standardization or the 802.15.3a Task Group (TG3a).
The two groups developing UWB technology failed to come to agreement on a single solution.
Wireless Fidelity (Wi-Fi) includes IEEE 802.11 that is an evolving family of specifications for WLANs developed by the IEEE working group.
There are several (e.g. Sense Multiple Access with collision avoidance (CSMA/CA) for path sharing.
The modulation used in newer 802.11 specifications is complementary code keying (CCK).
The newer modulation methods provide higher data speed and reduced vulnerability to interference which permit users to surf Internet at broadband speeds when connected to an Access Point (AP) within the BSS (about 100m far) or in Ad hoc mode on the IBSS[16].
"RFID is the most pervasive communication technology mainly used in the called Internet of Things (IoT)3, in fact, the International Telecommunication Union (ITU) considers RFID a key enabler of the IoT concept."
That is because its good standardized status and low price of the simplest units.
"Main components of RFID technology are a transponders, interrogators and middleware."
A transponder (tag) is attached to or implanted in an object.
"RFID tags can be passive, semi-passive or active in nature, and information on tags can be read-only, read-write or rewritable[17]."
The communication between RFID tag and reader is performed using magnetic inductance (contactless).
This mechanism can also provide enough power to allow passive tags to operate without internal power source when they are exposed to the reader’s magnetic field.
"Passive tags have very limited range, but some active ones can offer a range of up to 100 meters."
Information from the RFID objects is usually fed through some middleware application which forwards data to back-end systems for further processing or storage.
"Normally one is not going to access objects directly, but utilize the data through back-end applications."
"NFC is an extension of the ISO 14443, standardized in ISO 18092 and ISO 21481 using the frequency band of 13.56 MHz."
NFC basically combines the operation of RFID transponder and interrogator (the reader) into one unit.
"The range of operation is very limited, about 10 centimeters (via magnetic field induction), which allows high density of objects in a given space so that they do not interfere with each other [18]."
NFC is a combination of RFID contactless communication technology and wireless networking technology.
The main difference between NFC and RFID is that in the NFC is possible to have a bidirectional transmission of information and NFC readers are primarily aimed at its usage in mobile phones.
"The principal applications of this technology are the peer-to peer communication between NFC enabled devices, payment and ticketing applications on mobile phones (this was one of the drivers for the creation of the NFC standard) and services or communication initiation[19]."
"These can be wired or wireless connections providing connectivity with remote services, central processing units or data aggregation facilities."
Examples would include WSNs connected back to environment monitoring information servers which are located in a monitoring centre.
Often this link is referred to as 'backhaul' and it is the data pipe that brings the sensed data back to a centre where it can be processed.
"Although narrowband solutions could be used if the data rates are low and network latency is permissible, the key breakthrough many times is the availability of Broadband technologies such as xDSL, WiMAX, 2.5 G (GPRS), 3G(UMTS) or satellite communications [20]."
We consider that it is relevant to seamlessly compare the main well know wireless communication standards since it is important to get an idea of which of them we are going to use in the DiYSE scenarios.
"In fact, choosing a technology or another, we will likely obtain more or less advantages regarding coverage, topology, deployment, and so on."
"Selecting the most appropriate networking technology for a specific application can be challenging, and one size does not fit all."
"In some cases, a hybrid approach may be the best option, as we later show in the interoperability subsection."
"For instance, a low-power, short-range subnet, such as ZigBee or 6LoWPAN aggregating sensor data for wide area communications across a GPRS/UMTS or Wi-Fi network."
"With a growing selection of wireless networking alternatives, users are no longer confined to wired installations, and with cost-effective and reliable wireless products emerging based on global standards, users are no longer restricted to proprietary wireless approaches."
In Figure 3 a comparative graphic with the most well known wireless communication standards is presented.
In section 3.1.1. we have presented an overview of the WSN communication technologies which could be found in the current market.
As we described there are some of them which have become standards and others that are emerging quickly and are intended to get the standardization soon.
"For sensor-based systems that require the flexibility of a wireless network, and which can tolerate modest message latency, users can select between proprietary and standards-based solutions."
"Since proprietary systems are usually customized to their application, they can offer benefits in transmission range, very low power consumption and per unit cost."
"However, they are not generally more secure than standards based systems, and their proprietary nature means that they can’t achieve the high unit volumes and aggregated industry investment of standards-based systems [21]."
"Because the standardization is paramount to simplify and assure the broad use and applicability of the WSN technology, hereafter a comparison table of four of them (which we consider are probable candidates for the DiYSE scenarios) are presented4."
In the table it has been showed their main technology features and on the bottom their weaknesses and strengths that should help us to decide which protocol we will apply in the each of the proposed scenarios.
"In the next table we roughly compare IEEE 802.15.1 (Bluetooth) wireless link technology, which falls also under the WPAN classification and IEEE 802.15.3 that pushes WPAN capabilities further, with greater throughput and support for more nodes."
"Although both are intended for battery operation, they only target lifetimes of several days to several weeks."
"In contrast, 802.15.4, which was before compared in Error!"
"Finally, the IEEE 802.11 standards (including Wi-Fi which is designed to substitute wires between devices) is also included in the comparative table."
"In addition to this comparison, we can find many related studies in the literature."
"For Bluetooth and Wi-Fi, Ferro and Potorti [24] compared their main features and behaviours in terms of various metrics, including consumption."
"In addition, the power management of 802.15.3 is easier than that of 802.11e."
"Since Bluetooth, ZigBee, 6LoWPAN, Wi-Fi and others use the 2.4GHz band, the coexistence issue between these standards must be dealt with."
"Basically, Bluetooth and UWB provide adaptive frequency hopping to avoid channel collision, while ZigBee and Wi-Fi use dynamic frequency selection and transmission power control."
IEEE 802.15.2 discussed the interference problem of Bluetooth and Wi-Fi.
"Also, Sikora and Groza [26] provided quantitative measurements of the coexistence issue for ZigBee, Bluetooth, Wi-Fi, and microwave ovens."
Regarding WSNs there are several studies towards the coexistence of this emerging technology.
"In Figure 4 we can observe the range, band and data rate of the surveyed standards."
"Applications might access devices through the usage of hierarchical names, using naming systems such as DNS or LDAP."
DNS in particular is interesting because it allows to record service and device descriptions along with addressing information.
"Using DNS, it is very well possible to obtain information concerning a single device by making use of different names."
"Different applications can make use of different naming schemes, so that naming hierarchies can reflect the logic of an application."
This enables application to build names according to their requirements.
The same device becomes reachable using different categorizations.
This means that it become possible to use different criteria for addressing a device.
Location- based addressing for instance could compose DNS names by combining the names of different locations.
They are used to create an alias for a DNS name with another DNS name that contains the actual information.
This is useful to map a device under several categories.
Typically PTR names contain the network protocol used to communicate with a device.
"For instance, if a device implements a SOAP stack and is reachable as a HTTP server, it may have a PTR record under the name _http._tcp.domainname.org."
These records are used to map the name of a device into an IP or IPv6 address.
"The same name could be mapped into several IP addresses, which is ideal for multihoming."
"In case of devices that are not directly connected to an IP network, this record will contain the address of the gateway through which it is possible yto reach the device."
These records are useful to add extra service information beyond a name-address mapping.
In fact SRV records may contain the TCP or UDP port number at which a particular service on a device is listening.
This is useful whenever a device exposes more than one interface.
"An application or device can use them to store specific device description informations, or links to them."
"For instance, a service running inside a device could store a web link to its WSDL descriptor file."
Applications that are based on onthologies could store links to their OWL descriptors.
DPWS: Device Profile for Web Services is a set of specifications that enables devices to embed web service interfaces on them.
Dynamic DNS: It is possible to dynamically send updates to the DNS server(s) whenever the situation of the internal network changes.
In this way the DNS information are always up-to-date.
REST: Representational State transfer is an architectural style that describes how to treat and manipulate stateful resources in a way that is similar/compatible with the behaviour of the World Wide Web.
REST can be used by gateways to provide Web Applications with a representation of the internal state of a device.
Devices that do not have direct access to an IP network will need to be accessible through a gateway.
"The gateway must either be always on and enabled to receive incoming requests from the network, or may use existing network protocols to notifiy its devices to external parties."
It could use a fixed scheme that maps each device to a different IP address/port/context path and provide the routing mechanism towards the internal network.
Typically it will have to detect changes inside the internal network (e.g. a wireless device connecting or disconnecting) and map them into the IP connectivity layer.
"Section 3.2.2 contains a list of protocols that may be useful to track the availability and lifecycle of devices, even when they are not directly connected to IP networks."
Normally each non-IP mechanism contains provisions specifying how to detect signals about the presence of a device.
"Device disconnection or unreachability is more difficult to track instead, and in this case applications must rely on keep alive mechanisms."
"For instance, if Dynamic DNS is used to keep IP applications informed about the presence of a device, then every DNS update will have to contain a valid time to live entry that dictates when that DNS name has to expire."
The Time-To-Live must be as close as possible to the duty cycle interval at which keep-alive messages are exchanged inside the internal network.
Similar considerations apply to protocols like SIP.
"Instead, protocols that are based on multicast discovery schemes like DPWS need to provide a way to propagate multicast messages outside the internal network."
"Finally, if REST is adopted, it become possible to create applications that do not need to rely on presence information."
In fact it is possible under REST to create a stateful resource in the network which acts as a remote agent for a specific device.
"Under this model, the agent is always online and available for other devices and applications to communicate with even when its physical device is offline."
"It is also possible to express presence as a resource, if needed."
Approaches that are based on UDP like DPWS or DNS must use a way to describe a device that does not take too much space in terms of size.
This is because the protocol adopted to send these information have inherent issues in sending large blocks of data.
"Under these models it may be useful to put the device description aside (for instance, as a file on a web server) and propagate only the link to it."
"This is what happens in DPWS Discovery, where a device sends only links to its description and not the description itself."
Approaches such as REST allow a resource or device to provide a link to its description in the device state itself.
The description of a device might differ from a protocol to another.
Devices implementing SOAP interfaces may provide a WSDL file that describes the messages they accept/send.
"A REST exposure of a device, on the contrary, could be self describing using tags but in general would not require the definition of an interface and rather rely on self-describing data types (usually through the specification of a MIME-Type)."
The Devices description working group has developed a core vocabulary to adapt content in Mobile Web.
"There are “Aspect” that are the type of components (device, web browser, network connection…) and “Properties” to refer a specific “Aspect”."
The vocabulary refers to [1] is a set of properties to define two specific aspect “web browser” and “devices”.
The UWA Ontology [2] is recommended to extend the above vocabulary with other Properties.
This ontology has a “Device” class which represents a device in the deliverable context and some of its properties.
The core device ontology contains taxonomy of device types and basic device and manufacturer information.
"The state machine model representing the concepts of states and transitions, which are updated in the run-time and represent the device/service actual status."
FIPA is an internationals organization to promoting the industry of intelligent agents by openly developing specifications.
The following table illustrates how define a devices with its most general properties.
These models usually have a devices description as a fundamentally part of a context.
"An Ontology-based Context Model in Intelligent Environments [7].This context ontologies are divided into upper ontology (high-level ontology which captures general context knowledge about the physical World, figure 3) and domain- specific ontologies (collection of low-level ontologies which define the details of general concepts and their properties in each sub-domain)."
The following figure shows an OWL/RDF graph in one scenario where CellPhone- John and Fridge-Kitchen are type of the class Device and are related with other elements in the context.
Context Studio is an application personalisation tool for semi-automated context-based adaptation.
"Context Studio has context ontology, with an enhanced vocabulary model, is utilized to offer scalable representation and easy navigation of context and action information in the UI."
The ontology vocabulary hierarchy is transformed into a folder-file model representation in the graphical user interface.
"Each context (object) is described using six properties: Context type, Context value, Source, Confidence, Timestamp, and Attributes [7]."
"Actions are defined with two properties, Action type and Action value, which describe actions as Context type and Context value describe contexts."
"When an IP network is set up, it is possible to retrieve data from and manipulate devices through their IP interfaces."
"Whenever devices do not support IP, it is necessary that a gateway in between the devices and IP networks understands and converts information between the two interfaces."
It is important to observe that the application space should not be polluted with issues which are specific to a certain connectivity technology or else the application gets locked into it.
An example of this is a network of ZigBee sensors that communicate with an IP-based application through a ZigBee-To-IP gateway.
If the data from the sensors are tunneled to the IP entity as they are they may contain ZigBee-specific information (like the strength of the radio signal) which are “just there” although they may not be related with the measurement data at all.
"This would require applications to be able to handle transport-specific data, and it should be avoided or the application would lock into that transport technology (ZigBee in this case)."
"On the other hand, some transport parameters should be made available for configuration through the IP interface."
However the manipulation of these parameters should be made through a specific interface that should not be intertwined too much with the one used for data operations.
"In general, pollution of the application space should be avoided especially when devices from different networking technologies are expected to communicate together (they will usually do that, either directly or indirectly through an IP network)."
At the IP level it is possible to use several protocol to exchange data and control information.
SIP: the SIP protocol is ideal whenever data must be acquired in a conversational manner.
It is the ideal when data producers operate by maintaining streams of information where clients subscribe and unsubscribe.
Using the SIP protocol a stream producer could set up a SIP session and register itself into it as a stream producer.
Consumers could just subscribe to that stream through a SIP URL.
"The SIP URL of a given stream could, if not previously known, be registered under a DNS name using a DNS TXT record."
The XMPP protocol is ideal when data and control data structures are sent using messages.
"Instead of a session-based communication, XMPP favours a one-to-one approach, where endpoints send messages directly to each other."
"XMPP URLs resemble those of emails, and, like emails, it is possible to keep messages in a storage memory when an endpoint is offline."
"Therefore XMPP is better suited for loosely-coupled interaction, where device control may happen asynchronously."
SOAP: SOAP is a protocol used to exchange data with a web service.
It is possible (using software stacks like DPWS) to embed web service interfaces within devices.
In case SOAP is used a device will expose its interface through a description language called WSDL.
This description language relies on XSD (XML Schema Definition) in order to describe the structure of the data that can be exchanged with a device.
"Given the client-server nature of SOAP, it is ideal for devices that can behave like servers, meaning that have a very high availability and are capable of servicing a great amount of traffic."
"However, given the faulty nature of hardware, SOAP clients should not assume the services to be always up and running, and provide a buffer solution for downtimes."
"REST: With REST, it is possible for every device to maintain its own resources inside the network, and to store its exported data over there."
This has the advantage that data is available even when a device is offline.
"Likewise, control information could be put inside a resource by a device-controlling application, and have the device periodically read them (or being notified through HTTP Server Push), especially after it goes online."
"Therefore REST is a compelling solution when having to manage loosely-coupled systems, where the different system components and devices have different uptimes."
"IP-based security is a broad topic that has been covered extensively over the years, and here we provide just the basics of it."
Almost all of the authentication and authorization technologies in the IP world are based on data encryption.
Infrastructure) where a trusted certificate authority provides the infrastructure to create and verify digital signatures of messages.
"This enables entities to understand whether a message is original or fake, and to protect messages with a varying degree of protection."
"Every entity in the system has one or more roles associated with it (which are normally stored somewhere, most of the times in a LDAP repository) which determines which actions it can performs and where."
"This allows devices to check whether a request message is coming from a trusted source, and if that source has the rights to ask that request to be performed."
"Also, the device will be able to encrypt the response in a way that only the intended destination will understand."
Particular care must be done at the boundary between IP and non-IP networks.
"In fact, most of the times the security mechanisms that have been in place in an IP network won’t work outside of it."
"A possible way to ensure that end-to-end security is achieved is to encrypt messages at the level of the native device network (USB, ZigBee, X10 and so on) using the same PKI infrastructure in use at the IP level."
"However, this requires the gateway to act as a simple tunnel for the data packets, which means that there is the risk of polluting the application space with device-dependent data."
Another constraint to this solution is given by the limitations of the devices themselves.
"In fact most of them have limited memory and processing power, meaning that supporting encryption at the native level is not always possible."
"However, the problem could be mitigated if wired networking is used and the wired network is situated at a secure location."
"Too bad, most native technologies (a part IEEE 802.11, which comes with an advanced and flexible security stack) do not provide more than simple data integrity checks (like parity checks or CRCs) but with no built-in security."
"This implies that security at the native level would require additions to existing standards, which may be impractical, especially for the sake of interoperability."
Devices could communicate between entities using different networking protocols only if a protocol translation occurs.
"However, given the sheer number of connecting technologies, it is not scalable to think in terms of protocol-to-protocol conversion."
"Instead, a common language or framework needs to be set up."
"This framework is IP, which is the building block of every networking protocol on the Internet."
Schemes for translating native protocols into IP can be implemented at the gateway level as defined in section 3.5.2.
"Simple and inexpensive objects, as WSN devices are, will not be equipped with large-scale active intelligence, so the data they produce and the communication methods they use to transmit the data are also relatively simple."
"Objects may transmit information between similar kinds of objects quite easily, but when data needs to be transferred upstream into real Internet or through another neighbour network, it is not feasible to make every object handle all the burden of the TCP/IP stack, to give an example."
"On the other hand, if we desire to merge two wireless networks in order they can cooperate (e.g. interconnect WSNs with the Internet), there are many approaches in the literature that have proposed solutions."
"Overlay network is usually built on top of the Internet, and uses late address binding to achieve the independence of the underlying bearer protocols and addressing schemes."
Modified TCP allows running TCP/IP protocol suite directly in the WSNs [54].
"Regardless these approaches are focused on merging Internet with WSN, they could be also applied to interconnect other wireless networks."
"On MIMOSA Project the personal mobile phone is chosen as interface to Ambient Intelligence and a gateway between the sensors (RFID), the network of sensors, the public network and the Internet [57]."
"AlarmNet is another research project which integrates heterogeneous devices, some wearable on the patient and some placed inside the living space to monitor the ambient changes from an outer data centre (Bluetooth, tags, WSN, Wi-Fi, backbone) [60]."
"Culler., ""6LoWPAN: Extending IP to Low-Power, Wireless Personal Area Networks,"" IEEE Internet Computing, vol."
"Problem Statement, and Goals,"" Network Working Group RFC 4919, 2007."
"Communication Systems, WFCS 2008. , Dresden, Germany, 2008."
"Contactless Smart Cards and Identification, 2nd ed."
"Mobile & Wireless Commun, , Shanghai, China,, May, 2004, pp."
"Wireless & Optical Communications Networks, Bangalore, India, 2006."
This section addresses the challenges and state-of-the-art technologies for enriching raw data from heterogeneous devices to provide high-level information to WP3 reasoning.
"On the proposed DiYSE scenarios there will be a huge number of heterogeneous devices (sensors, actuators, PDA’s, smart phones, etc.)."
"Several of them are resource constrained, specially the individual devices in a WSN."
"The WSN are closely coupled to a changing physical world, then, the nodes forming the network will experience wide variations in connectivity and will be subject to potentially harsh environmental conditions."
"In order to avoid this issue, the referred nodes have substantial processing capability in the aggregate, but not individually, so we must combine their many vantage points on the physical phenomena within the network itself."
This is one of the primal objectives of what we have named “virtual sensors”.
"On the other hand, by using the combined information, the virtual sensors have also the capability of reasoning by using fusion techniques5."
"The aim of this latter case, is to offer to requester nodes a high and enriched information that is collected from the surrounding sensors."
"It is important to stress that for us, a virtual sensor has all the properties of a real sensor, with respect to its capability to communicate the sensed data, but the information that it offers to a requester node is derived from information already processed in other surrounding nodes."
"However, the information derived from a virtual sensor itself can be treated in the same fashion as a real one."
What is challenging of our proposal is that the fused information should be retrieved from many different and heterogeneous real sensors.
"For instance, let us think to an actor that wants to know if a specific person is inside a room."
"Instead of interrogate every potential sensor inside the room (wasting time and resources –recall the constrained features of sensors), the actor only needs to retrieve the information that it desires from the virtual sensor."
"Even more, the supposed actor should not need to get into the room to retrieve the referred information and therefore it should not have the necessity of discover every sensor instance within the room since the virtual sensor does its best for it."
The idea of merging heterogeneous sources to get an enrich information and the concept of virtual sensor are not new.
"In fact, we can find some related examples in the literature: Stefano Piva et al."
"Currently, data fusion systems are used extensively for target tracking, automated identification of targets, and limited automated reasoning applications [2]."
"In their work, the authors provide a solution to allow for sets of heterogeneous sensors, namely CCD video cameras and WLAN 802.11b radio devices, to be integrated in order to extract biometric information (position and ID) regarding objects in a given environment of interest."
Robot teams have the advantage that they can collectively share information.
"Then, they are able to fuse range information from a variety of different platforms to build a global occupancy map that represent a single collective view of the environment."
A virtual sensor is simply an abstraction of the team’s occupancy map [3].
Their virtual sensors abstraction connects users directly to sensors in the local environment.
"Virtual sensors can be deployed on small devices, operate independently of heavyweight infrastructure, and provide on-demand, real- time connection to information that enables users to complete their tasks quickly, safely, and with the best possible information."
"The same authors in [6] and [1] define a kind of virtual sensors that abstract a set of physical sensors and the operations that are performed on them, providing a new way of extracting data from heterogeneous wireless sensors."
"Moreover, their virtual sensors also offer a way to tailor a generic sensing environment to specific applications, which will be especially necessary as sensor networks become more widespread and general purpose."
We will follow their work trying to go beyond it since their contributions have a major impact for the DiYSE virtual sensors.
Also in the literature we have found virtual sensors from the point of view of their implementation.
"In [9], a set of programming abstractions that allow a programmer to interact with several nodes (specified in a declarative way) as if they were a single virtual node is presented."
"That is achieved by relieving programmers from the details of data collection, allowing them to focus on the application logic."
"To conclude this section, in the literature we have also found approaches using the concept of virtual sensors towards the seamless interoperability of different communication protocols and to simplify the applications development for integrated services involving multiple types of sensors [10]."
In-door localization is about to determine the node's location (position) within the network [11] .It means for a node to determine its physical position (with respect to some coordinate system) or its symbolic location.
In this section we will review the techniques to compute the node’s localization by presenting initially the methods that are used to estimate the distance to beacon/anchor nodes6 and then the types of signal and models used to get those estimations.
"This first technique uses the time of transmission, the known signal propagation speed and the time of arrival of such signal in order to compute the distance between two nodes in the WSN."
"This technique is simple and efficient but it presents problems such exact time synchronization among nodes, reflections, and overhead."
"However the main drawback is that it is difficult to precisely record the arrival time of radio signals, since they travel close to the light speed."
"Therefore, it works best with an acoustic source as is proposed in [12] and [40]."
This approach uses two different signals with different propagation speed (e.g. ultrasound and radio signal).
To estimate the distance it computes the difference between signals arrival time.
The signals propagation speed must be known but it improves upon the ToA by eliminating the need to know when the signal was transmitted.
Problems: Limited coverage (3-15m) and high dependency of the density of nodes within the WSN (number of nodes and connectivity).
It is a method for determining the propagation direction of a radio-frequency wave incident on an antenna array.
The AoA determines the direction by measuring the Time Difference of Arrival (TDoA) at individual elements of the array -from these delays the AoA can be calculated – usually the antennas array uses a direction of reference.
"Problems: Calibration, expensive/energy-intensive hardware, high cost."
The nodes which use this method send out a signal of known strength (using the signal attenuation) and after they use the received signal strength and the path loss coefficient to estimate the distance to the known location .
"Another use for RSSI is profiling, in which a map of RSSI values is constructed during an initial training phase."
Sensors then estimate their position by matching observed RSSI values with the training data.
Those nodes are very used in the distance estimation techniques but it has its shortcoming.
It does not scale well in large networks and problems may arise due to environmental conditions.
"Recently, there have been several published techniques that determine the position of a node based on the observed frequency of a signal [17][18]."
Signal frequency will undergo Doppler-shift when the transmitter and receiver are moving relative to one another.
The observed Doppler-shift at multiple infrastructure nodes can be used to derive the position and velocity of the mobile node.
In the last section we have reviewed the techniques to estimate the node location or its position within a wireless sensor network.
In most of them it has been specified the use of different types and modes of signals for the estimation purposes.
"Next, we summarize these signals and the used methods as well as we address the research papers and projects where they have applied."
Ultrasound is a cyclic sound pressure with a frequency greater than the upper limit of human hearing that is approximately 20 KHz.
These systems use both ultrasound and radio signal.
The localization is hence performed by calculating the difference of the ToA of the referred signals [19][19][20] and [21] use this method.
Infrared radiation (IR) is an electromagnetic radiation with a frequency range between 1 THz and 430 THz.
The infrared-based localization systems use infrared light to perform their calculations to get the node localization by measuring the constrained to the device Line of Sight (LoS) and a proper orientation to the transmitters.
Radio frequency systems employ a transmitted signal that is received by some mobile devices within the network.
These systems are commonly used since almost all type of WSN communication standard use this carrier.
"The RF is used in several estimation techniques such as the received signal strength intensity, angle of arrival, time of flight and after it is employed by triangulation to calculate the node’s position Visible light communication systems can provide solutions to the frequency band communications since light is not interfering with the crowded radio frequency band."
These systems employ sound signals instead of ultrasound signal to avoid the signal attenuation.
Usually these acoustic signals are used in distance estimation techniques that compare the differences on arrival of two or more signals with different propagation speed.
They use Ultra high Frequency (UHF) and Very High Frequency (VHF) signals to perform their calculations.
Ultra-wideband (UWB) is a radio technology that can be used at very low energy levels for short-range high-bandwidth communications by using a large portion of the radio spectrum.
"The ultra wide band systems employ a high frequency signal, above TOA to calculate the position by triangulation [28]."
"A Wireless Local Area Network (WLAN) links devices through a wireless distribution method (typically spread-spectrum or OFDM radio), and usually provides connection to the Internet using Access Points (APs)."
WLAN location systems employ the exiting Wi-Fi network infrastructure access points.
The systems measure the received signal strength to perform calculations to get the estimated position of nodes within the range or cell.
These systems must deal with multipath and Non-LOS problems.
WLAN systems often use probabilistic models to mitigate such problems as is demonstrated in [29] and [30].
Bluetooth is an open standard and a communication protocol primarily designed for the exchange of data in low power consumption networks with short range of communication (i.e. Personal Area Networks - PANs).
In such networks (PicoNets) the Bluetooth localization systems use the received signal strength intensity to calculate the position of the devices inside the network [31].
"Because the devices use a radio (broadcast) communications system, they do not have to be in the LoS of each other and the synchronization is avoided."
"ZigBee is a specification for a suite of high level communication protocols using small, low power digital radios based on the IEEE 802.15.4-2003 standard for wireless personal area networks."
"The systems which make use of this technology, as the Bluetooth ones, employ the received signal strength intensity to calculate the position of the mobile devices [32]."
RFID location systems deploy a number of readers in the area where the tags will surely move around.
By reading and identifying the tags (Assuming that the readers are placed in a well known position) the distance or the placement of nodes estimation is calculated.
The RSSI intensity is used again as is demonstrated in [33] and also in the WhereNet project [34] .
Most of these systems use printed codes or patterns that can be recognized by Webcams or IP cameras.
The code gives information about the position or the number of objects that could be in a room.
Another proposed technique attached to artificial vision is the named “schema analysis”.
"The well known GPS system is composed of three parts: between 24 and 32 satellites in Medium Earth Orbit, four control and monitoring stations on Earth and the actual navigation devices."
"GPS satellites broadcast signals from space that GPS receivers use to provide three-dimensional location (latitude, longitude, and altitude) time."
Then a GPS receiver calculates its position by precisely timing the signals sent by the GPS satellites [36][37].
The main drawback of this technique is its limited use in outside environments.
However with the appearance of systems like Assisted-GPS (A-GPS) the trend go towards the use of this technology also over indoor environments.
These systems use magnetic readers and magnetic tags.
"Using the distance estimation methods with different signal modalities previously sorted, it is possible to get accurate node’s location within the WSN by applying any of the next position estimation techniques."
This first technique estimates a node position by computing the node’s distances to three non-linear points with their location is beforehand known.
"To compute the distances to anchors, the trilateration make use of the previously reviewed distance estimation techniques."
"For a 2-Dimensions space, three anchors are enough but for several localization works such [12] and [39]."
"When a node desires to compute its position but the anchors are not in the node’s range, it makes use of its neighbor nodes as relays to reach the beacon nodes and eventually compute its current position."
Count the number of hops assuming that the length of one hop is known (DV-Hop).
"If there exist a range estimate between neighbors, use them to improve the total length of route estimation in the previously defined method (DV- Distance)."
"It is similar to Trilateration, but rather than distances, angles are used to determine a node position."
"Generally, to compute the position two angles plus a distance between two well known anchors are needed (2 Dimensions - for 3 Dimensions also the azimuth is used)."
This estimation technique is very useful in a network of phased antennas array where different receptors with a well-known distances measure the ToA of the target signals and compute the angle.
"Multilateration, also known as hyperbolic positioning, is the process of locating an object by accurately computing TDoA of a signal emitted from that object to three or more receivers."
It also refers to the case of locating a receiver by measuring the TDoA of a signal transmitted from three or more synchronized transmitters.
"Multilateration should not be confused with trilateration, which uses distances or absolute measurements of ToA from three or more anchors."
It makes use of neighbor nodes to determine their position and then those act as beacons for other nodes.
"For instance, assume that some nodes can hear at least three anchors (to perform triangulation), but not all."
Let more and more nodes compute position estimates and spread their position knowledge in the network.
The infrastructure is created in an Ad-hoc manner but the problem mainly arises on errors propagation and high computation in every node.
"The main drawback is that this technique requires compiling a database of features, thus extensive infrastructure."
This technique aims to determine when an object is near of a well-known location instead of compute the specific or accurate space locations.
Monitoring or polling wireless Access Points (APs).
"This third method aims to combine the use of different identification techniques such as credit cards, logins, registers, and footprints, IDS to know the approximate node location."
It is important to remark that these three methods could be applied in any of the proposed DiYSE scenarios since most of them looks for objects or people tracking This technique is overall used in Robotics.
"Robots obtain their current velocity from wheel encoders or other means, and use this information in conjunction with the amount of time that has elapsed since the last update to derive current position and heading [41][41]."
"The major drawback of this approach is that the position estimation accrues error over time, primarily because of noisy encoder data due to uneven surfaces, wheel slippage, dust, and other factors [42]."
"Multilateration problematic (convergence, accuracy)."
In the DiYSE project we will aim to solve some of these issues and to go beyond the presented literature approaches.
Nevertheless we will use and combine the basis of localization in WSN in the proposed scenarios to reach our targets.
A very important concern related with localization is people and objects identification.
In many cases when a person or an object is located it is also identified but most of the times in an inaccurate way.
There exits hence several techniques to locate and identify people and objects inside a WSN in a proper way.
The identification systems intended for monitoring and tracking people in both indoor and outdoor areas have become increasingly important.
The efficient tracking of many people motion in either large buildings or outdoor areas are still relatively difficult tasks.
"There are several standard systems working in the Identification (ID) of low frequency or high frequency rates, but during the ID process, the tracked person or the object must somehow touch or be near to the reader or even insert an ID card into a reader."
Next we present some of the most well know identification systems: RFID Systems use tags with a microchip as a data-carrying device.
These tags have a Unique IDentification (UID) code.
The RFID systems are completed with a tag reader that interrogates the mobile tags to get theirs UID and an interface to a host application such as a computer to allocate such UIDs.
"In the referred systems, the targets that are being monitored are not required to perform any action during the ID process, that is, to be computationally headless [43][44][45] and [45]."
From [46] a tracking system for a constant ﬂow of targets in which the speed of the targets is determined using previous sensor measurements is presented.
The new obtained data is continuously updated by using the current sensor measurements dependent of the previous ones.
"In [47][47] another tracking system is presented, the authors modify the layer two MAC protocol of the RFID standard to get as faster as possible the tags ID."
The systems based in the wireless LAN technology use the MAC address to perform the connection to the network.
"Hence, it is straightforward to get the device ID since MAC addresses are unique and therefore the nodes are perfectly indentified."
"Bluetooth is an open wireless protocol for exchanging data over short distances from fixed and mobile devices, creating personal area networks called piconets or scatternets which are limited to seven devices."
"As in WLAN, the network identification use unique MAC addresses [12][12]."
"ZigBee is a specification for a suite of high level communication protocols using small, low power digital radios based on the IEEE 802.15.4-2003 standard for wireless PANs."
Zigbee has not the Bluetooth limitation of the number of nodes belonging to a network.
"Moreover, Zigbee provides two ways of identifying nodes, by using the devices MAC address and a two bytes address to identify the node into the current wireless sensor network."
Both methods could be used to indentify uniquely the nodes within the network [32].
Most of these systems use printed codes or patterns that can be recognized by Webcams.
There are several research projects with the main focus put on the management of context and knowledge information.
"The gathering of that information involves three main different aspects: the description, the storage and retrival, and the acquisition of information."
This section is going to cover two of these issues: the description and the storage due these two aspects are the most important ones in order to communicate the information to the application layer (WP3).
DANAE project [49] aimed at providing a complete framework for not only describing multimedia information but also for transporting this information to the user with the best QoS taking into account the session context information.
"ITACITUS project [50], where a distributed cultural resources repository is to be offered to the visitor or researcher."
AMBIESENSE project [51] the end user is a mobile citizen surrounded by an intelligent environment which senses the contextual information and offers personalized services.
In this case context tags are used to implement the context-aware technologies.
"The main objective of the project is to define and implement a platform to simplify and speed up the task of developing and deploying mobile services, making it commercially feasible for the wider IT industry (not just telecom companies) to provide such services."
"With respect to the storage and retrieval of context information, many content-aware multimedia services have been presented in the literature, such as content-based retrieval, content-based navigation and real-time video streaming."
A Classification Framework for Storage and Retrieval of Context [55].
This paper presents a classification framework for the storage of the context model and the retrieval of the context information from the context model.
"The context model is used to add context meaning to the raw monitoring data, and is thus a necessary element for most context-aware systems."
"After the context model adds meaning to the raw monitoring data, the resulting context information is used by the system."
Adaptive storage and retrieval of large compressed images [56].
"Enabling the efficient storage, access and retrieval of large volumes of multidimensional data is one of the important emerging problems in databases."
"This paper presents a framework for adaptively storing, accessing, and retrieving large images."
"By adapting to user access patterns, the system selects and stores those view elements that yield the lowest average cost for accessing the multi-resolution sub region image views."
Context-Aware GRID Services: Issues and Approaches [57].
This paper contains a section related to context management system.
"The context management service uses the context gathering and publishing service, the context retrieval service and the context storage service."
"Context information is obtained from a wide plethora of applications, services and sensors (collectively called context sources) spread all over the network."
The job of the context gathering service is to collect this information and put it into a common model understood and accessible by all components of the context service.
This highly distributed characteristic introduces a great challenge for the manageability of all this information.
Hence there is a need for a common context information model and a context publishing protocol.
The context is then stored in a context information base for access by context consumers through the context retrieval service.
The relationship between the context sources and consumers are shown in figure 1 below.
Towards a Conceptual Model for Context-Aware Adaptive Services [58] Recent advances in both portable devices and wireless networks make mobile computing a reality.
Embedded and invisible computing resources are paving the way to a new paradigm known as pervasive computing.
More attention needs to be paid to the development of intelligent services in such a highly dynamic environment.
This paper aims to present a conceptual model for context awareness based service adaptation methodology.
"SECURITY,"" in Harbour Protection Through Data Fusion Technologies."
"Wireless Sensor Networks: Methos, Models, and Classifications.,"" ACM Computing Surveys, vol."
"Sensors,"" in International Symposium on a World of Wireless, Mobile and Multimedia, Washington, DC, USA, 2006, pp."
"University of Texas at Austin TR-UTEDGE-2007-003, 2007."
"Flexible Interactions,"" in Casemans '09: Proceedings of the 3rd ACM International Workshop on Context-Awareness for Self-Managing Systems, New York, NY, USA, 2009, pp."
JEITA (Japan Electronics and Information Technoloy Industries Association).
IEEE Journal of Selected Topics in Signal Processing.
"Conference on Multisensor Fusion and Integration for Intelligent Systems, 1996."
"Li: ""Adaptive storage and retrieval of large compressed images,"" in Storage & Retrieval for Image and Video Databases, VII, M Yeung, B.L."
"This section zooms into a specific technology for the interaction with the environment, Wireless Sensor and Actuator Networks."
"Given the broad spectrum of research subjects in that area, we will identify the potential and the major challenges raised by its use in DiYSE applications, and analyze the associated requirements and state-of-the-art."
Coulouris et al [1] define a distributed system “as one in which hardware or software components located at networked computers communicate and coordinate their actions only by passing messages”.
Wang in [1] claims that one of the main challenges of distributing computing comes from the conflict between the contexts of distributed computing and the embedded sensor devices.
"Distributed computing should support scalability, reliability, dependability, and heterogeneity, but this demands the careful the design under the context of resource limited devices and dynamic network topology."
"In order to provide the above mentioned high level services, while providing support for the existing heterogeneity in Wireless Sensor Networks architectures, a middleware layer is required."
"Middleware for sensor networks can be considered as a software infrastructure that glues together the network hardware, operating systems, network stacks, and applications."
"A complete middleware solution should contain a runtime environment that supports and coordinates multiple applications, and standardized system services, such as data aggregation, control and management policies adapting to target applications."
"Also, middleware software architectures should offer mechanisms to achieve adaptive and efficient system resources use, in order to prolong the sensor network's life."
"Different middleware approaches were found, García in [3] has classified these approaches, taking into account the programming models in sensor networks, see Fig."
Programming sensor networks includes two major classes: programming support and programming abstraction.
Manage to the way a sensor network is viewed and presents concepts and ideas of sensor nodes and sensor data.
There are two main approaches for programming abstraction classes the global behavior and the local behavior approaches.
"This first programming abstraction approach, the sensor network is programmed as whole rather than writing low-level software to drive individual nodes."
A global WSN’s behavior is programmed at a high-level specification that enables node concerned about dealing with low-level.
"Some examples of this approach are: Kairos [4], Regiment [5], Abstract Task Graph [6] and Semantic Streams [7]."
This second programming abstraction approach deals with the behavior of the sensor network nodes from a local point of view in a distributed computation.
"The local behavior approach focuses on the nature of the sensed data and, in particular, on a specific location in a sensor network."
"Manage the providing systems, services, and run-time mechanisms, such a reliable code distribution, safe code execution, and application-specific services."
"The programming support class consists of five approaches (see Fig.1): virtual machine-based, modular programming-based, database-based, application-driven, and message-oriented middleware."
"This approach consists of virtual machines, interpreters and mobile agents."
"Its main characteristic is flexibility, allowing developers to write applications in divided small modules, which are injected and distributed through the network by the system using tailored algorithms and then interpreted by the virtual machine."
"Some examples of this approach are: Maté [12], Squawk [13]."
The use of mobile code facilitates the injection and distribution through the network and leads to application modularity.
Less energy is necessary when broadcasting small modules instead of the complete application.
"Some examples of this approach are: Impala [14], Smart Messages Project [15]."
"This approach observes the entire network as a virtual database system, offering an easy-to-use interface that permits the user extract data of interest and issue queries about the sensor network."
The database is one of the earliest examples of high-level abstractions for sensor network programming.
"Some examples of this approach, TinyDB [16], SINA [17], DSWare [18] and MiLAN [19], which in addition to these features, provides a data service that features QoS support."
"This approach is quite suitable in pervasive environments such as Wireless Sensor Networks, where most applications are based on events."
Message-oriented middleware uses the publish-subscribe mechanism to facilitate message exchange between nodes and the sink nodes.
"Many applications, which are deployed over Wireless Sensor Networks, are context- aware."
"Therefore, it is necessary to found mechanisms in order to get context information from the environment in a structured way."
"Besides, this information has to be meaningful from the application point of view."
"In this sense, the middleware layer in Wireless Sensor Networks has to implement some mechanisms in order to reach efficient deployments of context applications over Wireless Sensor Networks."
Since each application interprets the underlying sensor network differently according requirements.
The middleware layer proposed in [22] is based on an execution Framework.
"That Framework is able to manage contextual information by using an architecture divided in three sub-layers: Context Provider, Context Process and Context Adapter."
"The middleware’s life cycle is divided in three phases: acquisition of context data, interpretation of context information and adaptation according to identified situation."
The Context Provider layer provides “crude” data about the environment and sensor status.
The Context Process layer filters and aggregate the crude data from Context Provider.
"The higher layer, Context Adapter, is able to take decisions about the convenience of performing an adaptation."
"In this proposal there are context nodes which provide context information by using five primitive components: Context Process, Context Reasoning, Context Configuration, Activity Manager, and Message Manager."
In [23] a middleware for contextual agents was proposed.
This middleware layer was thought with the purpose of compose an execution Framework suitable for agents in ubiquitous computing environment.
The contextual model implemented by this proposal allows using different reasoning mechanisms like first order logic and temporal logic.
"The types of agents and services coexisting in this middleware are the following ones: Context Providers, Context Synthesizer, Context Consumer, Context Provider Searching Service, Historic Context Service and Ontology Service."
The most of WSN solutions are based on arrays of homogeneous sensors.
"To solve the three major problems in WSNs mentioned above, a Semantic Sensor Network (SSN) was proposed in [24]."
This approach allows semantically tagging the sensed data from a heterogeneous distributed sensor network in order to ease the managing of contextual data in a large scale network.
In [25] a Context Aware Sensornet (CASN) was proposed.
CASN integrates the contextual computing theory [26] with sensor networks concept.
"In CASN, the node’s context is most important than the human context."
This approach implies several challenges as a suitable behavior abstraction or the technologies required for context representation in an energy-efficient way.
"The middleware’s framework is composed of four main components: Context Representation Component, Context Interpreter Component, Contextual Service Component, and the Kernel of the node."
The Context Representation Component uses a lightweight ontology called µSONG (Micro Sensornet Ontology) which provides a simple and flexible way of presenting the context.
The context interpretation is achieved by using an interpreter based on fuzzy rules called CIBFR (Context Interpreter Based on Fuzzy Rule).
In [27] a rule based Middleware called MIDSEN was proposed.
This proposal includes two major algorithms: event detection algorithm (EDA) and context aware service discovery algorithm (CASDA).
Both algorithms are implemented by inference engine.
MIDSEN defines sensors and applications as services.
EDA takes an input as sensor readings and makes an event primitive.
A primitive event is built by event detection time and event format.
"By matchmaking, CASDA discovers services, which match with given service request."
"However, each proposal used its own language to represent that information."
"Currently, there is not a standard to formalize the representation of information which is managed in resource constrained systems as Wireless Sensor Networks."
"In this sense, several representation models have been proposed to be used in Wireless Sensor Networks."
"Between them, we can found WISNO (WIreless Sensor Networks Ontology) [28]."
WISNO includes an ontology divided in two levels: high and low.
The high level ontology is used to perform a fine analysis of contextual information.
The low level ontology is used to characterize the data from sensors which are deployed around the Wireless Sensor Networks.
Reasoning rules based on descriptive logic and SWRL [29] have also included in WISNO specification.
"Another proposal, which is based on formalized representation system of sensor information, is [30]."
In this proposal each sensor provides an energy level as well as its status.
"The condition of every sensor integrated into the node is described by the following quadruple: <t, m, e, a>, where t is the sensor type, m is the operator type, e is the energy consumption of that sensor, and a is the sensor precision."
"The dynamic information of each sensor can be summarized in tuples like <E, {S}>, where E is the remaining energy level and {S} is the set of one or more quadruples which describe the status of the sensors in the node."
Sensors and actuators use to have a very small process capability.
These devices are starting to deploy real distributed systems.
"In this sense, the concept of artificial intelligence is starting to be included into sensors and actuators [31]."
"Different paradigms have been used to perform this intelligence, like knowledge based systems [32], fuzzy logic [33][34] or artificial neural networks [35]."
Deckneuvel [31] reported an analysis of intelligent sensor and purposed a language specifically developed for the design of these systems.
"Lately, hybrid systems, which are composed of fuzzy logic and neural network, have been proposed Averkin and Belenki [37]."
"In [38], the use of a distributed rule based fuzzy logic engine designed for collaborative WSN has been described."
Wireless Sensor Network consists of a multitude of tiny embedded devices that are capable of sensing information continually and transmit data from one device to another via a wireless ad hoc network.
Such networks are characterized by their ease of deployment and being self-configuring.
"Nowadays, the applications of WSN technology have been broken down into two main categories: Monitoring and Tracking."
"One of the most important features of the WSN for DiYSE is that they can be completely heterogeneous characteristics, for example, nodes may have multiple types of sensors, different power and processing capabilities and can interact with other network through a gateway."
"Powerful devices can perform complex operations, but are more expensive and power-hungry consume much power."
"Otherwise, weak WSN devices enable higher deployment densities and increase network lifetime as they are cheaper and consume less power."
"By integrating devices with different resources and capabilities, a heterogeneous WSN can combine the advantages of both powerful and weak devices."
The heterogeneity of the network presents significant challenges for service provisioning.
New programming models are necessary to simplify WSN application development and increase overall network utility.
Service-oriented computing can simplify application development by hiding platform- specific capabilities behind services.
"These services are dynamically discovered and used at run-time, enabling applications to be platform-independent and adapt to network dynamics."
"While service-oriented computing is widely used on the Internet, adopting it to WSNs is non-trivial due to the extremely limited resources available and highly dynamic nature."
"Nowadays, Wireless Sensor Networks are systems that have a limited amount of resources."
"Therefore, service provisioning in Sensor Networks is a huge challenge."
The classical SOA-based approaches are not currently feasible to be used over Wireless Sensor Networks because of the intrinsic resource limitations of that kind of technologies.
"The SOA standards such as XML, HTTP, SOAP, WSDL and UDDI are majorly related with web services provisioning by using no resources-constrained computers so they are not recommended to be applied in WSN."
There are some proposals which try to solve the service provisioning in Wireless Sensor Networks by using SOA-based technology.
In [42] an iterative SOA-based design process was proposed.
"Services-oriented architecture suits particularly well for WSNs as the development of the whole network can directly be mapped to service, simple or complex."
The proposed design process is based on agile design technologies [43].
The authors of [42] chose this methodology since the WSN development is iterative and short what suits with the agile methods.
"However, it is structured according a waterfall model [44]."
"The waterfall model includes eight stages: gathering of the requirements, their analysis, the design of the solution, development of the software architecture, development of the code, testing, deployment and post implementation."
As it has been commented in previous section in [45] sensors and applications are modeled as services.
This proposal includes a service discovery algorithm called context CASDA.
This algorithm takes input as service request (SR) and available services (S).
"For filtering purpose, only those services that belong to service requester category are managed."
This algorithm returns degree of similarity between service request and available services.
"To perform the comparison between requested and available service some factors are taken into account such service’s inputs and outputs, and required contextual information."
"Fok in [46] proposed a middleware when the applications are implemented as task, which are platform-independent application processes that contain code, state, and service specifications."
"Services are able to maintain state, provide multiple methods, and have their own thread of control, enabling them to operate in parallel with task."
Servilla provides two light-weight programming languages tailored to support service provisioning in WSNs.
"The first, ServillaSpec, is used to create service specifications and descriptions that enable flexible matching between tasks and services."
"The second, ServillaScript, is used to create tasks and is compiled into bytecode that runs on a Virtual Machine."
Services are implemented in NesC on TinyOS and compiled into native binary code for run-time efficiency.
An important feature of Servilla lies in its capability to support coordination and collaboration among heterogeneous devices inside a WSN.
"Wireless sensors networks, as the field of matures, needs support more complex applications and collaboration among them in order to provide services."
"For this propose, it’s necessary more powerful programming methods, monitoring and control, both hardware and software, during its operation."
Some solutions have been propose reprogramming sensor networks in the field.
The ability of loading and updating applications after deployment is one of the factors that it will be the local sensor networks usable.
Lately there have been some interesting proposals in this regards.
"SensorScheme [47] is a platform for dynamic program loading and execution, based on the semantic of the Scheme programming language and designed to meet the demands of sensor networks applications."
"This platform focused on efficient code transport, minimizing its size, by separating the format while transmitted from the in- memory code storage while executing, optimizing the communication channel and energy consumption."
Interactive and Extensible Framework for Execution and Monitoring of Wireless Sensor Networks (ISEE) [48] is an environment for the execution and monitoring of sensor network services.
"Is supports verification and testing of sensor network services, whether simulated, emulated or real."
"So, this framework can be used during all process in wireless sensor network, development, deployment and real use."
"This framework is based in previous work like EmStar [49] and TOSSIM [50], a simulator for TinyOs Networks."
"Also, related whit this are the Virtual Sensor Networks."
"They are a collaborative Wireless Sensor Networks to provide protocol support for the information, usage, adaptation and maintenance of subsets of sensors collaborating on specific tasks."
"The main target is to enhance applications in which subsets of sensors, varying dynamically, must to achieve the desired outcomes, while relying on the remaining nodes connectivity, deployment and resources constrains."
"Now, the objective is to get an execution environment that it allows to configure dynamically a service."
"But, usually, a service shall consist of a group of applications that, using a collaborative way among then, they will provide a service."
"Therefore, it’s necessary to develop an environment that configures each application and the relation with the others applications that provide the service."
The function of Wireless Sensor Network Management Systems is to provide monitoring and controlling capabilities functionalities.
"This kind of ubiquitous networks presents several peculiarities that make more difficult the management task performing over them, where can be identified open issues like the constrained- resources of nodes, dynamic network topology, variable channel capacity and prone to fail [51]."
"Due these limitations, main efforts in management procedures for sensor networks are mainly focused on monitoring and controlling tasks, in order to optimize the network operation and maintain the network performance [52]."
The network management protocols and frameworks designed for Wireless Sensor Networks had take into account the properties of sensor nodes.
"In next Subsection, foundations of main approaches for sensor networks management will be presented, classifying them into protocols and management frameworks."
"RRP (Register mechanism Routing Protocol) [55] is a cluster-based mobile routing algorithm aimed to improve the network life-time, using for this a system’s load balancing schema, which defines a set of flooding-zones for the data forwarding decisions, in order to perform the data aggregation tasks."
"RRP proposes a hierarchical deployment based on three area types: manufacturing, warehouse and service."
"Acquisition of data is carry out in the manufacturing area, delivering the processed data to the warehouse and service area."
"The main advantages of RRP are that zone flooding ensures low message overheads, and adjusting the size of flooding zone, it ensures high reliability."
"The main lacks of RRP are that it requires a GPS device attached to the sensor nodes, in order to implement the zone-flooding protocol."
SNMS (Sensor Network Management System) [56] is an interactive system for sensor network health monitoring.
It provides a query-based network health and event logging functions.
SNMS supports collection and dissemination of traffic patterns.
"Collection traffic pattern is used to obtain health data from the network, while dissemination traffic pattern is used to distribute management messages, commands, and queries."
"To achieve the previous exposed goals, SNMS develops a gathering tree to collect network health information, introducing a minimal impact on memory and network traffic."
SNMS further minimizes energy consumption merging multiple queries into a single message.
"On the other hand, SNMS network management function is limited to passive monitoring only, requiring human managers to submit queries and perform post-mortem analysis of management data."
"WinMS (Wireless Network Management System) [57] proposes an adaptive policy- based sensor network management system, which provides self-management for network performance maintaining, adapting the network behavior according to the traffic conditions."
"WinMS architecture defines a schedule-driven MAC protocol, to collect and disseminate management data, form and to the sensor nodes in a gathering tree."
"Also, it implements a local network management scheme, providing autonomy for wireless sensor nodes to perform management functions, and a central network management scheme, to perform preventive and corrective maintenance."
"It is worth nothing, however, that the initial setup cost for building the gathering tree is proportional to network density."
BOSS (Bridge Of the SensorS) [58] defines a service discovery management approach for Wireless Sensor Networks.
"It supports network state information retrieval from the Wireless Sensor and Actuator Network, including sensor node device description, the number of sensor nodes in the network, and the network topology."
The localization service provides positioning information for each sensor node in the network.
The synchronization service is focused for clock synchronization among sensor nodes in the network.
The power management service offers support for checking remaining battery and changing the sensor’s operation mode.
"On the other hand, BOSS requires human interaction to analyze the network states, taking management actions accordingly."
"MANNA (Management Architecture for Wireless Sensor Networks) [59]is a policy- based management architecture designed for gathering dynamic management information, mapping it into sensor networks models, performing management functions and services based on wireless sensor network."
"It defines the MANNA Network Management Protocol (MNMP), which is a light-weight protocol designed for management information exchange between management entities (i.e., cluster- heads, nodes and manager)."
"Some of the management procedures covered by MANNA are related with coverage area supervision, networking parameters configuration, network topology and connectivity discovery, energy map generation, maintenance, reducing the network overhead, packets collision, and energy consumption, turning off redundant nodes in the Wireless Sensor Network."
"SSNs (sensor sub-networks), which contains sensor nodes of same type, in order to large, heterogeneous Wireless Sensor and Actuator Networks."
To interconnect different SSNs is proposed the use of gateways.
"In addition, this approach proposes the use of MS (Management Stations), a laptop or a remote workstation, which is connected to the Internet, and where the network topology can be visualized."
Multimedia Wireless Sensor Networks (MWSNs) can be considered as a specific application of WSNs.
The benefit of using such architectures is the deployment and maintenance facility induced by the inherent plug-and-play and self-organized nature of wireless sensor networks.
"Several academic organizations and corporations are working on the development of new devices, protocols and architectures for MWSNs."
"Authors of [61] give an extensive overview of the existing algorithms, software and hardware for multimedia wireless sensor networks."
Yale University has developed SOS [64] an operating system that employs video sensor for behaviour interpretation using distributed sensing.
"Georgia Institute heterogeneous sensors (scalar, low-res cameras, high-res cameras) for different studies at the MAC, Network, Transport and the Application layers."
"Event-centric wireless sensor networks (EC-WSNs) differ from common WSNs, where the communications are triggered either by an on-demand or a sink-based process."
"Indeed, in this case, the communication is triggered only when an event is detected in the immediate sensing-range of a node."
"Final users, i.e. users interested in an event occurrence, can subscribe to one or more event interest, and get updates from the sensor network."
"For example, clients (digital billboards, cell phone, laptops, PDA) interested in parking spots availability in a specific area may subscribe to this service and get updates each time the sensor network detects that places are available."
The intent is to provide a pseudo real-time view of all the occurring events of the network.
"Examples of application of EC-WSNs can be envisioned in urban environment, where final users may connect to a large scale EC-WSN and subscribe to various event-interests like: parking lots or public bikes availability, queues and lines status in different offices (postal office, supermarkets, fuel stations, etc."
"A wireless sensor network is vulnerable due to its characteristics as an open medium, with a network topology that dynamically changes, which employs cooperative algorithms, it lacks an element for managing and monitoring the network and it also hasn’t a perimeter defence [66][68][70] clearly defined."
"The main vulnerabilities in wireless sensor networks are [67][69]: wireless links, auto unattended operation."
"The security problems in a wireless sensor networks become clear with the assumption that radio links are insecure, which makes communication in wireless sensor networks insecure too."
"An attacker could easily listen to the channel as it is a broadcasting one, inject whatever data, and even play some bit packet headers that were sent before."
"In addition, an attacker could gain control of one or more motes and attack from them the whole sensor network."
Attacks on wireless sensor networks can be made from outside the network or can be originated inside it.
"Attacks from malicious motes that are not part of the network and try to join it without authorization, are often done applying cryptanalysis techniques and attacking physically the device."
Motes are part of the network and they may attack if they have been compromised by an attacker that has manipulated them [66].
"The most common attacks that often occur in motes that are part of the network are: flood, alteration or replications of routing information, selective transmission, sink attack, Sybil attack, wormhole attack, HELLO flood attack, spoofing recognition, passive listening, denial of service and subversion of a node."
Security in wireless sensor networks is currently provided exclusively through symmetric key cryptography but there is some studies which purpose ultra-low power hardware implementations of public key algorithms.
Several public key schemes can be used to provide the security services described above.
"In [6] we take a closer look at Rabin’s Scheme, NtruEncrypt and Elliptic Curve implementations."
"Although these algorithms are more powerful and secure than those of symmetric key, we must take into account the time they take to encrypt and decrypt, the number of bits to be added when we encrypt a message and the energy consumption are much higher than that of symmetric key algorithms."
"RC5 (Rivest Cipher-5) is an encryption block algorithm [73], which may be one of the cryptographic algorithms more suitable for WSN due to their good behavior in devices with low memory capacity."
"Although RC6 is an algorithm with a security level something greater than RC5, it performance is significantly lower in WSN [74]."
"Another important algorithm used in Wireless Sensor Networks is TEA [75] (Tiny Encryption Algorithm), TEA is a block cipher algorithm which requires little memory space."
"XTEA (eXtended TEA) is a block cipher algorithm, which appeared to correct the weaknesses of TEA."
It was designed by engineers at Cambridge Computer Laboratory in 1997 and it has not been patent yet [76].
The small size of the implementation of this algorithm has provided an option that is highly recommended on systems with very high memory restrictions (such as embedded systems or wireless sensor networks).
"Some studies [77], concluding that the memory requirements imposed by XTEA in sensor networks are a quarter of those required by AES (Advanced Encryption System)."
"Thus also studies made by our researchers [78], has been shown that the use of the AES algorithm reduces half the batteries life."
The traditional DES (Data Encryption Standard) uses many computational resources and therefore it isn’t recommended [79] for use in WSN.
TinyECC and WMECC [80] are two implementations of public key cryptography on the TinyOS operating system.
"Both include cryptographic primitives based in elliptic curve cryptography optimized for wireless sensor networks, such as models Micaz, Telosb and Imote2."
"One of the greatest advantages is that the primitives are already included a specific operating system for wireless sensor networks, allowing developers use this type of primitive easily."
TinyECC and WMECC perform for the first time deployments based in public key cryptography and introduce the concept of digital signature in devices designed for use on WSN.
"However, the main disadvantage of this type of cryptography, is the high run time (with temporary magnitude scales around a second) required for data encryption or for processing or verifying digital signatures."
"The .NET Micro Framework Microsoft architecture [81] also included in version 2.0 a namespace (package or classes group) oriented to the security for very low capacity devices, as employees in wireless sensor networks."
"This space name, named Microsoft.SPOT.Cryptography [82] incorporates two cryptographic algorithms, one based on symmetric key cryptography and the other based on public key cryptography."
The symmetric key algorithm is XTEA in a version optimized for WSN.
"Although cannot speak about a security model, .NET Micro Framework provides the necessary tools to create a complete security model."
Directive 95/46/EC of the European Parliament and of the Council of 24 October and on the free movement of such data was the first document where confidentiality of communications was guaranteed.
Directive 97/66/EC of the European Parliament and of the Council of 15 December telecommunications sector translated the principles set out in Directive 95/46/EC into specific rules for the telecommunications sector.
"In the case of public communications networks, specific legal, regulatory and technical provisions should be made in order to protect fundamental rights and freedoms of natural person."
"Measures should be taken to prevent unauthorized access to communications in order to protect the confidentiality of communications, including both the contents and any data related to such communications, by means of public communications networks and public available electronic services."
"In digital mobile networks, location data giving the geographic position of the terminal equipment of the mobile user are processed to enable the transmission of communications."
"On 25 June 2008, the European Parliament's Standing Committee on Civil Liberties, Justice and Home Affairs asked for measures to correct the European Commission's proposal to amend the Directive on Privacy and Electronic Communications (called ePrivacy Directive)."
"Peter Hustinx, the European Data Protection Supervisor (EDPS), adopted, on 14 April, an Opinion on the European Commission's proposal amending, among others, the ePrivacy Directive."
The EDPS basically supported the EC proposal giving a few recommendations such as the obligation to notify any breach of security not only from providers of public electronic communication services in public networks but also from providers of information society services which process sensitive personal data.
"When the number of nodes in the WSN grows and new services more complex are implemented, it is necessary to include authentication and authorization services in order to verify the data source and to allow taking authorization decisions."
"In a model of communication between two parties, the data authentication can use symmetric mechanisms."
Sender and receiver share a secret key to generate and verify a MAC (Message Authentication Code) [72].
MAC mechanisms can be integrated into a sensor network through the protocol family SPINS (Security Protocols in Networked Systems ) [84].
This solution presents as advantage that only adds 6 bytes in the packet payload and the energy consumption is only the 20 % of the total energy use.
A widely authentication method used in WSN is the Authentication broadcast.
This authentication requires an asymmetric mechanism.
"Unfortunately, the asymmetric communication rate and storage, as already mentioned in previous paragraphs."
"The uTesla protocol solves this problem by introducing asymmetry through the delayed revelation of symmetric keys, allowing an efficient authentication broadcast scheme."
However [85] explains that uTelsa is not suitable for the authentication traffic between nodes because it provides authentication delayed in time.
"In this protocol generated keys are applyed to generate messages MAC sequentially, but are released with a delay once the packets are received."
"Therefore, authors as [86], propose the replacement of the initial distribution unicast using broadcast-based techniques."
We can found some researches about the way to provide entities authentication in hierarchical sensor networks.
"The authors of [87] propose the use of a certificate called TESLA, which can be use by low capacity devices (such as WSN nodes) to provide entity authentication."
"Its framework authenticates new nodes on the network, while supports trust relationships."
The authors of [88] propose a scheme based on Elliptic Curve Cryptography (ECC).
The idea of this scheme is to use PKI (Public Key Infrastructure ).
"In this solution, there is a base station placed in a safe environment with increased capabilities of processing and storage."
This base station serves as CA (Certification Authority).
A certificate of a legitimate user (U) is signed by the CA.
This schema requires more processing on the encryption and signature verification as on the decryption and signature.
The authors claim that the use of ECC is feasible in this type of networks.
However it may cause a bottleneck process from the sensor nodes if there is excessive traffic on the network.
A weakness of this protocol is that an attacker can gain false certificates and signatures.
In addition DoS attacks could be received by continuous sending of certificates that exhaust the memory and the battery of these nodes.
There is also the possibility of a source authentication system broadcast based on sending multiple messages MAC [89] called MultiMAC.
"What is new in this mechanism is to provide a key distribution combinatorial and deterministic, providing authentication is implemented as a security component of TinyOS."
This mechanism based on multiple MAC messages and requires that network nodes have a key ring.
"To authenticate a message, the source node generate a list of MAC based on their keys, and added them to the message."
The receiving node will verify the message based on the MAC that has generated using keys that are shared with the source node.
To meet the WSN restrictions must be designing an appropriate key ring.
"Networks: A Survey,"" Journal of Computer Science and Technology, vol."
"Sensor Networks Using Kairos,"" in Distributed computing in Sensor Systems, S. Berlin/Heidelberg, vol."
"Sensor Networks,"" in First International Workshop on Data Management for Sensor Networks, 2004."
"Methodology for Architecture-Independent Programming of Networked Sensor Applications and Services, pp."
"Regions,"" in First USENIX/ACM Symposium on Networked Systems Design and Implementation (NSDI '04), 2004."
"Conference on Distributed Computing Systems (ICDCS'04), 2004."
"Aggregation Service for Ad-Hoc Sensor Networks,"" in Fifth Symposium on Operating Systems Design and implementation (OSDI'02), Boston, 2002, pp."
"Wireless Sensor Networks,"" in 11th Workshop on ACM SIGOPS European workshop, Leuven, 2004."
"Special Issue on Mobile and Pervasive Computing, pp."
"Workshop on Middleware for pervasive and ad-hoc computing, Toronto, 2004, pp."
"Proceedings of the 3rd international workshop on Middleware for sensor networks, Leuven, Belgium, 2008."
"Ubiquitous Computing Environments in Ubiquitous Computing Environments,"" in CM/IFIP/USENIX International Middleware Conference, Brazil, 2003."
"Proceedings of the First International Conference on Semantics, 2005."
"Middleware Architecture for Wireless Sensor Network,"" in IEEE International Conference on Services Computing, 2009."
"A. Fernández, and V. J.R., ""A Knowledge Based Wireless Sensor Network."
"Conference on Information Technology: Coding and Computing, Washington, DC, USA, 2005, pp."
"Modelling, Design, Application,"" in 8th IEEE International Conference on Emerging Technologies,, 2001, pp."
"Architecture for Wireless Sensor Network,"" in IEEE International Conference on Service Computing, 2009."
"Networks through Flexible Service Provisioning,"" in 11th International Conference on Coordination Models and Languages, Lisboa, 2009, pp."
"Monitoring of Wireless Sensor Networks”, First International Conference on Communication System Software and Middleware, 2006."
"Sensor Network”, Proceedings of the International Conference on MultiMedia and Information Technology, pp."
"Sensor Networks, to appear in Handbook on Mobile Ad Hoc and Pervasive Communications, edited by M. K. Denko and L. T. Yang, American Scientific Publishers, 2006."
"Chowdhury, “A Survey on Wireless Multimedia Sensor Networks”, Computer Networks Elsevier."
"System for Wireless Sensor Networks,” Proceedings of the Second European Workshop on In Wireless Sensor Networks, 2005."
"Management Architecture,” in Proceedings of the International Conference on Mobile Computing and Ubiquitous Networking, 2005."
"Architecture for Wireless Sensor Networks,” IEEE Communications Magazine, Vol."
In Proceedings of the International Conference on Wired/Wireless Internet Communications.
"Acquisition via Heterogeneous Image Sensors,"" IEEE Journal of Selected Topics in Signal Processing, vol."
"Akyildiz, T. Melodia, and K. Chowdhury, ""Wireless Multimedia Sensor Networks: Applications and Testbeds,"" Proceedings of the IEEE, vol."
Art in Ultra-Low Power Public Key Cryptography for Wireless Sensor Networks”.
"John Paul Walters, Zhenqiang Liang, Weisong Shi, Vipin Chaudhary."
"Proceedings of the 7th ACM International Symposium on Mobile Ad Hoc Networking and Computing, MobiHoc."
Proceeding of the 10th Annual Network and Distributed System Security Symposium.
Proceedings of ACM Workshop on Wireless Security (WiSE ‘03).
Task 2.4 aims at providing savvy users the means to assemble and program hardware that can be used by end-users to customize their smart environment.
This section will provide a brief survey on the existing Do-it-Yourself hardware platforms and identify the technical challenges that need to be addressed to simplify the exposure of DiY devices in the DiYSE platform.
A list of existing devices that can be connected to DiYSE has been provided in section 2.1.
This section describes a few illustrative examples of inexpensive and open hardware platforms with a strong community support that hobbyists can use to create their own DiY devices.
"Just as widgets make GUIs easy to develop, Phidgets [1] (or physical widgets) are building blocks that make the new generation of physical user interfaces easy to develop."
The “Phidgets Interface Kit” is a board powered and controlled by a computer’s USB port.
It features a number of analog inputs and outputs to which different kinds of low cost sensors and actuators can easily be plugged.
"The interaction with the “Phidgets” is done through very simple APIs, consistent across a large number of programming languages, ranging from Java to Microsoft Excel."
Arduino is a simple open hardware design based on the Atmel AVR family of microcontrollers.
"It can easily be programmed using Wiring, a simple programming language, and the associated Arduino IDE."
"Arduino features add-on modules called “shields”, which allow to add preassembled circuits to the main board to control motors, add Ethernet, Bluetooth, ZigBee, etc."
"Standalone non-networked device: it can interact only through input and output sensors and actuators, not with other devices."
An example is a “DiY mood lamp” that changes color randomly.
"Computer peripheral: device is connected to a computer through serial, USB, or Bluetooth."
"It is programmed to act as a slave of a program running in the computer, just like Phidgets (Bitlash [6] or Firmata [7] libraries are useful for this)."
A typical project using this approach is a computer-controlled railway model.
This is the simplest communicating setup as all microcontrollers have at least a serial port.
"The drawback is that in order to operate the device, the computer needs to be running."
"Networked device: Arduino boards can participate in a network, either using Ethernet or ZigBee shields with the corresponding libraries."
"In this set up, different Arduino-based devices can talk to each other, to computers in the LAN or even to servers on the Internet (a gateway is still required for ZigBee to IP bridging)."
This is the most interesting configuration for DiYSE as it enables interaction between the application creation environment and the devices.
Extensive support for the usage of Arduino is available online or in the “Making things talk” book [8].
A huge number of embedded devices today run *NIX-like operating systems such as GNU/Linux and are open or hacked so that they can run custom software.
"Indeed, peripherals such as Phidgets can be attached thus turning them into IP ambient devices that can be placed in buildings, vehicles or outdoor, powered by AC, batteries or even solar panels."
This section will focus on how to easily connect self-programmed or self-assembled devices to a common infrastructure so that they can be accessed from the DiYSE application creation environment.
Non-networked devices or devices that communicate with each other without interacting with computers or IP networks at all (e.g. a WiiMote controlling an Arduino-based Bluetooth lamp) are out of the scope of the DiYSE project because of the lack of obvious means to link them to the DiYSE application creation environment.
"Open or hacked Linux-powered devices, such as listed above."
"In general, IP devices host servers exposing their built-in functions, either through TCP or UDP servers, HTTP servers (possibly using a RESTful resource model [11]), UPnP [12] or DPWS [13]."
"Often, they are open platforms where new functionalities can be implemented using Software Development Kits."
"In that case, user-added functions should also be exposed as services in the network."
"As IP devices, they can directly participate in network interactions without intermediaries, either on the local network or through the Internet."
"Discovery: the device needs to be discovered, either through a dynamic lookup or in a directory."
"Most dynamic discovery protocols, such as the ones used by Zeroconf, UPnP and DPWS, rely on multicast UDP datagrams, that don’t propagate outside a LAN without a proxy."
UPnP and DPWS protocol stacks fully match the needs of plug-and-play IP devices and open-source tools enable the development of the service software for many embedded platforms.
"However, the required effort make it more suited for industrial companies than for hobbyists."
"Using an HTTP server (preferably using a RESTful resource model) is a good compromise, as HTTP servers are available in binary format for all kinds of IP devices and programming can be simply done through server-side scripts."
"Description: in addition to discovery, the protocol enabling to control the device should be described or the software component enabling its usage (driver) made available in order to avoid users manually describing the interaction protocol."
"Eventing: if devices are meant to receive commands and notify events, a callback mechanism should be implemented."
"These devices will need a device-specific software “driver” running on the computer which will hide the specificities of the peripheral to the controlling application, which is independent of the underlying communication protocol."
"Assuming that the semantics and coordination of the device interaction is ensured by the upper layers, the remaining challenge for a Do-it-Yourself usage of this category of devices is the seamless search and deployment of the appropriate device drivers."
"In order to achieve a sense of interaction without computers, these peripherals can be connected to the one of the abovementioned embedded GNU/Linux-based computers, which can run permanently, silently and hidden."
"In this case, a network service exposing the peripheral to remote user applications would be required."
This category groups devices that communicate using networks that do not use full TCP/IP stacks.
"As an example, an increasing number of hobbyists that want wireless battery-powered devices buy ready-to-use ZigBee modules [14]."
These modules are easy to use as they behave like simple modems (communication uses serial and configuration is done through Hayes AT commands).
They form wireless networks with star or mesh topologies that self-configure and route messages.
"Having a computer (“gateway”) run a program that controls the whole network, hides its underlying complexity and exposes it as a service or “virtual device”."
The drawback is that this program would be usage-specific.
"The advantage is the solution is simple to implement, as it is equivalent to exposing a peripheral."
The state-of-the-art solution to implement this on top of low-power devices is headers on top of low-power devices (both wired and wireless).
"In this case, the role of the gateway is solely to compress and uncompress the IPv6 headers."
UDP and ICMP protocols are already supported in a number of devices.
"The remaining issue is that running a TCP stack on such low-power devices, even if feasible, is over-engineering for its actual usage."
"In the application layer, current works, such as 6lowAPP [16], propose the usage of simple protocols similar to REST."
The development of such protocols and development libraries for non-experts remains a challenge to be addressed.
"This document, the EIRENE Functional Requirements Specification version 7.1, is an interim version released to address some known issues and errors in the specification and to ensure consistency with the EIRENE System Requirements Specification."
It has been released alongside a new interim version of the EIRENE System Requirements Specification - version 15.1.
"It offers access to improved features such as shunting, EIRENE Data Only Radio and alerting of a controller."
System requirements relating to the EIRENE Data Only Radio (EDOR) have not yet been defined and added to the EIRENE System Requirements Specification.
"In case of any inconsistencies relating to EDOR, the EIRENE Functional Requirements Specification version 7.1 takes precedence over the EIRENE System Requirements Specification."
"The changes made in this interim version were agreed within the UIC, GSM-R IG, CER, EIM and ERA and were agreed in the ERA control group meeting on 3rd June aspects)."
"Please note that, notwithstanding this interim version, the documents required for interoperability remain to be the EIRENE Functional Requirements Specification version 7 and the EIRENE System Requirements Specification version 15 - the relevant documents from this point of view, referenced in the CCS TSI, Annex A."
"No part of this publication may be copied, reproduced or distributed by any means whatsoever, including electronic, except for private and individual use, without the express permission of the International Union of Railways (UIC)."
"The same applies for translation, adaptation or transformation, arrangement or reproduction by any method or procedure whatsoever."
"The sole exceptions - noting the author's name and the source -are ""analyses and brief quotations justified by the critical, argumentative, educational, scientific or informative nature of the publication into which they are incorporated"" (Articles L 122-4 and L122-5 of the French Intellectual Property Code)."
A passive or active device normally mounted in proximity to the track for communications with passing trains.
A standard for balises has been devised within the EUROBALISE project.
A call made to all members of a pre-defined group within a local geographical area.
"Only the initiator of the call may talk, with all other group members listening only."
The radio and associated user and other interfaces installed in the cab of a locomotive and for use principally by the locomotive driver.
A member of the train crew with overall responsibility for passenger-related Railway activities on-board the train.
A number assigned to an item of rolling stock on a permanent basis.
The coach number may form a component of a functional number used to address users/systems on an item of rolling stock.
An individual responsible for the conduct of some aspect of train operations (also known as dispatcher).
"For the purposes of this specification, the following - power supply controller."
"Dependent upon local circumstances, a number of functional roles can be carried out by a single controller or a single functional role can be carried out by a number of controllers."
The term for back-to-back or set-to-set radio communications without the use of any ground infrastructure.
An on-train system which monitors the alertness of the driver and provides warnings and alarms to other systems as appropriate.
"An EIRENE network is a railway telecommunications network, based on the ETSI GSM standard, which complies with all related mandatory requirements specified in the EIRENE FRS and SRS."
An EIRENE network may also include optional features and these shall then be implemented as specified in the EIRENE FRS and SRS.
"An EIRENE system is a railway telecommunications system based on the ETSI GSM standard, which complies with all related mandatory requirements as specified in the EIRENE FRS and SRS."
An EIRENE system may also include optional features and these shall then be implemented as specified in the EIRENE FRS and SRS.
A number assigned to an item of traction stock on a permanent basis.
The engine number may form a component of a functional number used to address users/systems on an item of traction stock.
The radio equipment dedicated to support the ETCS train control application data transmission requirements.
This equipment includes one or several radio transceivers and their enclosure.
A UIC fiche or leaflet is a document adopted by UIC members.
Statements within the fiche may comprise specifications which are binding on UIC members (‘obligatory’ specifications) or optional (‘recommended’ specifications).
The existing track-to-train radio standard is contained within UIC fiche 751-3.
"It is envisaged that the EIRENE standard will be covered by a new UIC fiche, 751-4."
"A term used to describe the process of addressing a call using a number representing the function a user is performing, rather than a number identifying the user’s terminal equipment."
A description of the function performed by a called or calling party.
The functional identity can include characters and numbers.
The full number used within the functional addressing scheme to identify an end user/system by function or role rather than by a specific item of radio equipment or user subscription.
A standard radio closely based on commercially available units for general use.
"Only one member of the group may talk at any instant, with all other group members listening only."
"High priority calls (critical group calls for drivers in the same area initiated by a driver, critical group calls for station and security staff, trackside maintenance staff or controller groups) are made in exceptional circumstances where the situation requires a higher level of priority than for normal operational calls, but the same call handling regarding alerting and setup."
These calls have lower priority than Railway emergency calls.
A form of unidirectional signalling transmitted periodically or constantly from one radio to another to allow the receiving user to detect a break in radio transmission during critical manoeuvres (eg during shunting).
A term used to describe the process of addressing a particular function (typically a controller) based on the current location of the user (typically a train).
A voice communication method whereby a number of parties defined by the call initiator may participate in the call.
A term used to describe communications between the drivers of each active cab in a train comprising multiple traction vehicles.
"The part of the functional identity of a user which defines the functional role performed by the user on a specific train, engine or coach."
These are railway communications directly concerned with train and shunting movements or train operation.
A handheld radio suitable for use by people involved in railway operations.
An open interface is an interface complying with published standards.
A controller responsible for the management of the traction power supply.
The location and direction of movement of any particular train permits the unique identification of a Primary Controller.
The Primary Controller is currently the co-ordinator of train emergency calls.
The Primary Controller is normally responsible for the operation of a designated area of track.
The exact responsibilities of the Primary Controller are determined on a national basis.
A point-to-point voice call which is used to notify non-railway authorities (such as Police and Ambulance services) of an emergency situation.
An ERTMS/ETCS term referring to a centralised safety unit to establish and control train separation using radio as the train-to-ground communication medium.
"A call of highest priority for informing drivers, controllers and other concerned personnel of a level of danger requiring all Railways movements in a pre-defined area to stop."
Shunting emergency calls (for Railway emergencies whilst involved in Shunting operations).
The use of a mobile on any communications network other than the user’s home network.
A Secondary Controller is a train controller who holds responsibility for the safe running of trains on a designated area of track (e.g. a signaller).
Secondary Controllers require the facility to communicate with trains in all situations in order to perform their function.
The split of responsibilities between Primary Controllers and Secondary Controllers is determined on a national basis.
A radio is considered in “Shunting Mode” when it is prepared to receive shunting emergency calls but cannot receive train emergency calls.
A handheld radio suitable for use by people involved in railway operations including shunting operations.
A group of people manoeuvring trains in order to change their location or composition.
Communications for shunting are particularly critical when a driver at the front of a train is pushing it backwards towards buffers or other potential obstructions.
In this case a lookout is often required to report progress to the driver.
A number assigned to an item of traction or rolling stock on a permanent basis.
A stock number may form a component of a functional number used to address users/systems on an item of traction or rolling stock.
These are railway communications which are not directly concerned with train movements or train operation.
"For example, such communications might involve the passage of catering, maintenance or timetable information."
A controller who has responsibility for the safe movement of trains.
The process by which the movement of a train is influenced without any action by the driver.
"For the purposes of this specification, reference to train control also encompasses automatic train protection, automatic train operation and in-cab signalling."
The interoperable train control system will be the ERTMS/ETCS application.
A radio is considered in “Train Mode” when it is prepared to receive train emergency calls but cannot receive shunting emergency calls.
A number given to a train by operational staff for a particular journey.
A train number may form a component of a functional number used to address users/systems on a train.
A controller who has responsibility for the scheduling of trains and the ‘flow’ of trains over the network.
"For example, traffic control personnel are responsible for such activities as holding connecting services and minimising disruption to the timetable."
The traffic control function has no formal safety responsibility.
This specification has been developed within UIC Project EIRENE.
It specifies the functional requirements for a digital radio standard for the European railways and is part of the Technical Specification for Interoperability.
The EIRENE Functional Requirements Specification defines the requirements of a radio system satisfying the mobile communications needs of the European railways1.
"It encompasses ground-train voice and data communications, together with the ground- based mobile communications needs of trackside workers, station and depot staff and railway administrative and managerial personnel."
"The scope of this specification is to provide interoperability for trains and staff crossing national or other borders between systems, and to provide manufacturing economies of scale wherever practical."
The primary objective of this specification is to ensure interoperability along international lines which are generally high speed and cross suburban areas with a high level of traffic.
It is also important for this specification to provide an appropriate standard for future replacement of national radio systems operating on both important internal routes and low to medium traffic rural areas.
It will be determined on a national basis whether different classes of service need to be defined for such routes.
"The EIRENE Functional Requirements Specification defines a set of requirements which a railway radio system should comply with, in order to facilitate international interoperability between national railways and manufacturing economies of scale."
"This specification therefore defines the functional requirements, to ensure that core railway functionality is provided."
"The specification distinguishes between the requirements affecting a railway’s network infrastructure, onto which mobiles will roam, and the requirements concerning mobiles which will be used in any EIRENE-compliant network."
The statements made in the specification are assigned to one of three categories: - Mandatory (indicated by ‘(M)’ at the end of the paragraph).
It is mandatory that each railway meets these specifications on lines where interoperability is required.
The mandatory requirements define the full set of interoperability requirements for EIRENE systems.
"Optional requirements are not mandatory for interoperability and, as such, the selection (or non-selection) of a set of optional requirements on a national basis shall not be used as a precondition for the certification and the acceptance of roaming mobile equipment on GSM-R networks."
"When an option is selected, the method defined in the SRS and FRS by which such features are implemented becomes mandatory, both to provide a consistent service and to present a recognised and agreed standard to manufacturers in order to obtain economies of scale in development and manufacture."
Information (indicated by ‘(I)’ at the end of the paragraph).
These are statements intended to provide explanatory s.
It shall be possible for applications external to EIRENE to access EIRENE bearer services.
The network services necessary to meet the range of UIC requirements are detailed below.
These services are to be considered as a minimum set for implementation within each UIC standard network.
This section describes the generic voice telephony services which are to be supported - multi-party voice calls.
All voice call services shall be able to operate between any combination of fixed and mobile equipment users (excluding specific data terminal equipment).
The system shall support point-to-point voice calls between any two call parties.
Such point-to-point calls shall allow both parties to talk simultaneously.
The system shall allow a user to make public emergency point-to-point voice calls.
Such emergency calls include ‘112’ calls and may not be used for railway emergencies.
The composition of call groups shall be able to be modified within the network.
A single user shall be able to be a member of one or more call groups.
It shall be possible for controllers to speak at any time during the call.
The network should support the transmission of point-to-point and point-to- multipoint text messages from the ground to mobile users.
The network shall support point-to-point data communications.
The network shall support data rates of at least 2.4 kbit/s.
"It should be possible for the network to prevent the identity of certain users from being displayed on the mobile, either when being called, calling or both."
Any user who is not within the list of allowed EIRENE users shall not be able to gain access to any of the functions and services provided by the network.
It shall be possible for an incoming call or data message for one user to be forwarded to another user using functionality provided by the network.
"In the case of voice calls, it shall be possible for the user who is attempting to forward a call to converse with the intended recipient prior to forwarding."
It shall be possible for the user to re-join the call which is on hold at any time.
The EIRENE network should also provide support for shunting mode (see section 14).
This section describes the requirements for the EIRENE network and the performance levels which are to be achieved.
It may be necessary to supplement this Functional Requirements Specification with special requirements for supporting the train control application.
The level of coverage should be at least 95% of the time over 95% of the designated coverage area for a radio installed in a vehicle with an external antenna.
Call set-up time requirements are dependent mainly upon priority (see section 10.2).
The requirements for end-to-end call set-up performance are indicated in table 3-1.
The required call set-up times shall be achieved in 95% of cases.
The group or broadcast call area used will have the effect of determining which mobiles can participate in the call (ie those currently within the area defined).
"Any group or broadcast calls initiated in a given location shall be broadcast over an associated area based on the location of the call originator, and also to any fixed network numbers associated with the originating location."
"All EIRENE mobiles are specified with a common level of basic services, facilities and features."
"This section of the specification gives details of these core requirements, whilst sections 5, 6, 7, 7A and 16 detail requirements specific to each of the radio types."
Operational radios – for use by railway personnel involved in operations such as trackside maintenance.
Shunting radio - for use by railway personnel involved in train operations such as shunting.
ETCS data only radios - for the transmission of train control data.
"It shall be possible to operate all mobiles in the frequency bands around 900 MHz, allocated for use by the railways, and in the public GSM networks."
This sub-section defines the core environmental and physical requirements for all EIRENE mobile equipment.
"The requirements provided in this section are augmented by those provided in later sections for each individual radio type, with each radio type being specified by the superset of the core plus specific requirements."
"The categories of requirements defined for each type of mobile equipment are as - climatic conditions (temperature, humidity, solar radiation, altitude, etc); - physical conditions (flammability, contamination, physical protection, etc); - electrical conditions (power supply variation, battery life, overloading, etc); - EMC (both emissions and immunity)."
Any environmental and physical requirements stated may be superseded by national requirements if the national standards provide a higher level of environmental and physical protection.
The design of EIRENE mobiles shall comply with the relevant European Norms for - mould growth.
This section identifies the functional requirements for the EIRENE Cab radio.
"In this subsection, the functions to be provided by the Cab radio are described."
It shall be possible for the driver to initiate a call to any of the following types of controller with a minimum of driver action being required (eg a single keystroke): (M) - power supply controller.
"If the radio system cannot give a unique identity for a given type of controller, the identity could be obtained using external systems as defined in 11.4.7."
The functional identity shall be displayed to the controller.
"If the system is not able to connect the call, an audible and visual indication shall be provided to the driver that the call was not received by the controller."
This shall also indicate if the called party was busy or if the network could not connect the call.
Either the lead driver calls the controller or the controller calls the lead driver.
"In the latter case, the controller is automatically added into the multi- driver call."
Functional identity of the controller shall be displayed in the leading cab.
"Not more than 2 MMI actions should be necessary to switch between groups, i.e. to leave one group and to subscribe to another group, excluding the operations necessary to select the required group from a list or enter digits."
This shall be carried out by entering the train number (option 1 in 5.2.3.26).
The radio equipment that will be mounted in rolling stock can be split into two classes: in-cab equipment and external equipment.
Each type of equipment has slightly different requirements placed upon it in terms of EMC and climate.
Ease of maintenance should be taken into account in the design and installation of radio equipment.
The design of the equipment shall make it possible to install it within a cab complying with the requirements of UIC fiche 651 concerning the layout of cab equipment5.
The driver shall be able to adjust the contrast of the display.
The emergency call button shall be red and shall be protected against accidental use.
Displayed characters shall have a minimum height of 5mm.
A driver safety device (DSD) interface should be provided in traction units that are equipped with a DSD in order to support the transmission of a DSD alarm.
DSD alarm information shall be transmitted to the primary controller.
Additional information may also be provided if available from external systems.
This section identifies the functional requirements for General purpose radio.
It shall not be possible for any General purpose radio user to send a Railway emergency call by dialling a short code or telephone number.
The user may then talk whilst the PTT function is used.
The-Shelf (COTS) mobile whilst adhering to the specifications provided in section 4.3 and this section.
"The General purpose radio should be small, compact and easy to carry."
It should be possible for a user to change the battery without the use of tools.
The weight of the General purpose radio including battery should not exceed 250g.
Changing the battery should not result in losing data stored in the radio.
The General purpose radio should be suitable for use with a car adapter kit.
"If the ability to initiate Railway emergency calls is implemented in the radio, accidental initiation of a Railway emergency call shall be prevented."
This section identifies the functional requirements for the EIRENE Operational radio.
"In this section, the functions to be provided by the Operational radio are described."
The Operational radio shall comply with the basic standards defined for all EIRENE mobile equipment in section 4.3 and this section.
The Operational radio should have a carry feature that allows the operator to instantly have both hands free without dropping the radio.
"Controls shall be designed for use in a wide range of conditions, eg splash proof and suitable for viewing in direct sunlight and in darkness."
The weight of the Operational radio including battery should not exceed 800g.
It shall be possible to change the battery without losing data stored in the radio.
"This common terminal platform should have interfaces, applications and accessories to fulfil specific national railway needs."
It shall be possible for the user to change shunting group numbers within 5 seconds (the confirmation response of the network is not included in the 5 seconds).
"For activation, a maximum of 2 MMI actions should be allowed."
"These may be physically separate or co- located; however, the majority of interaction is with the primary controller."
Detailed specification of controller equipment and the interface between such equipment and the EIRENE network is at the discretion of the railway operator.
The primary controller’s MMI should provide the following functionality: (O) - Queue all incoming calls or call requests.
Emergency calls should be identified and presented at the top of the queue followed by calls in order of their priority.
"The functionality required by other types of controllers is essentially the same as for primary controllers, but the control area will differ and the call set-up subsystem may be integrated into their own function management system."
"At the detailed level, different controllers may have specific addressing needs, eg catering controllers will need to call specific vehicles in a train."
The communications architecture will be dictated by local circumstances.
The definition of this interface is beyond the scope of EIRENE.
International standardisation of numbering plans is needed to ensure interworking between networks.
"Furthermore, standardised allocation of numbers to subscribers will facilitate schemes for identification, barring, etc."
"Telephone numbers can be defined on a national basis, but codes for certain functions shall be used on an international basis in order to allow interoperability."
"For certain functions, standardised telephone numbers shall be implemented."
"To provide interoperability between the fixed railway networks within the EIRENE network, standardisation of UIC group numbering will be required."
"In the case where an EIRENE mobile attempts to make a Railway emergency call over a public network, the ability to pre-empt lower priority calls (particularly public emergency calls) may be inhibited, unless a special agreement is in place."
Shaded cells on the access matrix mean that this call is outside the scope of the EIRENE specifications.
"If required, a railway may make additional restrictions to the access matrix."
"Examples include EIRENE mobiles, controller terminals, railway fixed network telephones and public telephones."
"During this recovery period, the system shall not permit the use of unverified functional numbers."
"If the mobile is in shunting mode, the emergency call button shall initiate a shunting emergency call, otherwise the call shall be a Train emergency call."
"The predefined areas for emergency calls shall include, where necessary, parts of one or more network(s)."
Shunting calls shall have ‘Railway operation’ priority (see section 10.2).
"For the driver, this indicates that the radio link is operational."
This facility is required principally for the safe conduct of pushing manoeuvres to assure continuing availability of the radio channel while a shunting worker is guiding a train driver.
It is possible for a controller to be a member of several group calls simultaneously.
The controller can actively participate in only one of these calls at any time.
Each type of equipment has slightly different requirements placed upon it in terms of EMC and climate (UIC fiche 6515 is a useful reference concerning the layout of cab equipment).
"Copyright This project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant Unless officially marked PUBLIC, this document and its contents remain the property of the beneficiaries of the WYRED Consortium and may not be distributed or reproduced without the express approval of the Project Coordinator."
"The requirements document is created in the first steps of the project for getting a wide vision about what kind of data, users and functionalities are going to be presented in WYRED the project (García- Peñalvo, 2016; García-Peñalvo & Kearney, 2016)."
"This document also represents a guide for the developing process, because it informs about the priority of the tasks, the dependencies among the tasks and the information they require, including the background, objectives, and targets too."
"In the process of the requirements definition, we can use different approaches depending on the software methodology."
"In this case, we chose the Durán and Bernárdez (2002) methodology because it offers a simple, but powerful, process to elicit and document the requirements."
"This methodology is based on tables, where we fill the information about a specific requirement."
The project requirements represent properties that our project is going to have.
"However, there are properties about different things (functionalities, design, information, etc.)."
"In our methodology, the authors defined three types of requirements."
This type of requirement groups all requirements about the information that the system is going to manage.
There is very important to set these requirements in order to develop the system that is going to manage the data.
"In WYRED one of the most important thing is to maximize the users’ privacy, due to this we are going to split the user’s information between public and private in the platform."
This information was selected with ours partners to keep the minimum information required to develop a correct social dialogue.
"These fields are the nickname (Table 1: NicknameTable 1), the language (Table 2), the avatar image (Table 3), the area (Table 4) and the topics of interest (Table 5)."
The platform also has to manage more information about its users due to this can help us to extract patterns and get conclusions.
"However, this information will be private and nobody will see the private information of a specific user."
"Therefore, it will be treated anonymously in order to respect the users’ privacy."
"The information that we keep private is: the name (Table 6), the surname (Table 7), the country (Table , the city (Table 9), the sex (Table 10), the age (birth date) (Table 11), the education level (Table 12) and the email (Table 13)."
The main problem to manage documents is that there are many formats that we have to support and they use many resources.
"For this reason, we decided keeping them in a dedicate server to improve the platform performance."
"The statistics save data about the number of publications for each user, her time in the platform, how many pages she has visited, in how many projects she is involved, etc."
The both requirements are described in Table 14 and Table 15 respectively.
"This type of requirements groups all requirements about what kind of technologies we are going to use, and regarding the platform design and architecture too."
"When we planned how to design a platform for youth people, we checked that they use more their mobiles than other classic devices such as laptops or desktops."
"For this reason, we decided to use a responsive design that can work well in all kinds of devices."
"However, creating a platform where our users are going to use mainly mobiles has other problem, the performance."
"Usually mobiles have wireless connections and depending on the country, they can be a bit slow, so we add a requirement about the platform performance."
The both requirements are described in Table 16 and Table 17 respectively.
"We also would like to develop a mobile application for the more common mobile systems (Android and iOS), in order to get a better response from the user."
"However, this requirement is more a wish than a urgent necessity and for this reason, it will have a minor priority."
One of the objectives of WYRED is to develop a platform without spend money in non-relevant functions.
"Due to this, we have planned to use Linux servers and free technologies."
"Linux servers are cheaper than Windows servers and offer a solid base to develop a complete web platform, in the same way, there are free technologies/software such as PHP or MySQL that are widely used in web development and we can use them without a specific cost."
These requirements are described in Table 19 and Table 20 respectively.
"One of the most important objectives is to keep all content in the platform hidden for public users, because we are working, in some cases, with underage people."
"So, the platform content does not have to be indexed."
This kind of requirements is related to the functions that the system has to support.
One of the aspect related to the privacy is how to keep the users’ information private and avoid arguments in the platform.
The solution that we have planned is to use an automatic system that checks all messages looking for a list of alert words.
"Although the intelligent system can find messages with alert words, these should be checked manually, for this reason we are going to develop a group of moderation tools for editing, deleting, moving, etc."
"Moreover, we will put an option where the users can inform a moderator that there is a message that should be analyze."
"These requirements are in Table 22, Table 23, and Table 24."
"The objective of WYRED is that the youth people can interact themselves and speak things that are important for them, in some cases, they also can offer solutions for their own problems."
"For this reason, we have to allow that a user can register in WYRED."
"However, WYRED is not a chat but a platform where there should exist a structured social dialogue, so we are going to develop something like forum topics."
This system helps the users answer questions and create discussion threads with their comments.
"With the objective of having a good response, first of all, the users will fill a form where they can say in which things they are interested in."
"Therefore, a researcher or a user will create a project, this will be hidden for all that are not invited to participate; for achieving this, the creator will select what kind of users are going to be invited using the public user’s information."
This process is described with the following requirements from Table 25 to Table 30.
One of the key elements to attracting young people is working on functionalities that improve the users’ engagement.
"This helps to improve a lot of metrics such as page views, used time and social sharing."
"The first requirement, which we have defined with this aim, was a translation system due to there are users from countries that speak different languages."
"We have also thought that it would be interesting to use a gamification system to increase the users’ engagement, due to it is one of the most common technique used right now."
"For improving the usability, we have planned to design custom styles for each age group, because of teenagers do not want to use a childish platform."
"We have also kept in mind that if a user likes our platform, she would like to share it with her friends, for this reason, we will develop an easy tool for social sharing."
"These requirements are described in tables: Table 31, Table 32, Table 33 and Table 34."
"In the social dialogue process, the researchers need to work with many kind of documents, such as text, audio, images and video."
"These documents are a relevant part in the WYRED project, so we have planned to develop tools for showing and sharing them."
The researchers also suggest that they need an online editor and an easy way for adding annotation in audio and video files.
"These requirements are described in tables: Table 35, Table 36 and Table 37."
"The researchers are also an important part of the WYRED project, for this reason, they are going to have a private zone."
"In this zone, they will be able to monitor their own social dialogues, share information between the project researchers and analyze their data."
"In order to improve the data analysis process, we are going to develop visualization tools and a pattern matching system."
"The visualization tools will help the researchers to discover knowledge using charts, trees and other representations."
"The pattern matching system will use techniques such as datamining or natural language processing, in order to give to the researchers some patterns about the stored data."
"These requirements are described in tables: Table 38, Table 39 and Table 40."
The system shall store the information corresponding to the user's nickname.
The system shall store the information corresponding to the languages that each user can use in the platform.
The system shall store the information corresponding to the user's avatar (a public image that represents him).
We will offer a catalogue of avatars and the users will choose one of them.
"If we can, it would be good has a system to personalize the avatar."
The system shall store the information corresponding to the user's localization.
The system shall store the information corresponding to the main topics of interest for each user.
The system shall store the information corresponding to the user's name.
The system shall store the information corresponding to the user's surname.
The system shall store the information corresponding to the user's country.
The system shall store the information corresponding to the city where the user lives.
The system shall store the information corresponding to the user's gender.
The system shall store the information corresponding to the user's age (based on the birth date).
"The best approach to manage age is to create group of ages, for example teens, kids, etc."
The system shall store the information corresponding to the user's education level.
The system shall store the information corresponding to the user's mail.
The system shall store the information corresponding to platform usage statistics.
"The system shall have a multi-platform native approach, for this reason we should create an application for the most important mobile operating system (Android and iOS)."
"The system shall keep all content hidden for public users, browsers, etc."
"The system shall have moderation tools to allow moderators edit, move and delete messages."
"The system shall have an intelligent system to check a list of ""alerts"" words."
We have to define what fields are needed in the register process.
The topics system must support that a user cite other user/users answer.
The system shall support selecting what kind of visibility we want for each part of the system.
"The allowed options are public, restricted by user or private."
"The system shall have an option where the researcher can select what kind of users he needs in his research, using the public profile fields."
The system shall have the possibility that a user can create a project and invite other users to join him.
The project has to have a zone where the users can speak and interact.
The system shall use an automatic translation system such as Google translator in order to allow the communication between people who speaks different languages.
"The system shall have an option to insert videos, audios, documents and other stuff."
The system shall have an online editor for documents.
The system shall have a system that allows annotation in video and audio files.
The system shall have monitoring tools in the researcher zone in order to see the social dialogue evolution.
"These tools should use the number of participants, their interactions, the number of comments, the number of uploaded documents, etc."
"The system shall have a powerful visualization system, that displays the statistics in graphs, charts, trees and other representations."
The aim of this system is helping the researcher to understand the data.
The system shall have a system that can analyse the data and find patterns automatically.
"This system can use multiple approach like NLP (Natural Language Processing), datamining, etc."
The WYRED Project: A Technological Platform for a Generative Research and Dialogue about Youth Perspectives and Interests in Digital Society.
"Journal of Information Technology Research, 9(4), vi-x."
Networked youth research for empowerment in digital society.
"In 2011, after a meeting of the Space Science Advisory Committee, the M3 candidate missions for the Cosmic-Vision 2015-2025 programme were selected for further assessment and consideration for launch in the early 2020’s."
The MarcoPolo-R Near-Earth Asteroid sample return mission was selected as one of the M-class candidate missions.
"The nominal launch date for M-class missions is now 2024, but the missions shall also be compatible with opportunities in 2022."
During the fall 2011 the mission concept was studied in the Concurrent Design Facility at ESTEC (internal pre-assessment) in order to prepare a thorough industrial assessment phase.
The purpose of the ongoing assessment phase is to assess the feasibility of this mission.
"After the assessment phase ending in 2013, one M-class mission will be selected."
"If adopted, the mission would proceed into definition and implementation (Phases B1/B2/C/D)."
"In parallel with the system level activities, an Announcement of Opportunity will be issued calling for the provision of scientific instruments by the science community through ESA."
It is anticipated that the selection of the science instruments will be confirmed by February 2013.
"Currently, references to the payload point to the Payload Resources and Requirements Document (PRRD, [RD16])."
"After the payload for MarcoPolo-R is selected, this will be replaced by individual Experiment Interface Documents – Part B (EID-B) for each instrument."
The overall mission development planning is shown in the figure below.
The dates and various activities are indicative only.
The planning will be updated following the assessment phase and the Contractor shall provide its own bottom-up development schedule.
This is a Mission Requirements Document (MRD) to be used as an Applicable Document in the MarcoPolo-R industrial assessment study.
"The purpose of the MRD is to provide all high-level mission-level requirements (including S/C and payload, launcher, ground segment and operations) necessary to achieve the science goals detailed in [AD2] for the MarcoPolo-R industrial system design studies running through 2012/2013."
It includes functional and performance requirements down to the sub-system level which can be defined at this stage.
"Later on in the course of the definition phase, it will result into two self-standing documents, i.e. the Mission Requirements Document and the System Requirements Document."
Recording and tracking of changes as well as giving a brief rationale is very important.
"The traceability of the requirements is paramount in order to make this document and its associated requirements easy to read and to understand at any stage of the mission assessment and possibly later definition phase, should this mission be selected."
It has been updated after the baseline selection review in the course of the assessment phase.
It will be reviewed as part of the assessment phase and will be updated following the Preliminary Requirement Review at the end of 2013.
The mission requirements document is one of the documents that constitute the foundations of the mission profile for MarcoPolo-R.
The mission document tree is given here below for information and lists the envisaged documentation (to be confirmed) available by the time of the Preliminary Requirements Review.
This issue of the Mission Requirements Document has been established in support of the Industrial Studies of the system design of the MarcoPolo-R mission.
The document is (currently) an open document and regular updates are expected.
"Particularly, iterative steps with industrial or internal study partners and the ESA study manager are foreseen."
"Revisions will be published, as required, at the start of, as well as during the system design."
The book captain of this document is the MarcoPolo-R study manager and any comment on this document should be directly reported to him.
Any conflict between requirements in this document shall be reported to ESA and any modification requires his/her prior approval.
Items included in this MRD are classified according to the following categories.
"If not complied with, the Agency shall immediately be notified."
"Their impact on the mission technical complexity and programmatic aspects (e.g. cost, risk) shall be limited so as to stay within the M-class boundaries."
Goals may be fulfilled under limited favourable conditions.
They are highlighted in italic in order to be easily identified.
Such an explanation can be found in italic below the requirement itself.
This is intended only to assist the understanding of the requirement or its origin (the Parent requirement ID might be sometimes included wherever applicable).
"Should a requirement be deleted in a later update of this document, its number will not be reused and should a requirement be introduced in between other requirements, the last digit will be used (e.g. R-YYY-115 between R-YYY-110 and R-YYY-120)."
"This paragraph describes the baseline MarcoPolo-R system and its mission profile selected at the Baseline Selection Review of the assessment phase in June 2012, in consultation with the European Science Study Team, the industrial teams and through an ESA internal review process."
The system breakdown is defined in the diagram below.
MarcoPolo-R is a sample return mission to the primitive Near-Earth Asteroid (NEA) 1996 FG3 which is a binary system.
"A spacecraft composite made of a main spacecraft, also called the sampling spacecraft and carrying the Earth re-entry capsule (ERC), will be launched by a Soyuz- Fregat MT 2-1b launch vehicle from Kourou on a direct escape trajectory to 1996 JU3."
The mission design and its development needs to be compatible with launch opportunities from launch slots between 2022 and 2025 have been identified with relevant backup opportunities and are all described in [RD1].
"Mission transfers, swing-bys and associated dates and duration slightly vary across the various opportunities."
The reader will refer to [RD1] for the full analysis and the requirements in this document refer to the most demanding case for each parameter.
"After one Venus Swing-by in October 2024, the spacecraft rendezvous with the NEA in February 2026."
In the 2022 scenario the proximity operations last for ~ 190 days (but for other opportunities it ranges from 180 through 390 days).
The proximity/science operations are described in 2.1.4.
"In a nutshell, this phase will include instrument calibration, far and close observations of the binary system with the various science instruments, gravity field determination and hazard mapping above roughly 5 km altitude."
Five sampling site candidates are then characterized at high resolution at about 250 m (TBC) distance to the surface during a few minutes in order to determine the most suitable sampling site (i.e. yielding the best compromise between science return and risk-mitigation).
"After one successful sampling rehearsal, the spacecraft, which will be designed to cope with surface hazards (e.g. large clearance to the surface), navigates towards the finally selected touchdown/sampling site and collects hundreds of g of surface material."
The sampling strategy is based on a touch and go approach to lower cost and risk.
Therefore the spacecraft performs a soft touchdown of the surface for a few seconds (in the order of 2-5 seconds) and then takes-off immediately after that to move into a safe position away from the surface.
"If it is confirmed, via a reliable verification technique, that a scientifically meaningful sample has been collected, the sample is transferred to the re-entry capsule and sealed."
The spacecraft is then ready for departure back to Earth or can carry on orbital science if desired.
"If the sampling operation was not successful, the spacecraft can undertake 2 more attempts (3 attempts in total)."
The spacecraft departs from the asteroid in August 2026 and returns to Earth in April 2029 after one Venus swing-by in November 2027.
The re-entry capsule is then released and undertakes a high-speed Earth re-entry at Ventry of maximum ~ 13 km.s-1 (in other scenarios the re-entry velocity is lower ~ 11-12.6 km.s-1).
The capsule will be retrieved on the ground at the Woomera test range which has already been used for Hayabusa landing.
The proximity operations shall serve the previously defined high-level mission requirements as well as science requirements defined in [AD2].
"In particular three phases have been identified as follows: Global Characterization Phase (GCP), Local Characterization Phase (LCP) and context measurements, the latter being performed during sampling operations (SAM) and therefore very short (in the orders of seconds)."
A so-called radio science phase is also implemented in order to get the gravity field of the binary system to the level required in [AD2].
"The science operations around the asteroid, to be further defined in [AD15], are part of the proximity operations."
"Other operations are: instrument commissioning, descent and sampling, etc."
All proximity operations for the 2022 scenario are shown in the figure below.
"Mission scenarios in 2024 and 2025 are less demanding as the duration of the proximity operations is far longer, i.e. resp."
"In the 2023 scenario, the proximity operations last for 180 days."
"So, the 18 days margins shown in the figure below become 9 days in the 2023 scenario."
The detailed description of the proximity and science operations as well as the associated requirements will be detailed in the Science Assumptions Document and the Mission Operations Assumptions Document ([AD14] and [AD15]).
The mission shall perform global and local characterization of the Near-Earth Asteroid to retrieve the sample context information at the resolutions defined below.
"Besides the science objectives, in-situ investigations defined in R-MIS-020 are meant to support the safe operation of the S/C in close proximity to the NEA and the safe collection of the sample(s)."
"The following requirements are related to the schedule, planning and development of the mission as a whole."
"The M3 mission is intended as a backup candidate for the 2022 launch slot, depending on JUICE schedule."
"Although in the science programme the baseline launch slot for M3 is 2024, all current study planning should remain compatible with a 2022 launch."
The final decision on the nominal launch date will be made following JUICE mission adoption.
The total mission duration shall not exceed 8 years.
Mission duration is defined as the time between launch and landing of the Earth re-entry capsule at the end of mission.
"These are the high-level requirements related to planetary protection and sample contamination (e.g. PP category, S/C cleanliness, contaminant tracking, etc.)."
"The engineering requirements related to it will be specified in the relevant category requirements (e.g. AIV for clean room environment, spacecraft for level of sterilization, etc."
The MarcoPolo-R mission shall comply with all planetary protection measures listed in [AD5].
Typical unwanted contaminants TBD by the science team.
"The potential contaminants shall be identified, controlled, tracked, documented and readily identifiable from the asteroid sample material."
The tracking of these contaminants shall start as of the S/C manufacturing process.
R-CON-030 Witness plates shall be implemented in order to track the possible contaminants throughout the AIV/AIT and various mission phases and shall be returned to Earth.
Here is a brief description of the model payload instruments.
"The reader is referred to the Payload Resources and Requirements Document [RD16] for more detailed data (interfaces, performances, requirements, etc.)."
This model payload has been defined by the MarcoPolo-R Science Study Team such as to fulfil the science requirements defined in [AD2].
Complementary instruments may also be envisaged but are not part of the model payload.
It will be determined at a later stage (Instrument AO – 2012) by the Science Programme Committee whether the complementary instruments shall and can be accommodated.
Used to identify the processes related to the exposure to space environment and collisions.
Provides the local microscopic context of the sampling area.
The model payload as defined in the PRRD [RD16] shall be assumed.
The model payload will be replaced by the selected instruments after the payload Announcement of Opportunity.
R-PLD-020 Science instruments shall not be used as baseline GNC sensors.
The sampling spacecraft shall provide a payload mass allocation of 36 kg (TBC).
R-PLD-100 During descent and sampling operations the spacecraft shall provide a power allocation of 15 W (TBC) to the close-up camera.
All other instruments are in off (if allowed by their thermal requirements) or stand-by mode.
"This power is common to WAC, NAC and CuC and should always only be counted once."
The following table defines the generic ESA TRL levels which have to be used in the frame of this study.
For performances of the launch vehicle it is referred to [RD1].
The launch vehicle shall be Soyuz-Fregat 2-1b with the Fregat-MT upper stage.
R-LAS-020 A launch mass margin of 8% shall be considered (TBC).
"R-LAS-040 Launch site shall be CSG (Kourou, French Guyana)."
This chapter defines the mission operations requirements.
"The following phases are covered in this chapter: post-launch or LEOP, cruise (outbound/inbound), DSM, GA, rendezvous, proximity operations, cislunar and re-entry."
The jettisoning strategy of any element shall ensure collision avoidance with the sampling spacecraft and the ERC or the asteroid at any stage of the mission with a TBD margin.
Re-entry conditions to be defined at 120 km altitude.
To remain within a feasible domain for plasma testing of thermal protection system.
G-OPS-100 Mission analysis should ensure a night re-entry of the ERC.
To ensure good observations of the chemical species involved in re-entry and limit temperature increase after ERC landing.
Data downlink is not considered to be a critical operation and therefore can be envisaged down to 3o.
"The mission design shall cope with the minimum distances to the Sun during all mission phases, i.e. coast and thrust arcs and asteroid proximity operations as specified in [RD1]."
"The mission design shall cope with the maximum distances to the Sun during all mission phases, i.e. coast and thrust arcs and asteroid proximity operations as specified in [RD1]."
The duration of a Solar conjunction or when the Sun-Earth-S/C angle is lower than shall be limited to 50 days.
R-OPS-090 Mission analysis shall ensure ERC re-entry velocity and flight path angle such that heat fluxes during re-entry do not exceed 15 MW/m2 (incl.
"Mitigation of risk, feasibility of science operations, maximizing rehearsals, etc."
The proximity operations shall allow 5 local characterization phases (LCP) before the first sampling attempt to image the 5 candidate sampling sites at high resolution and one LCP after a successful sampling attempt above the sampled site.
The local characterization campaign shall be such that all surface features larger than 20 cm (TBC) can be identified and located within a 10 meter (TBC) absolute precision on the 5 sampling site candidates.
Mapping of features on the sampling site candidates (+ local digital elevation model for slope estimation).
R-OPS-160 Proximity operations shall be planned so as to avoid collision with the primary asteroid and its secondary in case of temporary failures of the S/C or the ground segment.
In order to evaluate the science interest of the first acquired sample and analyse telemetry data from the previous sampling phase.
A descent rehearsal does not need to involve surface touchdown.
Its aim is to validate the convergence of the navigation filter.
The sampling operations on the asteroid shall occur on a fully illuminated location.
In order to get context information in the visible range (close-up camera).
The measurements in the visible range shall be performed with a local solar elevation angle between 30 and 60 degrees.
Visible range instruments shall nevertheless be on even during observations at other Sun aspect angles.
See definition of “Radio-science” orbit in chapter 13.2.
"Note that, if possible and of compatible with the instrument measurement requirements, other science measurements can be performed in parallel."
The selected sampling site should be free of features larger than TBD cm.
"This chapter defines the general system requirements applicable to the sampling spacecraft and the ERC or the space segment as a whole (general, margin, etc.)."
"They are derived from the science requirements, the mission safety, the general space design standards or more specific aspects of the mission applicable at system-level."
The spacecraft lifetime shall be 8 years in space and 2 years for pre-launch ground activities (AIT/AIV/storage) in a controlled environment and all space-based elements shall be designed and sized for this duration.
"The space segment shall be sized for the mission scenario which is most demanding (i.e. worst case ΔV, launch mass, thermal and sun illumination environment) as defined in [RD1], covering the full launch window as defined in [AD13]/R-DV-4."
"R-SYS-040 In this assessment study, the mission design shall follow the margin philosophy defined in [AD13]."
The margin philosophy and margin depletion scheme will be firmly defined at a later stage.
Any conflict between the requirements in this document and the ECSS standards shall be reported to ESA.
"The spacecraft system shall accommodate all necessary equipments and sub- systems, including mass and volume margins as defined in [AD13] and compatible with launch windows as defined in [RD1]."
"The maximum spacecraft dry mass, respectively wet mass shall be TBD kg, TBD kg."
R-SYS-110 A design-to-cost and risk minimization mission design approach shall be followed.
The sampling spacecraft should take images of the separated ERC after release.
The micro-meteorite environment is as defined in [AD4].
"R-SYS-190 During the touch and go sampling operations, the sampling spacecraft shall approach the surface with a maximum horizontal velocity of 5 cm.s-1 (TBC) at touchdown."
To limit the magnitude of forces on the touchdown/sampling system and to mitigate toppling.
"R-SYS-200 During the touch and go sampling operations, the sampling spacecraft shall approach the surface with a maximum vertical velocity of 10 cm.s-1 (TBC) at touchdown."
To mitigate toppling and to limit constraints on spacecraft geometry (e.g. solar panels).
Thermal Protection System with the asteroid surface is minimized.
The ERC and its sub-systems should be designed such that the shock loads on the sample are lower than 800 g quasi-static load (TBC) for any angle of attack up to 20 degrees (TBC).
"The ERC shall be statically stable and its dynamic instabilities, if any, shall be such that angle of attack variations are limited to 20 degrees (TBC) at all aerodynamic regimes after the peak of dynamic pressure."
"ERC dimensions, inertia, mass and CoM, CoP location."
"Before peak of dynamic pressure, angle of attack variations are less critical."
To ensure integrity of the ERC up to (excluded) landing.
The ERC design should ensure that the sample is never exposed to temperatures higher than +40oC.
"The ERC should be equipped with a flight instrumentation package to perform the following measurements during entry and descent: heat flux, temperature and pressure on both front and back shields at a frequency of 0.5 Hz (TBC)."
"If implemented, the maximum allowable shocks on the memory shall be defined and included in R-SYS-300."
The spacecraft design and operations shall transmit back to Earth a minimum total payload data volume of 122.35 GBit (TBC) before the end of the asteroid proximity operations.
"Without any margins ([AD13] guidelines to be implemented), compressed data volume."
"Without any margins ([AD13] guidelines to be implemented) , compressed data volume."
"Includes data from all phases, including GCP and LCP."
TBD Gbit of science data shall be transmitted back to Earth 2 weeks before the start of LCP operations.
"This chapter defines all key S/C sub-system requirements (pointing, thermal, power, data handling, telecommunications, etc.)."
They are derived from the system requirements or are requirements specific to a sub-system derived from space design standards or mission-specific need.
"The spacecraft thermal control system shall cope with the thermal needs of the various spacecraft sub-systems as required, including P/L, at any stage of the mission as a function of the spacecraft thermal modes, including safe mode."
Specific attention to be given to asteroid IR flux and closest distance to the Sun during transfer.
Lessons learns from Rosetta (e.g. need to thoroughly monitor the effect of pointing/solar aspect angle for the radiators).
Qualification margins for the TPS material are TBD.
"The spacecraft power system shall be made of solar arrays and batteries and shall cope with the power needs of the various spacecraft sub-systems as required, including P/L, at any stage of the mission as a function of the spacecraft power modes, including safe mode."
Eclipses due to the asteroid will be avoided for nominal operations but may be encountered if control of the spacecraft is lost or Earth eclipses during LEOP.
To avoid asteroid escape via solar radiation pressure.
The electrical design shall comply with the requirements of [RD6].
Start of proximity operations defined in chapter 13.2.
"R-GNC-050 During sampling operations, the AOCS/GNC system shall prevent total attitude excursions larger than 30 degrees (TBC) (with respect to the local vertical) and attitude rates larger than 5 deg/s (TBC)."
For instance to avoid the solar panels to hit the surface and further re-ascent with a safe attitude.
"The AOCS system shall be able to maintain during safe mode the composite in a Sun-pointing attitude using a minimum of the onboard resources while ensuring power generation, a survivable thermal environment and ground communication for vital equipment."
"R-GNC-070 In the event of unavailability of the star trackers, the AOCS/GNC shall have the capability to maintain and propagate attitude estimation whilst meeting the relevant pointing requirements."
"The spacecraft data handling system shall cope with the data transfer and storage requirements of the various spacecraft sub-systems, including payload, at any stage of the mission."
The DHS shall be able to receive TC and send TM from/to ground at the same time.
The DHS shall be able to command the instruments and equipment onboard.
The DHS shall provide reconfiguration capabilities in case of failure detection.
The DHS shall manage the redundancy for the relevant sub-systems.
"R-DHS-060 During touchdown/sampling operations, the DHS shall provide the capability to store the scientific and housekeeping data generated by the complete close-up camera and sampling operations cycle."
The DHS system shall support uplink and downlink file transfer.
The DHS shall provide the storage capability such that all science data can be downlinked (R-SYS-410/420/430) during proximity operations and assuming 2 consecutive downlink windows (i.e. 2 consecutive daily windows) are missed.
The propulsion system shall cope with all operations and associated Delta-V/thrust requirements incl.
The propulsion sub-system shall be designed to be compatible with any operational S/C attitude.
The main engine and any reaction control thruster shall be thermally qualified for such environmental conditions.
The propulsion sub-system thermal design shall assure that the minimum predicted temperatures of any wetted component or surface contacting the propellant remain at least 10oC above the maximum freezing point of the onboard propellant.
"The performances of the propulsion system in terms of total impulse and margin shall satisfy the requirements imposed by the mission, the trajectory analysis and the overall system requirements."
R-COM-020 Real-time data shall be provided directly to Earth during descent and sampling allowing monitoring of the major events.
Beagle 2 recommendations: get a minimum health status of the S/C throughout descent.
The communication system shall support the two-way Ranging and Doppler measurements of the S/C throughout all mission phases and ΔDOR if high- precision navigation is required (e.g. RSE campaign) TBC.
R-COM-060 Science data shall be downlinked by the spacecraft in X-band.
The maximum bit error rate during data downlink shall be better than 10-5.
The telecommunication equipment shall support the RSE as specified in [RD16].
"If Ka-band is required for science, this shall be considered as a science instrument."
"R-COM-130 All images taken by navigation cameras and required to be sent to ground (e.g. asteroid shape model, local slopes around sampling sites, etc."
"The spacecraft structure shall support the mechanical static and dynamic loads encountered during its entire lifetime, including: manufacturing, handling, transportation, testing, launch and in-orbit operations (incl."
The structural design shall be based on simple load paths.
The structural design shall provide a minimum margin of 15% over the minimum frequencies specified by the Launcher User Manual [AD8] before verification of S/C dynamic properties by test.
"The sampling mechanism shall have the capability to collect cm-sized fragments, plus a large amount (minimum several grams) of small particles (100s of μm-sized to mms-sized)."
Determine whether the sampling operation was successful or not.
R-MEC-060 All mechanisms involved in the SATCS chain shall be cleaned so as to fulfil levels specified in R-CON-010/R-SYS-370 and according to the standards defined in R-CON-040.
The design of the sample collection and distribution unit (incl.
"G-MEC-130 Through the monitoring of its various sensors’ information as a function of penetration progress, the SATCS should support the determination/estimation of the soil’s mechanical properties."
"Soil properties: density, porosity/compaction, hardness/cohesion, cementation, etc."
The design of the touchdown mechanism system as well as the sampling mechanism shall be such that total attitude excursions are lower than 30 degrees (TBC) (with respect to the local vertical) and attitude rates lower than 5 deg/s (TBC).
"R-AUT-010 Operations of the spacecraft shall be possible during all mission phases via the execution of pre-programmed sequence, or via onboard autonomy during the descent and sampling phase."
Level of autonomy and detailed spacecraft operations throughout the various spacecraft operations are TBD.
R-AUT-020 S/C autonomy shall ensure achievement of all mission goals.
"R-AUT-030 During asteroid proximity operations, if a ground TC is expected for the S/C to proceed with its nominal manoeuvre and this TC is not received within a TBD time, the S/C shall be able to perform a valid transition into an asteroid Collision Avoidance Mode."
"R-AUT-040 During descent/sampling operations on the asteroid, in case of any failure or non- nominal S/C equipment TM (sub-system or system) the spacecraft shall autonomously be able to perform a valid transition into an asteroid Collision Avoidance Mode."
"A “safe position” if during asteroid proximity operations phase, On its transfer trajectory in case of LEOP or interplanetary cruise phase."
The fault management systems shall be intrinsically fail-safe.
The spacecraft shall function autonomously throughout any solar conjunctions on cruise to and back from the asteroid.
R-AUT-150 Sampling site targeting and last go/no-go decision during actual descent and sampling shall be ground-based.
Autonomous sampling site re-targeting shall not be allowed (see R-AUT-040 instead).
"The following defines the environment-related requirements that the spacecraft has to comply with throughout the mission, whether that is the launch, interplanetary, spacecraft, asteroid or Earth re-entry environment."
The mission design shall be compliant with the general space environment (cruise) requirements defined in [RD4] and the mission-specific (e.g. asteroid) environment requirements defined in [AD4].
The sample shall never be exposed to magnetic field larger than 200 µT.
The asteroid body density shall be assumed to be 1300 ± 600 kg.m-3.
R-ENV-130 A diameter of 1550 m – 2110 m shall be assumed for the primary body.
R-ENV-140 A diameter of 430 m – 590 m shall be assumed for the secondary body.
Secondary orbital period around primary: 16.15 ± 0.02 hours.
The MarcoPolo-R mission shall be operated by ESA/ESOC.
LEOP is defined as the first 72 hours (TBC) after the separation of the spacecraft from the Fregat upper stage.
Also to be taken into account for ERC landing site selection.
R-GRS-080 It shall be possible to track the ERC re-entry during the whole re-entry operation.
The ground segment shall elaborate an operational concept based on multiple uplink and downlink attempts and a respective timing for the preparation of the orbit timeline to enable standard operations under superior solar conjunction conditions with a Sun-Earth-Spacecraft angle as low as 2° (TBC).
The required success rate sets of commands (number of commands in set: 50 TBC) and for telemetry packets is TBD.
Probability to be calculated for space weather conditions typical for the solar cycle at the time of the conjunction.
The ground segment shall provide for a flexible re-planning capability during the asteroid phase.
The manoeuvre planning for new asteroid proximity orbits and new sampling site targets shall be available within 4 days (TBC) after reception of the respective request.
The ground segment shall construct a global asteroid map and a global Digital Elevation Model with a 1-m spatial resolution (TBC) of the whole asteroid during the GCP phase primarily based on the navigation sensor information.
The ground segment shall construct a local map and a local Digital Elevation Model with a 20-cm spatial resolution (TBC) of the sampling site candidates during the LCP phase primarily based on the navigation sensor information.
"The ground segment shall be able to obtain the position information relative to the targeted sampling site sent by the spacecraft as a package of “images” and AOCS housekeeping data, process this data and upload an appropriate “guidance” telecommand within one hour (TBC) of reception of the images in order to either reach the sampling site or to abort the descent."
Safe Mode if during any other phase than descent/sampling operations.
The overall mission reliability shall be better than 90% (TBC).
The design philosophy for all mechanisms shall be as defined in [RD5].
The risk of casualty resulting from the ERC re-entry shall be 1:10000 (TBC).
"The Applicable Documents (AD’s) listed below shall be complied with, unless conflicting with the mission MSRD itself or where specifically stated."
Their contents shall be considered as parts of the requirements of this document.
A conflict between these documents and the MSRD shall be brought to the attention of ESA for clarification.
The published ECSS (European Cooperation for Space Standardisation) space standards documents quoted in the MSRD shall be used as design references throughout the MarcoPolo-R assessment phase and are available on the Internet at: www.ecss.nl.
The Reference Documents (RD’s) listed below are given as complementary information and background data related to the MarcoPolo-R Mission or the ESA standards.
The role of each element is briefly described below.
"The combination of the sampling spacecraft and the Earth re-entry capsule, stacked together from launch through asteroid surface and proximity operations and cruises phases up until the release of the ERC."
"Sampling Spacecraft: Module used for outbound and inbound transfer to and from the asteroid, orbital operations around the asteroid, descent, sampling and re-ascent operations to and from the asteroid surface as well as release of the Earth re-entry capsule."
Sometimes also referred to as the main spacecraft in the assessment phase.
The retrieved sample container is located inside the ERC.
"Sample Acquisition, Transfer and Containment System (SATCS): All equipments involved in the sampling, sample transfer, sealing and containment functions of the spacecraft."
This is considered to be a spacecraft sub-system (i.e. not a payload element) and thus should be under ESA responsibility (incl.
Relative pointing error: Angular separation between the actual instantaneous generalised pointing vectors of the S/C and the median generalised pointing vectors defined over a time interval containing the reference time instant.
"Sampling site (candidate): Safe area operationally (on an illuminated part such as to enable vision-based navigation and with hazards compatible with the S/C capability) and scientifically suitable for sample collection, defined on the asteroid surface by the ground teams."
Touchdown accuracy: Downrange major axis of the touchdown ellipse.
"Touchdown ellipse: Ellipse centred on the sampling site which envelops all possible touchdown locations reachable by the spacecraft at 3-σ confidence level taking into account the variation/error of input parameters: navigation (sensors, filter, etc."
"The asteroid proximity operations are arbitrarily defined at the start of the close asteroid approach, i.e. at a distance of 500 km from the asteroid and end when the SEP system is switched on and the S/C leaves the asteroid system."
"Radio-science orbit: In the context of MarcoPolo-R, a Radio-science orbit is an asteroid-bound orbit, favourable to radio science measurements, where the S/C does not require any orbit and attitude manoeuvres in order to remain above 3 km distance to the surface at any time, during four consecutive communication windows of 8 hours."
"Safe position: In the context of MarcoPolo-R, a safe position is an eclipse-free location where the spacecraft does not require any orbit and attitude manoeuvres during at least one week in order to remain at least 1 km distance away from the surface of the asteroid surface (and its secondary if applicable)."
"Such a position can be either an asteroid-bound orbit or formation flying point or a heliocentric orbit, out of the asteroid influence (however close enough to allow return to asteroid in limited time and manoeuvre budget)."
"The termination of the ability of an item to perform a required function (e.g. solar arrays not producing electric current following string failure, sampling mechanism stuck and not able to perform sampling)."
Updated WFM requirements table 5-2. extended energy ranges.
Updated system requirements table and added caption 08/09/2012 Completed SCI-SYS-G-04.
Orbit requirement is not strictly a science requirement.
Issue 2 of the document has a large number of changes.
This document records the scientific requirements for the Large Observatory for X-ray Timing (LOFT).
These are the reference requirements through which the Mission Requirements Document will be derived and also the instrument specifications are deduced.
The document starts with the mission statement (also called level 0 requirements) and the minimum scientific success criteria.
Next these goals are quantified in a number of sub-goals (level 1 requirements).
"These level 1 requirements translate into requirements for the two instruments, the mission and the observation plan (level 2 requirements)."
"Although the level 2b and 2c could be omitted we have included them as they define rather well the type of mission needed to optimize the science (and, for example, level 2c requirements follow a science judgement and cannot be derived from the top level requirements)."
"The structure of the document is as follows: first the top level objectives and science requirements are given (levels 0 and 1, see section 4)."
"Next the requirements for the two instruments are presented, including a detailed justification and specification of the requirements."
"These are, for a significant fraction, based on the observation plan given in section 7."
"Detailed description of dependencies in the requirements is presented in appendix A, showing that there is a safe margin in the key requirements with respect to achieving the science goals."
"In appendix B we provide an overview of the requirement flow down, in appendix C we provide some information about requirements which have been dropped and in appendix D we provide a detailed justification for the required energy resolution."
This version 2 of the science requirements document has relatively few substantial changes in the numbered requirements compared with the issue 1.6.
It has however been restructured to meet the request from ESA to provide a more rigorous flow down of the requirements.
Only the substantial changes are listed in the change log.
"LOFT: Large Observatory For X-ray Timing, M3 proposal."
"LOFT Large Area Detector Response Stability, M. van der Klis et al."
"LOFT Large Area Detector Background Models, R. Campana."
"Radiation damage of the LOFT SDDs and its effects on the energy resolution, E. Del Monte et al."
"LOFT System Measurement of the Radiation Damage from soft protons on the Silicon Drift Detectors, E. Del Monte et al., LOFT System , LOFT_SysN-IrradSoftProtons_20121112.."
"LOFT Large Area Detector: Telemetry Estimate, J. Wilms & C. Tenzer."
LOFT is designed to study the equation of state of ultra-dense matter and to explore the conditions of strong-field gravity.
EOS of ultra-dense matter and neutron star structure.
Understanding the properties of ultra-dense matter and determining its equation of state (EOS) is one of the most challenging problems in contemporary physics.
"At densities exceeding that of atomic nuclei, exotic states of matter such as Bose condensates or hyperons may appear; a phase transition to strange quark matter may take place at higher densities."
Only neutron stars probe these densities in the ‘zero’ temperature regime relevant to these transitions.
"Very “soft” EOSs give a maximum neutron star mass in the 1.4-1.5 solar mass (Mo) range, whereas “stiff” EOSs can reach up to 2.4 -2.5 Mo before collapse to a black hole becomes unavoidable."
"Apart from maximum mass, the relation between the neutron star mass and radius (M-R) is a powerful probe of the EOS."
"With the exception of redshifts of any narrow atmospheric lines (feasible for slowly rotating stars only), all tools devised to constraint mass-radius are based primarily on accurate time-resolved and high-throughput broadband spectral measurements."
"In ~25 neutron stars, spins are now observed in burst oscillations and/or coherent pulsations at frequencies of up to 620 Hz, proving that millisecond spins and dynamically relevant magnetic fields are common among neutron stars in low-mass X-ray binaries."
"LOFT will measure the masses and radii of thermonuclear powered millisecond pulsars to an instrumental accuracy of of 4% in mass and 3% in radius by modelling their pulse profiles: their fast spin and strong gravity affect the radiation from the surface hot spots producing the pulsations through relativistic beaming, time dilation, red/blue-shifts, light bending and frame dragging (hence they provide an alternative probe of strong field gravity effects as well)."
LOFT will be able to cross-validate these results by flux and spectral modelling at photospheric touch-down of radius-expansion thermonuclear X-ray bursts.
"Since the maximum rotation a neutron star can sustain depends on its mass and structure, fastest spin periods also constraint the neutron star EOS."
LOFT will detect periodic signals (and QPOs as well) with unprecedented sensitivity.
"Models indicate that the pulsation amplitude in fast spinning neutron stars in X-ray binaries could be as low as 0.1%, so the effective area of the LAD is needed to detect these pulsations in a typical 104 s observation of a over short periods of time, indicate that it should be possible to build up a much better spin period distribution for accreting neutron stars than has been possible with RXTE."
"These intermittent pulsations were also very hard, underscoring the need for a timing mission with a good hard X-ray response."
LAD can search for them with an unprecedented sensitivity (0.4 % amplitude in 100s for 100mCrab source).
A different approach has recently emerged from the discovery of global seismic oscillations GSOs) in the tens of Hz to kHz range from magnetars during the rare and extremely luminous giant flares emitted by these sources.
"The lower frequency GSOs likely arise from torsional shear oscillations of the crust and their frequency, in combination with the magnetic field inferred from the magnetar spin-down, tightly constrains the EOS."
"LOFT has the capability detect and study GSOs for the first time in ‘intermediate’ flares, which are tens of times more frequent than giant ones, down to amplitudes of 0.7%, an order of magnitude lower than seen up to now."
This will open a new window in the study of neutron star structure through astero- seismology.
The equation of state of ultra-dense matter will be quantified using neutron star mass and radius measurements and measurements tailored to neutron star crust properties.
"About 40 compact objects accreting matter in binaries are now known to display variability arising in, and occurring at the (millisecond) dynamical timescale of their inner accretion flows: black holes and neutron stars, respectively, show QPOs of up to 450 and 1250 Hz."
"These QPOs require an explanation that involves the fundamental frequencies of the motion of matter in the inner, strong-field gravity-dominated disk regions."
"In the absence of sufficient guidance from observations, modelling has so far been to a large extent phenomenological, and different interpretations are still viable."
"For example, competing models variously identify observed QPOs with the relativistic radial and vertical epi- cyclic frequencies or relativistic nodal and periastron precession."
"Very high-signal-to-noise LOFT/LAD measurements of the QPOs will unambiguously discriminate between such interpretations and in the process tease out as yet untested general relativistic effects such as frame dragging, strong-field periastron precession, and the presence of an innermost stable orbit."
"Crucially, LOFT will provide access for the first time to types of information in these signals that are qualitatively new due to the capability to measure dynamical timescale phenomena within their coherence time, where so far only statistical averages of signals were accessible."
This will allow studies that directly witness QPO formation and propagation and tie in with phenomena that state-of-the-art numerical work is just beginning to address.
"LOFT will allow direct measurements of the black hole mass and spin through timing measurements, to compare with other estimates such as mass from optical studies or spin from the thermal X-ray continuum or the Fe K-line profile."
"The spectral capabilities of LOFT will allow use of the energy dependence of amplitudes and phase delays in the QPOs together with the Fe-K line profiles to measure the compact object’s mass and spin, the disk inclination and to study massive black holes in the brightest active galactic nuclei (AGNs) by measuring with unprecedented accuracy the profiles and variability of their Fe K-lines."
"Additionally, LOFT's good response to higher-energy X-rays is crucial for most of this work; the discoveries of the highest- frequency quasi-periodic oscillations from black holes – the ones which can be used to probe the mass and spins of the black holes – were made only above 13 keV, despite the much higher count rates at lower energies."
"Similarly, reliable measurements of Fe lines can only be made when both the Fe spectral edges around 8-9 keV and the continuum at energies significantly higher than these edge energies can be well measured."
"The conditions of strong-field gravity will be quantified by measuring the mass and spin of black holes (BH) and by verifying predictions of general relativity (GR), such as precession and epicyclic motion."
"To these aims study of Quasi-Periodic-Oscillations (QPOs) in the time domain, Fe line reverberation and tomography in bright Active Galactic Nucleus (AGNs) and Galactic Black Hole Candidates (BHCs) will be exploited."
"LOFT will additionally be a powerful observatory for studying the X-ray variability and spectra of a wide range of objects, from accreting pulsars and bursters, to magnetar candidates (Anomalous X-ray Pulsars and Soft Gamma Repeaters), cataclysmic variables, bright AGNs, X-ray transients and the early afterglows of Gamma Ray Bursts."
Due to its high sensitivity it will also enable the study of disk- jet interaction.
Through these studies it will be possible to address a variety of problems in the physics of these objects.
"Coordinated optical/NIR and radio campaigns on specific themes, as well as spin measurements which can aid the Advanced Virgo/LIGO searches for gravitational wave signals from fast rotating neutron stars will add great value to the LOFT program."
The minimum scientific success criteria for the mission are reached if the two core science objectives (TOP1 and TOP2) are achieved.
It has been indicated in the description of these top level science objectives that supplementary observation strategies are followed to achieve this.
The EoS and the QCD phase diagram is constrained by measuring neutron star masses with 4% accuracy and radii with an accuracy of 3% for 3 NSs.
Strong-field general relativistic effects close to BHs and NSs are detected and BH masses and spins measured through time variability and spectroscopic measurements pf 3 BHs and 6 NSs.
"For each of the level 0 objectives we have identified above a number of complementary methods to achieve these, these are specified quantitatively as our level 1 requirements."
"Constrain the equation of state of supranuclear-density matter by the measurement, using three complementary types of pulsations, of mass and radius of at least 4 neutron stars with an instrumental accuracy of 4% in mass and 3% in radius1."
Probe the interior structure of isolated neutron stars by observing seismic oscillations in Soft Gamma-ray Repeater intermediate flares when they occur with flux ~1000 Crab through high energy photons (> 20 keV).
Detect strong-field GR effects by measuring epicyclic motions in high frequency QPOs from at least 3 black hole X-ray binaries and perform comparative studies in neutron stars.
Detect disk precession due to relativistic frame dragging with the Fe line variations in low frequency QPOs for 10 neutron stars and 5 black holes.
"Detect kHz QPOs at their coherence time, measure the waveforms and quantify the distortions due to strong-field GR for 10 neutron stars covering different inclinations and luminosities."
The scientific objectives may be achieved through the measurement of the X-ray photometric light curves and spectra of a range of different astrophysical target classes.
"The targets are all compact objects (neutron stars, stellar-mass as well as supermassive black holes) therefore the measurement requires no imaging capability."
Targets will be selected by pointing a collimating structure that discriminates the required source from the diffuse background and nearby X-ray emitting sources.
The photons from the selected target will be registered by an array of semiconductor detectors that will measure the X-ray photon energy and arrival time to high precision (~250eV FWHM and 10µs respectively).
A large effective collecting area ensures that sufficient photons can be collected to accumulate spectra and precision photometry over the variability time scales of interest for the different target classes.
"The energy resolution of the detector in combination with an energy range of 2 to 50 keV will enable the measurement of the Fe-line profile, needed for the Strong Field Gravity goals."
The data will be transmitted to ground in the form of photon event lists (time and energy of each photon).
To catch the relevant sources in outburst it is required to monitor a large fraction of the visible sky on a daily basis.
"If a change in state of a source for the core program is observed, LOFT may be pointed to this source and repeated observations are feasible till the source state is no longer of interest."
"This monitoring is enabled by a coded mask imaging technique, providing time- and energy sliced images of the available field of view, as well as spectra and light curves of bursts and transients."
For the core science objectives processing of these data on the basis of a few days is sufficient to adjust the observation schedule if a source state changes.
"As indicated in the section about science objectives, it is required that LOFT will allow ‘observatory type’ of science during the periods which are not required for the core science objectives."
This will be a significant fraction of the observing time (>25%) and will be allocated on the basis of peer reviewed proposals.
In this section we include a few of the most interesting topics.
"The LOFT LAD and WFM will be very important for the study of thermo-nuclear explosions on the surface of neutron stars, so called Type I X-ray bursts."
"Current instruments have revealed residuals in the spectra of a sub-set of these bursts (extreme radius-expansion bursts) suggesting the presence of absorption edges, perhaps arising from nuclear burning ashes mixed into the radiation-driven ejecta powered by the burst flux."
"Such features have been predicted theoretically, and can provide information on the neutron star compactness."
"However, as the occurrence of such extreme Type I bursts is unpredictable and as they occur infrequently, high-quality spectra have proved difficult to obtain."
The LOFT WFM should allow for the detection of these bursts with sufficient spectral resolution to investigate if the neutron star compactness can be constrained.
The LOFT mission will be capable to advance the field of Gamma Ray Bursts (GRBs) significantly.
"The LOFT WFM energy band, sensitivity, field of view, source location accuracy and energy resolution are well suited for the investigation of some of the open issues in the study of GRBs."
"Some of the issues include: the models for the physics of prompt emission, the existence and properties of spectral absorption features by circum-burst material (and hence the nature of the progenitors), the detection and rate of high-z GRBs (which is important for the investigation of the early universe)."
Another area where in particular the WFM will contribute is that of X-ray flashes.
WFM studies of the population and properties of X-ray flashes found to accompany supernova shock break-out and the disruption of stars and planetary objects by supermassive black holes should provide important results.
"A last example in this (incomplete) report on the LOFT Observatory Science involves the study of the magnetic accretion in, for instance, high-mass X-ray binaries."
The LOFT/LAD is ideally suited to study the X-ray time variability on timescales of a fraction of the neutron star spin period.
The variability is also reflected in the observed spectral properties such as the centroid energy of the cyclotron lines.
The prime instrument of the mission is the large Area Detector (LAD).
This is a non-focusing but collimated X-ray detector with a very large collecting area.
"This allows for very-high count rates and combined with its spectral resolution, allows researchers also to carry out spectral analysis of bright objects."
A large area detector with a collimated field of view (~1 degree).
Good spectral resolution using Silicon Drift Detectors (~ 240eV).
"It should be d that not all events can be reconstructed with the same resolution, depending on the number of anodes to reconstruct the energy."
A high level of modularity (the different detector segments operate independently) increasing the level of redundancy.
"The loss of a whole panel and subsequent reduction in effective area may compromise some capability (e.g. EOS2), however many science goals could be completed albeit with longer observation times."
The instrument requirements are summarized in Table 5-1 and more details are given for each requirement later.
Part of the justification of the requirements is given in the subsequent paragraphs but especially the flow down is discussed in Appendix A where also the relations between the different requirements are explained.
"The effective area requirement is given at 4 energies (maximum of the distribution, a high energy cut-off and at two lower energies)."
The effective area is directly related to the stopping power in the detector and the transmission of the thermal blanket and any inactive layer on top of the detector.
Especially at the low cut-off the effective area is a steep function of energy and the given energy should be interpreted as energy ± 0.5 keV.
"The projected collecting area for photons (a function of photon energy) determined as the product of geometric area and detectors’ quantum efficiency, transmission factors of collimators, and associated thermal/optical shields."
Justification Effective area provides the translation from a source flux to detected count rate.
"This requirement is the minimum detector effective area, near the peak of source photon and variability distribution in energy, that is required to ensure the most driving science case can be fulfilled (determine masses and radii of neutron stars , investigate gravity in the strong field regime)."
This area is required to reduce the statistical errors on the mass and radius to < 4% and < 3% respectively.
"The soft part of the spectrum is important for strong red wings in very broad Fe lines, see also SCI-LAD-R-03 [GOALS SFG2, SFG4, SFG5]."
A factor ~40% of the peak area is necessary to guarantee adequate modelling of the source spectral shape Justification See requirement but the goal is 10% more ambitious.
"Justification: To ensure that the LAD effective area does not change by more than ~20% over the energy interval (5-8 keV) in which the broad Fe-K lines are detected and studied.GOALS: SFG2, SFG4 and SFG5."
Justification See requirement but the goal is 10% more ambitious.
Justification To detect QPOs during intermediate flares of SGR/AXP; to detect the continuum emission of bright AGN (>1 mCrab) with a S/N of 200 to measure the Compton Justification See requirement but the goal is 10% more ambitious.
To allow for unambiguous interpretation the lowest number (9.5m2) in this range has been specified as requirement.
"However, this requirement is inter-related to several other requirements including the spectral resolution, the field of regard and the redundancy requirement."
"Deviations in the effective area can, for a significant part of the science, be compensated by a suitable combination of sky visibility and longer mission duration (see also appendix A)."
With the tuning of these other requirements the impact of the reduced area on the science can be made small.
In addition the 25% redundancy requirement may need to be adjusted in order to maintain a 7.5 m2 effective area in case of a single point failure.
"Justification to limit the impact of systematics in studies that require knowledge of absolute flux, e.g. accurate measurements of the Eddington luminosity during Type I bursts, translating into a (minimum) uncertainty of 7-8% in the determination of the radius of neutron stars through this technique."
Justification see requirement but uncertainties will be further reduced.
The lower and upper energies measured for detected photons after reconstruction.
For primary range the nominal binning appropriate to detector energy resolution shall apply.
For extended range a binning factor in energy may be applied.
Justification: 2 keV: to be able to study photoelectric absorption and soft components of a variety of sources; 30 keV: to determine the AGN and X-ray binary continuum spectra in order to study the reflection/absorption effects and allow for an accurate determination of the Fe-K line profile.
"After applying all known calibration factors, the linearity and offset of the energy scale applying to a measured spectrum shall allow a photon energy to be determined to within a small fraction."
Justification: to combine data from different epochs the energy scale should be known with a fraction (1/4) of the energy resolution (reference point is 6 keV).
"Justification: End-of-mission spectral resolution integrated over the full detector but after channel to channel corrections (e.g. gain); Using both single and double anode events this resolution allows for gravitationally broadened Fe Kα line-width studies, removal of narrow lines and edges, line/edge studies in PRE type I X-ray bursts."
This number includes all not-correctable contributions to the spectral resolution.
"The available margin on top of the Fano limit of Si will be distributed over different components (calibration, sensor uniformity, gain knowledge etc)."
See also appendix D and Tech on defined contributions to energy resolution.
Selected events are only those that correspond to the read-out of a single anode (explaining the 40% of the selected events).
The requirements are split between all events and the events that will be collected on a single anode of the detector (40% of the events).
Justification: Not all science goals require optimal energy resolution.
See section 7 (observation plan) and appendix A for more Justification: a degraded energy resolution similar to the requirement “standard” energy resolution effectively means a larger FoR.
The FWHM of distribution in transparency of the instrument (i.e. collimator) at the peak energy for the effective area.
Justification: Limiting confusion in crowded fields.
"Thist source confusion can be mitigated using offset-pointings Justification: improved background, affecting fewer sources and reducing the need for offset pointings."
"However this is related to the response stability, it can only be considered if the response stability goals are within reach."
"The fraction of photons, at specified energy, that reach the detector plane following transmission through the collimator from a large off-axis angle (for reference purposes 45°)."
"Justification: some response is required at off-axis angles to be able to observe seismic oscillations in SGR (EOS3), the value is not critical as long as it is in this range (0.02 – 0.2 %)."
This can be achieved by either a transparent collimator at higher energies or by a fraction of the LAD area which has no collimator at all.
"The key science requirement is to avoid any spurious (e.g., induced by a variable instrument response) modulation in the measured source count rate, down to a level of the astrophysical signal of interest."
"As the latter highly depends on the type of source/signal and its characteristic frequencies, it is hard to specify the requirement with a single number."
The derivation of these requirements is explained in [RD 3].
Response stability is the broad-band (e.g. 2-30keV) effective area as a function of frequency.
In practice this is derived from a Fourier transform of the effective area as a function of time.
On timescales of light crossing time of a few gravitational radii (10’s seconds) the signature of reflection lags must robustly be determined.
Low frequency QPOs seem correlated with broad band noise phenomena.
Unstable response leads to apparent noise in constant flux sources and also to QPO broadening or sidebands.
Intrinsic to the detector is that the arrival time of an event is not known much better than 10(7) µsec as the drift time through the detector depends on the position of the event with respect to the anode.
"However, as this distribution is stable and uniform, the absolute time knowledge should be better (2 µsec)."
"The 3σ uncertainty in assigning the time datum of an event to its actual arrival time on the LAD Justification: Behaviour of matter under extreme conditions and ultra-dense matter – modelling waveforms of periodic signals, X-ray burst oscillations and QPOs."
Moreover searches for very short impulsive phenomena.
The absolute time accuracy requirement is higher than the detector time resolution.
"For pulsars, knowing the detection time with an accuracy of 2 microsecond allows comparison with other wavebands (e.g. radio)."
"Justification: Giant pulses from Crab and msec radio pulsars are very brief (some as short as 0.5 us, observed in radio at 0.125 us resolution and rising within that time (Knight et al."
The critical parameter is the dead time knowledge but with a too large dead time it will be hard to reduce the error.
"Justification: Dead time is relevant to all sources where we want to do accurate characterization of aperiodic phenomena, particularly at high frequency (1/t_dead)."
We need to be able to calibrate the dead-time process to an accuracy better than the precision afforded by the count rates.
"That is, if you can measure the Fourier transform to a certain precision given the count rate, then the uncertainty in the distortions induced by dead time to the Fourier transform should be less than that precision."
"Equivalent flux of all cosmic diffuse, external particle and internally generated events that cannot be distinguished from true X-ray events from the target in the LAD field of view Justification: Some of the science goals are related to low flux sources (1-10 mCrab) such as AGNs and some accretion powered X-ray pulsar and black hole transients."
The lower goal increases the number of (AGNs) sources accessible to the LAD.
The accuracy with which the equivalent background flux is known after ground based application Justification: Some of the science goals are related to low flux sources (1-10 mCrab) such as AGNs and some accretion powered X-ray pulsars.
The spectral analysis of these sources is sensitive to residual systematics after background subtraction.
Justification: only sources brighter than 0.5 Crab require temporal re-binning.
Bright transient sources can be stored on-board and the full information can be transferred during subsequent ground contacts.
Around 30 sources in the observation plan have intensities > 250 mCrab and around 20 sources > 500 mCrab.
These sources will in general be observed during their bright state and require then the sustained data rate.
"Justification: improved performance, typical 10 sources will be above this level."
This does not drive the design in view of the spectral slope and the stopping power of the collimator for photons < 20 keV where the bulk of the photons are for these 1000 Crab sources.
Justification: Behaviour of matter under extreme conditions – modelling lines and waveforms of X-ray burst oscillations for instance during type I X-ray bursts.
Justification: Behaviour of matter under extreme conditions.
Brightest state of Sco-X-1 and very bright transients.
"The amount of data storage to be provided in the LAD sub-system for extended downlink, commensurate with the data generated by a bright target for specified duration Justification: Being able to retrieve all data over a number of ground contacts for bright and unexpected transients, taking advantage from long observation of weak sources (e.g., AGNs)."
Justification: In case of a major failure 75% of the area will still allow to achieve the minimum success criteria.
The main goal of the WFM is to provide good triggers of active sources for the LAD.
"Desirable trigger levels for bright transients is 100 mCrab for part of the sky accessible to LAD as 90% of these transients in this part of the sky should be identified, weaker transients (about achieved by a FoV that is a compromise between the accessible sky and the dimensions of the Galactic Centre region (~60 degree)."
A detailed trade-off has been determined (see RD 12).
Sensitivity (5 σ detection) over 50 ks must be < 5 mCrab over energy range of 2 - 50 keV for a field where there is no source confusion (outside the Galactic Centre).
The total allocation for the WFM data (in normal operations) is 10% of the total telemetry band width with a maximum of 100 kbits/s.
"If the LAD data rate is <80%, the WFM should be able to use up the available bandwidth."
Energy range and telemetry bandwidth should allow at least 8 spectral bands for the detection of spectral state changes in transient sources and be sensitive to thermal (e.g. disk) spectral components.
The angular resolution and source localization accuracy are related and the source localization depends also in the signal to noise ratio.
"Justification: Reduce crowding effects, and allow for better multi-wavelength follow-up."
"For each WFM camera, the FWHM angular distribution for a point source."
Justification: For sources of the specified brightness the driving requirement is the localization accuracy.
The localization depends on the angular resolution and the signal to noise ratio.
"The equivalent flux that can be detected in the centre of the WFM field, for a point source and for a given observation time."
"Justification: 1s: Fast events of all kinds: SGRs, AXPs bursts/flares, X-ray flashes and bursts."
Source detection sensitivity scales with the signal to noise ratio.
"Justification: Improved performance, especially opening up new parameter space (e.g. very fast transient events)."
"Following the application of calibration data, the accuracy with which the equivalent flux of a high S:N detected source can be specified."
The reference shall be targets recommended by International Astronomical Consortium for High Energy Calibration.
Justification: Cross calibrations with observations performed with other X-ray instruments.
"After applying all calibration knowledge, the relative change in flux sensitivity with off-axis angle must be known to a small fraction and within radii corresponding with an area at least 20% of peak on-axis area."
Justification Relative calibration of the flux determination precision of the WFM at varying off- axis angles down to 20% of the peak effective area.
This provides an upper limit on the systematic errors in source light curves as they are derived from different pointings placing the sources in different cameras and at different off-axis angles.
Justification further lowering the systematics in source light curves.
"After applying all ground based calibration knowledge, the accuracy of determining the flux of any given target, and the also minimum flux sensitivity, from one pointing period to another."
Justification Relative knowledge of variations in the sensitivity of the WFM over the mission duration.
Needed to cross check with other observations made of similar sky locations at different observing times and to maintain absolute flux calibration.
"Compared with R-18, this prioritises the relative change in sensitivity with time."
Justification Further reducing the systematic errors in long term variations of sources.
A selectable duration over which counts are integrated to detect a count rate increase for triggering burst mode.
The time scales are typical for the transient events to be studied in detail with the full resolution data to rise significantly above the background level.
"Full resolution data for validated triggers will be stored for nominally 300 s around the burst trigger time, including a pre-burst interval."
Transients with longer time scales can be studied with the normal image data with 300 s integration time.
"Justification: Triggering sensitivity to very short events (e.g., TGFs: Terrestrial Gamma- ray Flashes)."
The coverage of the celestial sphere provided by the ensemble of WFM units.
"Justification: Need to match as closely as possible the sky that is accessible to the LAD at any one time, but limited to 180 degrees centred around the LAD pointing."
"Allow study of the long term variability of AGNs, type I X-ray burst history, provide triggers for e.g. state changes and the occurrence of super-bursts."
"For a typical pointing, 50% of the accessible part of the sky of the LAD should match with 20% of the WFM peak effective area."
Justification: Part of the LAD accessible sky would otherwise not be monitored.
The lower and upper energies measured for detected photons in spectral accumulation mode.
For primary range the nominal binning of 100eV shall apply.
For extended range a further binning factor in energy may be applied.
"Justification: Soft response, below 5 keV important for high redshift GRBs, study of type I X- ray bursts, supernova-shock break out: Science products in the primary energy range: Extended dynamic range up to 80 keV intended for monitoring of very bright sources (>1 Crab) as part of LAD background monitoring strategy."
Justification: Allows better signal to noise ratio for the same geometrical detector area.
FWHM of a Gaussian distribution response to a monoenergetic stimulus of the detector Justification: Allows scientific products from WFM such as spectra for bight sources but it is not driving the design as the number of sources with sufficient countrates and spectral features is Justification: Improved energy resolution could eventually help.
The energy resolution (and hence the scale) is not a main driver for the WFM.
This allows scientific products from WFM such as edges from type I bursts.
Justification: Even though not a main driver several Observatory Science cases would benefit.
Justification: Allows the downlink of limited data in a number of energy bands that match interesting regions in the energy spectrum.
Justification: Typical integration time for images is 300 s (yet programmable).
The time scale corresponds to the resolution needed to monitor the intensity of non-bursting sources.
"The time resolution of triggered data will, however, be more accurate (10 µs) in the event by event mode."
This number matches the time information of the LAD.
Justification: Higher performance for brighter sources.
The accuracy with which the WFM time datum can be assiged to UTC after ground calibration.
The cadence of total count rate data per camera in 8 TBD energy bands.
Justification: Provide the ability to study time coherent or non-coherent time variability on shorter time scales than the normal 300 s integration for imaging data and in cases where imaging is not required to identify the source.
The primary use will be the monitoring of X- ray pulsars (coherent sources) over longer time scales.
Justification: WFM will be used to identify transient events and state changes in X-ray sources.
The presence of transients or state changes could result in follow up (ToO) with the LAD (prime mission science) or with measurements by other (ground based/space based) instruments.
The transients may be detected both in triggered data and in normal data if the transient rise time is >100s or a spectral state change has occurred.
"Justification: Factor 2 faster, it is not expected that this will drive the design and is acceptable if this is not reached for 100% of the cases."
Justification Onboard memory will store up to 3 hours of data (although depending on the event rate some binning is foreseen for bright events/episodes/areas).
"After a trigger into burst mode, the WFM will attempt to localise the source on the sky and determine the time of trigger."
These data will be broadcast in a Burst Alert message.
"Justification: If broadcasted, a set of ground receivers can see the trigger times and positions for follow up measurements."
A 30 sec latency is a reasonable number based on the chain of data transmission to the end-user.
Justification: Enhanced performance of the full system handling burst alerts.
"Justification Estimates suggest there should be at least 150 GRB per year detected by WFM, therefore statistically several per day should be accommodated."
"Justification: Other triggers such as Type 1 X-ray bursts, as well as potential false triggers imply the need for relatively frequent downloading of burst triggers."
The design and geometric arrangement of the WFM shall be such that in the case of a single point failure still the full FoV should be covered although it is accepted that the effective area as well as the angular resolution for a certain part of the sky is reduced.
Justification: storage of all event data for very bright transients in a continuous fashion without gaps (or less bright transients over longer periods).
This allows for transmission of these data to the ground after the transient event happened without loss of information.
Justification: the same but with increased capability.
In this section science requirements for the system are given.
This is clearly related to the instrument requirements but also to the strawman observing plan (see section 7).
The WFM is less than 10% of the total bandwidth unless a Guest Observer requests this to be higher.
The amount of observing time required to execute the nominal core science topics.
The goal is to have the mission extended by one year 50% of that time is reserved for core-science and 50% for observatory science.
The core science time is related to the top-level goals (see section 4.1) and the observatory science is related to the third top level goal.
Amount of observing time that can be devoted to non-core science topics Justification: In addition to the core science about 50% of the net observing time is proposed for observatory science.
All time will be allocated through a peer review process Justification: In case of an extended mission life time (to 5 year) it is expected to increase the guest observing time as well.
The calibration time is specified as a fraction of the total net observing time.
"Sufficient time should be allocated for periodic calibrations, both internal (electrical) and external (astrophysics sources)."
This number is based on past experience and not on a detailed calibration plan.
Justification: Maintain the same quality but over the mission lifetime its performance can be predicted and less calibration time is required.
"There is no theoretical limit on the shortest observation time and hence, during night time there will be additional observing time if the satellite slews to a given position."
Considering the slew rate we do not expect this will be very efficient.
"Nevertheless, from a science perspective some sources only accessible from the night side will be very interesting and this is estimated to be one strong source (1 Crab) and 10 weak sources (150 mCrab) per year."
Considering typical decay times it would be required to observe these sources over as many orbit that the source is visible (up to two weeks).
Justification: Increases observing efficiency for sources outside FoR.
"The energy resolution should be < 260 eV for SFG2, SFG4 and SFG5."
Justification: Combined with the mission duration (4 years) this gives a 98% probability to detect two BHCT and 98% to detect two AMXPs.
For various science goals (see section 7) the energy resolution is not critical.
Justification: This increases the probability to detect 2 BHCT and AMXPs to 99% for a 4 year mission and would still be 98% for a 3 year mission.
"Furthermore, it allows Observatory science to be done in the Galactic Centre area on the sky."
Otherwise (50% sky visibility) the observation time when the bulge is visible to LOFT is used for a significant fraction by observing the core-science targets.
The fraction of yearly coverage of the Galactic Centre location that is within the LAD Extended Field of Regard.
Justification: 35% corresponds to the Extended Field of Regard requirement of 50% of the sky [SCI-SYS-R-05] and allows for sufficiently long net observing time of the Galactic Centre to meet the top level goals.
Justification: This number corresponds to the Extended Field of Regard goal of 75% of the sky [SCI-SYS-G-05] and will optimize the science return as it enables longer viewing of the Galactic Centre which is important for the observatory science.
"Justification: With a 4 year mission all requirements in terms of observing time, probability to catch rare events and energy resolution are achieved with margin."
Details are given in appendix A. Justification: A longer mission duration allows for a larger science return.
The accuracy of pointing the LAD boresight towards a catalogued target.
"This shall be a 3σ radius value, and applies once the LAD boresight to star tracker offset is calibrated in orbit."
Justification: This is well within the field of view of the LAD.
It also corresponds to the accuracy with which the WFM can determine a source position.
This requirement is coupled to the stability requirement of the LAD pointing.
However this is TBD and not driving Justification: Reduces gradient of response vs. pointing in LAD to provide more margin in response stability.
The instantaneous reported star tracker reference axis location .
Justification: Any pointing jitter can be corrected on the ground if we have good knowledge about the pointing.
"This provides additional margin, especially in the case of finite frequencies that exceed the SCI-LAD-G-26 specification."
"The AMA should be small compared to the FoV, but the actual number (20 arcsec) is an engineering estimate and not strictly deduced from the science requirements."
Any distortions in the relative alignment in the LAD is included in the pointing error and not in this AMA.
Justification: As many star trackers provide few arcseconds pointing knowledge it would be nice to have this but it is not really required.
"Requirements on orbit are derived from a requirement on instrument background rates, stability and radiation damage due to charged particles."
At this level we only give a top level requirement and more details are given in the MRD.
Justification: Only a LEO orbit provides a low enough background.
In combination with a low inclination the radiation damage to the detectors will be low enough to have them passively cooled and still reach the end-of-life temperature requirements.
Justification: A lower inclination will reduce the effects of the SAA.
"Justification: This allows for slewing of the satellite during monitoring campaigns and is directly related to SCI-SYS-R-04, this is NOT equal to the average number of slews per orbit which depend on the observation plan (see RD4)."
Justification: This increases the number of potential observations of otherwise inaccessible targets (at a given time) by a factor 2.
Although not the prime science it is clear that fast response times will enable additional science.
The provided requirements are supposed not to drive the design but are nevertheless ambitious in the sense that the ToO response time should be optimized within the planned ground system.
Justification: LOFT is not a mission dedicated to fast transients (like SWIFT).
"However, it is important to be able to respond to state changes in sources at a reasonable rate (called ToOs)."
Therefore the ToO response time should not drive the design of the ground system.
"Clearly, this requirement should not inhibit faster response times in case a ToO is identified at the beginning of a working day."
"Although many targets will be triggered by a change in state, the number of ToOs is limited as subsequent observations of a target which changed state, will be pre-planned at the time of the first observation and do not need re-planning of the observation schedule."
"Following the change of a source state, the relevant sources will be on between something like a week to very long periods (campaigns up to one year after the transient trigger may be expected)."
This makes a response of < 12 hours for the core science not mandatory.
Clearly a faster response will improve the science in general (see the goal).
"A Quick Look data analysis subsystem should be provided at SOC (and SDC) in order to determine the properties of triggering sources and LAD target object in order to provide an alert for observation plan changes, and verify LOFT Burst Alert messages."
"The analysis using a QLA system should be powerful enough to be able to identify source spectral and brightness changes that allow an alert for new ToOs to be generated, or identify failure to meet observing proposal criteria."
The planning cycle to update the observing plan shall be <7days and therefore QLA should be able to generate the required data for Duty Scientist decision on a much shorter timescale.
The re-planning timescales should be faster to avoid loss of useful observing time.
"The science data rate generated by the instruments, after nominal binning and lossless compression ratios, when observing a source at the typical LAD brightness for event mode data."
"Justification: For a 150 mCrab source, observed with an efficiency of 60% the data rates must support the full LAD event mode data."
Simultaneously data for nominal event modes for the WFM should be transmitted (100 kbps).
Justification: Increase in the data rate for the WFM to exploit fully the available transmission rate.
"The science data rate generated by the instruments, after nominal binning and lossless compression ratios, when observing a source at the maximum LAD brightness for event mode data."
"Justification: For a 500 mCrab source, observed with an efficiency of 60% the data rates must support all LAD event mode data."
Simultaneously all data for nominal event modes for the WFM plus the transmission of data stored on board for previous measurements.
Justification: Increase of the LAD source to >1 Crab without loss of information.
"Justification: This is linked to the previous science requirement SCI-SYS-R16 (500 mCrab) , and SCI-LAD-R19 and the minimal telemetry of the WFM, under the assumption of no loss of LAD information within the above limits."
Justification: Enables the higher sustained rate required by the goal SCI-SYS-R-16 in the previous requirement.
In Table 7-1 the total observing time per core science requirement is given split over the different source categories.
Also the number of required sources per category is given as well as the number of observed sources.
"This number of observed sources is larger than the number of required sources as it is not always known a priori if a source is in a given state, We also specify whether the spectral resolution is important for the science goal (Fe-line characterization)."
"For the Neutron Stars, both transient outburst NS and the transient weak NS will be observed."
From these we expect that 3 will have the properties of an AMXP which are then observed for a longer period.
"Most classes of sources serve to address >1 science goal as is already indicated in Table produced based on this table, and for the purposes of deriving the impact of the observing plan on the system, has been made applicable to the mission in the MRD."
It should be recognized that a ToO for LOFT is of a different nature than ‘usual’ observatory ToOs.
"When the source state changes, a change in the observing program can be triggered but then, for this source, a campaign of weeks to longer periods is started."
"Only when, during this campaign, the source fades away, the campaign can be stopped to save observing time."
"So, effectively we expect about 60 ToOs over the mission life time."
Despite this difference with the more usual use of ToOs (changes in the observation plan by external triggers) we have kept the name as it would result in a re-planning of the observation schedule.
Note that observation of the same source can be used for different science goals.
The NS transient outburst NS and the transient weak NS will be observed.
Average time per pointing is total time/total pointings.
"If the total number of pointings is a concern, pointings of less than 10 ks can be added up to make pointings of at least 10 ksec in length."
For some ~10 of AGN2 sources additional offset background fields are needed (~700ks total).
There should be several “standard” background fields that must be quasi-periodically revisited to monitor the evolution of background.
Observing times and schedules in the overwhelming majority of cases are set by intrinsic source state variations rather than by S/N considerations.
"Sources have different spectral/timing states, and we need to sample each state over a range of luminosities in order to understand the processes we are detecting with LOFT, or in order to catch a source in the right state to see the process in the first place."
"Transients are named that will likely not be on, these serve as placeholders for similar transients that will be discovered by LOFT WFM and perhaps other means."
"The total observing time required for the top level science requirement is 24.7 Ms, which corresponds with a realistic but conservative observing efficiency of 50% to 1.6 years elapsed time of which ToO targets are to cover several flux levels in each source)."
"However, it should be recognized that we need a longer mission duration to ensure a good probability to observe the rare transient events needed for some of the science goals."
"There are no SGRs in the table as we only have the serendipitous offset observations as a top level goal – we DO plan to have TOO triggers in place for when an SGR becomes active, to point at them to see if intermediate flares happen – this is not guaranteed to succeed, hence not a top level goal."
A preliminary breakdown (based on reasonable assumptions on the targets for Observatory science) of observing time spent at different viewing directions is given in [RD 4].
"A final consideration for the observation plan is the mission life time to have a good probability to catch rare events: BHCT in the intermediate state with HF QPOs, and AMXPs."
We have selected realistic assumptions in the sense that we do not take into account that the number can be larger due to the huge improvement in the sensitivity of LOFT compared to RXTE.
"Still we assume that some of the known, persistent, sources will be active in the LOFT era."
This includes GRS1915+105 (BH transient outburst) and NGC 6440X-2 (AMXP).
This probability has to be folded with the field of regard of the mission (as it is of no use if LOFT cannot observe the source when it becomes active due to viewing constraints.
Based on these expectations it is concluded that the minimum life time of the mission should be 4 years for a sky visibility of +30/-50 degree and 3 years for +30/-70 degree.
Under these conditions the expectation for 3 BH transient outbursts and AMXPs is around 95% and the probability of detecting two in each group is larger than 99%.
"Also, with a conservative estimate of 50% observing efficiency the full program can be performed."
There is only a limited effect on attaining the core objectives.
"It will, of course, affect the overall science return of the mission as it reduces the discovery space."
"Hence the nominal Field of Regard with nominal spectral resolution is driven by those core science objectives which need good spectral resolution (SFG2, SFG4, SFG5) and for the other science goals the extended field of regard can be used."
"If good spectral resolution is available also for the observations aimed at the other core science objectives, it will enable a desirable a larger field of regard or extended field of regard allow for a shorter mission duration provided we can execute the observations for the core science (e.g. sky visibility of the Galactic Centre is sufficient)."
"Although the number of combinations is large, two issues are driving part of the instrument and mission design: the effective area and the sky visibility with good or degraded energy resolution."
We can demonstrate that the current instrument and mission requirements have a safe margin for these parameters.
In Table A-1 we provide an overview of the science impact of a reduced effective area.
"For this we provide first the basic effects of a reduced area, followed by the potential mitigation."
"As is indicated some of the L1 core requirements can be fully compensated but in other cases some loss of science (less sensitivity, fewer sources) can also be the consequence."
"In the last columns of this table we quantify the effect of a reduction to 70%, sources."
In summary this analysis shows that the core science goals are not at stake if the effective area reduces by the order of 10%.
"However, some of the science goals will be less ambitious (e.g. a slight reduction in the number of AGNs on which LOFT can perform highly significant Fe line tomography) whereas others can be still achieved but require (significantly) longer observation times (and hence mission duration)."
When larger reductions in the effective area are needed it is strongly recommended to optimize some of these other design parameters.
The Nominal Field of Regard is the part of the sky which can be observed with the nominal energy resolution and the extended field of regard has been introduced to allow for observations of sources where the energy resolution is not required.
The required field of regard is 35% of the sky (corresponding to the FoV in the M3 proposal) and the extended field of regard is 50%.
In practice this implies that for the extended field of regard the thermal requirements on the LAD instrument will be less stringent.
"A second factor which needs to be folded in is that a fraction of the relevant sources for LOFT is in the Galactic Centre, which implies that we need to consider the fraction of observing time for the Galactic Centre separately from the total observing time."
In Table A-2 we summarize the required observing times for the core program (top half) and the available observing time on the Galactic Centre for different assumptions.
"As can be seen there is a considerable margin between the needed observing time with good spectral resolution and the available observing time (needed 8.1, available 17.8 for a 4 year mission)."
Also with a shorter mission the margin is significant.
The last factor to be considered is the observing time available for the BHCT and AMXPs.
In total we require for these very bright sources 3.4 Ms which is not predictable in time (and may happen at a part of the year when the Galactic Centre is poorly visible).
Of these sources the BHCT require a campaign length of 100 – AMXPs require observing campaigns of typical 20 days (total required time is 300 ks per AMXP).
This potential risk is mitigated by the allowance of regular out of field of regard observations (due to the few hour thermal intertia of the system).
"As can be seen from Table A-2 the visibility with a very small solar constraint (± 10o) gives still a total of 8.7 Ms for a 4 year mission, well in excess over the needed observing time."
"LOFT will provide a unique combination of effective area, energy bandwidth and spectral resolution."
"The area, also in connection with the field of regard, has been discussed above and here we will discuss the justification and trade-offs for the energy resolution and bandwidth."
The energy resolution and bandwidth are driven primarily by the Strong Field Gravity science goals.
It is very important to have the broadband energy coverage to model the reflection properties measuring both Fe line profile and Compton reflection continuum above 10 keV.
"The good leverage on the continuum in a broad energy band will allow us to disentangle all spectral components and, in turn, to correctly model the residuals of the Fe line."
The power of the broad energy range in determining model parameters has been recently demonstrated by XMM and NuStar analysis of NGC1365 (Risaliti et al.
"In this respect the high energy response of LOFT is unique, covering simultaneously the 2-30 keV band with a great improvement in effective area in both low and high energy ranges, a factor >60 higher with respect to XMM in the Fe K domain and a factor of ~30 with respect to NuStar or Astro-H at 30 keV."
"The 2 keV low end of the bandwidth has been set to enable the study of photo electric absorption and soft components, the 30 keV allows one to determine the AGN and X-ray binary continuum spectra in order to study reflection or absorption effects and allow for the accurate determination of the continuum underneath the Fe-K line profile."
With an upper range of 80 keV (no specific resolution is required) fast high-energy phenomena such as SGR/AXP flares can be studied.
In practice these bandwidth limits are not absolute limits but the science will degrade gradually (an effect of about 10% in the energy thresholds has a small effect on the science but it depends somewhat on details of the science case).
"It should be d that the energy range is unique for the WFM and will, for the first time enable the monitoring of the sky below 5 keV with CCD-class spectral resolution."
The energy resolution of the LAD is driven by three of the five goals (level 1) of the Strong Field Gravity science and these have been used to define the energy resolution requirement.
"However, whereas these science goals drive the energy resolution, the combination of spectral resolution with timing resolution (large effective area) will open up a new discovery space and the results of this new discovery space cannot be predicted at this time."
"Hence, we have aimed at a design with an ambitious but feasible , but ambitious energy resolution."
"As we will show, with CCD-class spectral resolution and passively cooled detectors we can achieve these three science goals."
"They will have different resolution but for simplicity we will analyze the data for the full detector and refer to this as ~ 240 eV resolution (“nominal” energy resolution) and study the science impact in the event of a degradation, taking 270 eV and 300 eV as case study (it is useful to here that this is not the degradation in energy resolution associated with the extended field of regard, which is 400 eV)."
The two main components to the resolution are the intrinsic limiting resolution of Silicon detectors (called Fano noise) and the electronic noise (read-out pre-amplifier and detector leakage current).
"A number of other components - including uncertainties in the knowledge of DC noise, gain and offset (see LOFT-IAPS-PLC-MD-0001 for details) - contribute to the resolution but they are of less importance."
A degraded spectral resolution will increase the uncertainty on the determination of the centroid (typically by the inverse of the degraded resolution) for a given model.
"The extra uncertainty here is statistical (depending also on photons per phase or time-delay bin), rather than systematic (i.e. not being able to distinguish distinct variable spectral components, which are all broad in this case and variable in much longer time scale with respect to the orbital period of the disc)."
"Thus the increase of the uncertainty can be mitigated by longer observations, with the exposure time scaling roughly with the square of the relative degradation in energy."
This has been verified by detailed simulations for an orbiting hot spot and for the reverberation mapping.
The fact that the Fe-line is relatively broad and we also fit the broad reflection component confirms this also qualitatively.
This argument is only correct if the hot spot lasts long enough to compensate a loss in spectral resolution by longer observations.
"However, in case of a hot spot the prime science comes from the variability of the spectra."
In this case the complexity and correctness of the model for the emission without hot spot is therefore of less importance.
Essentially the same correction can be applied as for the reverberation mapping and tomography case.
"The driving requirement is to be able to disentangle all different emission line contributions in the Fe K band (3-8 keV), namely: narrow neutral and ionized lines (Fe Kα, Fe Kβ, Ni Kα) plus broad Fe K line with the goal of determining accurately the broad line parameters to recover the BH's spin."
"We worked with AGN, since they will represent the weak, i.e. worst, case scenario."
The requirement 240 eV (the expected resolution of single anode events with 200 eV resolution for 40% and shown in the left panel of Fig.
"A-2 where the 68, 90 and 99% (black, red and green respectively) confidence levels of the disc inclination vs BH’s spin are given We also mention that all narrow emission line components in the X-ray spectra of AGNs are produced in reprocessing media distant from ~0.1pc to a few pc from the central BH (BLR and molecular torus) and then likely constant over years timescales."
"Since we are targeting here bright AGNs, Chandra and XMM already observed all of them allowing characterization of the narrow emission lines."
It is also worth noting that Astro-H will observe the AGN LAD sample long enough to characterize with its unprecedented eV precision all narrow components in the Fe K energy range.
With the nominal energy response of 240 eV we are able to disentangle all the different line components in the Fe region and get good measurements of the blurred reflection components (continuum and lines).
"As an example, starting with BH spin a=0.7, we were able to recover the BH spin at the ~20% level of accuracy, despite the presence of narrow Fe Kα, Fe Kβ, Ni Kα and ionized lines due to a ""hot gas"" emitter with ionization parameter log(xi)~3.5 (see left panel in Fig."
"Assuming instead 300 eV FWHM energy resolution for the total of events, we detect some ambiguity in disentangling the different line contributions."
"In particular, the ionized lines (Fe XXV/XXVI with equivalent width ~ 40 eV) are blurred together and with the broad line blue wing that prevents the determination of the disc inclination and emissivity with the requested accuracy."
This also prevents an accurate spin determination and the error rises to > 50 % (see right panel in Fig.
We also check the effect of an intermediately degraded energy resolution (270 eV FWHM).
"In this case the scientific objective is still reached, although with a larger uncertainties on the spin determination (typical 99% confidence level at ~40%, see middle panel in Fig."
"BH’s spin for different value of the LAD energy resolution: the requirement value (240 eV), degraded (270 eV) and worst case (300 eV)."
"A-1 including warm absorption, cold reflection and narrow ionized Fe line."
We performed a sensitivity analysis of the risks associated with a potential non-compliance of the LAD energy resolution parameter with the requirement.
"It has been illustrated that even in the event of an energy resolution not meeting the requirement, consequences for the science objectives can be mitigated by longer observations, with the exception of the Fe-line profile fitting where a 10% spectral resolution degradation is still within the science requirements but a 20% degradation will not meet the requirements."
"Of course, this conclusion depends on the assumption that we have a correct understanding and description of the spectra of these sources (and with a better energy resolution this will be verified more easily)."
In this appendix we give the logic of the requirements flow down.
We have taken a number of reasonable assumptions for the balance between the various requirements (which need to be confirmed by the mission design).
Below we first present the flow down of the requirements (level 1 to level 2a> This is given in Table B-1 for the LAD and in Table B-2 for the WFM.
The flow-down from level 2a to level 2b is given in Table B-4 and finally we list the additional requirements (level 2c) that should not drive the mission design but are nevertheless important to optimize the science output of the mission.
The flow down from level 0 to level 1 is omitted for brevity.
In addition a number of level 2a requirements follow from the top level goals and the observing plan.
A large fraction of the events will take place in the Galactic See observation plan.
The actual value is set at 400 eV but could be also somewhat larger (100 eV) before affecting the science significantly.
LAD-18 With the proper knowledge on the background (including variations over an orbit) a larger background is acceptable.
WFM-08 Allows to combine data from different epochs.
Compared to the version 1.6 of the SciRD various requirements have been refined (in substance they were not changed but their definition has been sharpened to avoid misunderstandings).
At the same time a few requirements have been dropped as they were obsolete or better captured in a more general formulation.
The relevant requirements are given below for traceability.
Concept of flat top was dropped and replaced by pointing stability Replaced by a more top level orbit with low background and low radiation Dropped in favor of the more generic requirement.
"Likewise there were requirements on redundancy that were defined, but which are not classified as science requirements."
Accordingly it was decided that the data rate and other technical issues should be captured in this appendix in order to trace the scientific arguments behind design issues that should instead be reflected in the Experiment Interface Document Annex A.
"EChO (Exoplanet Characterisation Observatory) is an M-class mission candidate for the M3 slot within the Cosmic Vision programme, for a planned launch between 2022 and Advisory Committee (SSAC) to enter an assessment study (Phase 0), starting by an ESA internal study followed by parallel industrial study activities."
"Within the M3 boundary conditions, the readiness for launch by 2022/2024 is a severe requirement which in practice requires designing the space segment without major technology developments and with minimum developments risks."
"Therefore, only technologies with estimated Technology Readiness Levels (TRL) of at least 5 by the end of the Phase A/B1 (estimated at the end of 2015) may be used."
"This document aims at providing a complete and comprehensive list of all high level mission requirements (including S/C and payload, launcher, ground segment and operations) necessary to achieve the science goals detailed in [AD1]."
It is hence an applicable document that all mission design activities shall comply with.
The MRD will be further reviewed matching the results of future study phases (e.g. definition phase) to finally evolve in the System Requirements Document at the start of the implementation phase.
Requirements are mandatory and must be complied with.
They shall be verified by the Contractor using a verification method approved by ESA.
"Goals are desirable in order to maximise the science return while keeping the impact on the cost and complexity to a minimum, but not mandatory."
"They are to be the subject of system trade-offs and analysis, and are to be fulfilled under restricted conditions to be defined and quantified."
"Requirements are identified by the use of the term “shall”, as opposed to “should” for goals."
"X is the requirement type: “R” for a requirement or “G” for a goal YYYY is the requirement category consisting of 2, 3 to 4 letters nnn is the requirement identifier (sequential number of 3 digits)."
"Each requirement is applicable to either the S/C prime industrial contractor, the instrument consortium or the ground segment (or a combination of these 3)."
Requirements applicable to the S/C only are flown-down into the SRD.
Requirements applicable to the S/C and the instrument are budgeted into the RJBD.
"Requirements applicable to the ground segment will be flown-down into the Ground Segment Requirements Document, the MAD and the SOAD."
Supplementary text added to explain the source or reasoning behind a requirement shall be written after the requirement in italics.
This document is supported by the documentation package described in the following sections.
The mission document tree is given in Figure 1 for information.
"In addition to those, all ESA approved standards (including relevant ECSS standards) are applicable documents as well."
EChO - the Exoplanet Characterisation Observatory – is a survey-type mission dedicated to the characterisation of exoplanetary atmospheres.
"Using the differential technique of transit spectroscopy, EChO will obtain transmission and/or emission spectra of the atmospheres of a large and diverse sample of known exoplanets covering a wide range of characteristics."
"The instantaneous spectral coverage of EChO is unique in its breadth, spanning the visible to thermal infrared through a series of contiguous spectrometer channels that provide continuous spectral coverage."
This broad range opens up the possibility to study exoplanets with physical temperatures ranging from a few hundred to over a few thousand degrees Kelvin.
"Importantly, broad instantaneous spectral coverage that includes the visible waveband provides an essential means by which to monitor and subsequently correct for the effects of activity of the host star, which could otherwise introduce significant uncertainty into the final exoplanet spectrum and its interpretation."
EChO will observe the combined light from the exoplanet and its host star.
"The transit spectroscopy method, whereby the signal from the star and planet are differentiated using knowledge of the planetary ephemerides, allows atmospheric signals from the planet at levels of at least 10-4 relative to the star to be measured."
"Photometric stability rather than angular resolution is therefore key, and in fact the most stringent requirement of EChO, driving many engineering design and operational aspects of the mission."
For the brightest targets it will be possible to obtain high quality spectra in a single visit; for fainter targets the necessary signal-to-noise will be built up through repeated visits over the mission lifetime.
EChO will allow scientists to study exoplanets both as a population and as individuals.
"The mission will target super-Earths, Neptune-like, and Jupiter-like planets, in the very hot to temperate zones (planet temperatures of 300 K - 3000 K) of F to M-type host stars."
"The spectroscopic information (at resolving powers of ≥300 below 5 um and ≥30 above) on the atmospheres of the large, select sample of exoplanets that EChO will provide will allow the compositions, temperature (profile), size and variability to be determined at a level never previously attempted."
Do any of the planets observed have habitable conditions?
The EChO space segment consists of the Payload module (PLM) and the Service Module (SVM).
The SVM holds all the hardware necessary to operate the spacecraft in-orbit and support the payload.
"The ground segment provides the means and resources necessary to manage and control the mission via telecommands, to receive and process the telemetry from the satellite, and to disseminate and archive the generated products."
"The Mission Operation Centre (MOC) is responsible for the operations of the spacecraft and instruments, for ensuring the spacecraft safety and health, for provision of flight dynamics support including determination and control of the satellite’s orbit and attitude and for provision of data (science and S/C housekeeping) to the Science Operation Centre (SOC)."
The MOC performs all communications with the satellite through the ground stations.
"The scope of the Science Operation Centre (SOC) varies from one mission to another, depending on the scientific organisation of the mission, the responsibilities for each instrument and the partnerships to be put in place."
"For EChO, it is anticipated that the core function of the SOC will be the management of the observatory, including planning and scheduling of observations, pointing re-construction, instrument performances follow-up, step-by-step science quality control of observations, pipeline data processing, user support and operation of the science archive."
Several of these activities will be done in conjunction with an Instrument Operations and Science Data Centre (IOSDC).
"The launcher refers here not only to the launch vehicle, but also to the means and facilities made available on site for the spacecraft preparation, fuelling (if any), encapsulation and launch operations."
It is considered as a component of the system until the LV – S/C separation.
"In addition, all of these sub-components of the EChO system also include EChO specific ground support equipment (e.g. equipment at the launch site facility, AIV and test facilities equipment etc.)."
The S/C is composed of a SVM and PLM which are thermally de-coupled.
"In-orbit around the Sun-Earth L2 point for optimum thermo-mechanical stability, the EChO S/C will point at known transiting exoplanets distributed over the sky, with an expected bias towards targets closer to the ecliptic poles."
"This will enable an uninterrupted observation of the transits of these targets over longer periods of times within each year, as well as reducing the noise generated by the zodiacal background."
"The baseline payload consist of an off-axis afocal telescope, accommodated horizontally on the SVM."
"The telescope feeds a single science instrument, covering the complete wave range using dichroic mirrors to split the band into several channels."
The critical requirements needed to achieve the science goals defined in section Error!
"The M3 mission is intended as a back-up candidate for the 2022 launch slot, depending on JUICE schedule."
Although in the science programme the baseline launch slot for M3 is decision on the nominal launch date will be made following JUICE mission adoption.
The baseline injection strategy shall be to place the EChO S/C in an eclipse-free (Earth and Moon) direct transfer trajectory to the Sun-Earth L2 point.
"In practice, this requirement with MR-MIS-040 means that there are daily launch windows between 14h and 15h30, apart from a ~1 month period around both equinoxes."
"The LEOP phase shall be from launch to the end of the 1st manoeuvre for launcher dispersion correction, occurring no later than 2 days after the LV – S/C separation."
The S/C shall autonomously detect separation from the LV.
"MR-MIS-100 After separation from the LV, the S/C shall autonomously activate one of its transmitting channels and its 2 receiving channels to allow the ESA ground station network to establish the first contact."
"This manoeuvre is an attitude correction manoeuvre, not the 1st orbital correction manoeuvre defined in MR-MIS-070."
The instrument performance verification and science demonstration phase shall be completed within 6 months of the LV – S/C separation.
"Although it will take about 1 month to arrive at a point 1.5 million km away from Earth, it will take about another 2 months before the amplitude and angle conditions expressed in MR-MIS-040 are verified."
The post operations phase shall start from the end of the extended science operations phase and last for 2 years (TBC).
"In the case that there is no extended science operations phase, the post operations phase shall start at the end of the nominal science operations phases."
The decommissioning phase shall ensure compliance with the Space Debris Mitigation for Agency Projects [AD10].
"The nominal mission lifetime, from LV (upper-stage) separation to the end of the nominal science operations phase, shall have a duration of 4 years."
This margin accounts for e.g. possible launch delays or late deliveries of specific units.
"Following margins defined by MR-SYS-020 (i.e. [AD3] R-DV-1), 5% are to be added to the delta-Vs above, apart for the 50 m/s for de- commissioning (no additional margin needed)."
This mode will ensure science operations can be re-initiated “quickly” (e.g. within few hours) when needed.
Other instrument units (e.g. detectors and ICU) can be kept on if justified.
The pointing stability between the instrument LoS and the science target with the FGS in the control loop shall be controlled to ensure compliance with the noise and photometric stability requirement MR-PERF-350.
The maximum angular motion of these targets is 10 arcsec/min.
A de-contamination mode shall ensure out-gassing and moisture release does not degrade the mission performance at any point during the mission.
"This mode is necessary during LEOP and transfer to L2 to prevent contamination of the telescope and focal plane detectors during the initial out-gassing and moisture release of the S/C, but can also be re-used later during the mission lifetime to clean these units from any contaminants that might have accumulated since."
Axes and references frames are detailed in section 5.1.2.
"MR-PERF-020 During phases 4 and 5, the EChO S/C shall have the ability to make a full those attitudes."
"MR-PERF-030 During phases 4 and 5, the EChO S/C shall have the ability to make a rotation of 72 degrees around YECHO and observe a target from any of those attitudes."
"MR-PERF-040 During phases 4 and 5, the EChO S/C shall have the ability to make a rotation of 2 degrees around XECHO and observe a target from any of those attitudes."
"The rotation around XECHO is not a science need, it is only a safety margin that includes the Sun diameter."
MR-PERF-061 Corruption or loss of science data during a science observation shall be deducted from the observation efficiency budget with a degradation factor of 2.
This loss can be due to e.g. reaction wheel spikes etc.
The degradation factor is needed since a loss of X seconds during an observation out of transit means the equivalent X seconds in transit needed for the differential measurement are also lost.
"MR-PERF-070 An average observation shall be defined as the observation of a single science target for 3.7 hours, separated by 90 degrees from the previous and the next science targets (TBC)."
"For example, the Airy disk is 0.34’’, assuming a cut-off wavelength of 0.8 μm and a 1.2 m diameter telescope."
Assuming that the platform can provide a coarse APE of 3’’ (3 sigma) means the FoV of the telescope and FGS shall be larger than ~7’’x7’’.
Instrument requirements are derived for a classical dispersive/diffractive spectrometer design.
"In case alternative designs are proposed (e.g. FTS), equivalent requirements shall be derived."
MR-PERF-170 No-cut wavelength: R-SCI-030 in [AD1] is applicable.
MG-PERF-180 No-cut wavelength: G-SCI-031 and 031a in [AD1] are applicable.
These requirements give the wavelengths at which no cut between channels is allowed.
The complete wavelength range can be split into as many channels as necessary as long as all science performance requirements are met.
The width of the resolution element shall be taken from MR-PERF-190.
The resolving power shall be defined by R=λ/Δλ where Δλ≥FWHM of the monochromatic system PSF.
This should enable increasing the SNR at the expense of a reduced resolving power.
Any reduction in one of these parameters shall be compensated by a proportional increase of either of the other 2 parameters.
The minimum in-channel (i.e. not in the cut-off / overlap regions) figure of merit in any resolution element (as defined in MR-PERF-190) shall be no less than 80% of the figure of merit defined in MR-PERF-240.
The minimum out-of-channel (i.e. in the overlap regions between 2 adjacent channels) figure of merit in any resolution element (as defined in MR-PERF-190) shall be no less than 50% of the figure of merit defined in MR-PERF-240.
MR-PERF-242 can be achieved by the individual channels or by summing the response from 2 overlapping channels.
MR-PERF-255 An extended FoV of ≥ 20’’ (half angle) in the spatial direction of each science channel shall enable the monitoring of the background (e.g. zodiacal and thermal background but also detector dark current) using off-source pixels (TBC).
This is only required where the background is not negligible.
"MR-PERF-260 Spectral sampling shall be commensurate with the Nyquist-Shannon criterion, i.e. at least two samples between adjacent resolution elements separated by Δλ as defined in MR-PER-190."
MR-PERF-310 Stellar variability (post-processing) shall make a negligible contribution in RSS).
Observation of stars with higher residual variability is TBD.
"MR-PERF-330 An absolute photometric calibration accuracy of 5% (TBC), post- processing, shall be achieved for all targets across the full waveband defined in MR-PERF-150."
"MR-PERF-330 and 340 can be achieved by observations of reference celestial objects, which are the same observations as those defined in MR-PERF-080."
The zodiacal background contribution shall be evaluated using a worst case FoV per spectral bin of 10’’x10’’ (TBC) and the average zodi value as defined in MR- PERF-390.
These values has been derived using the performance parameters defined equivalent relaxation to the noise requirement would be acceptable.
This noise definition is extensively detailed in [AD2].
From 60 s (2x goal temporal sampling) to 3 days (to enable orbital phase measurements).
Observation of stars with neighbouring sources that make a larger contribution is TBD.
This means no additional budget needs to be apportioned to neighbouring sources in the total noise budget.
"The zodi model on which parameterization has been evaluated is based on the Hubble model out to 2.5 micron, and the DIRBE model at wavelengths beyond."
The SI international system of units shall be used.
"Radians, degrees and arcseconds are acceptable as angular units."
All (sub)multiples by factors of 10 of any of the aforementioned units are also acceptable.
"For instance, this implies [g], [microns] and [milliarcseconds] are acceptable."
"The list of ESA approved standards, including approved ECSS standards, shall apply throughout the ECHO study, and is detailed in [AD4]."
Tailoring of specific standards is possible and shall be subject to formal approval by ESA on a case-by-case basis with a detailed rationale.
The frames defined below are illustrated in Figure 9.
"The EChO S/C reference frame shall be defined by three orthonormal axes (XECHO, YECHO, ZECHO), with an origin at the geometrical centre of the separation plane between the LV adapter and the S/C."
"The longitudinal axis +ZECHO (roll axis) shall be coincident with the LV symmetry axis, and pointing in the positive direction from the LV – S/C separation plane up to the tip of the S/C."
"MR-SYS-070 +XECHO shall be defined, in the separation plane between the LV adapter and the S/C, as pointing in the positive direction along the telescope pointing axis ZE-TEL projected in the separation plane."
"The EChO telescope pointing reference frame shall be defined by three orthonormal axes (XE-TEL, YE-TEL, ZE-TEL), with an origin in the vertex of the telescope’s primary mirror."
"The telescope’s pointing axis +ZE-TEL shall be defined from the reference frame’s origin, in the positive direction going towards the centre of the targeted FoV."
The total wet mass of the EChO S/C (including all margins specified in [AD3] and the LV and S/C adaptors) shall be smaller than the LV baseline performance of 2160 kg.
"Single-point failures with a severity of catastrophic or critical (as defined in [AD4], ECSS-Q-ST-30C) shall be eliminated or prevented by design."
MR-SYS-160 Retention in the design of single-point failures of any severity rating is subject to formal approval by ESA on a case-by-case basis with a detailed retention rationale.
"MR-SYS-190 Any hazardous situation, which will not cause immediate loss of but may develop into the loss of the S/C or instrument, shall be prevented by design or protected against."
The design shall allow the identification of on-board failures and their recovery by autonomously switching to a redundant functional path.
"Where this can be accomplished without risk to spacecraft and instrument safety, such switching shall enable the continuity of the mission timeline and performance."
This means the design of fault management systems shall intrinsically be fail-safe.
"MR-SYS-210 Where redundancy is employed, the design shall allow operation and verification of the redundant item/function, independent of nominal use."
"In case of anomalies or failures from which an autonomous recovery is not possible, the S/C shall enter a Safe Mode to ensure S/C and instrument survival."
These can be triggered by either S/C or instrument failures.
The use of mechanisms shall be avoided as far as practicable.
Proposed use of mechanisms is subject to formal approval by ESA on a case-by- case basis with a detailed rationale.
The use of units inducing mechanical vibrations during science observations shall be avoided as far as practicable.
"Proposed use of such units is subject to a formal approval by ESA on a case-by-case basis, after provision of a detailed rationale."
"If approved, the supplier of such units shall characterise the generated vibration disturbances, and provide means of reducing these disturbances when necessary to ensure compliance with MR-MECH-030 and MR-PERF-350."
"MR-AOCS-040 A Fine Guidance Sensor (FGS) shall be implemented within the PLM, using the light focussed by the telescope, to meet the pointing stability requirement defined in MR-MIS-300."
"The light shall be split between the first science instrument channel and the FGS, while ensuring the figures of merit defined in R-PERF-240 are not compromised."
Application of ESA approved standards (including ECSS) related to operations and ground segment is required in MR-SYS-030.
The S/C design shall enable operational control by the ground segment during all mission phases and modes in both nominal and contingency situations.
"The MOC shall be responsible for the spacecraft operations after launch, including mission planning, spacecraft monitoring and control, and orbit and attitude determination and control."
The definition of the roles and responsibilities of the MOC will be detailed in [AD7].
The definition of the roles and responsibilities of the SOC will be detailed in [AD8].
"In all mission phases after LEOP, the S/C shall be able to operate nominally without ground contact for at least 7 days, without any loss of science or housekeeping data."
"In all mission phases after LEOP, the S/C shall be able to survive without ground contact for at least 11 days."
"MR-OGS-190 During the science operations phase, the ground contact duration and frequency shall be 14 hours per week, spread over 4 ground contacts."
"In average conditions, this time shall be divided into 2 contacts per week that are to be scheduled with a ±5 hours flexibility in order to allow the optimisation of the scheduling of the science observations (i.e. time constrained exoplanet observations)."
"Doppler tracking can be done simultaneously with ranging or science TM, but ranging cannot be done simultaneously with science TM."
"In addition, Doppler tracking and ranging can be achieved with LGAs, but science TM requires a HGA."
"If done in this way, the only time to be taken out of the observation efficiency are the 3.5 hours of science TM (plus slew time), if done with a fixed HGA (and with LGAs that cover the full sky whatever the S/C attitude)."
TRL 5 by the end of the definition phase (Phase A/B1).
End of Phase A/B1 is expected towards the end of 2015.
MR-PROG-040 European equipment shall be preferred as far as practicable.
European equipment shall be preferred to non-European equipment with an equivalent performance.
"If European equipment does not meet the requirements, a non-European alternative can be sought."
These 24 months already include a 6 months ESA contingency.
Slight changes to section order to improve readability.
Slight change to definition of LAD solar aspect angle.
"Boresight, and changed wording in explanatory text."
Added ‘and execution of the mission’ to R-AOCS-010.
"Deleted AOCS 050, 060, 070, 080. document with ‘deleted’ next to it."
"LOFT is an M-class mission candidate for the M3 slot within the Cosmic Vision programme, for a planned launch between 2022 and 2024."
"LOFT, with 3 other science missions, was recommended by the Space Science Advisory Committee (SSAC) to enter an assessment study (Phase 0), starting by an ESA internal study followed by parallel industrial study activities."
"Within the M3 boundary conditions, the readiness for launch by end 2022/2024 is a severe requirement which in practice requires designing the space segment without major technology developments and with minimum developments risks."
"Therefore, only technologies with estimated Technology Readiness Levels (TRL) of at least 5 by the end of the Phase A (estimated at the end of 2014) may be used."
"This document aims at providing a complete and comprehensive list of all high level mission requirements (including S/C and payload, launcher, ground segment and operations) necessary to achieve the science goals detailed in [RD 1]."
Accordingly it is an applicable document that shall be complied with for all mission design activities.
The MRD will be further reviewed matching the results of future study phases (e.g. definition phase) implementation phase.
Goals are desirable in order to maximise the science return while keeping the impact on the cost and complexity to a minimum.
"They are to be the subject of system trade-offs and analysis, and are to be fulfilled under restricted conditions which are to be defined and quantified."
Supplementary text added to explain the source or reasoning behind a requirement is written after the requirement in italics.
"Where appropriate, the parent requirement from the SciRD [RD 1] is declared in supporting text to the MRD requirement to aid comprehension."
This can also include reference to annexes in the case where the MRD requirement represents the translation of a scientific requirement into an engineering requirement.
For the Large Area Detector (LAD) and Wide Field Monitor (WFM) the following definitions are made.
The region of the sky where the LAD can be pointed to continuously for at least 1 orbit (disregarding a potential temporal occultation of the target by the Earth) guaranteeing the LAD nominal energy resolution [R-PERF-100] and nominal response stability at any time during the mission.
The region of the sky where the LAD can be pointed to continuously for at least 1 orbit (disregarding a potential temporal occultation of the target by the Earth) guaranteeing the LAD degraded energy resolution [R-PERF-101] and nominal response stability at any time during the mission.
The LOFT convention when discussing the LAD Field of Regard is to work from the reference position of the SC when the boresight of the LAD is orthogonal to the Sun-line (i.e. LAD SAA=90°).
"The Field of Regard is then expressed as a ± deviation from this position, e.g. the Nominal Field of Regard of 50% of the sky is written as 90°±30°."
The angle between the direction to the Sun and the viewing direction of the LAD (i.e. normal to the plane formed by the LAD detectors).
"The 20×20 degree area of the sky centred around the equatorial coordinates Right Ascension: 17:45:40; Declination: -29:00:28, J2000 Epoch."
LAD Module Reference Boresight: This is a unit pointing vector normal to the LAD Module mounting I/F plane on the Detector Panel (i.e. nominally aligned with the LAD Module peak response) in satellite coordinates.
"For the purposes of the Assessment Phase, the calculation of the LAD Effective Detector Operating Temperature can occur at Module-level, under the assumption that the temperature of the detectors across one Module is constant."
The Mission Requirements Document is one of the documents that constitute the complete documentation set for the LOFT study; the top-level LOFT document architecture is presented in the following figure.
"LOFT is intended to answer fundamental questions about the motion of matter orbiting close to the event horizon of a black hole, and the state of matter in neutron stars, by detecting their very rapid X-ray flux and spectral variability."
"LOFT would carry two instruments: a Large Area Detector (LAD) with an effective area (around 10 m^2) far larger than current space-borne X-ray detectors, and a Wide Field Monitor (WFM) that would monitor a large portion of the sky to provide interesting targets for follow-up observations with the LAD, and also to provide a rapid burst-alert function (via the LOFT Burst Alert System – LBAS) to the broader x-ray astronomy community."
"High-time-resolution X-ray observations of compact objects provide direct access to strong-field gravity, black hole masses and spins, and the equation of state of ultra-dense matter."
What is the equation of state of matter in neutron stars?
"Due to an innovative design and the development of large monolithic silicon drift detectors, the Large Area Detector (LAD) on board LOFT will achieve an effective area of ~10 m^2 (more than an order of magnitude larger than current space-borne X-ray detectors) in the 2-30 keV range (up to 80 keV in expanded mode)."
"With this large area and a nominal spectral resolution of <260 eV over the entire band, LOFT will revolutionise the study of collapsed objects in our galaxy and of the brightest supermassive black holes in active galactic nuclei, yielding unprecedented information on strongly curved space-times and matter under extreme conditions of pressure and magnetic field strength."
"In addition to these core science goals, LOFT will provide a 50% allocation of the observing time to observatory science."
"This, combined with the burst-alert function, means that LOFT will provide an extremely valuable resource to the x-ray astronomy community."
The scientific objectives are be achieved through the measurement of the X-ray photometric light curves and spectra of a range of different astrophysical target classes.
"The targets are all compact objects (neutron stars, black holes and AGN) therefore the measurement requires no imaging capability."
Targets will be selected by a pointing a collimating structure that discriminates the required source from the background of diffuse or nearby X-ray emitting sources.
"A large effective collecting area ensures that sufficient photons can be collected to accumulate spectra and precision photometry, over the variability time scales of interest for the different target classes."
"A complementary measurement will take place to monitor a large fraction of the instantaneously visible sky for transients and outbursts that allows for Targets of Opportunity, as well as long term source monitoring."
"This measurement is enabled by a coded mask imaging technique, providing time- and energy sliced images of the available field of view, as well as spectra and light curves of busts and transients."
The LOFT space segment consists of the Payload module (PLM) and the Service Module (SVM).
"The ESA ground segment (Kourou and Malindi) provides the means and resources to manage and control the mission via telecommands, to receive and process the telemetry from the satellite, and to disseminate and archive the generated products."
"This is complemented by the payload-provided LOFT Burst Alert System (LBAS) Ground Segment, a distributed network of VHF ground stations, which provides near real-time alerts of x-ray events."
The platform-provider will provide the TM-function on-board the SC to allow the WFM to transmit the LBAS packet to ground.
"The mission operation centre (MOC) is responsible for the operations of the spacecraft and instruments, for ensuring the spacecraft safety and health, for provision of flight dynamics support including determination and control of the satellite’s orbit and attitude and for provision of auxiliary data to the Science Operation Centre (SOC)."
The MOC performs all communications with the satellite through the ground stations*.
"The Science Operation Centre (SOC) depends on the scientific organisation of the mission, and the responsibilities for each instrument and the partnerships to be put in place are still TBD."
It is considered as a component of the system until the end of the launcher mission.
The following section presents the top-level mission performance requirements from [RD 1] which drive the mission and spacecraft design.
Requirements for which an allocation between the payload and platform is yet to take place; these requirements do not have directly derived requirements in the spacecraft requirements section 5.
The LAD nominal Field of Regard (FoR) is defined in section 1.4.
"A FoR of 35% of the sky can be achieved, for example, if the LAD solar aspect angle can be varied between 90±~20°."
The LAD Nominal Field of Regard (FoR) should be at least 75% of the sky at the beginning of the Nominal Operations Phase.
The LAD Degraded Field of Regard (FoR) shall be at least 50% of the sky at the end of the Nominal Operations Phase.
The LAD Degraded Field of Regard (FoR) is defined in section 1.4.
"A FoR of 50% of the sky can be achieved, for example, if the LAD solar aspect angle can be varied between 90±30."
The LAD Degraded Field of Regard shall contain a single point located within the Galactic Centre area for at least 35% of the nominal mission duration.
The Galactic Centre area is defined in section 1.4.
The LAD Degraded Field of Regard should contain a single point located within the Galactic Centre area for at least 65% of nominal mission duration.
"G-PERF-020 During the Nominal and Extended Operations Phases, for each Solar eclipse period, it shall be possible to perform a slew manoeuvre to point the LAD to any source in the sky not occulted by the Earth, observe it for at least 10 minutes (TBC), and slew back to the previous source upon eclipse egress."
"Once per orbit during the Nominal and Extended Operations Phase it shall be possible to observe a target located outside of the Degraded Field of Regard in the anti-sun direction for 10 minutes (TBC), at the degraded energy resolution of 295eV."
LAD Detector Effective Temperature requirements to fulfil the degraded energy resolution requirement are provided in [R-THRM-031].
Other attitude transients which suspend science performance.
Observations with the LAD shall be considered as suspended during the period of the orbit when the background integral flux of protons with energy greater than 50keV is greater than 0.5/cm2/s (TBC).
R-PERF-050 During normal working hours LOFT shall be able to observe with the LAD any target of opportunity located within the accessible sky within 12 hours after notification to the SOC.
G-PERF-050 During normal working hours LOFT shall be able to observe with the LAD any target of opportunity located within the accessible sky within 8 hours after notification to the SOC.
R-PERF-060 Outside working hours LOFT shall be able to observe with the LAD any target of opportunity located within the accessible sky within 24 hours after notification to the SOC.
The LAD instrument shall have an effective area of 9.5m^2 at 8 keV.
To show compliance to this goal at least the number of modules as specified in [R-SYS-072] has to be accommodated on the S/C and the alignment requirements [R-MECH-028] and [R-MECH-030].
The LAD instrument should have an effective area of 10.0m^2 at 8 keV.
To show compliance to this goal at least the number of modules as specified in [G-SYS-072] has to be accommodated on the S/C and the alignment requirements [R-MECH-028] and [R-MECH-030].
"R-PERF-100 During science operations within the Nominal FoR, the energy resolution of the LAD detectors throughout the mission to the end of the Nominal Operations Phase for 2 anode events, shall be better than 260 eV (FWHM) at 6 keV."
"For the purposes of evaluating compliance to this requirement, the LAD Detector Effective Operating Temperatures at the beginning and end of the Nominal Operations Phase specified in [R-THRM-030] are applicable."
"R-PERF-101 During science operations within the Degraded FoR, the energy resolution of the LAD detectors throughout the mission to the end of the Nominal Operations Phase for 2 anode events, shall be better than 400 eV (FWHM) at 6 keV."
"For the purposes of evaluating compliance to this requirement, the LAD Detector Effective Operating Temperatures at the beginning and end of the Nominal Operations Phase specified in [R-THRM-031] are applicable."
"The energy resolution of the WFM detectors throughout the mission to the end of the Nominal Operations Phase, for 6-anode events, shall be better than 500eV (FWHM) at 6 keV (ENC=12e-)."
It shall be possible to downlink the science data generated by the WFM with a maximum delay of 2 orbits in duration with a probability of 99% (TBC).
The WFM instrument data will include information on transients which must be down-linked in a timely manner in order to be input into the observation planning for the LAD instrument - see [SCI-WFM-R-14] in [RD 1].
The time and position of triggered events detected by the WFM shall be broadcast to end users within 30s for 65% of events.
The time and position of triggered events detected by the WFM should be broadcast to end users within 20s for 75% of events.
The WFM shall be able to localise x-ray sources down to 1 arcminute accuracy.
This requirement supports sufficient source position accuracy to enable observations by the LAD and also to provide the required localisation accuracy to the LBAS.
The WFM should be able to localise x-ray sources down to 30 arcseconds accuracy.
The spacecraft shall be compatible with a launch on Soyuz-Fregat 2-1b from Kourou.
The values presented include the launch vehicle adaptor.
"The mission shall be compatible with a launch date in 2022 (study baseline), with a launch in 2024 as study back-up."
"This requirement limits the instrument background and the radiation dose to the detectors, which in-turn limits the growth in temperature limits to be defined to achieve the required energy resolution specified in [R-PERF-100], [R-PERF-101] and [R-PERF-130]."
The S/C shall autonomously detect separation from the launcher.
"After separation from the launcher, the S/C shall autonomously activate its TT&C system with at least one Tx and Rx channel active to enable ground to establish contact."
"During the Commissioning Phase, the payload instruments on-board shall be deployed, calibrated and tested."
The Commissioning Phase shall last no longer than 3 months.
"This limit is required in order to constrain the radiation dose seen by the detectors in support of achievement of the required energy resolution, and also to constrain the overall mission operations costs."
The Nominal Operations Phase (NOP) shall last 4 years.
"See [SCI-SYS-R-01, 01, 07] in [RD 1] and Annex A.1."
The Extended Operations Phase (EOP) beginning after the end of the Nominal Operations Phase should have a duration of 1 year.
The Decommissioning Phase (DP) shall not last longer than 2 months.
Design and operations of the space segment shall comply with the rules and procedures put forth in [AD 8].
"In the case of LOFT, this necessitates a controlled re-entry capability, due to the need to comply with casualty-risk regulations specified in [AD 8]."
See [RD 7] for a preliminary prediction of the casualty risk for an uncontrolled re-entry of the LOFT SC.
"This corresponds to a design for the nominal plus extended science operations, as defined in [R-MIS-130] and [G-MIS-150], and the commissioning phase [R-MIS-130]."
In the EOP degradation in mission performances are allowable.
All S/C consumables and radiation sensitive units shall be sized to last from launch till the end of the Extended Operations Phase.
"Radians, degrees, arcminutes and arcseconds are acceptable as angle units."
All (sub)- multiples by factors of 10 of any of the above mentioned units are also acceptable.
"For the initial phases of the study, the margin policy described in [AD 4] shall be applied."
A launcher performance margin of 5% shall be considered.
All reference frames shall be right-handed orthonormal triads.
"The spacecraft wet total mass including all applicable margins shall not exceed the launcher performance derived for the operational orbit from [AD 10], and considering the performance margin defined in [R-SYS-025]."
The spacecraft shall accommodate the LAD and WFM payloads as described in the LAD EID-B [AD 2] and WFM EID-B [AD 3].
The spacecraft shall accommodate at least 121 LAD Modules.
This requirement does not preclude the possibility to relax/tighten the Module alignment requirements in combination with a larger/smaller number of Modules to achieve the same effective area.
The spacecraft should accommodate at least 128 LAD Modules.
The FWHM FoV of the LAD (1.1°) shall be un-obscured by other spacecraft or WFM structures.
The spacecraft shall accommodate the Next Generation Radiation Monitor as specified in [AD 15].
"At all times during operation, the WFM shall be shielded from direct solar flux by a sunshield."
"The FoV of the WFM at zero-response, as defined in the following table, shall not be obscured by other spacecraft structures by more than 10% (TBC)."
"Because the WFM FoV is very large, partial obstructions of the FoV by other S/C structures are likely, and may be acceptable to the instrument – if the obscuration is more than 10%, this is to be agreed on a case-by-case basis."
"The reference axis of the WFM global reference frame, shall be aligned with the FoV of the LAD to within an accuracy of 1° (TBC)."
"This is not a strict co-alignment requirement, but is intended to specify the expected relative orientations between the LAD and WFM instruments, and ensure that the LAD boresight is within the most sensitive region of the WFM FoV."
The overall reliability of the spacecraft (inc. payload) shall be ≥ 85% from launcher separation to the end of the Nominal Operations Phase.
SC responsibility and is not contained within the payload reliability figure.
The spacecraft design shall eliminate or prevent single-point failures with a severity of catastrophic or critical as per [RD 4].
Non-compliance to [R-SYS-090] above shall be subjected to formal approval by ESA and an issued waiver.
No failure of any single component at unit level shall lead to failure of or damage to another component or subsystem.
No failure of any instrument shall lead to failure of or damage to other instruments or subsystems.
Degradation or delayed loss of the spacecraft caused by failures of either instruments or spacecraft subsystems on any level shall be prevented or protected against by design.
The spacecraft shall have a safe-mode which assures spacecraft and payload survival.
The spacecraft shall enter safe-mode in case of anomalies or failures from which it cannot recover autonomously.
"For design and analysis purposes, an average of 2 safe modes events of 4 days each per year shall be considered."
"The design of the S/C failure detection, isolation and recovery (FDIR) function shall be such that all anticipated on-board failures can be overcome either by autonomous on-board action or by clear, unambiguous and timely notification of the problem to the ground segment."
A temporal statistical interpretation is to be used for the evaluation of the pointing requirements (TBC).
Pointing requirements must be evaluated in accordance with the updated ESA pointing error engineering handbook and ECSS standard [RD 6].
The LAD Reference Boresight LoS Absolute Performance Error (APE) shall be better than 1 arcminute (TBC) at all times during observation to a confidence of 99.7%.
This requirement applies to the LAD Reference Boresight which is defined in section 1.4.
This requirement ensures that the LAD commanded pointing direction brings the source to within the flattened central region of the LAD response (where stability and effective area are maximised) - see [SCI-SYS-R-08] in [RD 1].
R-POIN-020 Each WFM Camera Reference Boresight LoS Absolute Performance Error (APE) shall be better than 50 arcseconds (TBC) at all times during observation to a confidence of 99.7% with respect to the J2000 reference frame.
G-POIN-022 Each WFM Camera Reference Boresight LoS Absolute Performance Error (APE) should be better than 20 arcseconds (TBC) at all times during observation to a confidence of 99.7% with respect to the J2000 reference frame.
These requirements apply to the WFM Camera Reference Boresight which is defined in section 1.4.
"The quantity given in this requirement is the portion of [R-PERF-152, G-PERF-153] under the responsibility of the SC (i.e. up to the WFM Camera I/F); the remainder (misalignments internal to the WFM Camera) is the responsibility of the payload."
"R-POIN-030 During LAD instrument operations, the LoS RPE (pointing jitter) of the LAD Reference Boresight and each LAD Module Reference Boresight shall not exceed the requirement limits specified in the following table."
"G-POIN-030 During LAD instrument operations, the LoS RPE (pointing jitter) of the LAD Reference Boresight and each LAD Module Reference Boresight should not exceed the goal limits specified in the following table."
A suggested conservative approach will be to ensure that Power Spectral Density of RPE is always lower than the PSD specified in the following figure.
"The absolute knowledge error (AKE) during instrument operation of the AOCS reference frame shall be better than 20 arcseconds (TBC) for each spacecraft axis to a confidence of 99.7%, with respect to the J2000 reference frame."
This requirement refers to an AOCS reference frame linked to the Optical Head of the star trackers.
The Absolute Knowledge Error (AKE) is equivalent to the previously used Absolute Measurement Error.
The information should be made available on ground.
The spacecraft shall be compatible with the payload allocated volume of the launcher as specified in [AD 6].
The spacecraft shall be compatible with the launcher environment as specified in [AD 6] at any stage before and during LEOP.
The use of mechanisms shall be avoided as far as possible.
The mechanical misalignment at any time between the LAD Reference Boresight and any LAD Module Reference Boresight during instrument operation shall be less than 1 arcminute (TBC) to a confidence of 68.3% when evaluated over all LAD Modules.
This requirement applies to the LAD Module Reference Boresight which is defined in section 1.4.
This requirement supports the restriction of the loss in A_eff due to misalignment of the LAD Modules.
The mechanical misalignment at any time between the LAD Reference Boresight and any LAD Module Reference Boresight during instrument operation shall be less than 3 arcminutes (TBC) to a confidence of 99.7% when evaluated over all LAD Modules.
"R-THRM-030 During science operations within the Nominal FoR, the LAD Effective Detector Operating Temperature shall be always kept below the maximum temperatures specified in the following table that ensure the fulfilment of the energy resolution requirement [R-PERF-100] throughout the mission until the end of the Nominal Operations Phase."
"For the purposes of evaluating compliance to this requirement, the formula for LAD Effective Detector Temperature provided in section 1.4 is applicable."
"R-THRM-031 During science operations within the Degraded FoR, the LAD Effective Detector Operating Temperature shall be always kept below the maximum temperatures specified in the following table that ensure the fulfilment of the energy resolution requirement [R-PERF-101] throughout the mission until the end of the Nominal Operations Phase."
"R-THRM-070 During science operations, the operating temperature of the WFM detectors shall be always kept below the maximum temperature that ensures the fulfilment of the energy resolution requirement [R-PERF-130] throughout the mission until the end of the Nominal Operations Phase."
"The LAD payload components shall be maintained to within their operating, non-operating and start-up temperature limits as defined in the following table."
"The WFM payload components shall be maintained to within their operating, non-operating and start-up temperatures as defined in the following table."
"The temperature of the LAD and WFM detectors shall be monitored by the platform in support of maintaining the requirements [R-THRM-040, R- THRM-080]."
"R-AOCS-010 During all mission phases, the AOCS shall acquire and control the S/C attitude and orbit within ranges allowing for nominal operation of all S/C systems and payload, and execution of the mission."
Damp-out any residual rates within the specifications of [AD 6].
Allows a continuous and sufficient supply of power for S/C survival Prevents damage to the instruments.
The propulsion subsystem shall guarantee that the spacecraft can maintain an operational orbital altitude for the mission lifetime as defined in [R- MIS-181].
The Power subsystem shall provide sufficient power for the spacecraft systems and payload instruments during all operational modes and mission phases.
The spacecraft shall comply with the ESA telecom standards within [RD 4].
The average contact duration with the ground segment.
"The TTC subsystem shall be compatible with Kourou and Malindi ground stations, as defined in the ESA Tracking Stations Facilities Manual [AD 5]."
The TTC-link shall support range and range-rate measurements.
"If a cost advantage could be realised by omitting this capability, this can be considered."
"The receive function of the TTC subsystem shall be hot-redundant, the transmission function shall be cold redundant."
The TTC subsystem shall enable spacecraft mode-changes through ground commands.
The uplink and downlink data rates shall be compatible with the data transmission requirements during all mission phases.
The retransmission of the data shall be attempted not later than the next pass.
The use of CFDP shall support the timeliness requirements of priority data (e.g. WFM data) and maximise the overall data downlink volume.
"LOFT shall be able to downlink, on average, 6.7 Gbit of science and housekeeping data from the payload per orbit."
"The requirement refers to raw science data at the output of the payload, prior to encoding (FEC), the addition of telemetry frames, or additional overhead for CFDP."
The spacecraft shall be able to uplink with an average TC-rate of 64 kbps (TBC) during ground contact periods.
This requirement ensures the LOFT uplink capability shall be sufficient to upload the required calibration data for the LAD instrument within reasonable timescales.
"The LBAS subsystem shall be compatible with the LBAS Ground Segment, as defined in [AD 14]."
"The time and position of triggered events detected by the WFM shall be broadcast to the LBAS Ground Segment, in less than 10s (TBC) since detection."
The data content to be broadcast is less than 1 kbit/event.
The implementation for this capability is use of a low-rate VHF telemetry transmitter on-board to the SVOM ground network.
"The time and position of triggered events detected by the WFM should be broadcast to the LBAS Ground Segment, in less than 5s since detection for at least 75% of the triggered events."
"Telecommand acquisition, decoding validation, and distribution On Board Control Procedure management (OBCP) functions."
The spacecraft shall be compatible with Soyuz-Fregat I/F requirements as specified by [AD 6].
"The spacecraft shall provide the interfaces required by the LAD and WFM payloads, as described in [AD 2], [AD 3]."
The spacecraft shall be compatible with the launcher environment specified in [AD 6].
The spacecraft shall be compatible with all mechanical environments encountered during flight.
The spacecraft shall be compatible with the thermal-vacuum environment expected during all mission phases.
ISO 8 standard cleanroom facilities must be used for activities involving the LAD collimators (TBC).
"The spacecraft shall be compatible with the radiation environment for all mission phases, as specified in [AD 13]."
Applicability of ESA approved ECSS standards related to AIV is required in [R- SYS-030].
The S/C design shall allow simple mounting and dismounting procedures so that any unit can be individually installed or uninstalled and tested throughout the integration process.
The SC shall provide the AIVT environment described in the EID-B [AD 2] for the LAD.
The SC shall provide the AIVT environment described in the EID-B [AD 3] for the WFM.
Applicability of ESA approved ECSS standards related to operations and ground segment is required in [R-SYS-030].
The S/C design shall enable the operational control by the ground segment during all mission phases and modes in both nominal and contingency situations.
The LOFT ground segment shall provide sufficient RF communications coverage with the spacecraft to downlink all recorded telemetry data.
"The MOC shall be responsible for spacecraft operations after launch, including mission planning, spacecraft monitoring and control, and orbit and attitude determination and control."
The MOC shall perform all communications with the spacecraft through the ground stations.
"Exception: this requirement applies only to the nominal TM downlinked by the nominal TT&C subsystem; it does not apply to the WFM burst-alert data transmitted by VHF transmitter to the SVOM ground network, which is under the responsibility of the payload consortium."
The MOC shall provide telecommand history and other auxiliary data including attitude history to the SOC within TBD days.
The SOC shall be responsible for instrument characterisation and calibration.
"SOC shall be responsible for LOFT instrument operations, including instrument control, collection of science data and transmission to the SOC, and intervention in case of anomalies."
"The SOC shall be responsible for analysing the science data received from the spacecraft via the MOC, as well as data reduction and production of the final scientific products."
The SOC shall prepare the Science Operation Plan and provide detailed operational requests to the MOC.
"The SOC shall be responsible for the science data archive, which will contain raw telemetry, processed science products and relevant auxiliary data."
The SDC shall perform pipeline processing of Science Data and deliver products to the SOC.
The Instrument Team Centre (ITC) shall be responsible for characterising and calibrating the instrument responses.
The ITC shall be responsible for monitoring the science performance health of the instruments.
The mission shall be compatible with the network of ESA ground stations [AD 5].
"During LEOP and critical mission phases, the 15-m ESA station at Kourou shall be used."
The spacecraft shall be compatible with the LBAS Ground Segment as defined in [AD 14].
The S/C shall support autonomous (without ground contact) operations according to a mission timeline uploaded from ground.
The S/C shall support re-scheduling of planned events in the mission timeline by ground.
The S/C shall support interruption of the mission timeline execution by ground command.
"During LEOP, the S/C shall be able to operate nominally without ground contact for at least 12 hours."
"In all mission phases after LEOP, the S/C shall be able to continue to operate nominally without ground support for at least 1 day (TBC)."
"In all mission phases after LEOP, the S/C shall be able to survive without ground contact for at least 7 days (TBC)."
"If a European equipment does not meet the requirements, a non-European alternative can be used."
This appendix provides traceability for those science requirements which have been transformed or allocated into spacecraft requirements.
"In each of these cases, the format declares the relevant MRD requirement, the parent SciRD requirement(s), and a brief justification text for the MRD requirement, with references to supporting documentation as appropriate."
There are 2 separate science requirements that impact on required science mission lifetime.
"These are unpredictable and rare events, with frequency of occurrence within an observable field of regard that can only be roughly estimated from previous experience (e.g. RXTE)."
This is then comparable and consistent with the estimation of time needed for an overall observing programme.
"For example for the range of object classes, and targets per class, to be observed in order to fulfil the top level science goals, a total of ~20Ms observing time is required."
"However these observations must be spread over extended “campaigns” to observe objects in appropriate emission states, and furthermore some objects in nearby regions of sky cannot be observed simultaneously."
"Hence, given some baseline estimate of observing efficiency the 20Ms observing time must be spread out, with an estimate of +/- 4 years again resulting from initial simulation work."
Extended operations [G-MIS-150] naturally follows from providing margins on the above arguments for greater security in completing the core science observing aims.
In 5400 days (15 yrs) RXTE observed 17 big or major (very big) outbursts of 11 BH transient sources.
We have taken those outbursts where the accretion state occurs during which the high-frequency quasi-periodic oscillation was detected with RXTE/PCA.
In 4 years you have a probability of covering at least one of these outbursts of 98%.
"In 4 years the probability to get 2 major outbursts is 90%, to get 3 is 74%."
The RXTE rate of new AMXP discoveries is 13/15=0.87/yr.
"These outbursts are brief so RXTE misses 10% of them, and LOFT will see less due to the reduced accessible sky fraction when compare with RXTE."
"It is important to understand that prob=f(FoR, duration), so failure to meet FoR or mission duration requirements will necessitate re-evaluation of the satisfaction of these requirements."
The choice of orbit for LOFT is strongly influenced by the requirement to minimise the instrument background - furthermore for reasons of reducing systematic effects due an unstable background (contributing to background knowledge error) the orbit must be chosen to avoid regions intersecting known enhancements of charged particles.
"See [RD 10] which demonstrates that for the specified range of orbits, the LAD background and background knowledge are suppressed to acceptable levels."
"In addition to the mean background rate, it should remain as much as possible stable."
"While the background will be periodically monitored by pointing to selected fields containing no bright sources, the variation between an observation and a reference field must be minimised."
"Effects such as geomagnetic shielding of the primary cosmic rays, and the solid angle for accepting atmospheric albedo neutrons may be compounded by the variability in orbital charged particle populations."
Therefore maintaining a circular orbit will minimise the variability of such components.
The energy resolution of the SDD is a function of the bulk leakage current – this is influenced primarily by (i) accumulated radiation damage and (ii) temperature.
LAD/WFM SDD detectors in support of their energy resolution requirements.
Two types of radiation damage are generally encountered by silicon devices: bulk damage and surface damage.
"The surface damage is related to the increase of the fixed oxide charge, and the production of trapping holes in the Si-SiO2 interface and is quantified by the Total Ionizing Dose (TID)."
"The bulk damage, i.e. the displacement of the Si atoms from their lattice sites that creates additional energy levels within the band gap, producing a variation of the effective bulk doping and increasing the leakage current, is quantified by the Non Ionizing Energy Losses (NIEL)."
"Because active thermal control (cooling) of the LAD array is not feasible (because of its very large area), it is necessary to target a LEO orbit at low inclination, to minimise the radiation dose seen by the detectors, and accordingly to relax the detector temperature requirements to achievable values."
See [RD 11] for a full description of the modelling of the detector damage for the candidate range of orbits for LOFT – this document provides the resulting maximum allowable detector temperatures which provide the required energy resolution.
Also see [RD 12] for initial test results on radiation damage tests to the SDDs which supports the assumptions made in [RD 11].
"Given the other important system-level factors to consider when selecting the baseline orbit (launcher performance, orbit maintenance dV requirements, GS contact times…), the MRD requirement has been expressed as a range, within which the baseline can be freely selected by the System Prime (to first-order the T/O is between required detector temperature and fuel required for orbit maintenance)."
"The temperatures specified in the MRD requirements on energy resolution are derived from [RD 11] which describes the modelling of the SDD radiation damage, and resulting increase in leakage current, for the candidate range of orbits for LOFT – this document provides the resulting maximum allowable detector temperatures which provide the required energy resolution, for the range of candidate orbits."
"Given the other important system-level factors to consider at LEO (launcher performance, orbit maintenance dV requirements, GS contact times etc…), the MRD requirements have been expressed as a range, within which the baseline can be freely selected by the System Prime (to first-order the trade-off is between required detector temperature and fuel required for orbit maintenance)."
The variation of the LAD effective area will modulate the count-rate seen by the instrument – this must be limited to ensure that distortion of the core astrophysical signals of interest is kept down to levels that are acceptable in the view of the statistical quality with which they will be measured.
"A statement has been received from the LOFT consortium that, after calibration, the residual error in the WFM camera is of the order of ~arcseconds."
"Accordingly an initial allocation has been made of 10’’ to the WFM instrument, with the remaining 50’’ allocated to the SC, up until the mechanical I/F with each WFM camera."
"The LOFT consortium is in the process of developing a WFM source-localisation budget, within which the platform contribution shall be placed."
"The LAD scientific telemetry budget is estimated assuming default event-by-event data transmission, 24-bit per event."
We conservatively assume a source with intensity 500 mCrab in the field of view at any time (this flux threshold includes >95% of the known X-ray sources with flux above 1 mCrab).
"The expected count rate under the assumption is ~117 000 cts/s, in addition to the expected ~3000 cts s-1 from the background."
"Preliminary simulations have been carried out using simulated LAD data streams and standard compression algorithms (gzip, bzip2, 7Z(PMMd), ZPAQ, PAQ8l), providing compression factors up to ~2.1."
"Therefore, adopting lossless algorithms for space applications (e.g., Rice compression) we assume that a 2 compression factor is affordable."
The required computational resources are being evaluated as well.
A 64 GB mass memory on the DHU will allow the temporary storage of excess telemetry.
Some of the key science targets (~10 persistent sources and some bright X-ray transients) will have average LAD count rate above 1.2x105 cts s-1.
"In these cases we will employ a flexible set of data modes, as was done with the Event Data System (EDS) on RossiXTE."
These modes allow the time and energy binning to be optimized for the science goals within the available telemetry budget.
"The observing plan will be optimized by alternating bright and weak sources to allow for a gradual download of the excess telemetry, a strategy already successfully adopted by the RossiXTE/PCA."
See [RD 13] for a simulation of LAD telemetry generation and downlink.
See [RD 14] for an analysis of the WFM instrument TM generation within the ~100kbps allocation.
"The LAD observations require co-addition of data taken by the >28,000 detector channels composing the detector, reaching the required energy resolution."
This implies that any differences in the response of the ASICs is known with sufficient accuracy so as not to introduce worsening of the energy resolution due to different gains of the circuitry.
"As this is known to depend on the temperature, we initially fixed a cautionary requirement on the maximum temperature variation across the instrument (5C) and during an observation (stability)."
"In addition there is planned a linear on-board correction to the event amplitude, based on a set of pre-loaded look-up tables providing the linear coefficients of the off-set and gain of the ASICs as a function of temperatures, within the operative range."
"The tables will be built during the thermal tests on the ground, by using the fast and effective electrical calibration procedure, allowing to inject know charges into all pre-amp channels and get the response with high statistical accuracy (the test capacitor will be in turn calibrated against X-rays on the ground with the required statistical accuracy, as planned)."
The electrical calibration can also be repeated and benchmarked in orbit.
"Of course, the concept of temperature correction implies that for every detected photon an equilibrium temperature can be defined and used for correction (i.e., T variations should not be “too fast”)."
On January 2013 the first LAD ASIC prototype was made available at IRAP and temperature tests were carried out.
These tests show a much better thermal stability of the gain under this design than the one used as early reference.
"The analysis, reported in LAD_TempReq_v2 (22.01.2013) by F. Muleri et al., shows that with the LAD ASIC the energy resolution is affected by less than the required 1% over the full temperature range even without the application of the linear gain correction."
"Based on this result, the temperature stability requirements of the LAD can be much relaxed in comparison to the previous specification."
We maintain the on-board linear gain correction approach for robustness.
"The above requirements concern only gradients and stability, under the assumption that the absolute T value is in-spec, guaranteeing the required energy resolution."
R-SPI-030: Corrected according to pointing standards.
Added a definition in section 1.4. requirement to 2E-6 from 6E-7.
R-OGS-180: refined definition of distance requirement.
"STE-QUEST is an M-class mission candidate for the M3 slot within the Cosmic Vision programme, for a planned launch between 2022 and 2024."
"STE-QUEST, with 3 other science missions, was recommended by the Space Science Advisory Committee (SSAC) to enter an assessment study (Phase 0), starting by an ESA internal study followed by parallel industrial study activities."
"This document aims at providing a complete and comprehensive list of all high level mission requirements (including S/C and payload, launcher, ground segment and operations) necessary to achieve the science goals detailed in [[AD 1]]."
It is hence an applicable document that shall be complied with for all mission design activities.
Performance goals are desirable in order to maximise the science return while keeping the impact on the cost and complexity to a minimum.
"They are to be the subject of system trade-offs and analysis, and which are to be fulfilled under restricted conditions which are to be defined and quantified."
"In addition to the definitions above, the following definitions shall apply: A 4-year time period, as used in many requirements refers to a time-span within R-MIS- years."
The mission requirements document is one of the documents that constitute the complete documentation set for the STE-QUEST study.
This document follows the issuing schedule as described below.
These refinements/updates will be issued as a new revision during the validity of any issue.
"Given the preliminary nature of a requirements document for assessment studies, a full re- issue including a new numbering will take place after the industrial studies."
Theory of General Relativity is a cornerstone of our current description of the physical world.
"It is used to describe the flow of time in the presence of gravity; the motion of bodies, from satellites to galaxy clusters; the propagation of electromagnetic waves in the presence of massive bodies; and the dynamics of the Universe as a whole."
"Theory of General Relativity, as well as numerous other alternative or more general theories of gravitation, are classical theories."
"As such, they are fundamentally incomplete, because they do not include quantum effects."
"A theory that solves this problem by accounting for both relativistic and quantum effects, would represent a crucial step towards the unification of all the fundamental forces of Nature."
"Several approaches have been proposed and are currently under investigation: examples are string theory, quantum gravity, extra spatial dimensions."
All of these tend to lead to tiny violations of basic principles.
"Therefore, a full understanding of gravity will require observations or experiments which can determine the relationship of gravity with the quantum world."
This is currently a 'hot' topic and includes the study of dark energy.
Improvements in technology mean that several experiments can now be performed in space with significantly improved accuracy.
"Taking advantage of this, STE-QUEST is designed to test the different aspects of Einstein's Equivalence Principle using quantum sensors."
"Local Position Invariance (LPI): In local freely falling frames, the outcome of any non-gravitational test experiment is independent of where and when in the Universe it is performed."
The mission will also have the capability to perform Lorentz Invariance and Standard Model Extension (SME) tests.
The accuracy levels achievable in these tests are currently under evaluation.
Test the universality of the free propagation of matter waves to an uncertainty in the Eötvös parameter better than 1.5x10-15.
"The ground track can be optimised to maximise visibility at the STE-QUEST ground stations, which may be located in Boulder (USA), Turin (Italy), and Tokyo (Japan)."
These locations are particularly favourable because of their geographical distributions and vicinity to research laboratories operating highly stable and accurate atomic clocks.
"Centres for instrument operations and data analysis, respectively."
Close monitoring of the spacecraft will be necessary during the on-orbit characterisation phase which is expected to last for the first 6 months of the mission.
The estimated data volume is compatible with small ESOC ground stations.
"Space-to-ground clock comparisons will be performed all along the orbit, and in particular, while the spacecraft is at apogee and perigee."
"In this way, Einstein's prediction of the gravitational frequency shift will be verified both by an absolute measurement between space and ground clocks and by examining the modulation of the redshift effect on the STE-QUEST clock between perigee and apogee."
"STE-QUEST will also allow common-view comparison of terrestrial clocks, which can be used to measure the periodic effect of the gravitational frequency shift induced by the Sun."
"The atom interferometer will primarily perform differential acceleration measurements while the spacecraft is around perigee (spacecraft altitude below 3000 kilometres), thus maximising the signal-to-noise ratio of a possible violation of the Weak Equivalence Principle."
A direct consequence of Einstein's Equivalence Principle is that time passes (or clocks tick) more slowly near a massive body.
"This effect can be detected when comparing the time intervals measured by identical clocks placed at different positions in a gravitational field, or when their tick rates (frequencies) are compared."
Time and frequency can be transferred between remote locations using electromagnetic waves generated directly from the local clock and transmitted to a particular detection position (ded by x').
"In this gravitational redshift formula, νi(x') is the frequency of clock i located at xi, as observed (measured) at the particular location x' where the comparison between the two clocks takes place (see Figure below); U is the gravitational potential."
"Theory of General Relativity, this frequency ratio is universal, and independent of the nature of the clocks."
The link transfers the clock signals in both directions (space-to-ground and ground-to-space) allowing the received signal to be compared with the local clock at both ends.
STE-QUEST will search for a possible violation of the gravitational redshift formula.
"Phenomenologically, such a violation may be described by a dependence on the gravitational potential of one or more of the fundamental constants that determine the clock frequency: X = X(U l c²), where X is a generic dimensionless fundamental constant or a dimensionless combination of fundamental constants."
Such dependence would correspond to a violation of the Local Position Invariance principle (LPI).
"The Earth's gravitational redshift was measured with an accuracy of 7×10-5 by the 1976 Gravity Probe-A experiment by comparing the frequency of a clock on the ground with the frequency of a clock on a rocket, as the height changed."
"The Atomic Clock Ensemble in Space (ACES) mission, planned to fly on the International Space Station (ISS) in the 2014- Atomique par Refroidissement d'Atomes en Orbite (PHARAO) cold atom clock."
"STE-QUEST will make use of the improvements in cold atom clocks and an orbit optimized for such measurements, resulting in improvements in sensitivity by 1 to 2 orders of magnitude."
"STE-QUEST will also perform a comparison of clocks on ground, by measuring the daily variation of the redshift effect in the Sun's gravitational field."
This will provide a means to search for the neutron’s scalar charge and to test the anomalous coupling of matter to the Standard Model quantum fields.
The Weak Equivalence Principle (WEP) postulates that the world line of a freely falling test body is independent of its structure and composition.
"Theory of General Relativity, but also for almost all modern theories of gravitation."
Experimental tests of this principle are therefore based on the detection of tiny differential accelerations between test masses of different structure and composition.
An experiment measuring a value of η not equal to zero would disprove the universality of free fall and violate the Equivalence Principle.
"In tracking the free propagation of matter waves, free-fall experiments extend into the domain of quantum objects."
This approach is conceptually different from all other free-fall tests based on classical bodies.
"As per the principles of quantum mechanics, particles have to be described as wave packets; in the context of an atom interferometer (as adopted by STE-QUEST) this introduces the concept of coherence of the different partial matter waves."
"STE-QUEST will compare the free-fall of the two isotopes of rubidium (85Rb and 87Rb) while the spacecraft orbits around perigee (see Figure below), in order to conduct a quantum test of the Weak Equivalence Principle with an accuracy down to 1×10-15."
Principle of the atom interferometry measurement to be performed with STE-QUEST.
"Time and frequency metrology: STE-QUEST will connect atomic clocks on Earth in a worldwide network, bringing important contributions to the generation of atomic time scales and to the synchronization of clocks on ground and in space."
"The comparison of clocks on Earth will give access, via the redshift formula, to differential geopotential measurements on the Earth's surface."
A resolution at the level of 1 centimetre on the differential geoid height can be achieved by STE-QUEST.
"Cold-atom and matter wave physics in conditions of weightlessness: STE- QUEST will study the evolution of ultra-cold atomic samples in an environment free from perturbations, over long free-propagation times."
The optical and microwave links will allow the cross-comparison of different ranging techniques and the measurement of differential atmospheric propagation delays in the optical and microwave domains.
The spacecraft shall be compatible with a launch on Soyuz Fregat from Kourou.
No backup launcher/launch site is foreseen within the M3 missions.
"The mission shall be compatible with a launch date in 2022 (study baseline), with a launch in 2024 as study backup ."
"The orbit provided is achieving the target accuracies in [AD 1] with the assumed payload performances, based on the algorithm in Annex 1 (TBW)."
The operational orbit shall be reached with direct insertion.
The gravity-gradient at perigee shall not be larger than 2.5⋅10-6 s-2 after LEOP.
Pre-launch s/c state shall support vacuum maintenance for instruments.
The spacecraft systems shall be compatible with a shelf lifetime of 2 years.
"In case of launch delays, the dry spacecraft will be stored in an appropriate clean-room."
"During launch and until a safe attitude is acquired, all payload systems shall be switched off with the exception of vacuum systems and the spacecraft in a minimal power stage using s/c batteries."
Spacecraft Science commissioning phase (2.2) shall last no longer than 6 (TBC) months.
Nominal operations phase shall last at least 4.5 years.
Extended operations shall start at 5 years from launch.
Design and operations of the space segment shall comply with the rules and procedures put forth in [AD 10] with the exact measures towards compliance to be traded and subsequently agreed upon.
"Currently, only active, controlled de-orbit is believed to fulfil the requirements Consumables for de-orbiting shall be calculated for the worst case required delta-V within Phase 4 with margins according to R-MISD-070."
The mission shall be designed for a lifetime of 5 years.
The mission shall be designed for an extended lifetime of 6 years total lifetime.
The spacecraft shall distinguish between nominal modes for science operations and manoeuvring/transitional modes.
Definitions for nominal modes shall be defined by the contractor.
"E.g., two main nominal modes can be foreseen: perigee mode (below 3000km); apogee mode (remainder of orbit, except transitional modes)."
"During nominal modes, no spacecraft re-orientations and/or orbit maintenance manoeuvres shall be performed."
"The Contractor is advised that he will be provided with an orbit fulfilling the requirements on the orbit by ESA/ESOC and will not be required to take any action on the orbit requirements, but is invited to check their impact on other parts of the system design."
It shall be possible to perform atom interferometer measurements in parallel with the clock measurements.
It shall be possible to operate the atom interferometer during all nominal modes (defined in R-MIS-240) along the full orbit in addition to performing the measurements at perigee passage.
It shall be possible to operate the atomic clock during all nominal modes (defined in R-MIS-240) along the full orbit.
Currently it is foreseen to fulfil this requirement using a GNSS receiver locked to the on-board frequency reference and laser ranging.
"The error in the determination of the gravitational potential at the space clock location shall lead to a fractional frequency uncertainty due to the red-shift effect of less than 3E-17, after post-processing."
"The ground clocks distribution shall allow establishing at least two common-view contacts (preferably three) of pairs of ground clocks with the STE-QUEST spacecraft clock per orbit, the two contacts involving at least three different ground clocks."
It shall be possible to compare the same ground clock (out of the available ground clocks) with the on-board clock of the spacecraft in the vicinity of apogee and perigee of the same orbit in any order (i.e. first perigee then apogee or vice versa).
Vicinity to be understood in the terms of R- SPM-030.
The same ground clock (out of the available ground clocks) shall be compared with the STE-QUEST on-board clock for most of the time (70%) spent by the spacecraft between apogee and perigee (or vice versa).
The spacecraft shall be inertial pointing during perigee pass (below 3000 km).
"In all three s/c axes, the angular velocity of the STE-QUEST spacecraft with respect to a non-rotating freely falling reference frame averaged over the atom interferometer sequence duration (<15 seconds) shall be within the interval [10-6, +10-6] rad/s during main atom interferometer operations (i.e. at least during periods below 3000 km altitude)."
The requirement assures a separation between the atomic clouds of less than 10 µm.
The PSD shall be calculated according to the algorithm in Annex 2.
"DC non-gravitational accelerations on the spacecraft shall be less than 1E-6 m/s2 , within the instrument volume, when measuring."
"DC non gravitational accelerations on the spacecraft along the sensitive axis of the atom interferometer shall be less than 4⋅10-7 m/s2 , during atom interferometer operations."
"At any time, the gravity gradient induced by the self-gravity of the spacecraft measured at the atom interferometer reference point (centre of mass of the atomic cloud during the measurements) shall be smaller than the gravity gradient induced by the Earth at perigee passage."
"Until detailed definition of the instrument, it is reasonable to assume the reference point on the central axis of the mu-metal cylinder around the AI volume at a height of around 1/3 the cylinder length."
The STE-QUEST time and frequency transfer links shall be able to compare the space clock and clocks on ground to a fractional frequency inaccuracy smaller than 3E-17 as well as to compare ground clocks to a fractional frequency inaccuracy smaller than 5E-19.
The STE-QUEST time and frequency transfer links shall be able to provide at least one phase comparison measurement per second between the space clock and the ground clock with 1Hz measurement bandwidth.
"The space and ground terminals of the STE-QUEST time and frequency transfer links shall be able to carry out space-to-ground and ground-to- ground time transfer with the link-induced differential time error between any two observations separated by a dead-time Td being less than TDEV(Td), where TDEV represents the time deviation1 resulting from R- SPL-10, R-SPL-11, for the microwave link."
This requirement shall be maintained over a minimum measurement interval of 20 days.
"The space and ground terminals of the STE-QUEST time and frequency transfer links shall be able to carry out space-to-ground and ground-to- ground time transfer with the link-induced differential time error between any two observations separated by a dead-time Td being less than TDEV(Td), where TDEV represents the time deviation resulting from G- SPL-20, and G-SPL-21 for the optical link."
The STE-QUEST microwave link shall be able to simultaneously compare the space clock with at least four clocks on ground.
The STE-QUEST optical link shall be able to simultaneously compare the space clock with two clocks on ground.
The differential delays of the Science Links shall be calibrated to a time uncertainty smaller than 50 ps for all applications.
This includes calibration of the differential delays between uplink (transmission from ground to reception in space) and downlink (transmission from space to reception on ground) and of the differential propagation delays in the atmosphere due to the non-reciprocal paths of uplink versus downlink.
The differential delays of the STE-QUEST links (both optical and microwave) used for the synchronization of two clocks on ground shall be calibrated to a time uncertainty better than 50 ps.
This includes the calibration of the differential delays (uplink-downlink) for each space-to- ground link.
"The kg, m, s system shall be used for all documentation."
"In general, the SI system of units shall be applicable."
"The coordinate system along the orbit shall be right-handed orthogonal with the origin as defined in R-MISD-060, the +z-axis towards nadir, and the +y-axis in the direction of the negative orbit normal, and the +x-axis completing the system."
The margin policy described in [AD 2] shall be applied to the assessment study (Ph.0/A).
The margin philosophy and margin depletion scheme will be defined fully at a later stage.
The spacecraft shall be dimensioned for the mission duration.
The spacecraft shall be dimensioned for the extended mission duration.
The spacecraft design shall eliminate or prevent single-point failures with a severity of catastrophic or critical as per [AD 9].
Non-compliance to R-SYS-040 above shall be subjected to formal approval by ESA and an issued waiver.
"The spacecraft shall be designed in a modular way in order to obtain simple interfaces to the payload, but with the core science instruments contained and protected within the structure of the spacecraft."
"No interface shall require the presence of more than one instrument, i.e. no routing of interfaces and no common use."
The accommodation of the payload shall be designed such that any instrument can be tested individually and removed or added to the spacecraft for these tests.
The spacecraft shall ensure an environment compatible with instrument specifications.
The spacecraft shall provide structural interfaces to the instruments and launch vehicle.
The spacecraft shall be compatible with the launch payload allocated volume of the launcher as specified in [AD 5].
The spacecraft shall be compatible with the launcher environment as specified in [AD 5] at any stage before and during LEOP.
Thermal Control shall control the interface to the instruments to a relative stability of +- 3 K (TBC) over 1 orbit.
The propulsion subsystem shall be sized to correct injection errors according to [AD 5] and perform orbital maintenance/attitude control during the full mission duration.
The propulsion system shall be sized to support the compensation of non- gravitational accelerations exerted on the spacecraft by its environment to the levels specified in Section 5 during all nominal operation modes in Phases 2 and 3 and 4.
"The propulsion system shall be sized to according to R-PROP-030, but taking as a baseline the optional orbit with perigee altitudes below 600 km (as defined in the MAG [AD 11])."
The power for the spacecraft and all its subsystems and payload shall not rely on radio-isotopic generators or other radioactive materials and processes.
The Power subsystem shall provide sufficient power for the spacecraft systems and payload instruments during all modes and mission phases.
R-PWR-030 A detailed power usage scenario shall be derived per operational and mission phase which demonstrates the power consumption and necessary storage requirements.
The spacecraft TTC subsystem shall comply with the ESA telecom standards within [AD 8].
"The TTC subsystem shall interface with the ESA network of ground stations, as defined in the Estrack facilities manual (DOPS-ESTR-OPS- MAN-1001-OPS-ONN 1.1."
"Timelines shall be supported, i.e. the execution of several commands according to a timeline and according to specified conditions."
G-CDH-030 Handling of nested timelines shall be possible.
"For all mission phases, the OBDH shall provide sufficient memory to store all data (science and platform housekeeping) in between downlinks and with a margin of 4 orbits."
The OBDH system shall provide for payload science and housekeeping data processing and storage.
R-CDH-090 On-board software updates shall be possible.
R-CDH-100 Mode changes through telecommand shall be possible.
The payload shall perform according to specifications in the on-board environment of the spacecraft during all nominal modes (defined in R- MIS-240).
The antennas for the microwave links shall be placed on a dedicated s/c face or panel compatible with their task with no obstructions within the main beamwidth of their radiation pattern.
The optical link terminals shall be placed such that their beam can reach any point on the currently visible (i.e. reachable) face of the Earth from the current orbital position at any time during the orbit.
"Exception is during the execution of specific, time-limited, manoeuvres of the spacecraft."
The precise orbit determination equipment shall ensure the performance specified in section 5.
A GNSS receiver capable of receiving signals from least two independent GNSS constellations shall be used.
The GNSS receiver shall have an interface to receive an external clock reference providing signals in one single frequency.
The spacecraft shall be equipped with corner cube reflectors compatible for use with the International Laser Ranging Service stations.
The POD equipment shall be compatible with the standard spacecraft reliability requirements in Section 6.2.3.
The spacecraft shall be compatible with launcher requirements.
The spacecraft shall provide all necessary interfaces to the payload.
The spacecraft shall be compatible with standard practices for ground operations.
Standard cleanliness and contamination requirements for missions to Earth orbit shall apply.
The spacecraft shall be compatible with the standard EMC requirements.
The AIV programme shall include a clear path of timely (at least 24 months before launch TBC) payload delivery and a clear AIT process of all instruments to be implemented on the S/C.
There shall be a dedicated single mission operations centre run by ESA and a dedicated science operation centre for centralized science data processing and storage.
The mission shall support file-based operations (TBC).
"The mission operations segment shall forward science telemetry as well as applicable housekeeping data (such as range, range-rate, status data) to the science operations centre."
"R-OGS-050 Mission Operations Centre shall be responsible for spacecraft operations after launch, including mission planning, spacecraft monitoring and control, and orbit and attitude determination and control."
"R-OGS-060 MOC shall be responsible for STE-QUEST science operations, including instrument control, collection of science data and transmission to the SOC, and intervention in case of anomalies."
SOC shall be responsible for instrument characterization and calibration.
SOC shall be responsible for operating the ground terminals for the clock comparison links.
SOC shall be responsible for analysing the science data received from the spacecraft via the MOC as well as data reduction and coordination of the production of the final scientific products.
The SOC shall be supported by DPCs (Data Processing Centres) for generation of higher level science data products.
"The SOC shall be supported by Instrument Operation Centres (IOCs) for the operation and monitoring of instruments, as well as data processing."
SOC shall prepare the science operations plan and provide operational SOC shall be responsible for the science data archive.
The mission shall rely on a maximum of two MOC ground stations for TT&C during nominal operations.
"Propositions for a suitable ground station, that is part of the available stations in the ESTRACK network, are encouraged."
"Two G/S might be required to cover gaps in single station coverage, however, one G/S is preferred."
"As a baseline for the current baseline orbit, New Norcia and Malargüe can be assumed as ground stations."
The clock measurements shall be done with ground terminals linked to high precision clocks meeting the science requirements.
There shall be at least 3 ground terminal locations.
At least one microwave and one optical ground terminal shall be transportable.
The ground terminals shall be located such that the projection of the difference vector (G/T’s – centre of Earth) on the equatorial plane between any pairs of different ground terminals has a length of at least 4500 km.
"If there are more than 3 ground terminals, only three of them have to fulfil this requirement."
The ground terminals design shall be equipped with high-precision position and velocity determination equipment down to at least 1 m (TBC) in all directions.
R-OAUT-010 Operation of the spacecraft shall be possible during all mission phases using either direct communication with ground or on-board intelligence using on-board storage followed by periodic communication.
It shall be possible to upload timelines with commands for on-board time- tagged deferred execution for at least 10 days.
PA requirements will be developed at a later stage.
"The overall mission cost to ESA shall be less than 470 M€ Cost at Completion, e.c."
This annex describes the recipe adopted for the estimation of power spectral densities.
"Timescales relevant for STE-QUEST are defined by the cycle time of the instruments, which are on the order of 10 s. As such, acceleration PSD specifications need to be fulfilled within each 10 s interval of instrument operation."
"It is advised to raise a flag at instrument level when PSD acceleration specs are not met, thus identifying those measurements requiring further analysis or to be rejected."
Such events shall not exceed 1% (TBC) of the total number of measurements.
Data are acquired at least at 2 kHz sampling rate after appropriate anti-aliasing filtering.
It is assume that the reader is aware of the need of low-pass filtering data before sampling to prevent aliasing effects.
"For a discussion of the role of aliasing in spectral estimation, we refer to any standard textbook in numerical data processing."
Data are acquired continuously for 50 s giving a total of at least 1·105 data points.
Each segment is de-trended by fitting the linear function c1·n+co and by subtracting the resulting best fit function to the data of that segment.
De-trending applies to data prior multiplication by the window function w(n).
A Blackman-Harris window function is used (see [RD 05]).
In addition a PSD estimate on the entire 50 s data time series without dividing it into segments is produced.
"The window function is again the Blackman-Harris one, with Nd now being the entire length of the data series."
Linear de-trending should also be applied to the entire data series.
The above algorithm is not supposed to deal with anomalies like spikes and sudden jumps that are visible above the noise in the data time series at the time of their occurrence.
"Therefore, data shall be inspected against the occurrence of these features and data streams containing them should be reported for further processing."
"This document provides the top level science requirements and the implied top level payload and mission requirements for Euclid, ESAs mission to map the dark Universe."
Euclid will tightly constrain the dark energy equation of state and address key cosmological questions.
"In response to the first Call for Missions for the Cosmic Visions plan, two dark energy related mis- sions were proposed: “DUNE: the Dark Universe Explorer” by A. Refregier and coworkers, and “SPACE: the Spectroscopic All Sky Cosmic Explorer” by A. Cimatti and coworkers."
"The two con- cepts have been merged into Euclid, a single medium class (“Class M”) mission which concentrates on measuring weak lensing (WL) and baryonic acoustic oscillations (BAO)."
This Issue 4 of the Science Requirements Document (SciRD) will be the basis for the Euclid mission and payload design during the Definition Phase.
Earlier issues of this document (Issue 3 and lower) are superseded by this issue and refer to earlier phases of this mission.
We give a summary of the science case as well as the objectives in Sections 2 and 3 of this docu- ment.
The full scientific case of Euclid is described in detail in the assessment phase study report [RD10].
Section 4.4.1 – formerly the slit spectroscopy requirements section - has been kept as an empty section to keep the requirement numbering consistent with previous issues of the document.
"This document covers all Science Requirements of the Euclid mission, and aims at showing clearly the links between science requirements and derived mission and payload requirements, in order to help understand, trace and support the analysis of the relation between the payload/mission specifications on the scientific objectives of the mission."
"The science requirements document will be used as a reference for the Euclid Mission Require- ments document, which is the basis for the industrial activities."
"Amara, A., Refregier, A.: 2008, submitted to MNRAS, arXiv:0710.5171 (astro-ph) Angulo, R. et al."
"The detectability of BAOs in future galaxy surveys Guzzo, L., et al 2008: Nature 451, 541 : A test of the nature of cosmic acceleration using galaxy redshift distortions."
"Paulin-Henriksson, S., Amara, A., Refregier, A., Voigt, L., S. Bridle S, 2007, to appear in A&A, Wang, Y., 2006, ApJ 647, 1: Dark Energy constraints from BAOs."
An introduction and overview of the mission based on the science case is provided in Section 2.
In Section 3 we present the science objectives and the implied top level science requirements.
"We try to follow the scheme “objective → method → requirement”, whereby requirement is always at the contents."
The numbering of the requirements facilitates later discussions and change control.
Section 4 contains the technical requirements for payload and mission.
These requirements are derived from the top level requirements.
"With Issue 0/4 of this document, we have removed all text and requirements related to the slit spectroscopy option."
"This option has been considered during the assessment phase, but was deemed infeasible in the framework of an M-Class Cosmic Visions mission."
Several independent observations indicate that the cosmological expansion began to accelerate when the universe was around half of its present age.
"This conclusion assumes the correctness of General Relativity, and requires that the universe must contain a new component known as dark energy."
"As a surprising consequence, the dark energy contributes to 76% of the total energy density of the universe, while the contribution of baryonic matter is only 4%."
"The remaining 20% is com- posed of dark matter, which, just as dark energy, has no explanation in standard physical theory."
"Like the accelerated expansion which took place during the early epoch of our universe, commonly known as “inflation”, the present acceleration leaves imprints on the different phases of the expansion of the Universe."
"At the same time, the growth of structures in the Universe is sensitive to the details of the acceleration process, but also to the very nature of the force of gravity, a modification of which might be the alternative explanation of the apparent acceleration."
The equa- tion of state of dark energy can thus be constrained from observations of the expansion history of the universe throughout its visible epoch since the decoupling of the microwave background.
"Com- plementary, the need for a new theory of gravity can be either ruled out or confirmed from observations of the growth of large scale structure in the Universe."
Euclid is an ESA mission to map the geometry of the dark Universe.
The survey mission will investigate the distance-redshift relationship and the evolution of cosmic structures by measuring shapes and redshifts of galaxies and clusters of galaxies.
The statistical study of structures in a large volume of the Universe requires a survey of a large fraction of the extragalactic sky.
Euclid will address key fundamental cosmological questions.
"Is dark energy merely a cosmological constant, as first discussed by Einstein, or is it a new kind of field that evolves dynamically with the expansion of the universe?"
"Alternatively, is dark energy instead a manifestation of a break-down of General Relativity and deviations from the law of gravity?"
What are the initial conditions which seed the formation of cosmic structure?
"The mission is centred on weak lensing and baryonic acoustic oscillations, two powerful and robust probes of the dark Universe."
"The mission also incorporates other cosmological probes such as galaxy cluster statistics, the integrated Sachs Wolfe effect, and the redshift-space distortions."
"Beyond these breakthroughs in fundamental cosmology, the Euclid surveys will provide unique legacy science in various fields of astrophysics."
"In the area of galaxy evolution and formation, Euclid will deliver high quality morphologies, masses, and star-formation rates for billions of galaxies out to z~2, over the entire extra-galactic sky, with a resolution 4 times better and 3 NIR magnitudes deeper than ground based surveys."
"The Euclid deep survey will probe the ‘dark ages’ of galaxy formation as it is predicted to find thousands of galaxies at z>6, of which about 100 could be at z>10, i.e. probing the era of reionization of the Universe."
"With Euclid, the majority of the new sources identified by future imaging observatories, from radio to X-rays, will be readily associated to a known redshift, out to a redshift z~2."
"This adds an enormous power to the science return of these other projects, as it eliminates the time-consuming phase of redshift follow-up."
Euclid will measure the distance-redshift relation and the growth of structure by optimizing its instrumentation and observing strategy to two complementary dark energy probing methods.
The weak gravitational lensing (WL) method relies on the fact that the distribution of mass along the line of sight distorts the apparent shapes and orientation of galaxies.
"The matter distribution, and hence cosmological structures, is obtained from the inferred gravitational field causing the weak lensing."
This provides a measurement of the effect of dark energy both the geometry and the growth of structure.
"The baryonic acoustic oscillations (BAO) method relies on the distribution of baryonic matter, i.e. a galaxy redshift survey, to infer the redshift-distance relation."
The characteristic scale length of structure which can be accurately determined from the cosmic microwave background is used as a standard rod.
"By measuring this characteristic scale in the galaxy power spectrum (or correlation function) as a function of redshift both in the tangential and redshift directions, one directly probes the expansion history H(z) and thus the equation of state of dark energy w(z)."
"At the same time, the statistical distortion of the clustering pattern is a direct consequence of the growth of structure."
The science concept of Euclid relies on the fact that the combined results of the two principal me- thods provide very strong constraints on the dark energy equation of state and enable to sort out systematic uncertainties and biases that are inherent to each of the individual probes (Sect 3.1.1.2).
"Besides the two principal probes for which the mission is optimized, other DE probes can also be addressed with the Euclid survey and will provide additional constraints on the DE equation of state."
A list of the Euclid DE probes is given in Table 2.
"Observing from space provides a well-controlled environment and avoids sources of systematic errors caused by the Earth’s atmosphere and thermal variations, which seriously limits similar observations from ground."
This will give an unprecedented improvement in the dark energy characterisation in comparison to what can be achieved from ground only.
"The Euclid survey will produce a visible image of a large fraction of the extra-galactic sky (20,000 deg2) at a diffraction limited spatial resolution not possible from ground, and near-infrared (NIR) images in one or more bands of the same area."
The sky coverage and depth in NIR photometry cannot be achieved from ground due to the high background emission from the atmosphere.
Euclid will also yield medium resolution (R=500) spectra of about a third of all galaxies brighter than the minimum limiting magnitude of H(AB) = 19.5 mag or with emission line Hα flux of 4×10- difficult to access from ground for faint galaxies at 1<z<2 due to the high background emission from the atmosphere.
"In addition, the high number of atmospheric sky lines requires a higher spectral resolution for a ground based experiment to obtain the same redshift accuracy from space."
"This means that each ground-based spectrum would be much bigger on the detector, thus making a massive redshift survey as Euclid unfeasible from the ground."
The spacecraft will be placed in a large L2 orbit which will ensure stable thermal and observing conditions.
The satellite will be launched on a Soyouz ST-2.1B rocket from Kourou.
The nominal mission duration is 5 years and the observations will be done in step-and-stare mode.
Image dithering will be achieved at spacecraft level to fill detector gaps and allow correction for cosmic rays.
A fine guidance system will provide a relative pointing accuracy of 35mas over one dither exposure of ~500s.
"Euclid’s primary wide survey will cover 20,000 deg2, i.e. the entire extragalactic sky, thus measuring shapes and redshifts of galaxies to redshift 2 as required for WL and BAO."
"For weak lensing, Euclid will measure the shape of over 2 billion galaxies with a density of 30-40 resolved galaxies per arcmin2 in one broad visible R+I+Z band (550-920 nm) down to AB mag 24.5 (10, extended object)."
"The photometric redshifts for these galaxies will reach a precision of σz/(1+z)= the range 0.92-2.0 micron) reaching AB mag 24 (5, point source) in each, complemented by ground based photometry in visible bands derived through engaged collaborations with ground based projects."
To measure the shear from the galaxy ellipticities a tight control is imposed on possible instrumental effects and will lead to the variance of the shear systematic errors to be less than 10–7.
The BAO are determined from a spectroscopic survey with a redshift accuracy of σz/(1+z) ≤0.001.
"The Euclid baseline is a slitless spectrometer with constant λ/Δλ=500, which will detect predominantly Hα emission line galaxies."
"The limiting line flux level is 4×10-16 erg s1cm2 (point source 7σ at 1.6 micron), yielding 70 million galaxy redshifts with a success rate in excess of redshifts can be determined."
Euclid’s additional deep survey will cover 40 deg2.
"The primary science outcome of Euclid will be the detailed testing of the current standard cosmolo- gical model against the largest feasible observational data sets, with the specific objective of cha- racterising the nature of the Dark Energy based on the combined results of the WL and BAO measurements."
"Euclid will yield a unique and vast data legacy which is expected to have a large discovery potential in several fields of cosmology, extra-galactic and galactic astrophysics."
This legacy is seen as a very important all encompassing science objective.
"The properties of dark energy can be quantified by considering its equation of state parameter w=p/ρc2, where p and ρ are its effective pressure and density."
"Translating from linear time to observable redshift z, we can parameterize the DE state parameter w(z) = w0+wa(1a), with a=1/(1+z) is the scale factor."
The parameters w0 and wa are the present value and the rate of change of the DE state parameter.
"With this form, the errors on wp and wa become uncorrelated and the error on wp corresponds to the error we would measure for a constant w model."
By combining all current surveys its value is FoMDE ~ 10 (Komatsu et al.
"As well as the geometry, dark energy also affects the growth of structure."
"The expansion of the Universe acts as a damping term for the growth of density fluctuation so as the expansion rate increases, the growth of structure slows down."
"Importantly, however, the growth rate f(a) depends also on the gravity theory, which makes it a fundamental probe of modified gravity (see next section)."
"In the GR framework, measurements of f(a) represent a fundamental consistency test of our cosmological assumptions, while carrying additional information on w(a) beyond the geometric probes of the expansion rate."
The Euclid mission is designed to address all the sectors of the standard cosmological model.
"Adopting the DETF definitions, the precisions to be achieved with Euclid implies a FoM > 500, which is at least Stage IV on the DETF scale."
"Euclid alone to measure wp and wa to 2% and 10% (FoMDE = 500) (ii) Look for deviations from w = 1, indicating a dynamical dark energy."
"Measure the growth index, γm, to a precision better than 2%."
A number of cosmological probes have been put forward for measuring the properties of dark energy.
"In both reports of the DETF [RD08] and the ESA/ESO Working Group on Fundamental Cosmology (WGFC, [RD09]), the four main probes of dark energy are identified as: (i) weak lensing; (ii) galaxy redshift surveys (needed for the BAO measurement); (iii) Type Ia supernova measurements; and (iv) galaxy cluster counts."
"Other methods are also briefly discussed, but of the four main techniques, weak lensing and galaxy redshift surveys form a unique combination for As stand alone probes, these are the two most powerful measures of dark energy."
"Furthermore, as well as having the smallest error bars on the equation of state parameter (w), each one of these two probes is able to place strong constraints on both geometry and structure formation."
The combination of these two probes allows us to control and measure a wide range of systematics.
"In particular the cross correlation between these two probes allows us to measure and mitigate astrophysical systematics, notably intrinsic alignments for weak lensing and galaxy bias for galaxy redshift surveys."
"As well as breaking degeneracies in parameter space, a joint weak lensing and spectroscopic galaxy survey analysis is able to measure both Newtonian potentials, φ(k,z) and ψ(k,z), which describe the scalar (density) perturbations in a perturbed LFRW Universe, in order to provide constraints on modified gravity theories."
"Conventional wisdom in the dark energy community, which is emphasized in both the DETF and ESA/ESA WGFC reports, is that high precision and accurate measurements will require a combi- nation of two or more probes."
"Euclid is such a mission, making it the most promising dark energy probes of any being designed."
"According to Euclid’s first primary science objective (Table 1), the Figure of Merit (FoM) of the combination will be at least 500, which is 10-20 times higher than a DETF Stage II experiment, making Euclid at least a Stage IV experiment in the DETF scale."
"The science concept of the Euclid mission considers a telescope diameter of 1.2m, and the capa- bility to cover large areas of the sky within a realistic mission lifetime."
"In order to achieve the scien- tific objectives of Euclid as listed in Table 1, which require a FoM in excess of 500, the survey area of the WL and BAO surveys needs to cover a large fraction of the extragalactic sky of 20 000 deg2."
The Weak Lensing survey involves the measurement of (1) the galaxy shear from the shapes of galaxies down to a limiting magnitude and (2) the corresponding redshift of each galaxy.
The galaxy shear is measured in the visible by obtaining diffraction limited images from space.
Multi band photometry is employed to obtain the photometric redshift or “photo-z”.
"To achieve the best photo-z accuracy for the required redshift binning, the Euclid WL experiment relies on com- plementary ground based photometry in visible bands derived through engaged collaborations with ground based projects."
The inclusion of these data is an integral part of the Euclid mission design.
"The WL survey will address the four primary science objectives as listed in the previous section (Table 1), according to the specified precisions."
The WL survey will also form the basis for the measurement of mass-selected cluster counts and the measurement of the ISW effect through a cross-correlation with the Cosmic Microwave Background measurement from WMAP and Planck.
"The prime scientific objective of the Euclid wide-field spectroscopic survey is to measure the power spectrum P(k), BAOs and growth factor, and exploit them to place stringent constraints on the dark energy equation of state and cosmological parameters in synergy with the WL experiment."
"Determination of the expansion history H(z) and angular diameter distance DA(z) to 1-2% accuracy in dz=0.2 redshift bins between z=0.5 and z=2, to probe the evolution of dark energy without assuming a model."
"Identification of tens of thousands of galaxy clusters over a wide range of redshifts (up to z>2) to derive the evolution of their mass function and therefore place tight and independent constraints on w, σ8 and Ωm."
"Use the shape and turnover of the matter power spectrum P(k) in a way complementary to CMB as a probe of primordial fluctuations, matter density, baryonic and neutrino fractions and models of inflation."
"The combination of WL+BAO+growth factor +clusters will place the most stringent constraints on the Dark Energy equation of state, cosmological parameters, modified gravity scenarios and large scale structure evolution."
"The same dataset will allow probing, for free, the formation and evolution of galaxies with unprecedented statistical significance."
"The WL survey shall cover at least 20,000 deg2 (or 2π sr) and provide 30 galaxies per arcmin2 (required, 40 galaxies per arcmin, goal) usable for WL with a median redshift zm>0.8 (required, zm>1.0, goal)."
"This requirement is essential to achieve the target accuracy on cosmological parameters, especially to achieve ~1% error on w. It results from trade-off studies aimed at the optimisation of the survey configuration to minimise the errors on dark energy parameters [RD02]."
The errors depend on both the area of the survey and the number of galaxies.
The requirement can only be fulfilled if the extragalactic sky is covered at high galactic latitudes with b≥30 deg.
Requirement: Systematic effects shall be controlled to a level where they do not dominate over the statistical errors.
"This is accomplished if the variance of the residual shear systematics is controlled This requirement is essential for the WL survey to reach the cosmological objectives, see [RD03]."
The statistical error (z)/(1+z) in the photo-z’s shall be smaller than 0.05 (require- ment) and 0.03 (goal) in the range 0.2<z<2.0 with a low level catastrophic failures.
Photometric redshifts will be used to group the galaxies in redshift bins with small overlaps.
The catastrophic failure fraction (fcat) is defined as the fraction of galaxies whose photo-z lies beyond 3 (TBC) of the true redshift.
The mean of the redshift distribution n(z) of each bin must be known to a precision of δ(‹zi›)/(1+z) <0.002.
Higher moments of the distribution must also be known but are less constraining.
"This can be achieved with a spectroscopic subsample of about 105 galaxies representative of the WL sample [RD01, RD02]."
"The results of simulations show that a competitive value of the FoM (DETF [RD08]) for the slitless spectroscopic survey is obtained for an H limiting flux of 4×10-16 erg cm-2 s-1, 7σ at 1.6 micron and unresolved source."
This flux limit corresponds to a total estimated number of 7×107 redshifts.
The accuracy in the spectroscopic redshift of each detected galaxy shall be better than be z ≤ 0.001(1+z).
This requirement is based on extensive simulations of the statistical reconstruction of large-scale structure and the successive measurement of the BAO fluctuations in the power spectrum analysis.
"In case of larger values of z, the BAO FoM will decrease significantly."
Experience with ground- based spectroscopy at resolution R=600 shows that it is possible to reach an uncertainty in the redshift determination of σz ≈ 3×10-4(1+z).
"At R = 500, which is our baseline case, the accuracy should scale down to σz ≈ 5×10-4(1+z)."
Requirement: the survey area shall be at least 20 000 deg2.
This minimum area for the wide survey is set by the cosmic variance.
"The number of galaxy spectra (and hence redshifts) required to meet the accuracy needed in the BAO measurement for the wide-field survey shall be 4×107 as minimum, and 1.5×108 as a target."
These values are set by the BAO statistics we have to achieve.
Caveat: the assumption (number of detectable spectra) = (number of redshift) does not hold as there will always be some “redshift success rate” which will make Nredshift < Nspectra.
"The median redshift of the wide survey shall be at z~1.1, with an upper quartile at z~1.35."
Requirement: A spectroscopic subsample of at least 105 spectra representative of the galaxies used for WL shall be obtained to calibrate the photometric redshifts.
The Euclid spectroscopic channel is considered not sensitive enough to fulfil the photo-z calibration requirement if one assumes a deep survey which is 2 mag deeper than the wide survey.
Limiting magnitude or Hα flux Emission line flux > 4 10-16 erg cm-2 s-1 Continuum magnitude: H(AB)=19.5 mag.
"It has been recognized that the Euclid surveying capabilities will be unique, and can provide in a re- latively short period of time a large survey area of high quality images in the visible, deep NIR photometric images and NIR spectroscopy."
"Requirement: Considering Euclid’s unique instrument and surveying capabilities, a Euclid Deep Field Survey shall be performed with an area of a few tens of square degrees and depth of 2 magnitudes deeper than the wide survey."
"The wide survey not only provides a large amount of additional science information, but it is also necessary for calibration purposes."
The survey depth will be achieved by repeating about 40 times the observations of the same fields using the same wide survey observing modes.
"By carefully choosing the time intervals between the repeats, the deep survey data will be used to monitor the stability of the payload and spacecraft."
"In addition, a large number of spectra can be used for the calibration of the weak lensing photometric redshift determination."
In this section we describe the science that can be carried out with Euclid in addition to the Cosmology objectives as given in Section 3.1.
The wide and deep surveys will provide a unique legacy which can address many areas of astronomy.
"The importance of the mission legacy depends on (1) the size and depth, (2) the spatial resolution, (3) the spectral resolution, and (4) wavelength coverage of the survey."
The requirements on (1) to (4) follow directly from the WL and BAO spectroscopic redshift survey requirements.
"Besides its Dark-Energy-specific science goals, the combination by Euclid of imaging and spectro- scopy over 20,000 contiguous square degrees at high galactic latitude will result in an immense legacy value for the astronomy community, impacting a wide range of science topics."
"With its high angular resolution imaging (~0.16 arcsec in the optical channel), morphologies will be measured for billions of galaxies out to z~2, together with their optical-infrared colours."
"The unprecedented Euclid spectroscopic survey will produce at the same time the ultimate three-dimensional map of the distribution of luminous matter, along with the spectral properties of 200 million galaxies, over three-quarters of the lifetime of the Universe."
Euclid will therefore trace directly with exquisite statistics the evolution of galaxies within the dark/luminous scaffolding of the Universe measured respectively by weak lensing and galaxy redshifts.
"Euclid will sample between z= 0.5 and z= 2 a volume of 100 h-3 Gpc3, i.e. 1000 times that of the Sloan Digital Sky Survey."
"Obtain a complete census of galaxies over two-thirds of the age of the Universe and measure the evolution of their distribution functions (e.g. luminosity, stellar mass), reconstructing the history of star formation, mass assembly and nuclear activity."
Of utmost importance is the impact that Euclid will have on future surveys at any wavelength.
"The Euclid spectro-photometric database will in fact allow straightforward and precise optical iden- tification (thanks to the sub-arcsecond imaging) and distance measurement of millions of objects that will be discovered by forthcoming or planned new survey facilities, like Herschel, Planck, LOFAR, eROSITA, WISE, SKA and SPT."
"Sunyaev-Zeldovich surveys with SPT (4000 deg2) and Planck (all-sky) will yield several thousand cluster detections (>10,000 expected with SPT, ~8000 with Planck)."
"The majority of these will be visible and measurable by Euclid, which will provide a unique mean to obtain redshifts and calibrate their mass."
"Similarly, 50,000 groups/clusters will be readily identified in the eROSITA X-ray survey by simply cross-correlating with the Euclid data- base."
"Of these, there will be 20,000 clusters at z>0.5 with mass >1014 solar, whose mass will be calibrated using the weak lensing shear and correlated to X-ray and optical observables."
"Cross-correlation of Planck data with the Euclid galaxy redshift and weak lensing data will be uniquely useful for removing the dominant systematic effect, CMB lensing, in the primordial gravity wave signal from Planck."
CMB lensing is the gravitational lensing of the CMB signal by the intervening galaxies.
"This will help increase the likelihood that the “smoking-gun” signature of in- flation, primordial gravity waves, will be discovered at high significance in the Planck data."
"The analysis of the shape, turnover and slope of the galaxy power spectrum P(k) would be of immense value to the estimation of the cosmological parameters, as a probe of primordial fluctuations, to tests of inflationary models, and to matter density and baryonic and neutrino fractions studies."
The legacy will also provide a database for quasars with z>7 and for the study of the cosmic NIR background.
"These are only the most obvious examples of the immense legacy impact of Euclid, that will be a crucial support for any future multi-wavelength survey and a gold mine for new discoveries for decades, removing the classical “bottle neck” represented by the follow-up identification and redshift measurement."
The possibility that Euclid performs a deeper imaging/spectroscopic survey over a few tens of square degrees opens a further broad window of opportunity.
"With, e.g., infrared imaging to H=25 and spectroscopy to H=24 will sample galaxies with 2<z<5."
"Objects at z>5 and up to z~10 can be colour-selected from the Y, J, H photometry."
The most massive galaxies at these redshifts will be extremely rare.
"The large FOV of the Euclid spectroscopic mode, compared to JWST, gives it an enormous advantage: only ~0.3 massive galaxies should be present in the JWST field of view of ~10 arcmin2."
EUCLID is the natural complement to JWST for the study of high-redshift galaxies.
A significant fraction of these galaxies are expected to have Ly-α emission.
At z~6 the fraction of Ly- α emitters in a Lyman-dropout sample is as high as ~30%.
"With the Euclid payload capabilities, small changes in the survey mode of observations could address different important astronomy topics."
Below we list possible areas of astronomy which may be addressed.
Opportunities may arise during periods when the wide and deep surveys cannot be carried out in the nominal way.
"For example, during the equinoxes, the galactic polar caps (b>30 degrees) are poorly visible, and these periods can be dedicated to Milky Way science."
"Due to the longer expected lifetime of the NIR detectors, search for extra solar planets can be performed using only the NIR detectors during the later stages of the mission."
The feasibility of additional science objectives depends on the implementation of the science requirements of the primary science objectives.
"We provide a list of science topics, which can be investigated with Euclid, and would provide a major scientific contribution to that topic."
Requirements on dedicated observing modes and survey strategies to optimize additional science observations need detailed investigation.
A spectroscopic and photometric survey of the galactic plane.
The Euclid payload and mission concept design must fit in the ESA Cosmic Visions M-class envelope.
Review of the assessment phase studies has lead to the recommendation that the mission is programmatically feasible only if mass of the payload has a sufficient margin of 30% for a Soyuz ST-2.1B launch from Kourou.
"In addition, considering that the procurement of the long-lead items for Euclid is critically driving the schedule, it was recommended to constrain the amount of detectors in Euclid to a number significantly lower than envisaged in the Euclid Assessment Study Report [RD10]."
"These recommendations required serious revisit of the mission and payload concept design, which has been worked out during the optimization period during the first part of the definition phase."
Weak lensing measurements place specific constraints on image quality as it relates to the analysis of the shapes of galaxies to determine cosmic shear.
"In particular, we need to deconvolve the galaxy shapes from the Point Spread Function (PSF)."
This process involves measuring the PSF from the field stars and using this to correct the shapes of the galaxies in the field.
"Requirement: A broad red band R+I+Z (550nm – 920nm) shall be used, chosen to be optimal for galaxy shape measurements."
The usage of more than 1 filter band can be considered.
Galaxy shapes for gravitational lensing is best measured in the red part of the visible spectrum.
"The FWHM size of the system PSF at the reference wavelength of 800 nm shall be between 0.18 and 0.23 arcsec, not including pixelisation."
The size is defined as the Full Width Half Maximum (FWHM) of the PSF averaged azimuthally about the PSF centroid.
This requirement together with requirement 4.2.1.3 enables to obtain the number density of resolved galaxies (i.e. with a size greater than the PSF) usable for the weak lensing analysis.
The system PSF at 800nm shall be sampled with (CCD) detector pixels subtending less or equal to 0.1 arcsec.
This requirement is coupled to requirement 4.2.1.2.
Together they provide the nominal sampling for the shear measurement of resolved galaxies at the sensitivity limit.
"To achieve sub-pixel sampling, the array of detector pixels has to be moved with steps in two per- pendicular directions that are not integers of the pixel pitch."
A commonly used technique to achieve this is dithering of the detector array.
"This requirement assumes 4 dithers (see below) to allow PSF calibration using stars in the field, and galaxy shape measurements after PSF deconvolution."
More than 96% of the central flux (83% of the total flux) should be contained in a diameter of less than 3.0 times the FWHM.
The system PSF also shall have a small number of degrees of freedom for its dynamic variation.
"By dynamic we mean the part that cannot be calibrated from an image taken at a different time, such as a calibration run."
Control of systematics is of crucial importance for the Euclid mission.
It is assumed that there are sufficient calibration stars in the field to calibrate the shape of the system PSF.
The ellipticity and FWHM of the dynamic part of the PSF shall have small spatial variations over typically 50 arcmin2 and timescales of ~3 days.
The standard deviation of the variations shall be less than 2x10-4 absolute and the FWHM stability shall be 0.1%.
"The ellipticity of the PSF is defined as (FWHM(x)2-FWHM(y)2)/(FWHM(x)2+FWHM(y)2), where x and y refer to the major and minor axis of the PSF FWHM contour."
"The dynamic part of the PSF cannot be calibrated from an image taken at a different time, such as a calibration run."
"The three days is derived from an initially required stability of 3 wide survey adjacent strips, which is per- formed in approximately 2-3 days."
The 50 arcmin2 comes from the fact that ~50 bright stars (brighter than a magnitude R=18) are necessary to calibrate the PSF by measuring it from these stars.
Stars of this type typically have a number density of 1 per arcmin2 (RD06).
Requirement: Over the wavelength range 550–920 nm (Req.
The linearity of the detector response shall be calibratable to a precision of TBD for a S/N dynamic range of 1 to 1000.
PSF calibration process involves measuring PSF from high S/N stars (R~18 mag) and using this to deconvolve the instrument response from low S/N galaxies.
The flux per pixel due to diffuse straylight (including sky contamination within and out of the field of view) shall be less than 20% of the flux of the zodiacal light at the ecliptic poles.
"The combined effect of glitches (including cosmic rays) and dead pixels shall be removable to less than a few percent (5%, TBD) of pixels in the images."
Requirements on dead pixel clustering properties are TBD.
"A common technique to reduce the impact of glitches and dead pixels is to use dithering (see below, Req."
Requirement: geometrical distortions on scales of 1 arcsec (i) shall be lower than 1% anywhere in the FOV and (ii) shall be calibrated with residuals at a level of less than 0.1 percent.
This is to control the shapes of the lensed galaxies with respect to possible instrument systematics.
Accurate measurement of the photometric redshift of distant galaxies (0<z<3) requires space based photometry in the NIR.
"The NIR photometry shall be carried out at least 3 wavelength bands, in particular Y (920-1146nm), J(1146-1372nm), and Hp(1372-1600nm) (Hp(1372-2000nm, goal)."
"These bands (designated Y, J, and Hp) provide the ideal synergy with ground based surveys complement to meet the photometric redshift requirements."
"Requirement: To achieve the needed photometry, the resolution in the centre of the J band (1259 nm) shall be between 0.3 and 0.36 arcsec (system PSF FWHM) with a plate scale less or equal to A sampling of ~1 pixel per system PSF FWHM or slightly higher would give the best photometric results for point sources and is related to intra-pixel response, as most of the energy would fall within 1 detector pixel with a minimum background emission contribution."
Requirement: the “final” relative photometric accuracy (i.e. at the end of the data processing) shall be less or equal to 0.5% for the photometry supporting the photometric redshifts.
This number applies to the uniformity within a field and among areas on the sky.
"The final cali- bration includes the off-line data processing of the fields, which assumes additional ground-based information (secondary standard stars) and the possibility of “self calibration” based on consisten- cies in the (redundant) Euclid data."
"As long as the relative accuracy is met, the absolute photometric accuracy can be constructed from the data afterwards."
Enough statistics will be available from standard stars to obtain a consistent absolute photometric calibration of TBD final accuracy.
The flux per pixel of diffuse straylight (including sky contamination within and out of the field of view) shall be less than 20% of the flux of the zodiacal light at the ecliptic poles.
Requirement: Slitless or other multi-object spectroscopy shall be used for the spectroscopic redshift survey.
"The parameters to be considered are: number of grisms needed to cover appropriately the total observed spectral range (≈ 1.0 – 2.0 μm, see req."
A TBD fraction of the spectroscopic redshifts coming from the slitless or other multi-object spectroscopy can be used to calibrate the photo-z redshifts (see Sect 4.5.2).
"Requirement: the flux limit for an unresolved emission line shall be less than 4×10-16 erg cm-2 s-1 (7 sigma, point source) at 1600 nm, and the continuum magnitude limit is H(AB) = 19.5 mag."
"Requirement: the spectral range shall be 1.0-2.0 micron (required, <1.0 to >2.0 micron goal) to ensure the detection of spectral features expected for the redshift distributions of the galaxy samples."
"The spectral resolution for a point source shall be R = λ/dλ = 500 constant to ±20, where dλ = resolution element = 2 detector pixels."
Requirement: the success rate shall be larger than 35% (fraction) at the Hα flux limit according to req.
With the success rate or detection efficiency we mean the number of redshifts that can be retrieved from the available targets above the given detection limit.
Requirement: A NIR image of the same field as covered by the slitless spectrograph shall be acquired with a depth which is sufficiently deep to always allow an association between an emission line (without continuum) detected in the dispersed image with a counterpart in the field image.
"The NIR image is necessary for providing the positions of the objects, to derive accurately the zero- point of the wavelength scale (crucial for BAOs), to remove ambiguities with zero order spectra contamination, to derive the object sizes and orientations in order to enable the correct definition of the extraction aperture of the spectra as well as the flagging of contamination of spectra."
"The Euclid photometry channel H-band exposure would provide a depth of H(AB) < 24 mag, which satisfies this requirement."
Requirement: the maximum error in the wavelength of a given spectral resolution element shall be less than 50% (TBC) fraction of that spectral element.
This requirement addresses both the wavelength zero point calibration as well as the accuracy in the wavelength scale of a spectrum.
"In the case of for example R=500 and a fraction of 0.5, we obtain for the wavelength error contribution Δz ≤0.5/500=0.001, in accordance with Req."
The wavelength zero point is driven by the accuracy which can be achieved in the mapping of the sources in the field image (req.
"This mapping is governed by two essential sources of uncertainty: (1) the distortions (including displacements) due to the optical elements in the instruments providing the field image and the dispersed image, and (2) temporal distortions due to varying observing conditions, e.g. due to temperature variations."
"On ground and also with HST it is common practice to periodically acquire a direct image in a given filter (J or H band, TBC) with the spectrometer to calibrate out the time dependent distortions."
The measurement frequency depends on the timescale of the time dependent field distortions.
"In this case there must be the facility to use a filter and take a direct image of some astrometric field to establish the transformation from the RA, Dec catalogue (from NIP) to the slitless instrument from in-orbit data."
"In practice, and for integrity of the wavelength information, a short direct image through the slitless instrument taken periodically with a filter is enough to align the pointing to the RA, Dec catalogue together with the time independent field distortions."
"The direct image can be with a filter (J or H band being the obvious choice) or could be filter-less, thus exactly matching the slitless spectroscopy passband."
"This approach requires accurate repeatability of the filter wheel holding the grism, since any non-repeatability must be at the level of small fractions of a pixel in order not to compromise the wavelength accuracy (a crucial requirement for the BAO experiment)."
In high latitude fields the number of late type stars may not be sufficient to perform adjustment of the wavelength zero point.
The size of the PSF at 80% encircled energy shall be less than 1 arcsec (TBC) in imaging mode and better than 1 pixel in cross dispersion (spectroscopic mode).
"Requirement: A number of spectrally dispersed images shall be acquired over each elementary field of view, the integration time being driven by the spacecraft dither strategy."
"Requirement: For each elementary field 4 (TBC) rotation angles will be selected, or 4 (TBC) sub- samples of the spectral apertures will be filtered."
The flux per pixel of diffuse straylight shall be less than 20% of the flux of the zo- diacal light at the ecliptic poles.
The diffuse straylight includes sky contamination within and out of the field of view.
"Requirement: To achieve the statistics described above, a wide survey shall be performed over a large fraction of the extragalactic sky (larger or equal to 20,000 deg2)."
The extragalactic sky covers high galactic latitudes (b>30deg) while avoiding the galactic bulge.
"The survey depth in terms of AB magnitude limit shall be R+I+ZAB =24.5 (10σ extended source), assuming a PSF FWHM of 0.23 arcsec in this band."
"Requirement: To meet the photometric redshift requirement, the depth in each of the Y, J and H NIR bands shall be 24 AB (5σ point source)."
This depth yields the required 30 galaxies/arcmin2 useful for lensing with a median redshift zm >0.8.
The wide survey needs to be performed in patches contiguous in time and larger than 20×20 deg2 to ensure homogeneous image quality on scales relevant for weak lensing.
"According to the adopted Euclid survey strategy, a patch (of ~20×20 deg2) is made of contiguous strips of 20 degrees."
Requirement: the total overlap between adjacent images shall be 2.5% on each side.
This is needed to derive astrometric and photometric solutions as well as shape measurement cross– checks.
"Requirement: at least 4 dithers shall be performed with the VIS imaging channel to cover the detector gaps such that 95% of the pixels of the coadded image has at least 3 exposures, and more than 60% of the pixels have 4 exposures."
The signal-to-noise ratio specification shall be met after 3 exposures.
"Requirement: at least 4 dithers shall be performed for each band of the NIP channel for gap filling between the detectors and sub-pixel information, such that 95% of the pixels of the coadded image has at least 3 exposures, and more than 60% of the pixels has 4 exposures."
"Dithering is needed in the visible and NIR ima- ging channels to fill the gaps between the detector arrays, to mitigate the effect of clusters of bad pixels, to improve the PSF calibration and galaxy shape measurement from sub-pixel information, to provide for a distortion map, and to allow for cross-correlations between exposures."
The requirement is based on a typical cosmic ray rate.
"The objectives of the Deep Survey are: (1) to provide the Euclid additional science, in particular to investigate galaxy formation with very high statistical confidence (see Section 3.2.2), (2) to obtain spectroscopic redshifts required to calibrate the photometric redshifts needed for the weak lensing experiment, and (3) to support the calibration of the visible PSF by repeatedly visiting the same fields on the sky."
"In view of the importance of the wide survey in relation to the Euclid science objectives, the im- plementation of the deep survey must not impair the quality and completeness of the wide survey."
"For the NIS slitless spectra, the wide survey limiting magnitude H(AB)=19.5 mag is more than 2 magnitudes higher (i.e. brighter) than the NIP limiting magnitude of H(AB)=24 mag."
"If we adopt the deep survey strategy as outlined below, the NIS data are not sufficiently deep to obtain a spectroscopic subsample of ~105 spectra for the NIP photo-z calibration down to AB=24 mag (cf Reqs."
"Nevertheless, such a deep survey from space with a slitless spectrometer provides a unique opportunity to obtain an unprecedented data set, both for scientific as well as for cross-calibration purposes."
The slitless deep survey data can be used to calibrate the WL target selection function.
The deep survey is based on the requirements listed in the following sections and the requirement given in Section.
The effect of the different FoVs for the VIS/NIP on the one hand and the NIS on the other hand has to be assessed (TBD).
Requirement: A deep imaging survey shall be built from multiple visits similar to the wide survey scans.
The method of selecting the targets for slit spectroscopy down to H(AB)=24 mag is under discussion.
"We are presently considering the options (1) to use the imaging mode of the spectroscopic channel and increase the limiting magnitude to 24 mag, or (2) use the NIR photometric channel to perform a (pre-)selection of the spectroscopic targets."
Method (2) considers the construction of a catalogue using the NIS/VIS data containing all spectroscopic candidates in a given field down to H(AB)=24 mag.
The NIS imaging exposure will be used to determine the position an orientation of the array on the sky.
"Using the catalogue, the DMD will be set after a selection of a TBD fraction of the candidates with H(AB) < 24 mag."
The target selection can be random but can also be based on scientific considerations – e.g. high (photo- )z galaxies.
"One could think of the following survey strategy: if the catalogue selection is a random fraction of for example 33%, then 120 exposures of a given field would give an average total integration time of 6.3x6.3=40 exposures for all galaxy candidates in the field (2 mag = factor 6.3)."
"The numbers can be tuned depending on the construction of the selection catalogue (TBC), such that the required minimum deep survey area is met."
"In case of slitless spectroscopy, there is no selection of the targets."
The slitless spectroscopy for the deep survey will be as deep as H(AB)<21.5 mag or 0.5-0.8×10-16 erg cm-2 s-1.
Requirement: Visits of the same field shall be evenly distributed over the lifetime of the mission.
This requirement ensures the monitoring of the PSF at regular intervals during the mission.
The imaging depth of the deep survey shall be 2 mag deeper than that of the wide survey with R+I+Z < 24.5 mag.
This requirement implies about 40 visits of the same deep field area.
The spectroscopic channel enables a Deep Survey over a field of a few square degrees (e.g. ≈ 40 deg2).
"In the Deep Field survey, most of the spectroscopic sample will be a flux-limited selection down to a limiting magnitude of R+Y+Z=24.0 with no colour or photo-z cuts."
A fraction of objects (e.g. very high-z galaxy candidates) may be observed as compulsory targets in each visit.
"The cumulative sky surface density to H =24.0 is ≈ 125,000 galaxies deg-2."
"Given a sky coverage of 40 deg2, we expect to obtain spectra and derive spectroscopic redshifts for about 4 105 galaxies at 0 < z < 6 even with a low sampling rate of 10%."
"Requirement: A spectroscopic deep survey shall be performed with a total area of at least 40 deg2, complete for galaxies with R+I+Z < 24.5 mag, and consisting of patches with a minimum size of 10 deg2."
"Requirement: the deep-field spectroscopic survey shall have at least 105 galaxies with a limiting magnitude H(AB) = 24.0 mag in order to match the depth of the near-IR photometric channel and R+I+Z=24 mag (AB) corresponds to about H(AB)=24, depending of the colours of the targets (TBD)."
The deep survey is 2 mag = factor 6.3 deeper than the wide survey.
The implied total integration time (without overheads) for the spectrum of a deep field target is equivalent to ~40 wide survey exposures.
The equivalent S/N requirements are the same as for the wide survey where H(AB)=22 mag (see req.
"Simulations showed that at this limiting magnitude, the success rate in redshift measurements is high for all types of galaxies (see the PDD for more information)."
"Requirement: deep survey patches shall be acquired in successive order, i.e. the measurements of a patch have to be completed as good as possible before moving to the next patch."
"As a goal, the frequency of the visits of a given patch shall be twice a month (once every 14-16 days)."
With “coverage” we mean the area surveyed in wide survey mode.
"Assuming that the wide and deep surveys are intertwined, a duty cycle of 32-36 fields per day, and that the completion of a wide survey patch (of 400 deg2 plus 10% overlap) can be accomplished within one month, the amount of time available for the deep survey is equivalent to~2-5 days per month."
In this period it is possible to carry out 3-8 visits where an entire patch of 10 deg2 is covered.
The margins for the Euclid mission are tight: the wide survey scanning strategy needs to be well op- timized even with a nominal mission time of 5 years.
From an operational point of view it is impor- tant to assess the required completeness of the survey due to the tight viewing constraints and due to the fact that it is not possible to trade survey depth for survey area once the field observing mode has been fixed.
"In the following, the completeness requirements are provided at the different scales in area dictated by the wide survey characteristics."
"Requirement: To meet the science objectives, the total wide survey area to be collected shall be more than 95% of the required area of 20,000 deg2."
The wide survey shall be contained in two contiguous areas at the two hemispheres with no holes due to missed patches.
This requirement addresses possible situations where e.g. due to system events the survey cannot be completed in the nominal survey period.
"For Euclid, the area surveyed scales directly with the dark energy Figure of Merit, hence the choice of the 95% level."
"We must cover the two hemispheres without holes, i.e. the “missed” patches should be along the edges of the areas."
"Requirement: In case a nominal patch of 400 deg2 cannot be completed in the allocated amount of observing time at a given epoch, the “lost” fields shall be situated at the edge of the patch."
"This means that “holes” should be avoided inside a patch due to “missed” fields, and rescheduling is necessary to trade the hole for a “lost” field at the edge of patch."
"A field can be declared missed if no pointing was performed, (2) the science quality of a pointing was insufficient, or (3) the observing procedure went wrong, as was indicated in the S/C or instrument House Keeping."
A minimum number of missed fields (TBC) will define a “missed” patch.
"Requirement: For a given field, the presence of one non-responsive detector array for each of the VIS or NIP instruments can be tolerated during the field observing sequence."
"In case of a larger number of non-responsive detector arrays for VIS or NIP, and in case of one or more non- responsive detector arrays for NIS, the planned survey scanning strategy or the field observing sequence shall be modified."
One non-responsive detector array for NIS (of 2Kx2K pixels) implies a loss of 1/8 of the survey area in the present configuration.
"Requirement: in case of the presence of clusters of bad pixels invalidating the dithering require- ment 4.5.1.5, the planned scanning strategy or the field observing sequence shall be modified."
"For spectroscopy target selection photometric accuracy, see Req."
The following table gives a summary of the envisaged dedicated in-orbit calibration operations to be performed on a regular basis throughout the mission.
The table has been derived from the discussions during the CDF pre-assessment; its contents have to be confirmed.
"The Cross-scale TRS is one of ESA’s Technology Reference Studies (TRS, see also http://sci.esa.int/science-e/www/object/index.cfm?fobjectid=33170)."
The purpose of the TRSs is to provide a focus for the development of strategically important technologies that are of likely relevance for future scientific missions.
"This is accomplished through the study of several technologically demanding and scientifically interesting missions, which are not part of the ESA science programme."
The TRSs subsequently act as a reference for possible future technology development activities.
The TRSs will not interfere with (or replace) the standard ESA mission selection process.
The purpose of the mission requirements document is to provide level 1 (mission) requirements for the Cross-scale TRS system design study.
This issue of the Mission Requirements Document has been prepared to support the study contract for the system design of the Cross-scale Technology Reference Study.
The document is (currently) an open document and refinements or updates are expected.
"Particularly, iterative steps with industrial study partners and the ESA TRS study manager are foreseen."
"Revisions will be published, as required, at the start of as well as during the system design."
Any S/C (or transfer vehicle) shall not enter the “LEO protected zone” and the “GEO protected zone” after mission completion.
The LEO and GEO protection regions are defined in section 5.2.2 of [AD10].
The GEO protection region is limited in latitude (+/-15 degrees).
"R-2.3.2-5: During the nominal science acquisition phase, the following spacecraft scale distances shall be established (In GSE coordinates: x is sun-Earth direction, y is East/West, z is North/South."
The distance between any two S/C at the small scale shall not differ by more than .
The distance between any two S/C at the medium scale shall not differ by more than 10% from the actual average (medium scale) spacecraft distance .
The distance between any two S/C at the large scale shall not differ by more than .
"The large scale separation shall start with a baseline separation of 6,000 km."
"During the science acquisition phase, one scan shall be performed from 6,000 km (0.5y + commissioning time) to 3,000 km (0.5y) to 15,000 km (1y) to 6,000 km (till end of mission)."
D-2.3.3-1: Distances for orbital parameters are quoted from the centre of the Earth.
"The apogee shall be between 25-50 Re, baseline is 25 Re."
D-2.3.3-10: No apse control to keep the line of apses along the Sun-Earth line is foreseen.
The mission profile shall ensure that the spacecraft are deployed in the operational orbit and in the correct position of the constellation.
The scale distances and/or the centres of the three constellations are outside the .
In order to fulfil R-2.3.3-4 [preferably simultaneously with a).
D-2.3.5-9: It is not required to continuously update the constellation.
"The instruments shall be operated autonomously, also during eclipses and radiation belt crossings."
The timing accuracy does not need to be better than 0.25 ms.
"D-2.3.8-9: If R-2.3.8-4 and/or R-2.3.8-7 are mission drivers (cost, mass etc."
R-2.3.9-2: Each S/C shall have a communication link for the transmission to ground of science and housekeeping data as well as for the reception of ground commands.
R-2.3.9-3: All S/C shall be capable to receive and acknowledge commands from the ground at all times when communication links can be established.
R-2.3.9-6: Mode changes by telecommand shall be possible including the definition of new modes.
The spacecraft on-board-data-handling system shall perform all commanding functions of the satellite in a centralised manner.
Telecommands generated by the ground segment shall be validated and transferred to the relevant users; time and event triggering shall be provided.
"R-2.3.10-2: Provisions shall be made for the acquisition, processing, storage and transmission to ground of all data generated by the payload and the platform."
R-2.3.10-4: Onboard data handling and storage shall be reconfigurable by ground command.
It shall be possible to acquire process and transmit to ground only selected sets of onboard data.
"R-2.3.10-5: Acquisition of housekeeping data shall be performed for all instruments and the platform subsystems, such that their state of health can be assessed at all times."
D-2.3.10-10: Only a selection of the burst-mode science data will be down-linked to Earth.
The ground segment shall be able to archive the science and housekeeping data and the commanding history.
"R-2.7.3-3: All spacecraft shall respond to on-board failures by switching, independent from ground control, to a redundant functional path."
Where this can be accomplished without risk to satellite safety such switching shall enable the continuity of the mission timeline and performance.
"Thermal Control”, ECSS-E-30 Part 1A, 25 [AD7] “ESA Pointing Error Handbook”, ESA-NRC-502, 19-2-1993."
The purpose of the project is to develop requirements for mobile surveillance system (MSS).
"MSS should be able to use successfully regardless of the terrain, weather conditions, time of day, etc."
"Mobile system must provide effective border surveillance of large areas (land or sea) from the site, detection and recognition of intruders and vehicles, management of border guards in carrying out specific tasks on demand, prosecution, blocking, etc."
The use of MSS corresponding to requirements elaborated will enable border services of the Member States to increase capacity to combat migratory pressures at the external borders of the EU.
"The scope of the project is the delivery of equipment and its integration in a common surveillance system, staff training, guarantee and putting into operation at address of Purchaser by the Contractor."
To prove their capabilities each participant must submit references for a successfully completed project for MSS delivery.
"The reference must include information on the number of delivered MSS, the year of delivery, the value of the project and another that is considered necessary."
The operation of the system itself takes place over a period of up to 12 hours without exception stationary in the form that the sensors are deployed above the vehicle height in an elevated observation position.
"Mobile Surveillance System will be used for terrain (land or sea) observation, detection and recognition objects (people, vehicles, drones), for determining a target's location and own position, and also for recording the results of the observation and transmission observed image to the local coordination centre."
"The Mobile Surveillance System will be used at day- and night-time, under specific weather conditions of the temperate climate zone in various seasons of the year."
The Mobile Surveillance System will be used for at most 12-hour long operation from a stationary vehicle.
"If the vehicles require additional post-manufacturing equipment, a declaration that required transformations have taken place should be submitted with the quotation."
In the cabin vehicle shall have 2 rotatable (180°) comfort seats with armrests.
The continuously variable transmission gearbox is not allowed.
It is allowed to adjust (pneumatic or hydraulic) the height of clearance from the cabin of the vehicle.
"The temperature will be adjusted, in the operator’s or driver’s compartments, fluently or step by step (one step 1°C or less) within the range from +18°C to +26°C at the outside of the temperature from –30°C to +45°C in full sunlight."
There shall be signalling installed in the driver’s compartment.
The EO head drive system capacity shall be at least cover the weight of the components.
These components will be installed on a mechanically controlled platform that provides movement of the sensors both in heading and elevation.
Angels of sensor optical axes in both planes will be automatically measured.
The thermovision camera shall have an unattended cooled detector (min.
The thermovision camera shall provide changing of polarity of an image by operator selectable between white and black for heat sources.
The possibility of using additional colors is acceptable.
The average usage of each thermovision camera will be at most 12 hours per day.
The MTBF of daylight camera shall be not less than 10 000 h.
The MTBF shall be no fewer than 100 000 measurements.
The both cameras shall keep automatically the focus of picture during changing field of view.
The digital terrain model of selected country (or countries) should be chosen and loaded by operator.
"Labels – residential areas, territories, rivers, etc."
"The system shall allow to record and play an image displayed on either monitor selected by the operator, together with all its elements: minimum an image given by one of the sensors, object’s coordinates, real time."
"The power supply system shall consist of three independent power sources – an internal batteries, a vehicle’s alternator and an external power 230V 50Hz."
The Internal batteries must be made in maintenance- free gel technology.
The Internal batteries shall be independent from battery of the vehicle.
There shall be possibility to power the equipment set from vehicle’s alternator.
The length of time for a full charge of the batteries must not exceed 12 hours.
The length of the external cable shall be not less than 20 m.
All offered TETRA radio terminals shall have full and proven interoperability with existing equipment and system.
Interoperability may be proven with detailed test results or valid TETRA Interoperability Certificate.
The Tenderer is required to present the supporting documents of proven interoperability in its offer.
"The representatives shall, free of charge, provide the user with information, consultation and technical support (Hot-line) in so far as the use of the subject equipment of the contract."
"Equipment installed on MSS should be capable of continuous operation without failure, while exposed to direct sunlight, precipitation (snow, rain, freezing drizzle) and when EO head lid covered with ice for a duration of not less than 12 hours."
"The penetration of rain, snow and so on is prevented."
Electrical connections shall be provided by means of unified connective elements and a way that prevents all risks of damages caused during normal operation compliant with the manuals; inter-module electrical connections markings shall be identical with those used on the cabling schemes.
The certificate shall be issued by a laboratory accredited for tests required by an accrediting authority of any of the countries.
"Within the ESA Climate Change Initiative (CCI), a global monitoring program driven by GCOS requirements is in development to provide long-term satellite-based products which can serve the climate modeling and climate user community."
Land Cover has been selected as one of 11 ECVs which will be elaborated during the first phase of CCI (2010-2013).
"In the first stage of the Land Cover CCI project, a user requirements analysis has been conducted to derive the specifications for a new global land cover product to address the needs of key-users from the climate modeling community."
This user assessment is building upon the general guidance and requirements from GCOS an its related panel activities and provides the next step to further derive more detailed characteristics and foundations to observe Land Cover as Essential Climate Variable (ECV).
"As part of the requirements analysis, an user consultation mechanism was set-up to actively involve different climate modeling groups by setting out surveys to different type of users: 1) a group of key- users, most of them also participating in CMUG, 2) associated climate users who are involved and leading the development of key climate relevant models and application, and 3) the broad land cover data user community reflected in the scientific literature and represented by users of the ESA GlobCover product."
"As proxy for (tracking) human activities, i.e. land use affecting land cover; As datasets for validation of model outcomes (i.e. time series) or to study feedback effects."
The evolution of requirements for these aspects from current models to future new modeling approaches was specifically taken into account.
"Next to the surveys, requirements from the GCOS Implementation Plan 2004 and 2010 and associated strategic earth observation documents for land cover (GTOS, IGOL, IGCO and CMUG) were considered and integrated."
"Finally, a detailed literature review was carried out with special attention to innovative concepts and approaches to better reflect land dynamics in the next generation climate models."
"The outcome of the user requirements assessment shows that although the range of requirements coming from the climate modeling community is broad, there is a good match among the requirements coming from different user groups and the broader requirements derived from GCOS, CMUG and other relevant international panels."
"Quality of land cover products need to be transparent by using quality flags and controls, and including information on the probability for the land cover class or anticipated second class or even the probability distribution function for each class (coming from the classification algorithm)."
"As a next step within the Land Cover CCI project, the outcome of this user requirements assessment will be used as input for the product specification of the next generation Global Land Cover dataset which will be developed within this project."
The outcome has been added to section 4.7. summary document has been added to section 3.3.4.
Section 4.10 Statement of Appendix has been removed.
As has been discussed in section 4.7 users mainly articulated in meta data on the quality of the land cover dataset.
The mention of the importance of irrigated rice areas has been added in section 4.5.
"ECOSYSTEM, DYNAMIC GLOBAL VEGETATION MODEL (DGVMS), AND GENERAL CIRCULATION MODELS (GCMS): SCALES OF PREDICTION AND PROCESS RESOLUTION."
TABLE 9: NEAR-TERM AND LONG TERM REQUIREMENTS TO IMPROVE EARTH SYSTEM MODELING (HIBBARD ET AL.
This document describes the activities and results for the user requirement analysis (WP1100) for the product specification as part of the Land Cover CCI project within ESA’s Climate Change Initiative Program.
"The overall objective for the Land Cover CCI project is to critically revisit all algorithms required for the generation of a global land product in the light of the GCOS requirements, and to design and demonstrate a prototype system delivering in a consistent way over years and from various EO instruments global land cover information matching the needs of key users belonging to the climate change community."
"In the first stage of the project, the detailed specifications of a global land cover product will be defined which matches the requirements from GCOS (both for itself and as a surrogate for other important climate variables) and key climate users, and which is achievable on a regular basis using the current EO systems and building on the UN Land Cover Classification System (LCCS) for consistency and interoperability with other land cover products."
"To do so, key climate and carbon modeling users will be consulted to ensure the developed Land Cover products meet the requirements for a range of model communities and for application of existing and future modeling approaches (WP1100)."
This technical report gives an overview of the concepts and background of the user requirements assessment as described in chapter 1 of this document.
"In chapter 2 of this document, the methodology and user engagement mechanism are described."
"These outcomes are presented accordingly: the defined requirements from GCOS and other strategic earth observation documents are presented in section 3.1, followed by the outcomes of the user survey for the broad land cover data use community (section 3.2)."
"In section 3.3, the assessment of the climate modeling community requirements is presented both for the key and associated user group and finalizing with the review on (future) requirements from climate modeling literature."
"Issues of global, regional and national forest and land cover observations have recently received significant attention in a number of international processes on the political level, offering opportunities to improving relevance, acceptance, and approaches to operationalize global and regional land cover assessments."
"Since technological progress and methodological sophistication alone is not sufficient to implement global land assessments effectively, particular emphasize on fostering more saliency and legitimacy of land cover observations is needed in addition to technical credibility."
"The efforts of Land Cover CCI projects also address the issue to build a bridge between policy requirements, and scientific progress and consensus."
"It involves engagement with prominent political processes, the gathering of observation requirements, providing technical policy advice, the definition of observation strategies and priorities, evolving international technical consensus on critical issues, the specification of implementation guidelines, and implementation of dedicated case studies fostering technical progress, operations and applications."
"These activities are progressing in four major thematic areas: (a) standards for land cover characterization, (b) standard methods for land cover accuracy assessment, (c) global land cover observations and applications and (d) land cover change monitoring."
"As a prominent example, the current evolving activities to support the UNFCCC efforts for research and systematic observations of Essential Climate Variables (ECV’s) is taken shape into specific implementation activities such as attempted in Land Cover CCI project."
"While there is no detailed guidance on what it means to observe land cover as ECV, there is guidance provided from the political level and its subsidiary technical bodies."
"The UNFCCC requiring global land cover observation progress relates to research and systematic observations ((GCOS 2004, 2010b))."
"The scope is to continuously monitor ECVs to reduce uncertainties in understanding the global climate system, which includes land cover as one such variable."
"The related GCOS implementation plan (GCOS tasks defined in 2004 have been redefined in essential climate variable including (1) the establishment of international standards, (2) consensus methods for map accuracy assessment, (3) the continuity for fine-scale satellite observations, (4) the development of an in situ reference network and the implementation of an operational validation framework, (5) the generation of annual global land-cover products, and (6) the development of a high-resolution global land cover change dataset."
"As requested by the UNFCCC Subsidiary Body of Science and Technical Advise (SBSTA), reporting guidelines and standards are being developed for http://www.fao.org/gtos/topcECV.html."
Any ECV monitoring effort has to ensure saliency and legitimacy in addition to technical credibility.
"An international coordination mechanism among key actors worldwide (users, producers, science, regional/national experts) is essential to ensure that land cover products are accepted internationally and by the UNFCCC."
Such mechanisms are intrinsic to the land cover CCI project and will be described in more detail in chapter 3.
Land cover and land cover change are becoming more and more related to the climate modeling effort.
"Land cover change as a pressing environmental issue, is acting as both a cause and a consequence of climate change (Figure 1)."
"Reliable observations are crucial to monitor and understand the ongoing processes of deforestation, desertification, urbanization, land degradation, loss of biodiversity, ecosystem functions, water and energy management, and the influence of land cover changes on the physical climate system itself."
Current IPCC Assessment Reports are based upon an uncertain understanding of the land surface dynamics and related processes.
"Applications of land cover and land dynamics in climate change-related General Circulation Models, Earth System Models and Impact Assessment Models need to be better linked and coordinated."
The importance of these issues requires continuous monitoring systems and data.
"All models are driven by data, whether that data is derived from boundary conditions or through parameter estimation, empirical relationships or direct observations."
"In the end, model estimates, and, therefore, model error, reflects the information, or analyses that is used to establish initial conditions, parameter estimation or internal algorithms."
"For instance, land-use change emissions are highly uncertain to within a factor of 4, i.e. 500 to 2700 TgC/y (Denman et al."
"This restricts our ability to estimate the strength of global carbon sinks; although fossil fuel emissions and atmospheric CO2 concentrations are well-constrained, the large uncertainty in land-use change emissions means that the airborne fraction of total emissions (and hence the fraction of total emissions taken up by land ecosystems and oceans) cannot be constrained so well."
"United Nations Food and Agriculture Organization (FAO) is often inconsistent with land-cover data and actual practices (e.g., the extent of global plantation forests is uncertain)."
"For adequate modeling of processes at the land surface boundary to the atmosphere, an accurate representation of the land surface is necessary."
A climate model used to simulate these processes requires a proper determination of the land surface characteristics that are used in its parameterizations as boundary conditions.
"These parameters include, e.g., background surface albedo, surface roughness length due to vegetation, fractional vegetation cover and Leaf Area Index (LAI), forest ratio, plant- available soil water holding capacity, and volumetric wilting point."
"Three major communities, the General Circulation Models (GCM), Earth System Modeling (ESM), and the Integrated Assessment Modeling (IAM) community play an important role in understanding and quantifying Earth and climate system analysis and specifically, understanding the role of land use and land cover change."
These different model communities commonly have a global scope of some kind but focus on different set of objectives (Figure 2).
A variety of approaches to addressing land use and land cover change have been considered by these modeling communities.
General circulation models (GCMs) include a rather coarse level of ecological and biogeochemical process representation and use land cover as generic and fixed boundary condition.
"Earth system model (ESM) modelers have taken an approach that stems from a combination of basic ecosystem (e.g., carbon cycle) and dynamic global vegetation models (DGVMs), and that incorporates different plant functional types (PFTs) into their model structures."
"These aspects of ESMs are increasingly being used for impacts assessments, both for ecosystems themselves and the impacts on hydrology which are modified by ecosystem responses."
The ESM approach is derived from a tradition of using complex models to analyze the different components and interactions of the physical system.
"The focus has mainly been on the climate system, with an initial description of coupled ocean-atmosphere systems, and more recently the carbon cycle and dynamic vegetation."
"By extending its focus, the ESM approach is more- and-more implementing coupled climate with hydrology, agriculture and urban systems as integral components of the Earth system."
A number of ESM approaches have been developed ranging from GCMs that operate at the 2nd global grid cell scale to soil carbon process models that can be parameterized at the plot scale (Figure 2).
DGVMs are the main linking component to extrapolate the highly detailed process representation to the global level by including the state-of-the-art knowledge about the impacts of change on plant-soil interactions and their feedbacks on the climate system.
"A broad range of DGVMs of varying degrees of complexity is currently being adopted within ESM: CLM-CN, CLIMBER, JSBACH, IGSM, LPJ, BIOME-BGC, CENTURY, DNDC, HYBRID, SDGVM, TRIFFID, ORCHIDEE (Ostle et al."
Most DGVMs utilize the concept of “plant functional types” (PFTs: numbering between 3 and 20) to characterize global (vegetation) land cover diversity.
Each PFT represents a broad class of vegetation type such as deciduous forest or grassland and is parameterized for a core set of physiological processes and ecological phenomena.
"The IAM approach comes largely from a tradition of modeling human behavior explicitly and the interaction of human activities, decision making and the environment, including economic production and consumption, energy systems, greenhouse gas emissions and land-use."
"This community has also recognized the importance of land use as a critical factor in socio-economic decision making, for example for food and timber production, the state of ecosystems and their services, and increasingly, as a response to demand for biofuels for the electricity and transportation sectors."
"While many IAMs have focused strongly on energy-economy systems and only included land use emissions as exogenous factors, this is now changing with the development and implementation of increasingly coupled socio- economic and climate modeling strategies."
Several actors and types of users will be involved in representing the modeling communities concerned with climate and climate change issues.
Broad review of user requirements from the scientific literature including existing uses of land cover data for climate modeling but also on innovative concepts and approaches to better reflect land dynamics in the next generation of models.
"Selected users will be invited to participate the product development, implementation and validation and asked to provide input and feedback at different points during the process."
Final discussions with the users will yield feedback on the products and results in a set of recommendations to further improve ECV land cover monitoring beyond this project.
The purpose of this report is to present the experiences and results of the first step d above and more detailed in Figures 3 and 4.
Several actors and types of users can be identified as representatives of the modeling communities concerned with climate and climate change issues.
"Potential users that define model requirements originate from groups specialized in different fields of science: e.g., working in weather prediction, Global Circulation Modeling (GCM), Regional Climate Modeling (RCM), Global and Regional Earth System modeling, Carbon Cycle Modeling, Dynamic Vegetation and Hydrology modeling and others."
"Potential users of the new land cover products are also model development application groups working in numerical weather prediction (NWP), GCMs and RCMs, global and regional Earth System models, carbon cycle models and dynamic vegetation and hydrology models."
"With regard to climate and ESM, this comprises (1) groups participating in the global and regional (CORDEX) IPCC activities for the forthcoming 5th assessment report and (2) groups participating in the EU projects ENSEMBLES (http://ensembles-eu.metoffice.com/) and PRUDENCE http://prudence.dmi.dk/)."
"With regard to hydrology models, potential users are groups participating in the EU project WATCH (http://www.eu- watch.org/) and the associated WaterMIP (Water Model Intercomparison Project)."
NWP groups involve national weather services as well as the European Centre for Medium-Range Weather Forecast (ECMWF).
Key users: they are central to all phases of the user interaction within the project and are integral part as partners in the project.
"They are the Max Planck Institute for Meteorology (MPI-M), the Laboratoire des Sciences du Climat et de l’Environnment (LSCE) and the Meteorological Office Hadley Center (MOHC)."
"Key users are directly involved in the product specifications, product assessment and the final user assessment of the product."
These users maybe participating in meetings and in the user survey and their input would feed into the product specifications.
"These users are not partners in the project directly but could be engaged, in particular if involved in the user assessment of the products."
"Broad user community: will be considered through information of the project through the World Wide Web and through reviewing scientific literature, participation in meetings to synthesize requirements for the product specifications and through receiving feedback from general global land cover data users."
This group of users would also include known user requirements coming not directly from climate modelers but the “climate concerned” users such as those making use of land cover information for other societal benefits or national reporting and accounting.
The user consultation will address a broad range of issues due to the nature of the interactions of land cover and climate.
"Consequently, land cover user requirements for climate modeling and climate research are expected to be diverse and this complexity is reflected in the user consultation plan as presented in Figure 3 and detailed out in the next sections."
The Land Cover CCI project is based on the progress that has been made in terms of land cover characterization and validation procedures and addresses critical tasks which have not achieved sufficient progress up to date.
The plan for a thorough and complete user requirements analysis for developing the final product specifications uses a range of sources and mechanisms.
There are also different levels of how users representing the climate research community will be involved in this process (Figure 4).
"As indicated in the previous section, several actors and types of users are involved in representing the modeling communities concerned with climate and climate change issues."
The user consultation dialogue (Figure 4) for Land Cover CCI was coordinated by WUR in close cooperation with the Hadley Center (UK) that is represented in CMUG.
"The broad assessment of existing models and user requirements aims at looking, into the range of approaches, how land cover data have been used in climate models."
"This assessment includes different modeling approaches and communities, i.e. Global Circulation Models, Earth System Science models, Climate prediction and forecasting models, and integrated Impact Assessment Models."
"Detailed literature review of land cover representation in climate modeling, land cover parameterization approaches and studies that looked into the impact of land cover data on climate modeling results."
Broad land cover product user survey: user survey on requirements for next generation land cover products with special attention for climate and earth system modeling issues under the user community for the ESA GlobCover product.
The set-up and questions for this survey are presented in Appendix A.
This broad assessment of user requirements ensures that the full range of needs are considered and understood for deriving the detailed product specifications.
The second step in the user consultation process for the product specifications included the partners and processes directly involved or associated with the ESA CCI program and Land Cover CCI project.
The aim was to provide a detailed user needs assessment and identify specific requirements coming from the key users of land cover products of the project.
"A detailed user survey was conducted on the specific requirements for land cover data characteristics to be used (e.g., spatial, temporal, thematic detail, accuracy requirements)."
The detailed survey for the key-users (Appendix C was conducted through email while for the associated users a more concise survey was prepared (Appendix B) which was made available to the community (Appendix D) as an online survey.
The composition of the two user groups has been described in section 1.4.
This part of the user consultation has provided the requirements based on existing model applications requiring land cover data and future needs as identified by this community.
These users will also form the primary partners in the user validation and assessment phase to evaluate the Land Cover CCI products in dedicated model applications during next phases of the project.
"In the final step, the user consultation targeted at the set of requirements for the next generation models."
This is driven by the notion that the CCI products will need to consider not only today’s but future user requirements.
New modeling concepts have triggered discussion to improve the existing land cover characterization and parameterization concepts.
"Improved observations addressing a range of requirements can play an important role in that process and, therefore, the outcomes presented will also consider user requirements of the next generation modeling approaches."
"This has been implemented through an active engagement in scientific dialogs among the climate modeling community, i.e., on harmonization efforts for land cover among the ESM and IAM communities and on improved concepts of land cover parameterization (Hibbart et al., 2010)."
"Furthermore, the user requirements of the next generation modeling approaches have been distilled from a broad array of (scientific) literature."
"And finally, some specific questions in the key and associated user surveys were referring to land cover requirements for future climate modeling concepts."
The overall objective of the broad user requirement assessment is to identify how land cover data is currently used by the climate modeling community and what the future requirements for land cover data are for climate and earth system modeling.
"In this chapter, first (section 3.1) some core chapters on land cover monitoring from leading strategic earth observation documents are presented."
The GCOS requirements on land cover data are provided from the GCOS implementation plan 2004 and from the updated version of 2010.
"For completeness, the GCOS needs and principles on land cover data are also presented."
"Furthermore, the GTOS requirements on ECV land cover data standardization frameworks are given, followed by the CMUG, IGOS-P requirements for the Land and Carbon theme and the Integrated Global Carbon Observation (IGCO)."
In section 3.2 the results of the broad user survey are summarized an visualized.
This broad assessment of user requirements ensures that the full range of needs are considered and understood for deriving the detailed product specification.
Section 3.3 provides the results of the assessment of the climate modeling community requirements.
This includes the results of the key and associate user consultation (3.3.1 and 3.3.3).
Section 3.3.2 provides the summary of the comparison of model parameters versus land cover.
"Furthermore, section land cover parameterization approaches and studies that looked into the impact of land cover data on modeling results."
"The Global Climate Observing System (GCOS) is a joint undertaking of the World Meteorological Organization (WMO), the Intergovernmental Oceanographic Commission (IOC) of the United Nations Educational Scientific and Cultural Organization (UNESCO), the United Nations Environment Programme (UNEP) and the International Council for Science (ICSU)."
"In consultation with its partners, GCOS has prepared two implementation plans (GCOS_IP 2004, GCOS_IP 2010) that addresses the requirements identified in the Second Report on the Adequacy of Global Observing Systems for Climate in Support of the United Nations Framework Convention on Climate Change (UNFCCC)."
"This Plan, if fully implemented by the Parties both individually and collectively, will provide the global observations of the Essential Climate Variables and their associated products, to assist the parties in meeting their responsibilities (under Articles 4 and 5) of the UNFCCC."
"In addition, it will provide many of the essential observations required by the World Climate Research Programme (WCRP) and Intergovernmental Panel on Climate Change (IPCC)."
"As a starting point for the Land Cover CCI project, activities have been closely aligned with specific land cover tasks listed in the GCOS Implementation Plan of 2004 (GCOS 2004) (Table 1)."
"In this plan, tasks were already listed which were an answer to up till then defined model requirements: the need to harmonize land cover monitoring (GCOS task 22), validation of models (GCOS task 23), model quality assessment (GCOS task 25), and the need for an annual land cover product (GCOS task requirements needed to model the important climate variables for land cover monitoring."
"The implementation needs to be building upon progress made to define standards for characterizing land cover and for validation procedures (GCOS Implementation Plan, tasks 22 and 23)."
"The project further addresses critical tasks that have not achieved sufficient progress to date, i.e., on the implementation of an operational reference network and validation, and to create annual maps of global land cover."
These critical tasks are taken up in the GCOS Implementation Plan 2010 (GCOS 2010b).
The following paragraphs explain the different GCOS tasks in more detail.
There is need for both maps (static and updated) and dynamic monitoring products.
The development and derivation of the mapping products need consistency in land cover characterization to be inter- operable as part of an integrated global observing system.
The broad areas and topics requiring international consensus are outlined in the GTOS document on standards for observing land cover as ECV with focus on the thematic product ((Herold et al.
"This document emphasizes that land cover is defined as the observed (bio)-physical cover on the Earth’s surface, see also the section on the GTOS requirements."
"It includes vegetation and man- made features as well as exposed rock, bare soil and inland water surfaces."
The primary units for characterizing land cover are categories (such as forest or open water) or continuous variables (http://www.glcn.org/sof_1_en.jsp) provide a comprehensive and flexible framework for thematic land cover characterization.
LCCS classifiers enable better compatibility to be achieved between existing datasets and for future global monitoring systems.
This issue will be particularly important for the legend development of the ECV Land Cover product.
The definition of the target legend is constrained by three issues.
"It is dependent on the purpose of application of the land cover map, in this case land cover parameterization for the targeted user communities and their model requirements."
Different user groups may have different requirements that will be assessed as part of the project.
"Secondly, the LCCS classifier concept is to be used as suggested by GTOS (Herold et al."
Thirdly the information for all desired classes must be available and separable from the input observation data sets to derive a product of sufficient quality.
"There is also a need to ensure synergy with other ECV observation products (i.e. Fire, Biophysical Parameters, Snow Cover) that are directly related to land cover characteristics."
"The thematic validation of the products is required to be on independent nature, follows international standards where existing and uses existing references datasets and related experiences as much as possible."
"However, the independent accuracy assessment for monitoring land cover as ECV poses additional requirements and challenges."
The validation exercise needs to explore the options to perform validations for multiple dates in time.
For historical periods the availability of reference data sets (i.e. for the 1990’s) is rather limited.
For the future there is need to develop the foundations and start implementing on operational monitoring that ensures that progressing annual global land cover datasets can assessed consecutively.
"For the validation of land cover change, different protocols and approaches will need to be used."
"There is need for an independent quality assessment to ensure that the required standards are met, and that uncertainties are quantified and reduced as far as practicable."
"While diversity and redundancy is useful for building a sustained global land cover monitoring system and to ensure flexibility in incorporating evolving technologies, there also needs to be an independent assessment mechanism led by the international community."
"This mechanism should provide a comparative assessment and validation of individual products and work towards synergy to ensure that a common framework is used for global assessments, and that the “best global estimates” are made available based on the current stage of knowledge, data and information."
"The basis for such efforts consists of sustained global network of calibration and validation sites, international agreement and standards and approaches for land cover characterization and validation, and an internal coordination mechanism, currently lead by GOFC-GOLD and the Land Validation sub-group of the CEOS WGCV."
"Several global land cover products are currently available at the requested resolution including GLC2000, GlobCover and MODIS land cover products."
"Existing global land cover products partially meet the GCOS requirements in terms of performance, as illustrated in Table 2."
It indicates that none of the available land cover products meet the requirements expressed by GCOS in terms of class accuracy and stability.
"The Land Cover CCI activities are building upon the GlobCover heritage, cooperating with the MODIS team, and aiming at consistent annual global products."
"Particular attention will be paid to these two issues, by making the best use of spectral and temporal information content in existing EO time series (through suitable pre-processing and classification processes) and by specifically addressing the issue of inter-annual stability."
"Yet, it has to be stated that not all land cover classes have the same importance from a climate modeling perspective."
"To this end, the project will also require the definition of a legend."
"According to GCOS, a common language for class definition should be used, and thematic detail should be regionally adapted in order to satisfy requirements of international conventions, and as far as possible be harmonized with regional classification schemes presently in use (See the Annex J on Land Cover of the CCI statement of work (EOP-SE 2009b, a)."
Furthermore it is expected that the product stability over time will be strongly affected by the intrinsic quality of the EO time series available for a given period.
"With respect to the potential spatial resolutions required by modelers and with respect to the key associated issues that need to be considered in the ECV development in respect of the model needs, the following GCOS product framework is provided (see Figure 5) (EOP-SE 2009a)."
"Hereby, the key principle of consistency across spatial scale, time and between ECVs shall be paramount."
The land cover product definitions must accordingly concentrate principally on the determination of land cover using MERIS FR and RR and VEGETATION data and in merging these data.
A merged VGT and MERIS RR product shall be developed from 2002 onward.
"General guidance for the generation of Fundamental Climate Data Records (FCDRs) and derived ECV products based on surface-based, airborne and satellite-based observing systems, and subsequent quality assessment by providers as well as users, is given by the GCOS requirements explained in the previous section as recommended in the GCOS_IP 2004 (GCOS 2004) and its 2010 update GCOS_IP GCOS needs overview GCOS climate observation needs)."
These requirements are based on a broad consensus by the international climate community; and are reviewed on a regular basis.
"As part of this, to ensure full documentation, transparency and scientific stewardship in the generation (and update) of FCDRs and ECV products, the GCOS Steering Committee recommends that data producers pay particular attention to the 12 needs enumerated below and provided in the Guideline for the Generation of Datasets and Products Meeting GCOS Requirements (GCOS 2010a)."
"The Global terrestrial Observing System (GTOS) is a programme for observations, modeling, and analysis of terrestrial ecosystems to support sustainable development."
GTOS facilitates access to information on terrestrial ecosystems so that researchers and policy makers can detect and manage global and regional environmental change.
GTOS and FAO define land cover as the observed (bio)- physical cover on the Earth’s surface.
"It includes vegetation and man-made features as well as exposed rock, bare soil and inland water surfaces."
"The primary units for characterizing land cover are categories (such as forest or open water) or continuous variables classifiers (e.g., fraction of tree canopy cover)."
"Secondary outputs of land cover characterization include surface area of land cover types (hectares), land cover change (area and change trajectories), and observation by-products such as field survey data or processed satellite imagery."
"With respect to land cover monitoring, the recent GTOS report (Herold et al."
GTOS emphasizes the need for coordinated observations.
"An operational global land cover monitoring integrates information from different observation scales, e. integrating coarse and fine scale satellite data and in situ data."
"ECV monitoring assumes the use of all useful data sources - from historical archives, present assets and future monitoring programmes in a seamless and consistent manner."
"Acquisitions and the derivation of standard products should be coordinated among space agencies (e.g., with support of GEO, CEOS)."
Integrated and standardized mapping and monitoring refers to the need on static and updated maps and dynamic monitoring products at different spatial and temporal scales.
These outputs require different sets of observations and monitoring approaches.
The development and derivation of the mapping products need consistency in land cover characterization to be interoperable as part of an integrated global observing system.
The broad areas and topics requiring international consensus are outlined in the GTOS document on land cover (Herold et al.
"The issue of independent quality assessment follows the need to ensure that the required standards are met, and that uncertainties are quantified and reduced as far as practicable."
"Considering the suite of important land cover information (Figure 5), there is expected to be a diversity of products contributing to ECV monitoring."
"The basis for such efforts consists of sustained global network of calibration and validation sites, international agreement and standards and approaches for land cover characterization and validation, and an internal coordination mechanism."
"One important requirement in the GTOS and FAO related requirement is the fact that land cover information has to be compatible and comparable for multi-temporal analysis and map updates, within and among countries, within and between applications, disciplines and agencies, and across local to global scales (vertical and horizontal harmonization)."
"The Land Cover Classification System (LCCS, (Di Gregorio 2005)) and the related ontology specified in Land Cover Macro Language (LCML) is currently the most comprehensive, internationally applied and flexible framework for land cover characterization."
It defines a system of diagnostic criteria (land cover classifiers) that provides standardization of terminology and not categories.
"At this level, existing land cover data can be much better compared."
The Land Cover Data Macro Language is undergoing approval to become a standard of the International Standards Organization (ISO).
"A translation of existing land cover legends and data into the LCCS language usually provides the first step in developing understanding needed to apply the classifier concept, and many existing global, regional and national land cover legends have been developed or translated using LCCS (see http://www.glcn.org/sof_1_en.jsp)."
An agreement on a set of recommended classifiers provides the common ground for compatibility of land cover data.
"Non-vegetated cover types (bare soil or bare rock, built up areas, snow, ice, open water); Density of life form and leaf characteristics in percent cover; Artificiality of cover and land use."
The agreement and application of these classifiers have resulted in a number of generic land cover categories that should be considered in future mapping efforts: Herbaceous vegetation (further separated into grasslands and agricultural crops); Open water.
"These categories are defined independently of the mapping scale, and any application of a minimum mapping unit will eventually result in mixed unit categories of these generic classes, i.e. through specifying cover percentages for the mapping units."
This general approach is suggested for all operational land cover observation activities.
International Geosphere Biosphere Programme (IGBP) is the international research program studying global change across the Earth System.
Key projects with reference to land cover include the Analysis Integration and Modeling of the Earth System (AIMES) and the Global Land Project (GLP).
Global Observations of Forest and Land Cover Dynamics (GOFC-GOLD) is a project of the Global Terrestrial Observing System (GTOS) program.
"The main goal of GOFC/GOLD is to provide a forum for international information exchange, observation and data coordination, and a framework for establishing the necessary long-term monitoring systems (follow this link for documentation of the GOFC-GOLD land cover implementation team)."
The Integrated Global Observing Strategy (IGOS) is a strategic planning process initiated by a partnership of international organizations that are concerned with the observational component of global environmental change issues.
"It links research, long-term monitoring and operational programmes, bringing together the producers of global observations and the users that require them to identify products needed, gaps in observations, and mechanisms to respond to the needs of the science and policy communities."
"Its principal objectives are to address how well user requirements are being satisfied by the existing observation systems, and how they could be met more effectively in the future through better integration and optimization of satellite, airborne and in situ observation systems."
"Theme was initially proposed in November 2003 on the recognition that IGOS-P had not yet considered many observational needs relating to many aspects of the land, such as sustainable economic development, natural resources management, conservation and biodiversity."
To satisfy these needs there is considerable overlap in the types of observations needed by different users and hence assessment of the needs for enhanced observations is discussed under types of observations.
Land cover products are recognized by IGOS as having a central role for all applications.
Several observation needs and technical requirements are identified in the IGOS report.
"A critical requirement is identified to move from research to operational monitoring capabilities for land cover, with operational data and product suites that are better defined, flexible and openly available."
Agree upon an internationally accepted land cover classification system; Coordinate international collection of in situ data for calibration and validation efforts.
The overall goal of the Integrated Global Carbon Observation (IGCO) theme is similar to the overall goal of the ECV Land Cover project: to develop a flexible yet robust strategy for deploying global systematic observations of the carbon cycle over the next decade.
"Indeed, the most successful advances in understanding springs from the combination of data and models for the different domains, wherein results from one domain place valuable constraints on the workings of the other domains."
"The strategy for a coordinated system of integrated global carbon cycle observations (Ciais 2010) is first of all carbon crosscut of GCOS, GTOS , and GOOS (GOOS) and secondly an identification of new components not previously identified."
"The coordinated system of global carbon observations will be built around complementary core groups of observations to address three themes: fluxes, pools, and processes."
The first set of observations enables quantification of the distribution and variability of CO2 fluxes between the Earth's surface and the atmosphere.
"As part of this, land cover products are needed to create a combination of satellite observations, backed up by a long-term continuity of measurements, delivering global observations of parameters that are required to estimate surface-atmosphere CO2 fluxes where direct in situ measurements are scarce."
"The crucial satellite observations that are required for this are among others: land cover status, disturbance extent and intensity, parameters related to vegetation activity, ocean color."
"The second set of observations focuses upon changes in the key carbon pools, one of them being forest biomass."
Forest biomass inventories are important for monitoring changes in the above-ground terrestrial carbon pool size.
"At present, however, these inventories are primarily designed to quantify the volume of merchantable wood in a given region with high accuracy (standard error of 1% at the national level)."
This quantity relates in a predictable manner to carbon stored in tree biomass.
"Allometric equations relating biomass to diameter, height and tree age factors are needed to convert these volume estimates into whole tree carbon content."
"Using constant conversion/expansion factors, as is usually done, results in large errors, since both wood density and expansion factors vary considerably with age and between species."
"Further, conversion of volume increment obtained from repeated inventories into carbon sequestration needs an extra set of expansion factors that take into account differences in turnover rates of different plant organs."
"Much work has yet to be done to create continuous, standardized, geo-referenced forest biomass and soil carbon inventories."
"It is critical to harmonize the widely varying methodologies for inventory and analysis, in order to synthesize carbon estimates based on national forest inventories."
"In addition, a major observational challenge is to establish allometric functions converting above-ground biomass to total biomass."
"Further work is also needed to expand the coverage over non-commercial forests and woodlands, over tropical forests, and to develop satellite technology (LIDAR or Radar) for remote sensing of biomass."
SAR data are expected to contribute to estimating biomass.
"There is a need to build systematic, repetitive, spatially homogeneous and well coordinated global observation strategies for forest mapping by high resolution SAR."
The third set of observations in the system is measurements related to important carbon cycle processes.
"Most of these will remain in the research domain, to be coordinated within the framework of the Global Carbon Project."
"Two process-related observations, however, are more appropriate for the operational domain and will become part of the core set of the system."
These can be monitored by using land cover products.
"Fire distribution (hot spots) and burned area extent, to estimate the fluxes of carbon that are emitted during fires."
"Fire hot spots will be measured on (sub) daily time steps, with fire extent at monthly intervals."
"Land-cover change, to estimate the fluxes of carbon associated with forest clearing and reversion of agricultural lands to natural ecosystems."
The sampling interval will be 5 years with a spatial resolution of 1 km.
The land-cover change observations should also emphasize forest/non- forest transitions at higher spatial resolution (25 m).
The ultimate goal of the coordinated system of global carbon observations is to generate data products that are of value for the user communities.
"To create usable products, in situ measurements from a variety of sources need to be integrated with remote-sensing observations within a modeling framework."
"To achieve this, a major challenge is to collect, process and harmonize in situ data from diverse sources."
"At present problems with in situ data include, among others, inconsistent parameter definitions, incomplete data, differing spatial and temporal scales and sampling bias in measurements."
The broad user survey aimed at obtaining user requirements coming not directly from climate modelers but the “climate concerned” users such as those making use of land cover information for other societal benefits or national reporting and accounting.
This group represents the broad land cover data user community.
The broad user survey consisted of 12 closed questions and was online for a period of 21 days (24th Sept. 2010 to 15th Oct. 2010).
The user survey was send to the list of registered GlobCover users with more than 8000 addresses.
This group is perhaps currently the most active global land cover user community and quite suitable for border user requirements since the Land Cover CCI activities are building upon the GlobCover heritage.
"The total number of answered surveys was 372, from which 79 were only partially answered."
These partially completed surveys are only included in the results for the completed answers.
"In Figure respondents is working in a University/ Research institute, and 21% is working in the commercial sector (Figure 8)."
"The applications where the respondents use the GlobCover product for are mostly in the field of natural resources (28%) and Information technology/GIS (27%) followed by Remote Sensing (19%), Climate/ Meteorology/ Hydrology (16%), and Cartography (10%)."
"In general, the majority of the respondents (70 %) indicate that the required spatial resolution of the land cover products should be smaller than 300 m (Figure 9)."
For 20% of the respondents the current global standard spatial resolution (300-1000m) would be sufficient.
"When looking at the application type, climate users tend to prefer a coarser spatial resolution while users working in the field of natural resources prefer a more detailed resolution."
"On the question in what frequency updated versions of land cover products should be available, 70% of the respondents replied that a yearly update would be sufficient, while 27% of the respondents replied that a product every 5 years would be sufficient and only 8% of the respondents requires an update every 10 years (Figure 10)."
Users from the natural resources field prefer a less regular update frequency compared to the other applications fields.
"With regard to defining classification requirements, the question was asked which land cover classes are most important for the application case of the respondent."
"From the results (Figure 11) it can be seen that most respondents are interested in all classes with no particular emphasis, while the tree classes are most important as an individual land cover class followed by agriculture, urban and wetlands."
"In the field of land dynamics monitoring, the respondents are most interested in forest change monitoring (52% of the respondents), followed by urbanization and urban sprawl(23%)."
"Of those respondents who disagreed with the use of LCCS as classification system, some of them suggested to use a classification based on the Corine Land Cover product."
"Comments on the use of LCCS were mainly on the (fuzzy) way in which the classes are defined, and a need for greater sensitivity to different vegetation classes in the LCCS."
"Concerning the question on the preferred technique for downloading and the preferred file formats in which the land cover products should be available in the (near) future, the use of FTP servers in combination with GEOTIFF file formats or HTTP servers in combination with GEOTIFF formats was given as the preferred data access and delivery method (more than 90% of replies)."
"Torrent servers and HDF-EOS, and NetCDF file formats are significantly less popular to use for data access and delivery."
The key user consultation for the product specifications includes the partners and processes directly involved or associated with ESA through CMUG and being partner in the Land Cover CCI project.
The objective of this key user consultation was to provide detailed requirements on land cover data characterization as defined by the key users of the project.
"This is done by (1) actively engaging in the CMUG process (2) organizing and implementing a key user interaction and product specification meeting to finalize the Land Cover CCI product characteristics as dialog among users (implemented primarily through meetings) and producers and (3) conducting a detailed user survey on the specific requirements for land cover data characteristics to be used in the key and associate user models (spatial, temporal, thematic detail, accuracy requirements)."
"ESA has established the ""Climate Modeling User Group"" (CMUG), to place a climate system perspective at the centre of the CCI program, and to provide a dedicated forum through which the EO Data Community and Climate Modeling Community can work closely together (see also CMUG In a recent climate requirement baseline document (CMUG 2010), CMUG states that global land cover and land cover dynamics is an important variable for global and regional climate modeling over many time scales."
Land cover information is used in climate models for the initialization as well as a boundary condition.
"Besides this, detailed regional land cover information provides very valuable information for process studies like e.g. the assessment of the impact of fires."
"For land cover monitoring, CMUG defined several requirements for future land cover products."
"CMUG recommends that despite the fact that land cover data provides essential spatial patterns of different land cover types, land cover classes have to be translated into model relevant surface parameters that can be used in the model equations."
"Concerning the translation of land cover data into model parameters, it is recommends to make use of literature data (Hagemann 2002) or remote sensing based climatologies like ECOCLIMAP (Champeaux et al."
These methods and conceptual frameworks are according to research done by CMUG (CMUG 2010) used by most climate and earth system modelers.
"Furthermore, GMUG expresses the need to have a land cover product that is consistent with surface parameters datasets and needs to match albedo, fapar, etc."
"A variety of different global land cover products already exist (e.g. GLOBCOVER, MODIS) for limited time periods, but these products lack consistency in time."
CMUG also recommends combining land cover information with observed variability of land surface characteristics which would be essential to improve the description of land surface dynamics in climate models.
"While methods have been developed to retrieve consistent land surface parameters from satellite data these have not yet been combined with high resolution land cover information to generate a consistent, remote sensing based, land surface parameter data set which can be used as a boundary condition in climate models."
The Land cover CCI should aim at delivering a product meeting these requirements with a possible extension of the approach to longer timescales and an appropriate error characterization.
"The key user survey was performed during September and October 2010, and consisted of 27 questions (mostly open questions)."
Six key-users from three organizations representing 4 climate models were consulated for this survey.
"All three organizations (Max Planck Institute for Meteorology (MPI-M), the Laboratoire des Sciences du Climat et de l’Environnment (LSCE) and the Meteorological Office Hadley Center (MOHC)) are also participating in the Climate Modelling User Group (CMUG) of ESA CCI."
"The answers to the questions were divided in answers on land cover product requirements for three different time-frames: (a) current status/used in current models, (b) requirements as needed to improve current modeling practices, and (c) requirements needed in 5 years time, also considering new modeling approaches."
"According to agreements made during land the Cover CCI kick-off meeting and to reflect the CMUG need that land cover data have different types of uses for climate modeling, the survey was divided in 4 different themes: (1) General land cover requirements for climate modeling, (2) Land cover as proxy for land surface parameters (3) Land cover as proxy for human activities, and (4) Land cover for validation of model outcomes."
Specific questions were formulated to assess the requirements for all these elements.
The complete key user survey is presented in Appendix C. From the survey results it can be concluded that the key users that were consulted have a broad interest in earth system/ climate modeling and thereby represent to a broad extend the climate / earth system modeling community.
"Their main interest is in carbon (stock) modeling, vegetation modeling, plant- soil-carbon modeling, nutrient-cycling modeling and coupled earth system modeling (e.g. atmosphere- ocean-biosphere modeling)."
The most popular land cover products and –data that are currently used or have been used by the key users are developed in the time-frame 2000-2005 (Figure.13) but also older products are still commonly applied.
The most frequently used dataset is the IGBP Discover and GLCC as provided by USGS.
"However, for most model application a combination of land cover datasets is adopted."
"This document is the property of the LAND_COVER_CCI partnership, no part of it shall be reproduced or transmitted without the express prior written authorisation of UCL-Geomatics (Belgium)."
The consistency of the current land cover data with the key-users’ model requirements received a varying rating ranging from sufficient to rather insufficient.
"For example, the matching-up of datasets created in different periods according to different classifications is described as a problem concerning the consistency of current land cover data with the key-users’ model requirements."
"Linked to these difficulties concerning land cover product classifications, the main reason of interoperability problems is identified in different definitions being used for key-attributes in datasets and models."
Also differences in spatial and temporal resolution are regarded as reasons for interoperability problems.
"Furthermore, the allocation of model parameters and the transformation of land cover data to other information, due to interpolation issues, remains a source of inaccuracy."
"Regarding classification, a major issue is that the assignment of a given biome to a certain Plant Functional Type (PFT) is not at all straightforward."
"Even if for example the Olson classification (1994a, 1994b) is used this remains an issue since common PFT types are not directly represented in land cover products, especially with regard to crops (C3, C4), grasses (C3,C4) and wetlands."
"Due to these classification and resolution (temporal and spatial) problems, difficulties and inaccuracies arise in attempts to create combined datasets for running climate models if datasets for the historic period and present day situation are combined used as model input for studies on future scenario’s."
"The accuracy of the land cover product for continental/ regional scale modeling is regarded as poor, for the global scale modeling it is regarded as moderately sufficient."
"For one user where models are applied to different spatial extends, the accuracy of the land cover products is rated very good to moderate."
"Going from current to future model requirements, a trend towards an increase in required spatial resolution of land cover datasets can be identified (Figure 14)."
"However, the magnitude of the spatial resolution required differs for models at different scales."
"For example for global applications, future requirements for spatial resolutions of 1 km were mainly mentioned in agreement with currently available global datasets."
"However, for specific local to regional applications, spatial resolutions up to products over the coming 5 years (Figure 15)."
For current models including improvements there is a general agreement on a yearly update with a detailing in seasonality.
"However, the introduction of new modeling approaches will require temporal frequencies for some classes up to a monthly resolution."
"Furthermore, in order to improve current models and feed improved model approaches within 5 years, higher demands are put on the temporal ranges available of input data."
"For some global models, temporal ranges up to 10.000 years will be required."
"To produce accurate model output with relatively short simulation steps, historical data of high quality (spatial and temporal resolution) is required."
This sets the requirement for land cover data to 250-100 year historical data for global modeling purposes and yearly to half yearly data for modeling where crop rotations are taken into account.
The key users each have their own approach in translating land cover classes to plant functional types (PFTs) and vise versa.
"In some models, the Olson major ecosystem types (1994a, 1994b) are indirectly being used for defining PFTs as the land surface parameters are based on their distribution from the associated USGB dataset."
"In Figure 16, relative importance on which PFTs are used for land cover classification is displayed, and which PFT classes need to be incorporated and extended in future modeling approaches."
Some key users pointed out that within 5 years time classification schemes must be created that can deal with wetlands and especially with permafrost classification.
"Besides the use of land cover products to estimate the total area under a certain PFT, land cover product can also be used to determine land surface parameters."
"Examples of these land surface parameters mentioned by the key-users are: Albedo (surface, vegetation, snow), Vegetation roughness, vegetation fractions, Leaf Area Index, total soil water holding capacity, canopy height."
"In case the key-users use and/ or require multi-temporal land cover data for parameter estimations, the preferred seasonally."
"With regard to the monitoring of land dynamics triggered by human activities, the main interest lies in the topic of conversions between different land cover types resulting in e.g. urbanization, deforestation."
"Furthermore the interest of the key-users in human induced land dynamics lies in the field of specific agricultural land management practices and crop rotations, anthropogenic fire activities and land management practices as irrigation."
"A trend towards an increased frequency of available land cover products required for tracking human activities and land use change observations considering the frequency currently available, expected to be required to improve current modeling practices and the resolution needed in 5 years when new modeling practice are considered can be seen in fig."
"The thematic information that is of most importance for describing human activities and disturbances are currently classes describing different land use types focusing on crop types (C3, C4) and grassland."
"For future modeling practices on defining human activities and land cover dynamics, the following land cover classes will become important : crop and pasture/ grassland varieties (C3, C4), irrigated areas, forest, urban areas, specific agricultural land management practices and fire activity."
In Table 6 the model parameters are represented that are (expected to be) validated using land cover products and related observational data.
For each of the above mentioned parameters that would be validated using land cover data (Table 6) more specific information is provided on the level of detail required of the land cover product (Table 7).
"Besides land cover datasets, other datasets can be of great importance for modeling practices."
These datasets should be consistent with land cover datasets.
The most important datasets for modeling practices except from land cover products were: Digital elevation model; Water use; Soil data; photosynthetically active radiation (FaPaR); Biomass; Leaf area index (LAI); Fire disturbance and Soil moisture data.
"Also, more information on the character of the urban landscape is required."
"Concerning data access and data delivery, all responding key users agreed on the latitude/ longitude system as preferred cartographic reference system of land cover products."
Also the data format that is most convenient for land cover products was suggested uniformly as NetCDF.
"For land cover data delivery, the most popular delivery method is identified as the FTP server or a combination of web services and a FTP server."
"The current data retrieval process of input data is regarded as easy to moderately easy, however, it is also d that this is very data dependent."
"The relationship between land cover types and model parameters is one of the most important issues determining the accuracy and relevancy of land cover data for parameterization, calibration and validation of climate-related models."
"As described in the previous sections, land cover data are commonly used to consistently estimate quantitative land surface parameters."
The CMUG user requirements document (CMUG 2010) addresses this issue and mentions the work of Hagemann (2002) as one basis to provide a better quantitative understanding why and on what level of detail and accuracy climate users require thematic land cover information.
"In Hagemann (2002) a series of nine land surface parameters are derived from the Olsson land and ecosystem map (1994a, 1994b) using literature data and expert analysis."
We used these data to analyze the relative importance of different land cover classes for estimating model parameters.
The importance of each differentiating two land cover classes is reflected in the relative similarity for each actual land surface parameter value.
The similarity value is reported in percent with 100% representing the same parameter value for this pair of classes.
The result is a symmetric matrix of 75x75 classes for each of the nine surface parameters.
These large matrices contain important information but will be presented here as selected and aggregate results.
For different land surface parameters the pattern of class similarity is rather different.
"For Albedo, there are a few classes that obviously have a very different value (Snow, ice, water) than many of the other classes that are relatively similar."
"For the forest ratio, there is more of an equal distribution among the range of similarity values."
This highlights that the relative importance and thus accuracy of land cover categories for model parameterization varies depending on what model parameter is estimated from the data.
A single overall accuracy for a land cover map value will not be able to provide the information on how accurate a specific map is for parameter estimation.
"The Olsson map provides a series of categories with more or less consistent thematic definition drawing from land cover and vegetation types, climatic conditions, different levels of mixed classes and others."
To provide some information we have grouped the classes into major land cover categories used for previous global land cover comparison studies and somewhat reflecting the GTOS requirements for land cover (Herold 2008).
The areas with pink table cells have the highest average similarities among all land surface parameters.
There is a tendency that they are located near the diagonal of the matrix reflecting somewhat the ranking of classes 1-12 from Forests to barren and water areas.
Most dissimilar are the non-vegetated and vegetation classes.
A misclassification and confusion between two classes with large similarity will cause a much lower error in the quantitative parameter estimation than uncertainties among very dissimilar classes.
A group of 85 users from the climate modeling community was approached to fill in an online survey on their user requirements for current and future land use data requirements.
"The survey was performed in October 2010, and consisted of 16 questions (Appendix B)."
"For a selection of the questions, land cover product requirements for two time periods needed to be selected: (1) current status/used in current models, and (2) requirements needed in 5 years time, also considering new modeling approaches."
"In addition, land cover requirements were assessed for four different climate model aspects as presented in section 3.3.1 for the key user assessment: (1) land cover requirements, land cover as proxy for land surface parameters (3) land cover as proxy for human activities, and land cover for validation of model outcomes."
Selection of the group of so-called associated users was based their role as being main developers for a certain type of climate or earth system model (Appendix D).
"From the population of 85 users, 15 filled in the questionnaire resulting in a response rate to the associate survey of 18% from a broad range of countries all over the globe."
The results of the associate user survey show that land cover data are applied for a broad range of climate modeling applications (Figure 18).
Respondents were mostly applying their models at global scale (53%) or national scale (27%).
A broad set of different available land cover datasets are used where the most frequently mentioned are the IGBP Discover and GLCC datasets as provided by USGS and FAO statistics (Figure 19).
The results also show that in many cases land cover datasets for different coverage periods are combined to derive a time-series of land cover development.
"In general, the accuracy of the land cover product for climate model application is judged as moderate till good."
The user requirements for the spatial resolution reflect more or less the model application at global and national scale with preferred grid size of 100m and 0.5 degrees respectively (Figure 21).
"Looking at requirements for climate modeling application in 5 years, the results show that a more detailed spatial resolution is required but still the global model applications will use resolutions between 0.25 and 0.5 degrees."
Temporal resolution requirements for current model application are mainly on a yearly basis with some preference for high-frequency data up till daily but and for global applications with an update frequency from 5 till 10 years (Figure 22).
"However, there is a clear future need for more seasonal products with a quarterly till half year temporal resolution which would be able to track the seasonality of agricultural crops and forest ecosystems."
User requirements for the thematic aspect of land cover datasets indicate that agricultural classes are very important while also for current modeling applications natural vegetation classes (forest and herbaceous) are seen as important (Figure 23).
"However, for future modeling application it is anticipated that a proper representation of urban and wetland classes will become more relevant."
This agrees with the results of the key-user survey.
"When looking more specific at information requirements on human activities/disturbances or dynamics (Figure 24), the outcome of the survey shows that currently forest loss, agricultural expansion and vegetation phenology are important processes which are taking into account in the initialization or evaluation step of the climate models."
"For the next generation models, aspects wetland dynamics, urban expansion and long-term vegetation development will become important processes to take into account."
"Within the modeling process, land cover products are also adopted to determine land surface parameters which are then use to initialize the climate models."
"For example, Leaf Area Index (LAI) is one parameter that is regularly derived from land cover datasets."
"Although several other parameters are already derived from land use data, it is anticipated that especially future climate modeling approaches will increasingly apply this mechanism for parameters like vegetation albedo, vegetation roughness and plant water holding capacity."
"Finally, the application of land cover data to validate climate model output was assessed (Figure 26)."
"For future modeling applications, land cover data will increasingly be adopted to validate net primary production (NPP), albedo and LAI."
"Concerning data access and delivery, 50% of the users prefer latitude/longitude as cartographic reference system while in addition a broad range of other systems were mentioned: UTM (Albers), equidistant (Lambert Azimuthal), Transverse Mercator."
As most convenient data formats for delivery were mentioned NetCDF (50% of users) and GeoTIFF (45% of users).
"For data delivery, FTP (50%) and the combination of web services and FTP (e.g., request via web service and de-livery through FTP) (42%) were mentioned as most frequent options."
The broad assessment of existing (climate) models and accompanying user requirements aims at examining how land cover data have been used in climate models and which future needs can be identified for modeling practices.
"Below, the results from a standard literature review of key scientific papers published primarily since 2005 is presented."
"The performed review focused on current use of land cover data for climate modeling and on the identification of future needs, model requirements and -prerequisites."
Special attention is paid to highlight innovative concepts and approaches to better reflect land dynamics in the next generation models.
"This review includes different modeling approaches and communities, i.e. Earth System modeling community, Integrated Assessment modeling community and the Impact, Adaptation and Vulnerability community (Hibbard et al."
These specific time-frames were selected to make a division between urgent needs and requirements which should be put on the short term agenda and requirements that are still urgent but less pressing.
"The results are presented below and are, where applicable, linked to GCOS tasks for land cover as defined in the GCOS implementation plan."
Standardization of land cover products with regard to the definitions of classes and their thresholds is an important issue (Jung et al.
"This issue is also addressed in the in 2004 defined GCOS Implementation Plan (IP) task 22, which promotes the harmonization of land cover monitoring by creating international standards for land cover maps."
"It is widely acknowledged that land data products should ideally be produced by using a hierarchical, standardized land cover classification system which should be applied to validated land cover data and to time-series of data integrated at an appropriate scale (Lepers et al."
Land cover products often lack class specific accuracies and categories have large interclass variances (especially for mixed vegetation classes) (Jung et al.
"Plant functional types are often used as a basis for class definition (Olson 1994a, b), however more research is needed on the effects of wrong categorization of plant functional types on C:N ratios (Ostle et al."
In a more general sense it is stated that parameters must be used that are both mechanistically important and measurable (Ostle et al.
This need to validate parameters requires (new) methods for land cover map accuracy assessments (Williams et al.
"For example, knowledge about class specific accuracies of the product can, in conjunction with calculated fuzzy agreements be used to generate a map of confidence of the final product (Jung et al."
"Despite of such methods, validation of land cover maps remains an issue as was already addressed in GCOS task 23 (IP 2004)."
"Even if pre-defined land cover classes are used, as in e.g. land cover products provided by the FAO (Di Gregorio and Jansen 2000), global land cover is often inconsistent with land cover data and actual practices."
Accuracy assessment and error reduction should be improved (Williams et al.
This point was also raised as part of the 2004 GCOS task 25 ‘development of an in situ reference network for land cover’.
Models need to be more obviously comparable to the real world (Friedlingstein et al.
This may increase the reliability of for example the model estimated European carbon balance in the future (Vetter et al.
"Per definition, it is not possible to correctly interpret carbon cycle simulations if the overall-, user-, and producer accuracy is not known (Jung et al."
"Therefore, there is an urgent need for a network of ground and satellite based long term land cover monitoring (Jain and Yang 2005)."
"Thereby, the benchmarking of global models is a key-procedure and an expanded set of data for evaluation of short timescale dynamics for benchmarking is required (Sitch et al."
These datasets can partly be generated by linking optical remote sensing products which provide critical information on e.g. canopy structure and crop phenology (Williams et al.
"Furthermore, the scientific community suggested to further expand the FLUXNET tower network to obtain critical data on carbon exchange (Williams et al."
Special attention should be paid on the parameterization of albedo and the representation of crop phenology and the representation of evapotranspiration for different land cover types (Pitman et al.
"Therefore, the in 2004 defined GCOS task 26 which focuses on the creation of annual land cover products and GCOS task 27 which focuses on the creation of a regular fine resolution land cover (change) map, are still relevant and urgent tasks that should be dealt with on the short term."
"Summarizing, on the short term different issues should be addressed to deal with problems regarding the definition of land cover classes; classification of land cover data sets; variation in spatial resolution of the data sources and variation in temporal and spatial coverage of data sets."
"Furthermore, earth system model and climate model outcomes should be validated against reference data, preferably using fine resolution land cover datasets that can be provided on a regular basis In the previous paragraph, the short term requirements for earth system modeling and climate modeling as found in key-articles are presented."
"In this paragraph, requirements for a more long term (1-5 year) scope are discussed."
"More research on model- and data fusion is needed: multiple and different types of data, including associated uncertainties need to be integrated together with prior knowledge on model parameters and/or initial state variables (Ostle et al."
"More effort should be put in generating new information by combining existing data, for example by linking Eddy Correlation towers effectively with atmospheric column CO2 measurements generated by satellites like OCO and GOSAT (Williams et al."
"Besides model- and data fusion, there is also a need for an integral vision on the actual (eco)systems that are modeled."
"For example for ocean carbon cycle modeling there is a need for more complete treatments of ocean ecosystems, micronutrient limitation, and oceanic acidification impacts on calcium carbonate cycling (Friedlingstein et al."
"To advance scientific understanding and enhance data- and model integration, the earth system modeling and integrated assessment modeling communities have to collaborate closely with the remote sensing community (Hibbard et al."
"Regarding the use of land cover products as model input, some specific requirements for land cover change monitoring are addressed in literature."
"For the location of land cover change detection, land cover should be extended to regions that are not known as hotspots but where rapid changes may still take place and catch the scientific community by surprise (Lepers et al."
"Furthermore, the importance of including land-cover change in forcing scenarios for future climate change studies should be d."
"By accounting for a number of additional anthropogenic climate impacts, land cover forcing can be included which will improve the quality of regional climate assessments as e.g. IPCC SRES scenarios (Feddema et al."
"In addition, it is stated that without accounting for historical land cover changes, observed atmosphere CO2 growth cannot be explained (Brovkin et al."
This implies the need to incorporate historical land cover change into carbon exchange/ stock models.
"More research is required on the effects of land cover change on changes in land-atmosphere exchange in greenhouse gases, reactive trace gases and aerosols (Pitman et al."
"Linked to the requirement for earth system modeling to incorporate land cover change, the decline in land suitability due to soil erosion, acidification and salinization also need to be taken into account (Ramankutty et al."
"Besides a better understanding of the required model inputs, a more process based understanding of earth system and climate models is needed."
There is a need to critically evaluate the representation of plant-soil processes in global models (Ostle et al.
Also applied concepts of carbon-water cycle interactions regarding the representation of canopy conductance and soil processes need to be revisited (Jung et al.
"In general, a greater process-based understanding of large-scale plant-drought responses and interaction with wildfire and land use is needed and should be filtered in the next generation Dynamic Global Vegetation Models (Sitch et al."
"As a part of obtaining more knowledge on the models’ process understanding, more research should be done on model equifinality: where different model representations, through parameters or model structures, yield similar effects on model outputs, and so can be difficult to distinguish (Williams et al."
"For the short term, the implementation of several GCOS tasks (task 27 and 28 of the in 2010 defined GCOS tasks) will meet this demand."
"For the longer term, the scientific community addresses the need to set up storage and computing facilities to facilitate the collection of all data and provide a web- based interface for data exchange (Jung et al."
"As computational power, needed for e.g. millennium scale carbon cycling becomes available some studies can be repeated at different scales and across e.g. a range of different global carbon models (Pongratz et al."
"With regard to the FLUXNET network (used as validation for modeling practices where land cover data is used), it is suggested to improve data collecting facilities by nesting Eddy Correlation towers within the regional footprint of tall towers that sample the CO2 concentration of the planetary boundary layer (Williams et al."
"For the long term (> 5 years), defined requirements are strongly process based."
"For example, the role of nitrogen in earth system modeling should be clarified (Jung et al."
Nitrogen supply from soil organic matter is not known accurately and introduces uncertainty (Ostle et al.
"Furthermore, potential (in)direct effects of climate change on land use change and land cover change must be made quantitative."
"Due to an increase in greenhouse gases the area of land that is cultivable might increase, but yields might decrease."
This has to be taken into account in the future for example in a crop productivity parameter.
Also the effects of climate change on soil properties need to be accounted for (Ramankutty et al.
"Up till now, the effects of land-cover change on climate has been difficult because different bio- geophysical effects offset each other in terms of climate impacts, and, on global and annual scales, regional impacts are often of opposite sign and are therefore not well represented in annual global average statistics (Feddema et al."
"In this assessment we have implemented a detailed requirements analysis for a global land cover product that should meet the requirements of GCOS and other international panels, and the climate user community."
The study interacted with different types of users through different interaction mechanisms (Figure 27).
"Overall, three user surveys were completed for the broad, associated and key users respectively."
"While the frequency of responses vary, the amount and quality of feedback is suitable to derive a good synthesis on what climate modeling users need and expect from a new land cover product."
"In general, there is quite a good match among the requirements coming from different sources and the broader requirements derived from GCOS, CMUG and other relevant international panels (section 4.1)."
"In general, land cover has been and remains a fundamental dataset as consistent input to climate models and for the integration of other data sources."
"While it is assumed that any new land cover datasets should be better than previous ones and improve climate model and assessment performance, there are several ways land cover feed into different climate applications."
It has been emphasized that there is a need for both stable land cover data and a dynamic component (time-series and changes).
"Concerning the first item, land cover information act as proxy for a suite of land surface parameters that are assigned based on PFTs."
This parameterization is a complex process and is often not redone with every new land cover map and has commonly lead to little innovation in taking up new and updated datasets for climate model applications.
Consistency is the key requirement and thus one fundamental (land cover) dataset is the base for series parameters.
Some users have stressed that consistency among the different model parameters to be more important than accuracy of individual datasets.
This puts more burden on the accuracy of the land cover data since related errors propagate to all parameters.
The second item addressing the need to use land cover as proxy for human activities is important to study long-term effects (and feedback) on climate and for the carbon cycle (short-term impact on stocks and fluxes).
"Needs were articulated to provide natural versus anthropogenic vegetation (disturbed fraction) and to track human activities and define history of disturbance, i.e. land use affecting land cover with most detail needed for focus areas with large anthropogenic effect."
The third issue highlights the needs for the validation of model outcomes or to study feedback effects.
More process oriented models need less data for input/calibration but more for validation of outputs.
Validation can be regional or local but data must be of high quality and consistent.
"Common examples include time series, min/max values of parameters, vegetation types, biophysical variables and others."
"There are three types of quantitative requirements provided for the accuracy of the CCI land cover products coming from GCOS, the CMUG and the CCI."
"Given the fact that available land cover maps have an overall area weighted accuracy of around 70%, it can be assumed that the accuracy requirements for the land cover CCI should be higher."
"Secondly, GCOS requirements mention a maximum of 15 % omission / commission per class, those from CMUG and the CCI an error of 5-10 CMUG further requires stability in accuracies over time of less than 10% (Table 5)."
The accuracy of the products depends on its actual use in the model.
In particular the analysis of the model parameters versus land cover types has emphasized the relative importance of different class accuracies heavily varies depending on which parameter is estimated (section 3.3.3.).
This is an important implication that cannot be considered by using a standard overall accuracy reporting.
Any accuracy analysis should provide flexibility to account for such differences in how land cover data are used in models and the related impact on the uncertainty of the input data.
"The users also stressed the need for quality flags and controls, the probability for the land cover class or anticipated second class or even probability distribution function for each class (coming from the classification algorithm), and the need for accuracy numbers for land cover classes (potentially also with regional estimates)."
The users provided detailed information on the level of spatial detail they require and the results are summarized in Figure 28 and 29.
"First, there is not one spatial resolution that fits all purposes; it is important that the land cover product provides flexibility to serve different scales and purposes."
"On average, climate models run on broad spatial levels of detail and a resolution of 300 m or coarser is sufficient to meet modeling requirements for most users."
"However, for some and in particular for future periods (see figure 29) there are requirements of more detailed resolutions."
"This would mean that land cover observations to estimate model parameters and for description of change would need towards fine-scale satellite observations coming from Landsat- type observations in the coming years (e.g., Sentinel-2)."
Many users use annual updating of parameters initially derived from land cover data.
"While annual data are currently not available for land cover, the modeling community is using interpolation and ancillary data (i.e. from the literature or models) to provide the temporal detail required."
"The need for increased temporal resolution data is pertinent among all user groups, in particular for future periods moving into considering intra-annual and monthly dynamics of land cover (Figure 30 and 31)."
"While any addition to the temporal resolution of the currently often static land cover data is useful, the need to explore the potential of dense remote sensing time series signals is of fundamental importance."
"In terms of the temporal range, models use periods beyond the remote sensing era back in time and this range is expected to further increase in the future."
"While almost all major land categories in current maps are of importance, Figure 32 particularly highlights the need for forest, herbaceous, and agriculture classes in current models."
"Considering all users, the need for wetland and urban classes is expected to increase in future model and other land cover applications."
"Given the fact that users require a suite of different types of land cover categories (or plant functional types) for model parameterization that varies with type of model and modeling approach, any land cover product will need to provide some flexibility in responding to these different thematic needs."
The broad user survey has shown that more than 90% of the users find the UN Land Cover Classification System a suitable approach for thematic characterization; an approach which is also compatible with the PFT concept of many models and the concept of land cover classifiers.
C3/C4 grasses and crops and the consideration of human activities and land management practices.
"For example, the “disturbed fraction” has been advocated as one of such requirements."
"The different functional responses of C3 and C4 plants to nitrogen, radiation, and temperature makes this separation is important."
The priority for users is the separation of C3 and C4 grasses; secondly C3/C4 crops.
"Earlier studies have indicated the potential to derive estimates of the C3–C4 composition of grasslands from satellite sensor data (Foody and Dash, 2007)."
"In particular, simple measures based on the temporal variation in the spectral response of MERIS images explain 60–65% of the variance in grassland composition."
"However, a more recent study showed that MERIS Terrestrial Chlorophyll Index (MTCI) composites of the Great Plains in US relationship between MTCI data and grassland C3-C4 composition may be formulated for the State of South Dakota with R2 similar to 0.6 (Foody and Dash, 2010)."
To reduce the uncertainty for parameters which are derived from remote sensing datasets (i.e. C3/C4 separation) the use of external products or non-satellite derived data maybe needed in addition if it improves accuracy and parameter estimation procedures.
"For example, for the models operated at MPI-M (JS-BACH, REMO), all Olson classes (or fractions of), that are transferred into grasses, the separation into C3 and C4 grasses is conducted is based on work by Knorr (1997)."
The users also stressed the need for data on irrigated rice areas.
A fair amount of users (in particular the key users) do not use any change or dynamic products from land cover remote sensing in their current modeling.
"In addition, the needs for monitoring wetland dynamics, fire, land degradation and long-term vegetation trends are highlighted by the community of associated users."
It is also important to note that about half of the broad user community and one fifth of the associated users did not mention the need for any change/dynamic information.
"This re-emphasizes that fact that there is need for both stable and accurate land cover, and dynamic component reflecting time-series and changes."
The key climate users for this project were asked for their requirements on meta data and quality control information.
"There is need for metadata, including various data required to be made available with the satellite climate data records."
"Examples include a timeline of both satellite and instrument related anomalies, documentation on version of level 1 processing, what ancillary datasets have been used in the level 2 processing etc."
"An XML document with a well defined schema which clearly defines the instrument, its measurement technique and the analysis method used to retrieve the data record."
"CMUG mentions it would be helpful if the schema could, at the top level at least, share some of the structure which has been developed by the EU FP7 project METAFOR to describe climate models and their output."
"For example, descriptions of institutions could use the same schema elements."
"Next to standard metadata items, some specific requirements were mentioned by the user assessment: 1) validation information: specific areas which were checked with in situ data, and level of agreement with other land cover datasets; 2) clear description of classification methodology and underlying assumptions (e.g., cloud and snow mask); 3) information to support assessment of consistency with other EO derived products (e.g., albedo, vegetation-activity)."
It was mentioned to add a metric which shows how far the actual pixel value of albedo for example is deviating from the median temporal evolution of the average of the same land cover class.
This would allow to identify pixels which are less reliable (representative) and would give the possibility to make sub-classes for these pixels.
An alternative could also be to provide the distance of the pixel to the mean of the assigned class in feature space as used by the classifier or even better the probability that the pixel actually belongs to the class it was assigned to.
Information on the quality of the land cover products is considered as important to assess the applicability of the products in relation to its application.
This information is used to make a choice on which land cover dataset is used in the climate model and for interpretation of climate modeling results in case biases can be related to land cover information in the simulation of associated variables.
"At the most basic level, quality information should be available in the form of class accuracy estimates."
"As a next step, more spatial explicit quality estimates are required: per pixel probability for a land cover class and the anticipated second class."
It was mentioned that the BEAM toolbox as provided through ESA gives the opportunity to make a quick assessment of the quality of data products.
"However, to include these variables into climate models more adequate formats would be required which allow usage in scripting."
"From the user information available, the key climate users require NetCDF as format, while the broad users and a bit more than 40 % of the associated users require GEOtiff as suitable data format to meet their needs (Figure 34)."
The use of a geographic lat/lon coordinates is proposed as spatial reference system.
Data access through FTP (also combined with web services) is the preferred option for the climate user community (Figure 35).
The needs from the GCOS Implementation Plan tasks are well considered by the CCI land cover project and the accuracy requirements are taking into account (see section 4.1).
GCOS recently published a set of principles for monitoring of Essential Climate Variables that should be taken up the CCI project and the product specification.
"In this study, it is assumed that the a detailed survey and interaction with climate users is one of the key next step in specifying details for monitoring land cover as Essential Climate Variable."
"This effort is building upon the guidance from international panels, such as GCOS, and strategy documents but the detailed requirements from the climate user community now offer the next level of detail to start to specify product characteristics."
"One of the key conclusions from the survey is that despite differences in needs between the users targeted in the assessment, there is quite some congruency on what is required by the GCOS IP tasks, and the broader requirements by GTOS, IGOL, IGCO, and the scientific literature review, and the detailed user needs."
All have been described and documented in this report.
"Not only from the literature review it is obvious that climate science is moving more towards modeling the climate system incorporating human influence, impact assessment, vulnerabilities, and policy support."
"This direction necessitates a much stronger of the land component in terms spatial, temporal and thematic detail and related requirements for land cover and land use data."
Next generation land cover observation data are not only expected to feed into existing models but are expected to stimulate new and innovative modeling approaches beyond the current state of the art.
Land Cover has been selected as one of 11 ECVs which will be elaborated during the first phase of ESA Climate Change Initiative (2010-2013).
"In order to provide a comprehensive overview of the user requirements for the different ECVs, ESA has provided a standard template for presentation."
Below the summary for the Land Cover ECV user requirements is provided according to this template.
The land cover products will be projected in a Plate-Carrée projection with a geographic Lat/Long representation (WGS84 ellipsoid).
The coordinates will be specified in degrees/minutes/seconds.
Possibility to reproject the land cover product to model-specific projections should be included.
"An XML document with a well-defined schema (CMUG to help to specify) which clearly defines the satellite data, processing, measurement and monitoring techniques and the analysis method and quality information used to retrieve the data record."
"Specific requirements include: 1) validation information: specific areas which were checked with in situ data, and level of agreement with other land cover datasets; 2) clear description of classification methodology and underlying assumptions (e.g., cloud and snow mask); 3) information to support assessment of consistency with other EO derived products (e.g., albedo, vegetation-biophysical variables)."
"Trend monitoring and tracking human activities, i.e. land use affecting land cover; Validation of model outcomes (i.e. time series) or to study feedback effects."
There is a need for both stable land cover data and a dynamic component (time-series and changes).
"An user consultation mechanism was set-up to actively involve different climate modeling groups by setting out surveys to different type of users: 1) a group of key-users, most of them also participating in CMUG, 2) associated climate users who are involved and leading the development of key climate relevant models and application, and 3) the broad land cover data user community reflected in the scientific literature and represented by users of the ESA GlobCover product."
The evolution of requirements for these aspects from current models to future new modeling ap- proaches was specifically taken into account.
"Next to the surveys, requirements from the GCOS Im- plementation Plan 2004 and 2010 and associated strategic earth observation documents for land cover (GTOS, IGOL, IGCO, CMUG) were considered and integrated."
"Herold, M., van Groenestijn, A., Kooistra, L., Kalogirou, V., and O. Arino 2010."
"BROVKIN, V., SITCH, S., VON BLOH, W., CLAUSSEN, M., BAUER, E., and CRAMER, W., last 150 years."
"CIAIS, P., B. MOORE, W. STEFFEN, M. HOOD, S. QUEGAN, J. CIHLAR, M. RAUPACH, I. RASOOL, S. DONEY, C. HEINZE, C. SABINE, K. HIBBARD, D. SCHULZE, M. HEIMANN, A. CHÉDIN, P. MONFRAY, A. WATSON, C. LEQUÉRÉ, P. TANS, H. DOLMAN, R. VALENTINI, O. ARINO, J. TOWNSHEND, G. SEUFERT, C. FIELD, T. IGRASHI, C. GOODALE, A. NOBRE, G. INOUE, D. CRISP, D. BALDOCCHI, J. TSCHIRLEY, S. DENNING, W. CRAMER, R. FRANCEY, D. WICKLAND, 2010, Integrated Global Carbon Observation team: A strategy to realize a coordinated system of Integrated Global Carbon Cycle observations IGCO version 10."
"Plan, IGOS theme report, <http://www.igospartners.org/Carbon.htm>."
"CMUG, 2010, Requirement Baseline Document MOHC, MPI-M, ECMWF, MétéoFrance."
"EOP-SE, 2009a, Annex J: Land Cover CCI, in: ESA Climate change initiative phase 1: scientific user consultation and detailed specification, statement of work."
Available at: http://earth.eo.esa.int/workshops/esa_cci/Annex_J_Land_Cover_CCI.pdf.
The importance of land-cover change in simulating future climates.
International Journal of Remote Sensing 31: 351-362.
"GCOS, 2010a, Guideline for the generation of datasets and products Meeting GCOS requirements: An update of the “Guideline for the Generation of Satellite-based Datasets and Products meeting GCOS Requirements” (GCOS-128, WMO/TD-No."
"GCOS, 2010b, Implementation plan for the Global Observing System for Climate in Support of the UNFCCC, August 2010 (update), World Meteorological Organisation."
Available at: http://www.wmo.int/pages/prog/gcos/Publications/gcos-138.pdf.
"HEROLD, M., LATHAM, J.S., DI GREGORIO, A. SCHMULLIUS, C., 2006, Evolving standards in land cover characterization."
"HEROLD, M., WOODCOCK, C., CIHLAR, J., WULDER, M., ARINO, O., ACHARD, F., HANSEN, M., OLSSON, H., SCHMULLLIUS, C., BRADY, M., DI GREGORIO, A., LATHAM, J., and SESSA, R., 2009, Assessment of the status of the development of the standards for the Terrestrial Essential Climate Variables: T9 Land Cover."
"Avaialable at http://www.fao.org/gtos/doc/ECVs/T09/T09.pdf, FAO."
"AND C. SCHMULLIUS, 2008, Some challenges in global land cover mapping: an assessment of agreement and accuracy in existing 1 km datasets."
"HIBBARD, K., JANETOS, A., VUUREN, P., PONGRATZ, J., ROSE, S. K., BETTS, R., HEROLD, , and FEDDEMA, J. J., 2010, Research Priorities in Land Use and Land Cover Change for the Earth System and Integrated Assessment Modeling."
"JAIN, A. K., and YANG, X., 2005, Modeling the effects of two different land cover change data sets on the carbon stocks of plants and soils in concert with CO2 and climate change."
"JUNG, M., HENKEL, K., HEROLD, M., and CHURKINA, G., 2006, Exploiting synergies of global land cover products for carbon cycle modeling."
"JUNG, M., VETTER, M., HEROLD, M., CHURKINA, G., REICHSTEIN, M., ZAEHLE, S., CIAIS, , VIOVY, N., BONDEAU, A., CHEN, Y., TRUSILOVA, K., FESER, F., and HEIMANN, , 2007, Uncertainties of modeling gross primary productivity over Europe: A systematic study on the effects of using different drivers and terrestrial biosphere models."
Satellitengestützte Fernerkundung und Modellierung des globalen CO2-Austauschs der Landvegetation.
"Examensarbeit 49, Max-Planck Institut f. Meteorologie, Hamburg, Germany."
"LEPERS, E., LAMBIN, E. F., JANETOS, A. C., DEFRIES, R., ACHARD, F., RAMANKUTTY, N., and SCHOLES, R. J., 2005, A synthesis of information on rapid land-cover change for the period 1981-2000."
"OSTLE, N. J., SMITH, P., FISHER, R., IAN WOODWARD, F., FISHER, J."
"PONGRATZ, J., REICK, C. H., RADDATZ, T., and CLAUSSEN, M., 2010, Biogeophysical versus biogeochemical climate response to historical anthropogenic land cover change."
The global distribution of cultivable lands: Current patterns and sensitivity to possible climate change.
"ROSE, S., AHAMMAD, H., EICKHOUT, B., FISHER, B., KUROSAWA, A., RAO, S., RIAHI, K., and VUUREN, V. D., 2008, Land in Climate Stabilization Modeling: initial observations."
"SITCH, S., BROVKIN, V., VON BLOH, W., VAN VUUREN, D., EICKHOUT, B., and GANOPOLSKI, A., 2005, Impacts of future land cover changes on atmospheric CO2 and climate."
"TOWNSHEND, J. R., and BRADY, M. A., 2006, A revised strategy for GOFC-GOLD."
"TOWNSHEND, J. R., LATHAM, J., ARINO, O., BALSTAD, R., BELWARD, A., CONANT, R., ELVIDGE, C., FEUQUAY, J., EL HADANI, D., HEROLD, M., JANETOS, A., JUSTICE, O., LIU JIYUAN, LOVELAND, T., NACHTERGAELE, F., OJIMA, D., MAIDEN, M., PALAZZO, F., SCHMULLIUS, C., SESSA, R., SINGH, A., TSCHIRLEY, J."
"AND YAMAMOTO, H., 2008, Integrated Global Observations of teh Land: an IGOS-P theme IGOL Report No."
"WILLIAMS, M., RICHARDSON, A. D., REICHSTEIN, M., STOY, P. C., PEYLIN, P., VERBEECK, H., CARVALHAIS, N., JUNG, M., HOLLINGER, D. Y., KATTGE, J., LEUNING, R., LUO, Y., TOMELLERI, E., TRUDINGER, C. M., and WANG, Y. P., 2009, Improving land surface models with FLUXNET data."
Q3: What are the land cover spatial resolution requirements for your application?
Q4: How often do you want to have an updated land cover product?
Q5: What types of classes are the most important for your application?
"Q6: For which land cover changes are you mostly interested in, if any?"
"Q7: For the GlobCover MERIS composites, which composition period is the most appropriate for your application?"
Q8: Is the Land Cover Classification System (LCCS) suitable for your application?
Q9: How do you prefer to download the GlobCover MERIS composites?
Q10: How do you prefer to download the GlobCover land cover map?
Q11: What is the most suitable file format for the GlobCover MERIS composites?
Q12: What is the most suitable file format for the GlobCover land cover map?
What type of delivery mode do you prefer for data access?
What is the main reason of interoperability problems?
"You may choose from following: 1-30 m, 30-100 m, 100 – 300m, 300-500m, 500m-1km, 1- degrees latitude x longitude, 1-5 degrees latitude x longitude, 5-10 degrees latitude x longitude, > 10 degrees latitude x longitude, or national and regional aggregates/averages, other (please specify)."
"You may choose from following: Hourly, 0.5 days, 1 day, Month, 0.5 year, Year, Decade, Century, other (please specify)."
"You may choose from following: < 6 months, 6 months- 1 year, 1- 2.5 years, 10 years, 50 years, 100 years, more than 100 years, other (please specify)."
As datasets for validation of model outcomes (i.e. time series) or to study feedback effects.
The questions below will address some specific issues related to the identified uses of land cover datasets in your climate models.
"You may choose from following: Monthly, half-year, Year, 5 years, decade, century, other (please specify)."
"Potential options: Albedo, LAI, Biomass, Fire/burnt area, FAPAR, Snow cover, other (please specify)."
"Potential options: conversion of forest to agriculture, urbanization, other land cover and land use change (please specify), other (please specify)."
"Choose from following: Monthly, half-year, Year, 5 years, decade, century, other (please specify)."
What other (spatial) data sets are of importance for your application that should be consistent with the land cover dataset?
How you evaluate the current retrieval process of your input data?
"Meteorological Institute of the University of Bonn, Meteorological Research Institute of KMA, and Model and Data group."
This document formally describes the user requirements for the conceptual model of a modular emulator.
"It is intended for review by the project manager at the Nationaal Archief of the Netherlands (NA), project member of the Koninklijke Bibliotheek, National Library of the Netherlands (KB), as well as the coordinator of the development team at Tessella Support Services plc."
"The emulation report [EMU], written by the KB and NA in 2005, proposes construction of the modular emulator in three separate stages, with each stage specifying different user requirements."
"For efficiency reasons, a different approach has been presented by Tessella."
"However, the user requirements of both approaches are identical."
This document describes the requirements for the final concept of the modular emulator.
"Where necessary, user requirements defined in different stages will be identified as such."
There are components described in the final concept that build upon results achieved in the previous stages.
"As the work has a research element, and project decisions will be made based on produced results during the project, it is difficult to estimate precisely how long the development of each stage will take."
"As a result, the implementation of these components will depend on time available."
Requirements for these modules are marked “O” (optional) and “E” (extensions).
"This does not imply they are not part of the scope of the project, but they will be determined at a later stage."
"The Software Requirements Document, specifies the behaviour of the software system."
"The User Requirements Document, catalogues the users’ requirements for the system (this document)."
These digital objects are currently accessed via a standard computer system.
"In this project, a model of the standard computer system, the Reference Workstation (RWS), will be used; its capabilities reflect those of the standard computer system."
For background on emulation the reader is referred to [EMU].
Definitions of technical terminology and jargon common to emulation and used in this document are included in the Glossary in Appendix A.
This document lists requirements for the conceptual model of a modular emulator.
"Several emulators exist, most notably Bochs and QEMU, but neither implement an emulator with the same objective as desired in this project (see section 2.2)."
"As both these systems are open source, and fall under the GNU Lesser General Public License, they can be used as a starting point for creating the emulator specified in this project."
"The project consists of a number of stages, and will produce several versions during the course of development."
"Many of these versions should function as independent products, and will be used to assess the progress of the project and to determine the project’s course."
"The final product will depend on the approach used to achieve the most successful results; it is recognised that depending on the approach taken, not all user requirements may be met at the end of the project."
"Using the ‘software-emulation-of-hardware’ approach [EMU], the software will be capable of reproducing, as closely as possible, the hardware environment of the Reference Workstation."
"The priorities of this reproduction are, in order, execution speed, graphics, sound and network."
"The functional behaviour of the system of the software, compared to the RWS, will be assessed using various digital test objects."
"Ideally, the system will consist of distinct modules that emulate specific RWS hardware components."
"Once an initial version of the system is produced that fulfils the above capabilities, it will be extended with a library of emulated components, and a controller to interconnect these components."
"This will make the system capable of emulating multiple environments, besides that of the RWS."
"The hardware properties of each emulated components will be specified in a Module Specification File, while particular combinations and usage of the components that make up the environment of an emulator will be specified in an Emulator Specification Document (ESD)."
The ESD can be associated with stored digital objects to easily access them in the required environment.
The emulated components will be re-usable and will have the possibility to be enhanced.
"The ideal final software product will be platform independent, able to fulfil the above capabilities on different host hardware configurations."
The target group of the software product is end-users of computer software.
"Their intent is to run software packages to access, read and write various digital objects, including interactive multimedia applications, PDF documents, and database systems."
These objects may no longer be supported on current hardware and software systems.
"This raises the need to install older, unsupported operating systems in order to run the software packages necessary for accessing the digital objects."
The group can be classified as users with computer experience varying between minimal and knowledgeable.
Those with minimal computer experience will have no knowledge how to install operating systems or software packages.
"They will need to be provided with a complete, existing environment that is targeted towards the documents they want to access, shielding them from requiring inside knowledge of the emulator."
"Assuming they have developed some familiarity with the environment through continual use, simple interaction can be expected to load, read, write and save the requested objects."
"More experienced users can be expected to install the operating systems required for document access, as well as installation of software packages, once provided with the correct environment."
"Accessing more complex objects, more involved interactions within the system can be expected, resulting in higher loads to the system."
"Knowledgeable users will want to create their own environments on the fly, tailor-made to their needs."
"Customising various modules to create specific settings, along with custom installation of operating systems can be expected."
"The system will be used to the fullest, placing the highest stress on the system."
Interchanging modules within one environment to test and compare settings can be expected to lead to various configurations.
"Provided below is a simplified diagram, showing the information and control flows across the system boundary."
Virtual Machine creates a dependency on support from the manufacturer.
"Detailed knowledge of the inner workings of components is required, much of which may be considered proprietary by the manufacturer."
Reverse engineering may need to be applied to gather enough information.
"Development will be incremental, so later stages depend on previous results."
The list below indicates areas where knowledge is lacking or unclear.
These areas should be resolved before the document is used as intended.
"The reason for listing them in this section is that they are not forgotten in the body of the document, and provide a readily available list for discussion when possible."
The release license specifics need to be determined.
This feature should be built into the final system unless its cost is too high.
This feature can be built into the final system at the Project Manager's discretion.
This feature is recorded here so that the idea is not lost.
The decision on whether to include it in the system will depend on progress on the mandatory requirements.
The software should provide code that emulates a motherboard [speed] Front Side Bus.
Design question: is this part necessary to emulate?
The software should provide code that emulates a display adapter comparable to a nVidia GeForce MX 420 with 32MB memory.
The software should provide code that emulates sound comparable to the AC’97 specification.
The software should provide code that emulates a network adapter comparable to the Intel Pro/1000 T.
The software should provide code that emulates random access memory up to 1 GB.
"The software should provide code that emulates an optical storage device, comparable to a Compaq JLMS DVD-ROM LTD-1665."
"The software should provide code that emulates a 3.5” floppy drive, with average seek time."
"The software should provide code that emulates a mouse, supporting the PS/2 protocol."
The software should provide code that emulates a communications (COM) port.
The software should provide code that emulates a Universal Serial Bus (USB) port.
"Specification Documents (ESDs), which contain a list of components that make up a specific emulator."
Specification File (MSF) or metadata that specifies the hardware properties of that component.
An Emulator Specification Document (ESD) can be created via a user interface.
Specification Document (ESD) is loaded in the user interface.
The user interface contains logic to determine compatibility between components when loading / creating an Emulator Specification Document (ESD).
The software should be able to host operating systems comparable to Microsoft Windows 2000 Professional.
The software should be able to host applications software within the operating system capable of running the test objects.
There must be at least one emulated component (and associated Module Specification File) for every type of hardware component listed in section Fout!
"Emulated components should be organised in a library, associating emulated component code with Module Specification Files."
The library should maintain a component list consisting of Module Specification Files (MSF) or metadata that can be used in an emulator.
"The component list should be updateable with newer components, components."
The library should be able to provide the emulator with the emulated Specification Document (ESD).
It should be possible to re-use emulated components for multiple emulator configurations.
The process of interconnecting modules should be automated.
The software should be able to emulate the RWS at a reasonable speed.
"However, this is not a mandatory requirement because it is assumed that computers will continue to become faster (based on Moore’s law)."
"As this emulator will be focused on future use, speed is currently not an issue."
The software must be able to handle at least 40 GB target disk images.
The software should be able to give a correct representation of the test objects.
Issues: this requires comparison tests between RWS and emulated environment.
There are no relevant requirements in this section.
The software should be able to run on the x86 platform.
The software should be able to run on the PowerPC platform.
"Emulation components should be defined as distinct modules – “a finite set of programming code that, when executed, emulates a specific part of a computer system”."
The software should be constructed in a modular way.
"Knowledge, expertise and code should be shared with the open source community."
"All emulator information should be documented, including device specifications, protocol descriptions and standards."
The software should be able to read and write the format of disk images that are used as test objects.
This format is equivalent to the disk images used in Bochs and QEMU.
Is a description of this format available for design purposes?
Describe any constraints or requirements the client has specified relating to how the system should be delivered to them.
The emulator should be released under the GNU (Lesser) General Public License or compatible license.
To be decided officially when publicly releasing first set of code.
"Other interested parties should be able to freely use, modify and distribute the developed emulator in accordance to the license it is released under."
"Future developers should be able to recreate the emulator, using the available source code."
This glossary contains definitions of terms used within the User Requirement Specification document.
"It defines terms that are used within the emulation context, but because of their common use or multiple meanings, require clarification."
"The framework, either in hardware or software, which allows software to run."
"This typically includes architecture, operating system, and programming languages and their runtime libraries."
This section describes the services offered for High Value Payments (HVP).
"This includes the entry disposition, the settlement and the queue management."
This business process describes the processing of a payment order.
"Furthermore, there will be checks on blocked accounts/Parties."
Ancillary System transfers can be found in section 2 of this User Requirements Document.
A Central Bank acting on behalf of a credit institution.
CB has activated the back-valued payments for one RTGS account holder.
RTGS account holder in case of contingency situations.
RTGS shall allow it to be submitted for settlement beyond this time.
RTGS shall process payment orders according to their priority classification.
This means that the submission time for normal payment order is meaningless.
The RTGS account holder whose account is subject to the credit is not blocked.
The RTGS account holder whose account is subject to the debit is not blocked.
The bilateral or multilateral Limits are not breached for normal payment orders.
"For a EURO-CB, this check is not relevant since a EURO-CB Account can be negative."
The condition for drawing liquidity depends on the priority of the payment order.
"Where no bilateral Limit is defined, RTGS shall check the multilateral Limit."
"Where not enough liquidity is available, RTGS shall queue the payment order."
Optimisation has the objective to dissolve as soon as possible the queues.
Optimisation is designed in a way to provide liquidity-saving features.
RTGS shall post each and every payment order on a gross basis.
RTGS DCA without being processed by the settlement process.
Creation of a rule-based liquidity transfer order for submission to Central Liquidity Management to adjust the liquidity on the accounts involved so that the balance of the affected account reaches the specified target amount.
Same as RTGS.TR.HVP.PAYT.010 (Perform Technical Validation).
RTGS shall check the validity of amendment instructions.
The re-ordering of the queued payment orders triggers their settlement attempt.
Where several payment orders were selected they will be put on top of the queue according to their previous order.
The default order is determined by the submission timestamp.
Move one or more payment orders to the bottom of the queue in which they are held.
The re-ordering of the queued payment orders possibly triggers the settlement of another payment order.
Where several payment orders were selected they will be put at the bottom of the queue according to their previous order.
"Time as long it has not passed, and only to a time which is in the future."
This business process describes the revoke or recall of a payment order.
The process will be initiated by an RTGS account holder via sending of the respective message to RTGS.
"If the message content is either invalid or would result in reference data checks to fail, it will be rejected and a rejection notification with the appropriate error code(s) will be sent to the sender of the revocation/recall."
"If the message content is valid and reference data checks have been passed successfully, RTGS will perform a revocation attempt of the original payment order the revoke&recall request message is referring to."
"If the original payment order has not yet reached a final status, the original payment is revoked and a revoke&recall execution notification is sent to the sender of the revoke&recall request and a payment revocation notification is sent to the initial sender or the original payment order."
If the original payment order has a negative final status (rejected or revoked) a denial notification with appropriate error code is sent to the sender of the revoke & recall request.
"If the original payment order has a positive final status (settled) or the original payment order cannot be found in the list of payments of the current business day, the revoke&recall request is forwarded to the payment receiver quoted in the request (except it the original payment order is a direct debit or payment return )."
A notification is sent to the sender of the revoke&recall request informing that the request has been forwarded.
The receiver of the forwarded revoke&recall request is expected to respond either with a payment return or with a revoke&recall notification.
An incoming payment return is processed in the same way as any other payment order.
An incoming revoke&recall notification is forwarded to the receiver quoted in the notification.
The revocation via U2A is possible on the payment orders in the queue only.
"For direct debits, the creditor (=sender) can initiate the revocation."
Payment orders which are already settled cannot be revoked anymore.
RTGS DCA to another RTGS DCA within the same Liquidity Transfer Group.
RTGS shall perform service specific authorisation checks.
This check is not performed if the debitor or the creditor is a CB Accounts.
RTGS shall check whether enough liquidity is available.
The only specific rule is for liquidity transfer orders triggered by a lack of cash in CLM.
No specific rule has been identified for this process.
The amount that cannot be reserved is called the Pending Value and is queued.
The amount which is surpassing the available liquidity coverage is called Pending Value.
RTGS shall allow for interventions on pending reservation requests.
RTGS shall book the reservations finally and irrevocably.
This section describes the RTGS services for Ancillary Systems (AS).
RTGS DCA to a technical account either held by the AS or the CB for prefunding purposes.
Settlement period can be defined (see section 1.2 on Payment Order Processing).
The additional specific features for procedures 6 RT and Interfaced are described below.
AS transfers will be sent by dedicated AS batch messages (ASTransferInitiation).
Information and settlement periods will be provided as they were formerly in TARGET2.
"RTGS will manage the links as formerly in TARGET2 (""Debits first"" or ""all or nothing""), according the parameters set for the AS in CRDM (which procedure is used, see section 9 on Business Data Definition in the User Requirements Document for Common Components)."
Regular liquidity transfer orders (e.g. from RTGS DCA to sub account) at these business events can be set up through standing orders.
"Whenever the AS using this interfaced procedure starts a cycle, the liquidity on the sub account involved will be controlled by the AS."
"During a running cycle, a liquidity transfer which increases the balance on the sub-account settles immediately."
The control is given back to the settlement bank through the end of cycle.
"Always possible, either through an immediate liquidity transfer order or a payment order4."
Can be realised as immediate liquidity transfer orders between two different AS technical accounts owned by ACHs.
"HVP payment orders, except the specificities described below."
"The common monitoring of different AS transfer orders sent in one ""batch""."
"The ""settlement period"" is a time period set by the sender."
"The ""information period"" is a time period set by the sender."
Similar to RTGS.TR.HVP.PAYT.040 (Perform entry disposition).
Either they are settled immediately or they are allocated to the U queue.
RTGS shall consider linkage constraints due to multilateral settlement.
Similar to RTGS.TR.HVP.PAYT.060 (Queue payment order and optimise queued payment orders).
The main difference is the optimisation for linked AS transfer orders described below.
Same as RTGS.TR.HVP.PAYT.080 (Check balance floor and ceiling).
"Availability, calculated on a quarterly basis, shall be at least 99.7%."
Payment orders stemming from batch procedures of AS are excluded.
The RPO is a point of consistency to which a user wants to recover or restart the service.
In this case a data loss of two minutes will be tolerated.
All requirements must be fulfilled in a central integrated way.
RTGS shall be compliant with Cyber Resilience Requirements.
The query shall return relevant business attributes of the Audit Trail.
"The TARGET Service Desk, to act on behalf of any Party."
The User Interaction section covers intraday queries.
The extended list of the selection criteria and the output of the queries shall be defined in the UDFS.
All described queries in this section shall be provided in U2A and A2A mode unless otherwise stated.
RTGS shall provide the functionality to query any message in XML format.
RTGS shall provide the functionality to query the balance on any account.
RTGS shall provide the functionality to query all reservations on any account.
The query shall return all business attributes of the Limits.
RTGS shall provide the functionality to query on the account statement.
The query shall return all business attributes of the account statement.
This action has to be activated by the CB on RTGS account holder level.
The change will be valid for the current business day only.
This process describes how the update of the credit line will be handled in CLM.
The credit line update can only take place if the MCA is active.
"If the credit line modification order is valid, the credit line update shall be executed immediately."
Credit line updates shall be handled with the highest priority.
"As of ECMS launch, there is a need to do a value date check."
"If the update of the credit line is not possible, the request shall be queued."
"If the update of the credit line is not possible, CLM shall queue the credit line modification request."
Is still pending by the start of End of Day processing.
Connected payment orders cannot be revoked as there is no queuing.
The payment order amount may differ from the credit line update amount.
This process describes how the CLM End of Day general ledger files shall be produced.
User Requirements Document for business process CLM.CB.BP.CBS.CEODB.
This process describes how the setup of an overnight deposit shall be processed within CBS.
CLM account holders can use the deposit facility to make overnight deposits with their national CBs.
There is a need for dedicated overnight deposit account(s) to be set up in the CLM.
Liquidity transfer orders cannot be queued nor revoked.
"At the reception of the liquidity transfer order sent by CBS, CLM shall process it."
"Once processed, CLM shall send an acknowledgement to CBS."
"At the reception of the acknowledgement from CLM, CBS shall process it."
This process describes how the reverse of an overnight deposit shall be processed within CBS.
There is also a need for a dedicated overnight deposit account to be set up in CLM.
An overnight deposit for that business day has been previously set up.
CBS shall create a liquidity transfer order and transfer it to CLM for further processing.
"Once processed, CLM send an acknowledgement to CBS."
An overnight deposit has been set up on a dedicated overnight deposit account.
CLM/CBS also require the overnight deposit rate for the interest calculation.
"CBS, CLM shall process them and send an acknowledgement to CBS once they are processed."
Document for CLM for the business process CLM.BP.CLM.ISLT.
"At the reception of the notification from CLM, CBS shall process it."
"Moreover, there is a need for dedicated marginal lending accounts in CLM."
CBS shall create a payment order and send it to CLM for further processing.
Requirements Document for CLM for the business process CLM.BP.CLM.PAYT.
This process describes how CBS shall initiate and process an automatic marginal lending.
Day balances are available before initiating the process.
CBS shall check if the global End of Day balance is positive or negative.
CLM account holder is allowed to access the marginal lending facility.
Simultaneously decrease the CLM account holder’s credit line.
There is also a need for dedicated marginal lending accounts in CLM.
CBS shall calculate as of the start of provisioning of liquidity phase on the following business day (i.e.
The interest payment order shall debit the CLM account holder’s MCA and credit the CB account.
CBS shall calculate the interest at operation level.
This exclusion shall be possible at the level of the currency.
Simultaneously increase the CLM account holder’s credit line.
Contingency Settlement shall only deliver the information to CLM once CS is closed.
CLM shall produce the CLM general ledger file after the settlement of Standing Facilities.
CLM balances shall be taken into account for the calculation mentioned before.
CLM shall send the files after the settlement of Standing Facilities.
CBS shall ensure that all mandatory fields are populated.
"In case of completeness, CBS shall relay the general ledger files to CBs."
This process describes how CBS shall process the minimum reserve requirement input by CBs.
The credit institution needs to be subject to minimum reserve.
The minimum reserve requirement shall be updated with the new amount indicated by the CB.
Facilities and before the start of the new business day.
"With regards to penalties, a feedback from CBs is required before creating the payment orders."
The validation of penalties shall be possible on a U2A basis.
This User Interaction section covers intraday queries.
The extended list of the selection criteria and the output of the queries would be defined in the UDFS.
Common Components which are of relevance for CLM and CBS.
The user shall specify the following mandatory selection criteria.
The user shall specify the following mandatory selection criterion.
In addition each account balance shall be made available.
Period over which compliance with reserve requirements is calculated.
Interest rate applied to a marginal lending transaction.
The purpose of the Business Requirements Document (BRD) is to describe the different requirements for the Bank of Zambia’s (BoZ) envisioned Data Reporting and Analytics platform.
This document describes what the system would look like from a business perspective and lists critical requirements accurately in a technology-independent manner.
"The information has been captured and written through technical support from UNCDF MM4P and signed- off by the relevant stakeholders at BoZ, validating the requirements meet their core business needs."
"This document does not include technical and functional design specifications for the BoZ platform, nor provide an analysis of requirements related to systems outside BoZ."
"Having validated the structure and contents of the document, the below stakeholders are signing-off on their specific business requirements."
The Bank of Zambia (BoZ) is the central bank of Zambia.
"The principal responsibilities of BoZ include being banker to government, issuer of currency, manager of foreign exchange reserves, controller of commercial banks' liquidity and with responsibilities for the formulation and implementation of monetary policy."
The Bank is active in promoting financial inclusion policy and is a leading member of the Alliance for Financial Inclusion.
"It is also one of the original 17 regulatory institutions to make specific national commitments to financial inclusion under the Maya Declaration, during the Global Policy Forum, held in Riviera Maya, Mexico in 2011."
BoZ has deployed various policies to ensure that financial services are able to make in-roads in remote and rural areas.
"Still, financial services are concentrated in mostly urban and semi-urban areas, with capital region of Lusaka having the highest concentration."
"Zambia was the earliest adopter of digital financial services (DFS) in Africa in 2002, and the country has made significant improvements over the years in terms of financial services delivery outlets/channels offered through both formal and informal financial institutions."
"Despite that, the level of adults Zambians above 18 years who are excluded from financial services remains significant."
Data from the Finscope Zambia survey conducted in 2015 showed that only 59.3 % of the population are financially included.
The Bank of Zambia realizes the important catalytic role that Digital Financial Services (DFS) can play towards the increased usage of electronic payment mechanisms by the general public.
"The Bank of Zambia is therefore working with government and other private and public stakeholders to increase financial inclusion, by increasing access to formal financial services."
To this effect the Bank has amongst its strategic objective include plans to increase formal financial inclusion.
A number of initiatives have since been put into motion in order to meet this objective.
"To ensure integrity of the Digital Financial Services (DFS) sector and enhancing of financial access and usage, Bank of Zambia recognizes it is important that data and measurement tools are deployed for aiding effective supervision and policy making."
UNCDF is the UN’s capital investment agency for the world’s 48 least developed countries (LDCs).
"With its capital mandate and instruments, UNCDF offers “last mile” finance models that unlock public and private resources, especially at the domestic level, to reduce poverty and support local economic development."
This last mile is where available resources for development are scarcest; where market failures are most pronounced; and where benefits from national growth tend to leave people excluded.
Mobile Money for the Poor (MM4P) is a global thematic initiative to address the opportunities and challenges of implementing branchless banking and mobile money in challenging markets in Africa and Asia.
"MM4P’s long-term mission is to help low income and rural households in LDCs increase their financial security through appropriate, affordable and secure means to receive, manage and save money through these “digital financial services” (DFS)."
"DFS refers to a range of formal financial services accessible via digital channels, such as mobile money and agency banking, as opposed to traditional financial services accessed through physically visited at a bank branch."
"UNCDF is currently implementing this in eight countries (Benin, Laos, Nepal, Malawi, Myanmar, Senegal, Uganda and Zambia)."
"In Zambia, MM4P launched its program in March 2015, funded by both MasterCard Foundation, is aimed at increasing active usage of DFS from the current 3% to 36% by 2019 amongst the adult population."
"Using the MM4P theory of change, the program seeks to work with all DFS providers, the regulators and the government to achieve this mandate."
"The Bank of Zambia is mandated by the Bank of Zambia Act (1996) and the National Payment Systems Act (2007) to ensure that Zambian payment systems are safe, secure, reliable and efficient."
"In order to discharge these functions, the Bank needs a robust Data Reporting and Analytics platform (hereinafter “the Platform”) that will support its monitoring and policy making activities."
"Consequently, the ‘Banking Currency and Payment Systems Department’ at BoZ, with support from UNCDF Zambia, seeks to deploy a Data Reporting and Analytics platform that would automate the reporting processes and provide analytics useful for policy making."
BoZ collects a significant magnitude of data from financial service providers to carry out its regulatory obligations and policy making function.
"The transactional data is collected from a range of institutions include banks, non-banks and DFS providers (for list of reporting institutions please see Annexure 1)."
The present reporting process involves providers manually filling the required regulatory reporting data in a pre-defined excel spreadsheets and emailing it to the BoZ (Banking Currency and Payment Systems Department) within the first week of every month.
"Staff at Payment System then collects more than 50 excel files from 34 reporting institutions to manually aggregate the data from these sheets to prepare monthly, quarterly and yearly performance reports."
The monthly reporting process takes a dedicated resource nearly a week to complete and an additional week is required when quarter and year-end reports are prepared.
"Needless to say, the current process of manually entering, extracting, compiling, aggregating, analysing and reporting data creates numerous challenges for both; BoZ and reporting institutions."
"BoZ seeks to implementing a secure, flexible, scalable solution that automates the data collection, analysis and reporting process."
"Once the data has been collected and cleansed, it will be stored in a secure database and the analytical functionality would create intelligence in the form of dashboards, visualizations and reports (adhoc & routine)."
"Where the following sections of the BRD are based on more traditional approach, UNCDF is open to explore solutions that leverage innovative technologies for regulatory reporting, such as blockchain, provided these meet requirements set by BoZ and offers additional advantages in term of functionality and costs."
"Presently, BoZ does not have an in-house data centre and there is an abundance of disparate ICT systems which need to be integrated to facilitate information sharing."
A key objective under BoZ’s Strategic Plan Technologies to achieve operational efficiency and effectiveness.
The Bank in a bid to enhance operational efficiency and effectiveness will implement an Enterprise Architecture (EA) Framework2.
The EA Framework will assist the Bank to respond better to its stakeholders by having a method and an organising principle that aligns functional business objectives and strategy with an IT strategy and execution plan.
The Bank will also seek to implement greater integration among its information systems by implementing an Enterprise Resource Planning (ERP) platform.
Some of the benefits of the ERP include reduction in complexity of the Bank's Information Architecture through the establishment of a single platform for the Bank's business systems.
"The Bank has plans to an implement ICT Governance Framework, based on the new COBIT 5, to manage how ICTs are managed in the organization."
"COBIT 5 encompasses all stakeholders within BoZ and calls for the establishment of an ICT Steering Committee at Board that should make ICT-related decisions, such as which ICT investments to make and what ICT projects to run."
Client desktops based on Microsoft Windows 64-bit Operating systems Several Intel quad core processors servers running Windows 20xx 64-bit.
The envisaged Data Reporting and Analytics platform will be developed under the supervision and leadership of Bank of Zambia.
"Data will be stored in-house on Bank of Zambia servers, the platform would be the CAPEX model in nature with minimal ongoing maintenance and service costs."
"The platform will be optimised to collect data from various sources, transforming and cleanse the data into a standardized format, and warehousing the data for analysis and dissemination to users in various formats."
"In the ideal scenario the data warehouse could utilize Online Analytical Processing (OLAP) methodologies for analytical analysis and allowing users to construct queries ad-hoc, or “on-the-fly”."
The expected architecture of a solution should be sufficient to meet all essential business requirements and offer a coherent set of functionalities.
"Furthermore, the platform should allow it incorporate more features as business needs and technology evolves."
"Supports popular web-browsers such Mozilla Firefox, Opera, Chrome, Internet Explorer, Safari etc."
"The long-term vision of the platform includes straight-through processing of data from reporting institutions with minimal intervention to ensure data accuracy, integrity and timeliness."
"In a bid to enhance operational efficiency and effectiveness, BoZ has plans to implement an Enterprise Architecture (EA) Framework."
The platform would need to comply with these frameworks and might require integration with infrastructure components as they are deployed.
The platform therefore should consider all interdependencies and linkages that will be required as components of the new framework are introduced.
Bank of Zambia intends to procure in 2019 an in-house server for this system.
It’s specifications will be at a minimum: 8 Core CPU; 16GB Ram; 1 TB Hard Drive (with mirroring or Raid); 5 Mbps Bandwidth; 5 TB External drive for backup.
The data will need to reside in the Bank of Zambia in-house server as per Bank of Zambia policies and requirements.
BoZ seeks to enhance the efficiency of the data collection and analytics to ensure quality and timeliness of data.
The platform will provide functionality for managing and restricting system access according to each user group’s access privileges as authorised by BoZ.
"Limit access to the platform only to authorised and uniquely identified users by enforce authentication that can be based on combination of user/password or user certificate Manage and monitor privileges of users, allowing them access to features, sensitive data and outputs as per their privileges."
"In addition to BOZ, the envisaged platform will be used by a diverse group of stakeholders that include reporting institutions, and other industry actors who might be interested for reasons of transparency, investment or regional or international reporting reasons."
"To accommodate the different user groups, the platform will enforce user hierarchies and access controls to prevent unauthorised access to sensitive data and features."
"BoZ collects a large amount of data for statistical, prudential and monitoring purposes."
"Once the deployed, users from multiple reporting institutions will interact with the platform, through a secure web-based, to enter the required regulatory reporting data."
"Before the data is submitted to BoZ, the platform will check input values to ensure conformity to the defined business rules."
"If the submitted data/report is in conflict with the business rules, then the platform will display the appropriate error message that will allow user to identify and adjust the erroneous entries."
Key critical data elements to be provided to BoZ by reporting institutions can be found in the embedded excel file in the annexures.
"To ensure a harmonized model for input data as well as rules for analysis of collected data, the platform should operate as per the criteria and conditions defined by BoZ in the form of Business Rules."
"As reporting requirements can evolve with new regulatory priorities, the platform should provide the capability to define and modify business rules through the administrator login."
"Apart from increasing efficiency of supervision, a key objective of the platform is the measurement of progress towards Zambia’s financial inclusion goals."
"To that end, the platform should be capable of handling complex multi-dimensional data and have robust data analysis and modelling capability would gain a better understanding of the relationships between disparate pieces of data."
"This will allow BoZ to proactively manage the DFS sector and gain a better understanding of the relationships between disparate pieces of data, particularly on matters related to gender and youth."
"Ability to create totals of different fields by provider and provider types, for specified Ability to perform complex calculations, e.g. percent of total, rolling sums and averages, period comparisons etc."
"Ability to perform advanced statistical functions, e.g. standard deviation, variance, skew etc."
"The platform will provide additional ad-hoc data access functionality to users so they may run custom queries, according to their access privileges."
The platform would have the ability to generate a variety of decision making tools in different formats that would help BoZ and other stakeholders assess the performance of the DFS sector and make strategic decisions.
"In addition to generating a set of predetermined reports based on historical trends and future projections, the platform would also create customized reports and share automatically with relevant stakeholder."
Sample output being created by BoZ are summarised in annexures 5 for reference.
"BOZ warrants that the platform be designed and implemented to a high standard of security and reliability, with the objective of maintaining the integrity, availability and confidentiality of data."
"Accessible through web-browsers, the user interface should be windows-compatible and provide access to all platform features and modules."
The design should have a high level of usability with a common “look and feel” achieved through consistent Graphical User Interfaces (GUI) for all internal and external users.
"Interface consistency includes the use of common command entry syntax, dialog window styles, data entry structures, and information presentation."
Incorporate data entry features designed to reduce the amount of direct keying required to enter data.
"The platform solution must be scalable upwards and designed using modular architecture to accommodate increasing number of users, sessions, transactions, and analytical reports as need."
The developed cloud-based solution needs to ensure adequate security and maintain strict confidentiality of all information provided by stakeholders.
"To ensure integrity of the platform, all its components should have all required security certifications and conform to all industry security standards."
"All sensitive information such as user/passwords in the database should be stored securely, in encrypted form."
"Furthermore, the platform should provide full audit trails for all activities within the system, including system accesses and activities."
The platform must be easy to use in order to minimize a chance of human error leading to a malfunctioning of the system.
"At the minimum, the platform has to be available to users with official working hours in Zambia."
The platform should be able to handle at least 60 users concurrently.
"In terms of throughput capacity and response times, the platform should make due allowance for peaks in usage and general growth."
"In the ideal scenario, the platform should be capable of creating required reports within 10 seconds and allow replacing the back-end queries to be able to override slow performing queries with optimized queries."
The platform should provide high reliability and ensure flawless switching of all functionalities to the Disaster Recovery (DR) site to avoid catastrophic loss of critical information.
The platform should be designed with high redundancy level to ensure no or little impact by failure of one or more components.
This document contains the user requirements for the ODE (Oc´e Datapath Editor) application.
This software product is part of the Software Engineering Project (2IP35) at the Eindhoven University of Technology.
"These user requirements were established according to requests formulated by Group ODE taking into account the wishes of our customer, Egbert Teeselink, on behalf of Oc´e."
"This document complies with the speciﬁcations for a User Requirements Document (URD) by the software engineering standards, as set by the European Space Agency [2]."
During the project the group will create a tool in which Oc´e’s software engineers can model a datapath.
The User Requirements Document (URD) contains the requirements for the Oc´e Datapath Editor (ODE).
The document conforms to the ESA document standard [2].
These requirements are a negotiated agreement between Oc´e and the project team.
"All of the listed requirements, and only these, will be implemented according to their priorities."
Any changes to these requirements require the consent of both parties.
The ODE Group will provide Oc´e with an editor where the user can model a so called datapath.
"The editor will aid the process of choosing the correct hardware, required for the tasks a printer or copier should be able to execute."
The ODE will provide a visual environment in which the user can create and change these models and export them for analysis.
"The editor will also get feedback from the analysis tools, e.g. highlighting speciﬁc items in a model."
The function of the product at Oc´e will be to provide a correctly structured ﬁle for use in Oc´e’s own analysis tool chain.
"Because it is irrelevant of which actions the analysis and veriﬁcation tools consist, it is depicted as an abstract “Analysis” object."
This section contains a list of deﬁnitions for used acronyms and abbreviations.
"The remainder of this document is divided into two chapters, General description and Speciﬁc requirements."
The General description gives a clear and concise description of the ODE.
"It consists of a short view on the product, a short summary of the general capabilities of the product and a more in-depth view of the main parts of the product: the model editor and the repository."
"The Speciﬁc requirements are subdivided in capability requirements, describing what the system should do, and constraint requirements, describing how the requirements should be implemented."
"The ODE will provide a graphical interface for designing models representing datapaths, which can be exported and analysed by other software."
"The idea of using software to design and analyse datapaths in order to make the engineering of new printers, scanners and copiers easier and faster has been exploited by Oc´e for a while, but they have not been successful at creating a single tool that can generically model any datapath."
The analysis and veriﬁcation tools are still in development and the exact representation of data used by veriﬁcation tools has yet to be determined.
Deﬁning these standards and using them is beyond the scope of this project.
The ODE should provide the user with a visual way of modelling datapaths and it should also allow the user to export this model to a ﬁle for analysis and veriﬁcation.
"Besides being easy to use, it is also important that future developers can easily expand its functionality and adapt the input or output format."
"The ODE will consist of two parts, the model editor and a repository."
"The model editor will provide a visual way to model datapaths consisting of an application part, a platform and a mapping that maps the application onto the platform."
"The repository will allow the user to add and edit speciﬁc tasks, algorithms and hardware types in text."
"Deﬁnitions for tasks, algorithms and hardware types are given in a later stage."
Some deﬁnitions or terms used are listed in the following table.
Application node A generic item in the application.
Application edge A generic directed edge between nodes in the application.
A generic undirected edge between nodes in the platform.
A connection between an application node and a platform node.
"A project consists of a set of project properties, one application, one platform and one mapping between the application and platform."
"An item that can be edited in the repository, either a hardware type, task or algorithm."
"This part of the ODE provides a GUI in which the user can model an application, a platform and a mapping that maps the application onto the platform."
The entire structure of the model has yet to be deﬁned and is prone to change after this project has been ﬁnished.
"However, some details about the structure of various nodes and edges are known and unlikely to change during the course of this project."
The application consists of a set of application nodes and edges between these nodes.
The edges in the application are directed from node to node.
"There will at least be a type of node called step, some kind of start node and some kind of end node."
"A task can be assigned to a step, describing the properties of that speciﬁc step (e.g. scan, describing the speed and size of the scan)."
Applications will generally contain at most 20 nodes.
"For example, an application could be visually represented as in Figure 2.1."
A platform is an undirected graph consisting of platform nodes and edges between these nodes.
These nodes represent the hardware elements that the device will use to physically execute the tasks as deﬁned in the application.
There will at least be a type of node called resource block.
"A speciﬁc resource can be assigned to a resource block, describing the properties of that speciﬁc resource (e.g. 512 MB RAM, describing the size of the memory)."
The mapping maps an application onto the platform used to execute it.
Each link from an application node to a platform node can have an associated algorithm that is stored within the repository.
The algorithm speciﬁes how eﬃcient a task can be executed on this piece of hardware.
"The repository is included to allow users to add, edit and remove deﬁned algorithms, resources and tasks."
"Within each entry it is possible to add comments about the algorithm, resource or task in question."
"Because the export format and the input language are prone to modiﬁcations, it is important that future developers can easily modify the code to comply with new standards."
"Besides changes in the export format, it is also probable that the functionality of the product will be expanded."
Therefore the quality standards for the source code of the ODE are high.
The ODE is not designed to check the semantics of a given model.
"However, it may check for basic validity of models created with the ODE and provide constraints within its GUI to prevent some basic syntactical errors."
Details of these constraints are given in the SRD [3].
There are two types of users that interact with the ﬁnal product.
The ﬁrst group is a small group of users that use the actual program to model datapaths.
These users have in-depth knowledge of what can be modeled with the product.
"The second group of users does not use the product itself, but uses its code to add more features to the editor."
These users are also very important since the export format and the product’s required functionality are prone to change.
"Obviously, this results in high demands to the quality of the code and architecture."
The product will run on computer systems running either Windows XP or Windows 7 as primary operating system.
It will only be used by Oc´e’s in-house software engineers.
"In order for us to be able to provide a good product, we expect the customer to comply to several requirements."
These requirements have been formulated in cooperation with the customer.
The language to be used in the models is frozen before the end of the SR.
The semantics of the model are provided by the customer to the extent that matters to the editor.
The number of constraints inferred by the customer is small.
This chapter covers the capability requirements and constraint requirements.
"Each requirement consists of a unique identiﬁer, followed by a short description and a priority."
Must have: these requirements are essential for the product.
"Must haves, meaning they must be implemented if at all possible."
Could have: requirements which are not critical to the products success.
Any application node and platform node can be selected by the user.
It is possible to select any application node or platform node by means of a method call.
It is possible to highlight any application node or platform node by means of a method call.
Other programs can send messages to the product for selecting and highlighting edges and nodes.
The editor automatically saves the current projects frequently to a default directory.
The user can undo changes to the model made in the current session.
The editor supports alignment of any element (such as application nodes and platform nodes) relative to similar elements in its vicinity.
"When two nodes are copied which have an edge between them, this edge is copied along."
"It is possible to select multiple objects (such as nodes, edges or links) at the same time."
It is possible to add a number of objects to a selection.
It is possible to export the application or platform in a BMP image format to the clipboard.
It is possible to export the application or platform to a EMF vector image format to the clipboard.
It is possible to save the application or platform to a BMP image ﬁle.
It is possible to save the application or platform to a EMF vector image ﬁle.
The user can add an application node to the application.
The user can move application nodes and edges within the application.
The user can remove application nodes and edges from the application.
"The user can cut, copy and paste (parts of) the application to an (other) application."
The user can assign a resource to a resource block.
The user can change the resource assigned to a resource block.
The user can move platform nodes within the platform.
The user can remove platform nodes from the platform.
"The user can cut, copy and paste (parts of) the platform to a(n) (other) platform."
The user can create a link between an application node and a platform node.
The user can change the algorithm assigned to a link.
The user can connect the starting point of a link to a diﬀerent application node.
The user can connect the endpoint of a link to a diﬀerent platform node.
The editor will assign an algorithm to a link if there is exactly one algorithm available for it.
"The user can add an algorithm, resource and task to the repository."
"The user can add an algorithm, resource and task to the repository using a fancy wizard."
"The user can open an existing algorithm, resource and task in the repository."
"The user can remove an existing algorithm, resource and task from the repository."
"The user can modify an existing algorithm, resource and task in the repository."
"The user can close an open algorithm, resource and task in the repository."
The user can undo any changes made in the text editor of the repository.
It should be easy to add syntax highlighting to the repository.
Constraints posed by the modeling language are enforced by the ODE.
"Every method and class in the source-code is documented using comments, explaining what it does, and how it does this."
These comments have to be documented according to standards enforced by the documentation generation tool that the ODE group chooses to use.
At least 80% of the methods are functionally cohesive or sequentially cohesive.
Every method and variable in the source-code has a clear and verbose name.
The entire source code complies with the coding standard provided in the SRD[3].
There is a unit test for every method or class that is not directly responding to a mouse-click or keystroke.
The ODE does not measurably suﬀer from memory leaks.
DOCUMENT APPROVAL Author Release See Document Change Record.
This is the TMT Observatory Operations Requirement Document (OPSRD).
"It is one of the three systems engineering level one requirement documents, the others being the Observatory Requirements Document (ORD) (RD1), and the Observatory Architecture Document (OAD) (RD2)."
The three documents are the project’s response to the science requirements encapsulated in the Science Requirements Document (SRD) (RD3) and the Operations Plan (OPSPlan) (RD4).
The requirements in the OAD (RD2) will flow down to requirements for the observatory subsystems.
"As necessary, new requirements implied by the current document flow down into OAD (RD2)."
Site-specific implementation plans to fulfill these operational concepts are described in the TMT Operations Plan (OPSPlan) (RD4).
"The requirements in this document are numbered in the form [REQ-X-Y-Z], where the placeholders X, Y, and Z dethe level of the requirement, the document the requirement is associated with, and a unique number for the requirement."
This numbering scheme allows for unambiguous reference to requirements.
This document shall be used as guidance for the top level engineering function and performance requirements of the observatory.
The requirements documented in the OPSRD and the ORD (RD1) are intended to fully describe the top-level engineering and operational requirements to satisfy the criteria of the Science Requirements Document (SRD) (RD3) and Operations Plan (RD4).
"By this definition, the OPSRD will change in response to changes in the Operations Plan (RD4), but will not require modification when changes are made to the Observatory Requirements Document (ORD) (RD1), Observatory Architecture Document (OAD) (RD2), or to the Subsystem Requirements Documents."
The OPSRD shall also be used as guidance for the design and implementation of TMT operations processes and staffing plan.
"It is expected that each major TMT subsystem (e.g., AO systems, instruments, enclosure, APS) will have a separate operation concept definition document (OCDD) that describes operations, calibration, and maintenance processes."
"Reference documents contain information complementing, explaining, detailing, or otherwise supporting the information included in the current document."
Early operations is defined as the period that starts when the first nontechnical facilities are accepted and continues until the observatory has reached steady-state operations.
Early science operations are expected to begin during the first 12 months after the M1 has been fully populated and phased for the first time.
Steady-state (science) operations is defined as the period that starts 36 (TBC) months after the M1 has been fully populated and phased for the first time.
The intervening time is considered sufficient for tuning the performance and operational procedures to the level necessary to meet the requirements in this section.
Nighttime is defined as the time between the end of evening nautical twilight and the beginning of morning nautical twilight.
"At these points, the center of the sun is 12 degrees below the horizon."
"For Mauna Kea, this time interval corresponds to roughly 10 hours per 24-hour period in the mean."
"Term Definition Shall ""Shall"" derequirements that are mandatory and will be the subject of specific acceptance testing and compliance verification."
"Can/May/Should ""Can"", ""May"", or ""Should"" indicate recommendations and are not subject to any requirement acceptance testing or compliance verification by the supplier."
The supplier is free to propose alternative solutions.
"Is/Will ""Is"" or ""Will"" indicate a statement of fact or provide information and are not subject to any requirement acceptance testing or verification compliance by the supplier."
The development of TMT Observatory operational requirements is motivated by several key measurable metrics of success.
The primary metric of scientific impact will be the number of high-impact science papers per unit time.
"Conceptually, a high-impact paper contains transformational and/or unique scientific results."
"Quantitatively, high-impact papers lie in the upper 1% of all refereed papers ranked by number of citations."
The TMT Observatory will endeavor to maximize the production of high-impact science papers based on data obtained with the TMT.
"This metric will be evaluated per unit time (i.e. one year, TBC) and over the entire observatory lifetime."
"The mean number of citations per refereed paper based on data obtained with the TMT, measured per unit time (i.e. one year, TBC) and over the entire observatory lifetime."
The absolute number of papers published per year based on data obtained with the TMT.
Citation decay rate as a function of time (a measure of impact longevity).
"To maximize scientific success as measured by the metrics above, the TMT Observatory will strive for technical excellence as measured by the following technical success metrics."
High-impact papers often result from exploiting unique observatory capabilities.
"Such capabilities can lie in the areas of hardware (e.g. largest M1 collecting area, best science detectors), software (e.g. very efficient target acquisition system), or process (e.g. being the first of a new generation)."
"Conversely, it is well recognized that observatories that do not add new capabilities over time quickly become scientifically irrelevant, often limiting the overall scientific return on the original capital investment."
"By design, the TMT Observatory will be first in its class in many areas at the start of operations."
"To maintain its lead in as many areas as possible within available funding, the TMT Observatory will execute a vigorous development program during the operations phase."
"In particular, this program will endeavor to provide the TMT Observatory with a steady flow of new and unique instruments and AO systems commensurate with the evolving ambitions of the TMT user community."
"As the number of science integration hours decreases, so does the potential for transformational observations."
These quantities must be minimized – by design as well as by an efficient operational process and a comprehensive maintenance program.
"More specific requirements and goals are discussed in Section 3.2, Technical Operations."
"As system performance degrades, so does the scientific grasp of TMT and hence its potential for transformational observations."
These quantities must be optimized – by design as well as by a comprehensive monitoring and maintenance program.
The TMT Observatory shall provide allocation process tools to be used by the partners.
The TMT Observatory shall provide partner-share time accounting tools to be used by the partners.
The amount of time that each Partner can allocate is defined by the TMT Board.
Discussion: Only a preliminary ’Phase I’ proposal tool will be provided as part of the construction project.
The Operations plan (RD4) sections 3.3.1 and 3.12.3 for further description of Phase I and Phase II tools.
"Discussion: If required, TMT will provide technical feasibility evaluation at the proposal phase for individual instruments and AO systems, however it will be up to each partner to assess their observing proposals."
The TMT Observatory shall create and manage a master schedule based on output from partner-based TAC processes.
The TMT observatory shall support service observing and proposal process.
The TMT Observatory shall implement and manage a telescope scheduling process.
Discussion: This process will manage and track assignment of nights to specific activities and assignment of time to targets at specific celestial coordinates.
The TMT Observatory shall implement a time accounting process for each schedule program.
Discussion: This process will allow the time used for each observation to be automatically tracked and accounted to each partner’s allocated time.
Examples of time tracking policy are given in the discussion points below.
"The tracking will account for the amount of bright, gray and dark time used by each partner."
"As much as possible, such observations will be limited to nautical twilight at the beginning and ending of each night."
Discussion: Calibrations which are specific to an observing program and taken at night will be accounted in PI/partners time.
The TMT Observatory shall implement a proposal submission process that accommodates multi-partner collaborations and allows shared observing programs.
These programs will require that observing planning tools allow secure access to single or multiple users and that time allocation and time used for single observations can be shared between partners.
The TMT Observatory at the early light stage shall provide as a minimum two observing modes; PI Directed (Classical) Observing Mode and Pre-Planned Queue Service Observing.
The TMT Observatory in PI-Directed Observing Mode shall assign specific blocks of time that are no shorter than one half night.
"Discussion: During their assigned time, PI-directed classical observing users will have complete responsibility for how they use and configure the telescope and instruments and may modify their observing program during the night as they require."
"The TMT Observatory shall provide the following 2 observing scenarios: 1) remote observing (from headquarters or other physical location) and 2) physical presence, only when physical presence at the summit is essential."
The TMT Observatory shall support remote observing using hardware and software systems certified by TMT.
The TMT Observatory shall execute service queue observing on behalf of PIs from a combined list of observing blocks from all partners via a scheduling process over six month periods.
"Discussion: An adaptive queue which dynamically adjusts to atmospheric conditions from a larger pool of partnership-wide observing programs will not be offered initially, however service queue processes and tools should not preclude this being offered later."
The TMT Observatory shall implement an adaptive scheduling process within a single partner’s allocated observing time.
These tools are not part of the TMT construction project.
The TMT Observatory shall implement an eavesdropping mode that allows the PI to connect remotely during their observation window.
The TMT Observatory shall provide a service queue mode that includes synoptic and cadence observations.
The TMT Observatory in PI Directed and Service Queue Observing Modes shall implement a Target of Opportunity Observation process.
The Target of Opportunity observations will use predetermined observing information and instrument configuration setup information stored in the observatory database.
Section 3.7 of the Operations plan (RD4) contains further information about the implementation of these observations.
The TMT Observatory shall enable real-time selection and execution of observations with flexibility in response to changing conditions and ongoing observations.
The TMT Observatory OB shall contain all the user-specific information necessary for executing and scheduling an observation.
The description of an individual service queue observation will be known as an observation block (OB).
"Each OB will contain all the information necessary for TMT Science Operations staff to configure the TMT system for observation execution, e.g. target coordinates, requested guide stars, instrument configuration, etc."
"Each OB also contains all the user-specified information necessary for scheduling, i.e. atmospheric conditions, lunar phase, etc."
The process will allow for basic information to be entered into the observatory database (Phase I) with further details necessary to perform the observation entered via an on-line tool (Phase II).
The data stored in the data base will be directly accessed to prepare the observing queue (ref.
The TMT Observatory shall implement a process that allows an OB to be verified offline and prior to observing to determine that it is executable and compliant with standard TMT procedures.
The TMT observatory shall provide an observing process that enables the observer to check their OBs and observing scripts off-line before observing.
The TMT Observatory shall implement an observing backup process to prepare and execute backup programs for observations in the event that weather conditions or technical failures prevent the planned observation from taking place.
Discussion: Backup observing programs will be prepared for all TMT observing service queue programs in the event that weather conditions or technical failures prevent the execution of the primary science program.
"Discussion: For multi-aperture instruments, an automatic field acquisition and fine alignment system will be incorporated which enables final alignment of the mask with the target field."
The TMT Observatory shall develop an automated target acquisition and system configuration process tailored for each instrument.
The TMT target acquisition sequence will be automated and tailored to each mode of the TMT science instrument.
The TMT Observatory shall track and record times of target acquisition and system configuration.
The budget and monitoring will cover all observatory activities including telescope and enclosure slewing.
The TMT Observatory in steady-state operations shall have no more than 3% unscheduled technical downtime between the end of evening nautical twilight and the start of morning nautical twilight during hours scheduled for science operations.
Discussion: Scheduled technical time will be publicly announced and taken into account when the observatory science operations schedule is constructed.
Discussion: All instruments declared to be operational are expected to have unscheduled technical downtimes commensurate with the above system level requirement.
"Any time loss due to failures of the telescope, instruments, adaptive optics systems or science observing software which prevent useful science observing with a reasonable efficiency and performance will be counted as unscheduled technical Downtime."
"Some technical faults may mean no science observing can be done, while for others there may be some degraded level of performance which is tolerable."
The TMT Observatory available science time on the telescope for observing planning purposes shall be assumed to be 50% of time for seeing limited observations and 50% of the time for diffraction limited observations (using AO).
Discussion: Site weather statistics indicate that up to 70% of the time may be able to be used for AO LGS observing.
"Observatory instruments shall be ready for use, including being powered and with their operating parameters including temperature in the required ranges."
The TMT Observatory shall monitor operational metrics to identify potential improvements and monitor observing efficiency and other telescope performance metrics.
"Discussion: Operational metrics need to be defined, but they include as a minimum available science time, unplanned technical downtime, shutter open time, weather loss, commissioning time and scheduled engineering time."
Discussion: Details of these metrics are discussed in the Operations Plan (RD4) section 3.22.
The TMT Observatory shall monitor the delivered data quality and system throughput in focal plane of the science instruments as well as at other locations related to wavefront sensors and guiding units.
Discussion: Image quality measurements will be made on a regular basis as part of system-wide monitoring.
Discussion: Baseline image quality performance will be established during TMT integration and verification.
"The TMT Observatory shall provide a proposal and observation process that at a minimum includes instrument simulators; exposure time calculators (including overheads); multi-object mask definition tool; data reduction software, calibration plan and AO simulator support."
Discussion: See section 3.8.1 of the TMT Operations Plan (RD4) for further details of these tools.
The TMT Observatory shall implement a Web portal for the purposes of organizing all information the observatory wishes to present to its user community.
Access to that area will require user authentication.
These tools are not a deliverable of the construction project.
The TMT Observatory shall develop and maintain an electronic user helpdesk with the primary goal of helping users prepare and execute observations.
Discussion: Assistance with data calibration problems will be handled on a best-effort basis.
The TMT Observatory will be responsible for keeping this documentation and these tools up-to-date as TMT systems evolve.
The TMT Observatory instruments and associated AO systems shall be delivered with a user Handbook.
Other documentation will include technical operation and maintenance manuals.
The TMT observatory shall provide Graphical user interfaces (GUIs) for all normal scientific and technical operations.
Discussion: All high-level interfaces need to have the same look-and-feel.
It is desirable that all user observing tools have same or similar user interfaces to maximize user efficiency.
The TMT observatory shall provide observer interfaces that are as simple as possible.
"Discussion: In particular, the number of windows (widgets) that must be accessed must be minimized."
"Discussion: Examples of high-level observation description parameters include target/field coordinates, instrument configuration, desired dither patterns, etc."
Such descriptions will be tailored to each major mode of every science instruments.
The TMT observatory in steady operations shall not allow observers to modify low-level technical settings.
The TMT observatory shall provide a master alarm monitor that shows TMT subsystem status.
"The TMT status will be in an easily interpretable form, e.g., a screen showing a red (alarm) or green (operational) bar for each major sub-system."
The TMT observatory shall digitally encode and record data delivered to the surface of the science detectors.
The science data stream is defined to be all science instrument detector data and associated metadata that must be captured and stored in the local observatory data store.
"The TMT Observatory shall store science data in a searchable repository of raw observations, headers and metadata and it shall be made available on-line."
The TMT observatory storage systems shall provide sufficient storage to retain the science data and associated calibration data for the life of the observatory.
"Discussion: If there are TMT external archives or data centers, the storage systems will be able to retain the most recent two years of science datasets."
The TMT observatory science data and metadata shall support enforcement of an 18 month (TBC) proprietary period after delivery to the PI.
The TMT observatory science data and metadata shall be made accessible to the worldwide community after the standard proprietary period is over.
"The TMT observatory science data shall be compatible with, or transferrable to, Virtual Observatory (VO) standards and data structures."
The TMT observatory shall support access control and search criteria for planned use cases and the expected observatory user types.
"The science and associated data in the observatory database will be used by different groups of users (PIs, partner support personnel, TMT support staff, etc."
See Operations Plan (RD4) section 3.14 for details of the access and search user scenarios.
The TMT Observatory shall provide data reduction disk space and computing capability on remotely accessible observatory computers.
Discussion: Data reduction to a level suitable for scientific analysis will be the responsibility of the lead astronomer making use of generally available data reduction software combined with instrument specific software modules that shall be provided by TMT and instrument teams.
"The TMT observatory science and/or calibration data shall be processed by TMT Observatory for the following reasons: to confirm target acquisition before observation begins; and to assess data quality (e.g. signal-to-noise ratio, delivered image quality in science instrument focal plane) during observation and as part of observatory system performance monitoring program."
The TMT observatory shall deliver for each instrument self- contained data processing software modules that meet the requirements of [REQ-1- OPSRD-2405].
Discussion: Self-contained in this context means that the modules will run without depending on observatory software.
The TMT Observatory processing pipelines shall use the data processing modules produced for each of the instruments.
"The TMT Observatory processing pipelines shall be used for quick- look reductions, target acquisition during observing and system performance monitoring."
The TMT Observatory in steady-state science operations shall minimize the amount of night time needed for acquiring calibration data.
The TMT Observatory Day time calibrations shall be scheduled in conjunction with other technical work on the telescope and be unaffected by background lighting or other disturbances.
The TMT Observatory AO system night time calibration shall consume no more than 1% of the scheduled observing time.
Discussion: Attention must be given to making instruments mechanically rigid so that calibration data taken during the day can be applied to science observations acquired at night.
The TMT Observatory shall ensure that sufficient calibration data is obtained to meet minimum standards in the context of a scientifically useful archive.
The minimum standards for calibrations will be described in the Instrument and Facility Calibration Plan.
These minimal calibration datasets may or may not be sufficient for some (or many) individual science programs.
It will be the responsibility of the individual users (or teams) to review the on-going calibration program and decide whether or not to obtain additional calibration data tailored to their specific needs as part of their own observing programs.
The TMT Observatory calibrations data shall be available to all users and have no proprietary period.
The TMT Observatory shall enable operations of multiple instruments in parallel for the purposes of instrument configuration and calibration.
The TMT Observatory performance monitoring on-sky calibrations shall be made available for science calibration and accounted under general technical time.
Discussion: Individual users may need to obtain additional calibration data.
"If so, they must request sufficient time for these calibrations as part of their original observing proposal."
Time required to obtain such additional calibration data will be accounted to the observer.
The TMT Observatory additional calibration data shall be considered public information.
"The TMT Observatory shall design, install and maintain a site condition monitoring system."
The TMT Observatory shall monitor and record external site conditions from at least one position outside within the TMT site sub-lease area.
Discussion: A location will be selected which is the least disturbed by the effects of the summit facilities for a majority of wind directions.
"The TMT Observatory site monitoring shall measure as a minimum air temperature, humidity, pressure, wind speed, wind direction, cloud cover and IQ (DIMM/MASS seeing monitor)."
The TMT Observatory shall provide TBD supplementary information about atmospheric conditions from the AO systems or on-board wavefront sensors (WFS).
The TMT Observatory site conditions data shall be made available locally in real-time at the summit and remote control rooms and stored in the observatory database.
The TMT Observatory current weather information shall be available to the wider community via a TMT Web portal and historical weather conditions stored in a public archive.
The TMT Observatory subsystems (including instruments) are required to produce status and diagnostic telemetry for the purposes of performance monitoring and failure analysis.
"Discussion: To meet this requirement, the telemetry information needs to include both low-level (e.g. hydrostatic bearing pressures) and high-level (e.g. delivered image quality) information."
The TMT Observatory shall be capable of storing all technical data that is necessary for operations for the lifetime of the observatory.
The TMT Observatory in the construction phase shall provide technical data storage capacity and software capabilities for 5 years of operations.
The TMT Observatory shall maintain two (2) copies of the technical database with the prevision in mind that one copy will survive in the event of a local catastrophe.
The technical data stream is defined to be any telemetry data produced by any TMT sub-system that must be captured and stored in the local observatory database.
The TMT Observatory shall define which telemetry data is stored.
Discussion: This can be done using filters and other means.
The TMT Observatory subsystems shall implement private data caches in the case they require large volume outside the data management system budget.
"Discussion: This data caches can be very large, such as NFIRAOS RTC circular buffer."
The TMT Observatory shall provide persistent data storage for software subsystems.
The TMT Observatory shall be capable to capture and store duration bursts of high-bandwidth engineering telemetry data.
The budgets for these data will be allocated in OAD (RD2).
"The TMT Observatory engineering data archive shall allow remote search, retrieval, storage and analysis of data."
The TMT Observatory engineering data archive information shall be time-stamped to allow cross-referencing of parameters.
The TMT Observatory shall provide the capability to permit TMT Observatory staff to access all scientific and/or technical data.
The TMT Observatory will reserve the right to access and review all scientific and technical data submitted to or generated by the TMT system.
Such reviews will be necessary as needed to monitor system performance and/or diagnosis system problems.
The TMT Observatory shall monitor subsystems performance to detect abrupt or gradual changes in performance to enable timely corrective actions.
The TMT observatory will provide regular reports to future users for planning purposes and previous users for analysis purposes.
The TMT Observatory shall update system performance information periodically as required to provide adequate monitoring.
Discussion: A sub-set of this system performance data will be made publicly available through the TMT Web portal.
The TMT Observatory shall generate a set of automatic reports based on engineering telemetry for the purposes of monitoring technical performance.
The TMT Observatory shall be equipped with monitoring sensors and alarm systems that can remotely notify support staff in the event of any non-hazardous problem.
"Discussion: An example of non-hazardous problem will be an engineering parameter that exceeds a predefined range, but is not a danger to the instrument, observatory, or personnel."
Discussion: Hazardous conditions will be reported and managed via the observatory safety system.
The TMT Observatory headquarterss control room shall enable monitoring of subsystems and checks of equipment functionality at the summit.
The TMT Observatory in steady-state operation shall use no more than 24 nights per year for scheduled engineering time.
"These activities will include as a minimum: nighttime phasing and aligning after daytime segment exchange; extended shutdowns for M2 and M3 re-coating event; as well as nighttime calibrations to revise pointing models, control system look-up tables, and active and/or adaptive system performance tuning."
The TMT Observatory shall develop a system-wide budget for daytime and nighttime scheduled system maintenance and performance tuning activities including instrument calibration and preparations for science operations.
The TMT Observatory shall develop a cost effective technical support model which can react to problems quickly in order to minimize time loss.
The TMT Observatory shall record the descriptions and time required to recover from each event for tracking and analysis purposes.
"The TMT Observatory in steady-state operations, shall develop a segment exchange process that ensures no segments have their reflectivity degraded by more than 10% longward of 380nm and by 15% at shorter wavelengths when compared to a freshly coated segment."
The TMT Observatory M2 and M3 mirror coatings shall meet their mean net reflectivity requirements for at least 24 months.
The TMT Observatory shall be able to re-coat M2 and M3 within the same shutdown period window (Goal: 5 days maximum).
The TMT Observatory in steady operations will develop and maintain technical interface requirements.
"Discussion: Examples of technical interface requirements include motion control (and controller) interface; command/control interface; data transport and archiving system interfaces; physical connectors; cabling; basic services (e.g. power, signal, coolant,…); as well as the performance environmental constraints (e.g. mass, heat dissipation in enclosure, vibration…)."
The TMT Observatory in steady operations shall establish and maintain a data interface requirement and definitions document.
"Discussion: Instrument science commissioning will begin when all instrument modes have been demonstrated to meet their technical requirements, all software tools and interfaces are complete and robust, all documentation has been completed, and the instrument is ready for scientific use."
"Instrument science commissioning activity will be executed by the observatory staff with support from the instrument team, under the responsibility of the designated observatory staff member."
"Discussion: TMT Observatory will have responsibility for instrument maintenance, minor improvements and performance monitoring."
"As required, the instrument team will occasionally provide on-going support for more complex troubleshooting and problem solving."
Discussion: Instrument upgrades and enhancements will be undertaken by the instrument team or other organizations under contracts and managed by the observatory.
"Discussion: In steady-state operations, the TMT Observatory will schedule no more than 15 nights per year for instrument commissioning (including both technical and science commissioning)."
This assumes no more than one (1) new major instrument per year and 2-3 multi-night runs.
The TMT Observatory shall support a visitor instrument program.
"Discussion: It is assumed that visitor instruments will comply with basic requirements and interface specifications that ensure operational safety is not compromised and that normal operations will not be affected by the instrument through effects such as vibration, network security, electromagnetic disturbances, etc."
The TMT Observatory visitor instruments shall be operated only in PI-Directed mode and will include their own data acquisition and storage capabilities.
Discussion: Visitor instrument data will not be stored or archived by TMT.
The TMT Observatory summit facility shall be collocated with the telescope and M1 spare segment storage facility.
The TMT Observatory headquarterss Facility shall be established within two (2) hours drive of the summit.
"The TMT Observatory headquarterss Facility shall support as a minimum administration and business services, human resources management, logistics, local government interface management, and work space for TMT science operations staff performing off-site work."
The TMT Observatory headquarterss Facility shall have a remote observing center.
"The TMT Observatory headquarterss Facility shall be located in Hilo, Hawaii, USA."
"The TMT ES&H program has the specific objectives to prevent personnel injury or loss of life during all phases of the TMT project and TMT operations; to prevent environmental contamination during the construction, shakedown or operation of TMT; to prevent damage to equipment caused by accidents during all phases of the project; to comply with all national, state and local laws, rules and regulations."
"Discussion: During operations, the TMT ES&H program is the responsibility of the TMT Director."
"The Director has responsibility to insure that the TMT staff members identify specific ES&H issues and risks, and establish appropriate safeguards and procedures for addressing those risks."
"To accomplish detailed ES&H planning, documentation and surveillance, a TMT ES&H Officer shall be appointed."
The ES&H Officer will be responsible for all ES&H program activities and report to the Director on matters pertaining to the ES&H program.
Discussion: Partner institutions manage their own safety programs.
Activities at partner institutions will be governed by these programs.
"However, TMT systems will be designed and fabricated to safety standards established by the TMT Observatory."
The primary means for mitigation of risk will be to eliminate the hazard through design.
"Incorporate Safety Devices: Fixed, automatic or other protective devices shall be used in conjunction with the design features to attain an acceptable level of risk."
Provisions will be made for periodic functional checks as applicable.
"Provide Warning Devices: When neither design nor safety items can effectively eliminate or reduce hazards, devices will be used to detect the condition, and to produce an adequate warning to alert personnel of a hazard."
"Devices may include audible or visual alarms, permanent signs or movable placards."
"Procedures and Training: Where it is impractical to substantially eliminate or reduce the hazard or where the condition of the hazard indicates additional emphasis, special operating procedures and training will be used."
The TMT observatory shall minimize the physical and visual impact in its environs.
The TMT Observatory shall minimize the emission of all electromagnetic radiation that might interfere with either itself or possible nearby future astronomical facilities.
The copyright of this document is the property of EUMETSAT.
The details of the changes to the requirement is provided in the new Annex F with a comparison of the old text vs new text accompanied by an explanation of the change and its rationale.
A summary is provided in the change record herebelow.
This allows to update the requirements and the dissemination baseline independently.
"It led to the update of the requirements: MET-08020, MET-08060, DIS-14040, , DIS-14250, the deletion of MET-08040, MET-08080, DIS-14045, DIS-14047, DIS-14260, and the addition of DIS-14048."
"It led to the deletion of DIS-14380, DIS-14390, DIS- requirements had to be modified for various reasons (e.g. obsolete text, removal of TBC) but the scope is unchanged."
"It led to the update of the requirements: FCI-02340, IRS-04075, IRS- Handled by Multi-Mission Element (MME): It led to the update of the requirements: DIS-14020 and the deletion of: DIS-14100, Mission performance clarification: it led to the addition of the (spectral sampling interval); IRS-04124 (spectral FWHM."
For associated table 9 has been updated with refined radiometric performance.
Operational scenario replaced by operational practice.
Introduction of [MTGDIS] instead of the former Annex A and the document [L2HQ] and [L2SAF].
IRS Level 1 timeliness: the goal is to have a timeliness better than EUM on the operational configuration.
IRS Level 2 timeliness: the goal is to have a timeliness better than EUM on the operational configuration.
"In line with [MTGDIS] introduction, new column “timeliness applies to”, FCI & IRS L2 split in 2 separate level 2 only."
Editorial changes or changes to ensure coherency with the conventions and terms defined in annex C are not necessarily tracked.
Updated to reflect the comments of the STG-SWG and STG-OPSWG of §1.2.2 Deletion of the old (2008) GMES document [KOP_S4] which is not cross referenced in the text.
Addition of the date to [KOP_S4-5] §1.5 open issues: the way forward for the FCI level 2 products for RSS has been clarified.
"Added “applicability of timeliness for FCI/IRS level 2 products""."
FCI-02055 updated to clarify the wording for the southern boundaries of the LAC 4 in RSS mode (in §4.1.1).
New appendix F2 to capture the requirement change between the version 4 and 4A.
Submitted for approval by Council after review and endorsement by STG #73 on 09th October 2018.
V4C 6th December 2018 Version approved by 90th council in December 2018.
Addition of an open issue related to an old definition of “scheduled outage” spotted during FCI-MAG #1.
The purpose of this document [EURD] is to define the End-User Requirements applicable to the Meteosat Third Generation (MTG) Programme.
Service requirements expressed in this [EURD] apply at the interface between EUMETSAT and the End Users (excluding networks and service components that are outside the EUMETSAT control).
"Requirements in the [EURD] are used for the end-to-end verification and validation of system functionalities, services, interfaces and operational performance till commissioning."
Actual performances of the services of the system will be described in the Operational Services Specification after the system has been commissioned.
"The essential and In-orbit verifiable End-Users requirements on content, operational availability, timeliness, etc."
The detailed requirements addressing the SAF services are covered separately in SAF-dedicated user and product requirements documentation to be established for each SAF project.
"Service delivered by the MTG System will be provided through a cost-effective combination of dedicated and specific new developments and acquisitions and generic, enterprise-like infrastructure maintained, sustained, and upgraded by EUMETSAT."
"Provisions, functions and capabilities made available by the latter will not be detailed in this document."
"The ""MTG Products Distribution Baseline [MTGDIS]"" (EUM/MTG/DOC/17/946090) is an appendix of the [EURD] aiming to define the Level 1 and Level 2 datasets that will be disseminated and archived at EUMETSAT Headquarters as part of the Meteosat Third Generation (MTG) Programme."
These are the datasets that will be available to End Users and to SAF for processing.
The [L2SAF] document is considered as an annex of [MTGDIS] of relevance for SAF developers.
The requirements affected by the instruments performance will be updated in the issue 5 of the [EURD] foreseen after the CDRs and before the launch.
The following documents have been used to establish this document.
The following documents provide useful information but are not cross-referenced in a requirement.
"All requirements are uniquely identified according to the following convention: - ‘XXX’ represents for information the requirements group identifier (i.e. the service type), - ‘nnnnn’ represents the requirement number."
It is not necessarily updated if only the is updated or if only a table shared by several requirements is updated.
However those changes are also tracked in the Appendix F.
"Additionally, s may be attached to requirements providing clarification, interpretation to the requirement body."
"Even if this information is a component of the requirement; as such, this information is not to be verified."
A complete list of acronyms is provided in Appendix G. Words appearing in italics have special meaning defined in Appendix F.
The open issues and assumptions below are those affecting the scope or general content of the document.
The open issues and assumptions specific to a given product or recipient are listed in [MTGDIS].
Specific assumptions are written as s to the relevant requirements.
Specific open issues are identified with a TBD or a TBC and a summary list of TBC/TBDs is provided at the back of this document.
Assumption: Baseline is the dissemination of the 16 channels at normal resolution (FDHSI) for both FDSS and RSS via EUMETCast satellite.
The 4 channels at high resolution (HRFI) for RSS are disseminated via EUMETCast terrestrial.
"Should all channels be disseminated at both resolutions (16 NR + 4 HR), this would imply doubling the bandwidth for FCI-L1."
Increase by 18% if a single normal resolution channel is replaced by the corresponding high resolution channel.
Increase by 25% if a single high resolution channel is on top of the corresponding normal resolution channel.
Open issue: “RSS Level 2 products” are not defined.
Assumption: No level 2 products for the RSS service.
"Way forward: To select a subset of the FCI-FDSS Level 2 Products (including SAF), after having gained experience in orbit with MTG-I1, and to adapt them for RSS before the launch of MTG-I2."
The requirement is for 120s but the goal of the users (recalled in LI-MAG of spring 2018) is for 30s.
"Assumption: the current design, considered as challenging, is for 60s."
"Associated requirements: DIS-14220 and Table 17 of §5.1, [MTGDIS] §3.3 Way forward: During development phase, the design will be scrutinized."
"Should there be a risk that one minute is not achievable, the situation will be reported and reconsidered in particular at the CDR."
"During AIV and Commissioning, reasonable attempts will be made to tune the configuration parameters to try to improve the timeliness to achieve the 30s target (in particular over Europe)."
"If not sufficient, bottleneck will be identified and a further design improvement will be considered taking benefit of technology evolution."
"Assumption ""LI accumulation window for accumulated product is 30 seconds""."
The duration of the accumulation window may vary between 10s and 30s.
The situation will be re-assessed after gaining experience with MTG-I1 in orbit and in consultation of LI-MAG.
The request of the users through IRS-MAG is to have a timeliness better than 15 min.
EUMETSAT analysis showed that it should be feasible and the [EURD] requirement has been modified accordingly.
The design will be scrutinised through the facility and system CDR and tested by EUM on the operational configuration to confirm feasibility.
"Assumption ""all LAC to be disseminated"", not only LAC 4."
The request of the users through IRS-MAG is to have a timeliness better than 30 min.
"The design will be scrutinised through the facility and system CDR and tested by EUM on the operational configuration to confirm feasibility Open Issue ""Copernicus/UVN data distribution baseline remains to be formally endorsed by the EU commission."
"Open Issue “applicability of timeliness for FCI/IRS level 2 product” need to be clarified as it Way forward: Define the term chunk or replace it by a term already defined while checking potential impact on timeliness value, update the table 17 §5.1 accordingly."
The dissemination baseline over Africa will not be finalised before 2020 earliest.
"Assumption: An aggregate bitrate of 3.5Mbps is currently assumed which will be revisited depending on the capacities, affordability and priorities."
"Current baseline considers to disseminate MSG-like L1 spectral channels every 10 minutes with a spatial resolution similar to MSG, plus a Lightning accumulated product (pseudo radar) complemented with some Level Associated requirements: [MTGDIS] §4."
Way forward: Review during the African User Forum at end of September 2020 before being submitted to council decision.
Open issue: “EUMETCast terrestrial”: This MME functionality may not be fully operational/available for End Users and private companies at the time of MTG-I1 launch.
Assumption: EUMETCast terrestrial is not planned to be used before MTG-S1 commissioning in 2023.
The situation will be re-assessed at each milestone.
"Open Issue ""Global NWP Centres, dissemination mechanism""."
And there are over 20 global NWP centres designated by WMO.
The list of datasets and products to Global NWP Centres is tentative as it has not been discussed/agreed with them.
Dedicated communication lines to the global NWP Centres may be needed.
"Assumption: For Copernicus/S4, (ECMWF) as defined with ESA."
"For initial IOC version (after MTG-I1 launch), EUM will use whatever corporate data distribution mechanisms which exist now or will exist before the launch."
"This includes with current knowledge the mechanism like EUMETCast satellite, EUMETCast terrestrial, internet, GTS/RMDCN complemented by a few point to point links (e.g. ECMWF) regrouped in the document under ""Global NWP Centre""."
"For MTG-S1 and MTG-I2, any evolution of the corporate data distribution mechanism would benefit to MTG."
The list of MTG products to be disseminated by GTS/RMDCN is tentative and subject to change.
Way forward: To be discussed in the context of GODEX_NWP (global body representing the NWP data consumption community and the satellite data providers).
TBC and old text (once the satellite supplier / design is known) to be corrected in the extract of the convention document related to “scheduled outage” (annex C page 71).
"The mission of the Meteosat Third Generation (MTG) System is to provide continuous high spatial, spectral and temporal resolution observations and geophysical parameters of the Earth / Atmosphere System derived from direct measurements of its emitted and reflected radiation using satellite based sensors from the geo-stationary orbit."
"To fulfil its mission it is required to deploy sustained capabilities to acquire, process and distribute to downstream application users and second tier processing centres environmental data on a broad spectral range (from UV to LWIR), covering extensive areas (global and regional), and within a variety of different time scales to continue and enhance the services offered by the Second Generation of the Meteosat System (MSG)."
"The MTG mission encompasses the following observation missions: Flexible Combined Imager (FCI) mission, providing 16 channels with a spatial sampling distance in the range 1-2km (also called Full Disc High Spectral resolution Imagery (FDHSI)); and/or 4 channels with a spatial sampling distance in the range 0.5-1km (also called High spatial Resolution Fast Imagery (HRFI))."
It is possible to configure the FCI to scan the earth disc in 10 minutes in support of the Full Disc Scanning Service (FDSS) or a quarter of the disc in 2.5mn in support of the Rapid Scanning Service (RSS).
The combination of channels and coverage areas are defined in the list of products.
"The earth disc is split in 4 zones of equal size (called LAC for Local Area Coverage), and numbered LAC 1 to LAC 4, from south to north."
The scan pattern repeat sequence is arranged to revisit each LAC zone in a manner adapted to the need of the End Users (Europe is revisited more often).
"Lightning Imagery mission is achieved through the Lightning Imager (LI) instrument, detecting continuously over almost the full disc, the lightning discharges taking place in clouds or between cloud and ground with a spatial sampling distance less than 10km at 45 degrees north for the sub-satellite longitude."
The Space Segment of the MTG System consists of a satellites constellation.
"Three in-orbit satellites are needed to support the complete and total set of missions and functions listed above, the full operational capability (FOC)."
Each satellite is specified for a nominal lifetime (including commissioning) of ca.
"This distribution of the payload complement and redundancies gives regard to the novelty nature of the sounding missions (IRS and UVN) and their respective downstream applications using data from geo-stationary systems, balancing the payload mass distribution, power, consumables such as propellant, and data rates making effective use of the same platform."
"Similarly to MSG, the MTG System has the capability to accommodate a GEOSAR transponder, enabling the operations of the mission under the aegis of the COSPAS-SARSAT System."
Archived dataset retrieval services continue to be provided as part of the multi-mission EUMETSAT Data Centre services.
User support services are enhanced to address MTG as well.
"The full nominal operational configuration includes a prime MTG-I satellite (supporting the FDSS services), a second MTG-I satellite (acting as in-orbit hot backup for the prime MTG-I satellite and supporting the RSS services) and an MTG-S satellite."
"These three in-orbit satellites are needed to support the complete and total set of missions and functions listed above, also called the full operational capability (FOC)."
"Using the data received from the satellites, the following data services are provided within DCP message acquisition, bulletin generation and statistics generation, Data Archival in EUMETSAT Data Centre."
These services are on top of the ones specified to be available after the commissioning of MTG-I1.
"Until that time, the Rapid Scanning Service (RSS) is provided by MSG-4."
These services are on top of the ones specified to be available after the commissioning of MTG- I1.
The satellite specified lifetime shall be 8.5 years.
The system commissioning of MTG-I1 and MTG-S1 is expected to last 12 months.
Any follow-on MTG satellite is expected to be commissioned within 6 months.
"The MTG System shall include 4 satellites (MTG-I) embarking the Flexible Combined Imager (FCI), the Lightning Imager (LI) , the Data Collection Platform (DCP) receiver and the Search And Rescue (SAR) repeater."
The MTG System shall include 2 satellites (MTG-S) embarking the Infra-Red Sounder (IRS) and the UVN-Copernicus sounder.
The system shall provide the operational MTG missions (and the related services) when the supporting satellites are located within the nominal longitude range between 10°W and 10°E.
"The MTG Flexible Combined Imager (FCI) generates simultaneously images at various spatial resolutions for 16 spectral channels, including 4 at high spatial resolution (extension of SEVIRI HRV to 4 channels)."
A local area scanning is possible with a higher repetition rate (further called rapid scan for consistency with Meteosat first and second Generation).
Normal (full disc) and local area scanning can be interleaved on a single satellite (e.g. when only one imaging satellite is operational in orbit) or conducted in parallel when 2 satellites are available in-orbit.
These two scanning modes correspond respectively to the Full Disc Scanning Service (FDSS) and Rapid Scanning Service (RSS).
"The operational practices for the Full Disc Scanning Service (FDSS), after the launch of MTG-I1, and the Rapid Scanning Service (RSS), after the launch of MTG-I2, are both defined."
The capability to perform RSS and interleaved scanning is verified during MTG-I1 commissioning.
The potential use of interleaved scanning during routine operations depends on experience in orbit and recommendation of the OPS-WG.
The FCI acquires the spectral channels simultaneously by scanning a detector array per spectral channel in an east/west direction to form a swath.
The swaths are collected moving from south to north to form an image per spectral channel covering either the full disc coverage or the local area coverage within the respective repeat cycle duration.
"Radiance samples are created from the detector elements at specific spatial sample locations and are then rectified to a reference grid, before dissemination to the End Users as level 1 datasets."
"Spectral channels may be sampled at more than one spatial sampling distance or radiometric resolution, where the spectral channel has to fulfil FDHSI and HRFI missions or present data over an extended radiometric measurement range for fire detection applications."
"The spectral channels VIS 0.6, NIR 2.2, IR 3.8 and IR 10.5 are delivered in both FDHSI sampling and a HRFI sampling configurations, the latter is indicated by #1 in the table."
The FCI shall be able to generate images covering the full Earth disc (called full disc coverage (FDC)) and a subset (called local area coverage (LAC)) with the repeat cycle duration and coverage as specified in Table 2.
"The operational practice for the FDSS (based on the FDC alone) is that the acquisition start times are around HH:00, HH:10, HH:20 etc."
"The operational practice for the RSS (based on the LAC alone) is to scan Europe, as shown in Figure 2."
The capability to support simultaneously the FDSS and RSS service using a single satellite is verified during MTG-I1 commissioning.
"The reference scenario (based on FDC interleaved with LAC) is that the acquisition start times for FDC are around HH:00, HH:15, HH:30, HH:45 and the acquisition start times for LAC are around HH:10, HH:12.5, HH:25, HH:27.5, HH:40, HH:42.5, HH:55, HH:57.5, etc."
"The start of the FCI LAC shall be configurable, by ground telecommand, to any position within the FDC, provided that the LAC is fully contained in the FDC."
The LAC zones are labelled consecutively 1 to 4 starting at the southernmost and ending at northernmost (European) LAC zone.
At least the complete Earth surface visible from geostationary altitude at 0° inclination and at the north of the boundary described in Figure 4 is available.
The diagram indicates the minimum LAC zone 4 coverage in terms of latitude and longitude on the earth.
"As defined in [CONV], the quality threshold is met when the requirements on completeness, accuracy and timeliness are fulfilled."
The percentages of the images that meet the quality threshold requirements (within timeliness) are addressed in the dissemination sections.
Unless otherwise stated the requirements in this section apply: to all repeat cycles over each MTG-I satellite specified lifetime.
The FCI spectral response function difference between any two spatial samples of the same image shall be less than 0.05 for VIS and NIR spectral channels and less than 0.10 for IR spectral channels when integrated over three times the spectral width and centred on the central wavelength.
The FCI spectral response function difference between the actual spectral response function and that characterised on-ground shall be less than 0.10 for VIS and NIR spectral channels and 0.20 for IR spectral channels when integrated over three times the spectral width and centred on the central wavelength.
"The channels VIS 0.6, NIR 2.2, IR 3.8 and IR 10.5 are delivered in FDHSI sampling and HRFI sampling configurations."
The radiometric requirements for the HRFI sampling configuration are indicated by #1 in the table.
"The FCI radiometric noise shall be as given in Table 3 with the SNR (or NEdT) requirement scaled, at signal levels α (or T) between the minimum and maximum signal, different from αref (or Tref), according to the radiometric scaling function."
The FCI medium term radiometric stability in the image data shall be as per Table 3.
The FCI long term radiometric stability in the image data shall be as per Table 3.
The FCI calibration system shall ensure that the radiometric accuracy over satellite specified lifetime does not exceed the values provided in Table 3.
The FCI spatial sampling distance (SSD) shall be as per Table 1.
HRFI sampling configuration comply with the values defined in Figure 6.
The aim of the MTF inner template at the point at which the analogue signal is converted to a digital signal is to maximise the sub-Nyquist MTF.
The absolute value of the FCI absolute pixel position knowledge error (APPKE) within a 500 by 500 pixel imagette shall be as given in Table 4.
The absolute value of the FCI absolute pixel position knowledge error (APPKE) evaluated over the complete FDC or LAC image shall be as given in Table 4.
"The absolute value of the FCI relative pixel position knowledge error (RPPKE) shall be as given in Table 4, when evaluated over all pixels common between two consecutive FDC or LAC images of the same spectral channel."
The operational practice is to rectify at 0° if the satellite is located close to 0°.
The IRS has no operational predecessors in the geostationary orbit (GEO); pioneering experiments of an imaging infrared spectrometer in GEO are just being made with the first GIIRS instruments on the FY4 Chinese platforms.
"However, long relevant experience in retrieving geophysical parameters from hyperspectral satellite data has been made for soon two decades from Low Earth Orbits (LEO), starting with AIRS and continued with IASI and CrIS."
The development of the IRS Level 2 (L2) product processing chain will capitalise on this very valuable heritage and in particular on IASI operational experience within EUMETSAT.
The IRS acquires a number of spectral soundings simultaneously over a dwell using a two dimensional detector array.
"The dwell coverage is stepped in an east/west direction to form a line of dwell spectral soundings, before moving northward to form the next line, covering the local area coverage (LAC) within the repeat cycle duration."
Up to 4 separate LAC zones can be defined and the LAC zones scanned in any order with maximum sequence length of 96 LACs before repetition of the sequence.
"The spectral soundings are transmitted to the ground as interferograms and transformed to spectral channels as part of the ground processing, before dissemination to the End Users as level 1 datasets."
The IRS shall cover the spectral domain from 680 - 2250 cm-1 in two spectral bands; a long wave infrared (LWIR) and a medium wave infrared (MWIR) spectral band with the characteristics provided in Table 7.
The LWIR and MWIR spectral bands contain specified and extended wavenumber ranges.
For spectral channels lying inside the specified portion of the spectral band full compliance is required.
"No requirements apply to the extended range, except data delivery."
The IRS shall generate a dataset covering a subset of the full earth disc (called local area coverage (LAC)) with the repeat cycle duration and coverage as specified in Table 8.
"The reference pattern for satellite commissioning consists in sequences of quarter of disc scanning, with the complete sequence repeated every 6 hours according to the following patterns: 5 times (LAC3 + LAC4) followed by 4 times (LAC2 + LAC4) followed by 3 times (LAC1 + LAC4)."
"The operational practice is to have only sequences of quarter of disc scanning, with the complete sequence repeated every 6 hours according to the following patterns: 3 times (LAC3 + LAC4) followed by 3 times (LAC2 + LAC4) followed by 3 times again (LAC3 + LAC4) and ultimately 3 times (LAC1 + LAC4 as shown in Figure 7."
"The IRS LAC shall be scanned using a regular dwell sequence with respect to the target grid, with a slow step from geographic south to geographic north and a fast step in the geographic east/west direction."
A dwell sequence moving from east to west then from west to east for alternate lines of dwells is permitted.
"The IRS shall allow the configuration of 4 LAC zones, by ground telecommand, each LAC starting at any position within the FDC, provided that the LAC is fully contained in the FDC."
The diagram indicates the mandatory LAC zone 4 coverage in terms of latitude and longitude on the earth.
The percentages of the datasets that meet the quality threshold requirements (within timeliness) are addressed in the dissemination sections.
Three or more contiguous spectral soundings (in either direction) are declared missing soundings and have been declared missing soundings for the previous 20 LAC images.
"The bullet d) intends to cover satellite detector (""permanent"") failure."
"Thus for assessing the satellite performance, the whole requirement applies."
"For the assessment of the completeness of the data delivered to the End-Users, the last bullet d) has to be ignored, if it is due to a transient loss of dataset during the transmission."
"IRS dataset level 1 spatial and temporal requirements are met, IRS dataset level 1 geometric requirements are met."
Unless otherwise stated the requirements in this section apply: to all repeat cycles over each MTG-S satellite specified lifetime.
The IRS instrument shall be based on an interferometer concept (Fourier Transform Spectrometer or FTS type) that converts input spectral radiances into interferograms.
The spectral channel interval (Δν) for both IRS spectral bands LWIR and MWIR shall not exceed the value given in Table 7.
The spectral channel interval is given for the resampled spectral channel spacing.
The actual spectral sampling of the interferogram will be variable across a dwell coverage dependent on the maximum optical path difference for a spatial sample.
The full width half maximum (FWHM) of the IRS spectral sample spectral response function (SRF) shall be less than or equal to 0.754 cm-1.
The IRS spectral sample SRF centroid wavenumber shall be determined by the spectral calibration algorithm such that the radiometric error associated to the shift determination does not exceed 50 mK (NEdT@280K) when considering a spatially homogeneous scene and the spectra given by Figure 10.
"The requirement applies at a 68.26% confidence level calculated over all spectral samples within a spectral band, considering the LWIR and MWIR spectral bands separately."
"The IRS spectral sample spectral response function difference between the actual spectral response function averaged over one day, and that given by the SRF Estimation model shall not exceed a value corresponding to a radiometric error of 50 mK (NEdT@280K) when considering a spatially homogeneous scene and the spectra given by Figure 10."
"This means that, for every spectral band, at least 68.26% of the spectral channels of every spatial sample) meet the requirement."
"The portion of the spectral bands lying in the extended wavenumber range will be delivered, but no radiometric performance is specified."
The IRS radiometric noise shall be as given in Table 9 with the NEdT scaled at signal levels between black body temperatures 200K and 280K according to the radiometric scaling function and between black body temperatures 280K to 313K with a scaling factor of 1.
The IRS medium term radiometric stability for a spectral channel shall be as per Table 9.
The IRS long term radiometric stability for a spectral channel shall be as per Table 9.
The IRS calibration system shall ensure that the radiometric accuracy is as per Table 9.
The IRS spatial sampling distance (SSD) shall be as per Table 7.
For all IRS spatial samples of the spectral channels in the wavenumber range from 900 cm-1 to 2175 cm-1 the integrated energy (IE) shall be: over a square 4x4 km2 shall be equal to or larger than 67%.
The absolute value of the IRS relative sample position error (RSPE) between any two spectral channels shall meet the requirements in Table 10 when evaluated over a LAC.
The absolute value of the IRS absolute sample position knowledge error (ASPKE) shall be as given in Table 11 when evaluated over any LAC zone.
The absolute value of the IRS absolute sample position knowledge error (ASPKE) when evaluated over a single dwell shall be as given in Table 11.
"The absolute value of the IRS relative sample position knowledge error (RSPKE) shall be as given in Table 11, when evaluated over all spatial samples common between two images of the same LAC zone separated in time by twice the repeat cycle."
The Lightning Imager acquisition and generation has no MSG heritage.
"It provides a real time lightning location and detection (cloud-to-cloud and cloud-to-ground strokes, with no discrimination between the two types)."
The LI is using detector elements arranged in a detector array covering the earth (no scanning mechanism).
The power received by each detector element is integrated over the integration period and then compared with the LI Trigger Threshold.
"If the energy exceeds this threshold, it is identified as an LI Triggered Event."
"The integration period is optimised to meet the Detection Efficiency (DE) and the False Alarm Rate (FAR) requirements, taking into consideration a typical stroke of 0.6 ms duration when observed from above."
"During the ground Level 0 to Level 1 processing, the LI triggered events are filtered to minimise false alarms."
In parallel the LI background radiance images are processed to improve the geolocation of the flashes.
The whole of Turkey is to be taken to lie within Europe for this definition.
"The coverage is to be achieved when the satellite is positioned at 0° longitude, with the requirement SYS-00130 not being applicable for the calculation of the coverage."
The LI triggered events shall be obtained by measuring the LI lightning spectral radiance from the strongest lightning emission features within the cloud top optical spectra produced by the neutral oxygen atom lines in the near infrared.
The OI(1) line at 777.4 nm made of three lines of nearly equal intensity with a total separation of 0.34 nm.
The percentages of the datasets that meet the criteria threshold requirements (within timeliness) are addressed in the dissemination sections.
The LI shall provide a spatial sampling less than or equal to 10km at 45oN for the sub- satellite longitude.
"Observation of ultraviolet and visible and near-infrared radiation will be provided by MTG through measurements made with a dedicated instrument (UVN payload), that will be the GEO part of the Sentinel 4/5 System provided by EC and ESA."
"The UVN observations are used to measure several trace gas species (O3, NO2, SO2, HCHO, CHOCHO), and gain information on aerosols, clouds and the Earth surface."
The UVN is specified and developed in context of an ESA programme.
"This section can therefore not contain EUMETSAT requirements on the instrument, but rather reflects the current understanding of expected UVN performance as well as requirements on the ground segment to support its operations."
Details on UVN instrument requirements can be found in [KOP_S4-5].
"In its nominal mode, the UVN data acquisition service will provide data over the Geographical Coverage Area (GCA) specified in Figure 11."
The nominal GCA will comprise the longitude range from 30°W to 45°E at latitude 40°N.
The nominal repeat cycle of 1 h will correspond to a longitude range of 55° at 40°N indicated as the Reference Area (RA).
The RA is positioned at the easternmost point in the GCA during the morning and is moved westward to follow the solar illumination of the GCA during the day.
"The spatial sampling distance at 45N latitude, 0E longitude of UVN measurements, in both N-S and E-W directions, will be smaller than or equal to 8 km."
The spectral resolution will be smaller than or equal to the values specified in Table 12.
The spectral sampling ratio will be larger than or equal to the values specified in Table 12.
The position of the spectral channels centres in Earth spectral radiance mode for all samples acquired between two consecutive solar measurements will not vary by more than 0.01 (UV- VIS) and 0.05 (NIR) of the spectral sampling interval (SSI).
The SNR of the spectral channels for (Earth) radiance and reflectance measurements will be larger than or equal to the values specified in Table 13.
The absolute radiometric accuracy of the Earth spectral radiance (resp.
"NIR: MAX [ 1% Sref(λo), 5% S(λi) ] (threshold), MAX [ 1% Sref(λo) , 2% S(λi) ] (goal)."
Over land: 0.1 (Goal)/ 0.2 (Threshold) SSD (1-sigma).
Interband spatial co-registration knowledge between bands will be better than 0.2 SSD between NIR and the UV and VIS bands; and 0.1 SSD between the UV and VIS band.
"In order to provide continuity to the present Meteosat Second Generation (MSG) programme and its set of derived products, the extraction of Level 2 product(s) is also foreseen as a key service for MTG."
"The list of products to be generated from the MTG missions, the respective generation philosophies, and the decision where each product is generated (at the EUMETSAT Headquarter or within the SAF network) are decisions taken by Council following the established process as described below."
"For the Level 2 products generated at the Headquarter, the process for preparing these decisions include the consultation of the STG-SWG and OPS-WG before being presented to STG and approved by Council."
"For the SAF network, the decisions are taken in the context of the CDOP approval by Council of the SAF proposals and also by subsequent decisions of SAF SGs, as SAF plans evolve in response to user requirements."
"The Level 2 Products generation service at EUMETSAT Headquarters shall provide a continuity of service between MSG and MTG concerning the Level 2 Products generated, albeit with improved quality, resolution, timeliness and new Level 2 Products, as defined in [MTGDIS]."
"The Satellite Application Facilities (SAFs) use specialised expertise in Member States, to complement the production of Level 2 product(s) at EUMETSAT’s HQ."
The SAFs also supply software packages for generating products at the end-users’ own sites or generate additional products which may be fed or not into EUMETSAT’s dissemination infrastructure.
"As is the case for the centrally generated Level 2 product(s), the SAFs ensure a continuity of service between MSG and MTG while new MTG specific products are developed."
The operational availability requirements that apply to product generation at the SAF are to be agreed between EUMETSAT and the SAFs.
"The timeliness apportionment for SAF products is calculated such that for the end-users, the timeliness is comparable to centrally generated products."
The following diagram is showing the apportionment of the activities required for providing SAF products to the final users.
"The timeliness depends on the characteristics of the product, in particular its periodicity."
The following tables are showing the allocation of the end-to-end timeliness to the various contributors according to SAF categories.
The T1 to T3 Timeliness include a tentative allocation of 5 min for SAF to EUM HQ : Timeliness for FCI based products is calculated on a repeat cycle basis : Timeliness for LI is calculated per chunk of ca 10s.
The SAF system provides the catalogue update to MME-DAC (for archiving) within a day of the products generation.
"The Level 2 Products generation service by the SAF shall provide a continuity of service between MSG and MTG concerning the Level 2 Products generated, albeit with improved quality, resolution, timeliness and new Level 2 Products as defined in [MTGDIS]."
"The operational availability for the SAF acquisition, processing and SAF to EUM HQ transmission shall be 98% within the timeliness defined in Table 14, Table 15 and Table 16 in the column T1 to T3."
"The operational validation of the end to end performance (T0 – T5) is performed jointly by EUM and SAF against the thresholds values defined in the [MTGDIS], see also §5."
"The MTG Data Collection Platform (DCP) services involves, as a continuity of MSG service, the relay of DCP messages by the satellite, on-ground processing of the digitised DCP spectrum and dissemination of the resulting DCP messages, statistics and DCP Bulletins to end-users."
"The DCP platforms can be fixed on land or embarked on a buoy, ship, balloon or airborne."
The performance monitoring of the DCP mission includes monitoring of the reception of DCP reference platforms and the quality and timeliness of DCP messages.
"Acquire data, via MTG-I satellite relay from registered DCPs for further distribution."
Monitor and derive statistics for each individual DCP (e.g. deviations from the nominal time slot and frequency channel allocation) and provide notification to the relevant DCP operator within 2 working days of any anomaly detected.
Provide real time indication on the quality of the signal.
Create DCP bulletins from acquired DCP messages for further distribution.
The EUMETSAT Data Centre (previously UMARF) provides long-term archiving and catalogue functions for all EUMETSAT programmes and projects.
This section provides the requirements for the archiving.
It is expected that the EUMETSAT existing multi-mission EUMETSAT Data Centre evolves to cope with the MTG needs.
The SAFs are each expected to have their own local archive for the SAF-generated products.
"However, some SAF-generated products may be transferred for archiving in the EUMETSAT Data Centre."
"In any case, each SAF makes available the catalogue of its own archive on the EUMETSAT Earth Observation Portal."
"In this way, it is possible for end-users to browse the catalogue of SAF-generated products, as well as all of the centrally stored mission data."
The Level 1b and Level 1c disseminated dataset which have been centrally generated.
The Level 2 disseminated dataset which have been centrally generated.
"Reprocessed datasets from Level 1, Level 2 and selected SAF Level 2 product(s)."
"They are identified in the column ""EUMETSAT Data Centre""."
Assuming that the catalogue is maintained by the SAF archiving centre and provided to EUMETSAT.
"The EUMETSAT Data Centre archive and catalogue of all archived dataset elaborated from Meteosat First Generation (MOP/MTP), Meteosat Second Generation (MSG) satellites, and MTG shall be maintained over the lifetime of the MTG programme."
The continuity of EPS archive has to be addressed by Post-EPS programme and the continuity of Jason archive has to be addressed by Jason follow-on programme.
The MTG System shall allow reprocessing of any archived dataset to derive and archive new datasets or new versions of any dataset without impact on the nominal operational missions.
The following near-real time dissemination and relay services are covered in the following Search & Rescue (SAR) Relay Service.
The EUMETCast Dissemination Services might in future consist out of a combination of different telecommunication means such as satellite and terrestrial links.
The assignment of a service to a delivery mechanism is flexible and depends on the geographical distribution and size of the user communities.
"The split between them depends mostly on the amount of datasets to be delivered to users, with associated timeliness requirements taking into account their affordability to the users/member states."
"The need of different dissemination systems: EUMETCast over Europe and Africa and other distribution mechanism (Terrestrial, OLDA, GTS, MME-DAC, MME-MON) and the split between them depends mostly on the amount of datasets to be delivered to users, with associated timeliness requirements taking into account their affordability to the users/member states (main reason why there were two different dissemination methods in MTP and MSG)."
"With the information at hand today, delivery of the full set of MTG datasets to all potential users at all potential locations might not be possible within the financial envelope of MTG (at least at the beginning of the programme)."
"The radiometrically calibrated and geometrically rectified FCI images at reduced, normal or high spatial resolution and reduced or normal temporal resolution A compressed representation (e.g. Principal Components) of calibrated and geolocated IR Calibrated and geolocated UVN sounder datasets."
"The dissemination coverage is split in several zones (e.g. Europe, Africa, terrestrial…) and the exact content depends on the zone."
EUMETCast is also transmitting data from other internal programmes and is relaying as well data from third parties e.g. Foreign Satellite Data (FSD) and Meteorological Data Dissemination (MDD).
A dataset arriving after the mentioned timeliness is not considered as available for the end-user.
These figures apply as is to EUMETCast by Satellite.
"In the case of EUMETCast terrestrial, the network used has no formal Service Level Agreement (SLA), offering a best effort service."
Thus its outages are classified as external outages and are not taken into account in the figures.
"When including the availability of the network, the achieved value of the EUMETCast terrestrial service is expected to be above 95%."
The objective is to achieve the goal during routine operations.
This implies that the initial MTG System and its operation are designed to achieve the goal.
"The difference between the spec and the goal being a margin allowing some design optimisation and shared between system, ground segment and facilities."
At system level the formal verification will consist in the assessment of the margin against the specified values.
The operational system validation will be against the goal.
The LI flash product is generated following level 2 processing and consists of LI triggered events clustered into LI groups associated with a particular lightning flash.
EUMETCast terrestrial services for pre-defined users.
"The list and periodicity of disseminated dataset transmitted by EUMETCast, for each of the geographic regions, shall be as defined in [MTGDIS]."
"The dissemination of IRS level 2 products for the LAC 1, 2 or 3 is not a condition for the entry into operational services of the other IRS based services."
"The list, timeliness and periodicity of the datasets disseminated via the various dissemination mechanisms shall be configurable."
The IRS disseminated dataset shall consist of a number of principal component (PC) scores derived from the full set of spectral channels.
To be based on the experience derived from IASI data distribution.
The operational availability of rectified images of the Full disc scanning service (FCI-FDSS) shall be as per Table 17.
The operational availability of FCI Level 2 product(s) shall be as per Table 17.
The operational availability of DCP messages & bulletins shall be as per Table 17.
The operational availability of rectified images of the Rapid scanning service (FCI-RSS) shall be as per Table 17.
The operational availability of IR sounder dataset shall be as per Table 17.
The operational availability of IRS level 2 products shall be as per Table 17.
The operational availability of UVN sounder dataset shall be as per Table 17.
The operational availability of Lightning group and flash product shall be as per Table 17.
"During development phase, the design will be scrutinized."
The operational availability of SAF Products shall be as per Table 17.
The timeliness allocation for SAF Products dissemination is defined in §4.5.2.
The Regional Meteorological Data Communication Network (RMDCN) is used by WMO Region VI to carry the following GTS traffic (within Europe): Service messages.
The Global Telecommunication System (GTS) of the WMO (World Meteorological Organisation) may further distribute these data to users which are not connected to the RMDCN.
An evolution of the GTS into the WMO Information System (WIS) is foreseen.
"Operational availability, timeliness and the calculation method are defined in Annex C. A dataset arriving after the mentioned timeliness is not considered as available for the end- user."
"The list, characteristics and periodicity of disseminated datasets transmitted via RMDCN shall be as defined in [MTGDIS]."
The operational availability of Level 1 datasets shall be as per Table 18.
The operational availability of Level 2 product(s) shall be as per Table 18.
The operational availability of DCP bulletins shall be as per Table 18.
"Since MSG-1, every METEOSAT satellite carries a Search and Rescue (SAR) transponder for relay of 406 MHz beacons activated anywhere in its field of view."
"This secondary mission means that the satellite is part of the constellation of satellites that constitutes the space segment of the Cospas-Sarsat international system, whose aim is to provide distress alert and location information to appropriate rescue authorities for maritime, aviation and land users in distress."
"The MTG System shall support the SAR mission by accommodating a satellite repeater, on each MTG-I, between the SAR distress beacons and the SAR receive ground stations, as long as this is not to the detriment of the other missions."
The operational availability of the satellite SAR repeater shall be better than 99%.
Achieved when considering two MTG-I satellites in orbit.
Otherwise redundancy is ensured via Cospas-Sarsat satellites overlapping.
The retrieval of data via internet is now merged into §6 Data Retrieval Services.
"EUMETSAT provides Data Retrieval services as part of the multi-mission EUMETSAT Data for authorised users to retrieve recent centrally disseminated datasets; for the DCP operators to retrieve their own DCP messages and information about the operational status of their DCP platforms including statistics on the performance of the DCP for the general public, via the EUMETSAT website, to retrieve some dataset (e.g. Satellite Images or animation)."
"The service allow the users to register, navigate through the catalogue of MTG data, retrieve historical scientific mission data, browse low to moderate resolution data/products, and request data."
The dataset retrieval for off-line users is addressed in §7.4 Helpdesk service.
Registration is done via the EO Portal service described in §7.2.
The EUMETSAT Data Centre archived dataset and catalogue of all Meteosat programmes shall be available for retrieval by users over the lifetime of the MTG programme.
"The EUMETSAT Data Centre archive user guide (EUMETSAT Archive User Guide (see [UG04]) shall be maintained, to describe the ordering mechanism and options including the available media, the delivery formats and other characteristics of the MTG archived datasets which can be retrieved."
"Differences may relate to time ranges of data, subsetting, compression, etc."
"The operational availability, with a timeliness of 1 hour, of disseminated dataset for retrieval by End-Users shall be better than 99%."
The distribution of information about the operational status of the systems and services.
The provision of a centralised data access point (the Earth Observation Portal).
The provision of Operational Programmes data content on EUMETSAT corporative web pages.
"The User support services are capable of providing general, descriptive and expert information about the MTG and its mission data, products and services, both routinely and in response to requests."
"Depending on the context and urgency, the following Service Messages concerning the Administrative - Summarising the service interruptions during the whole of the previous calendar day."
The service messages and their release conditions are described in Appendix A.
"It allows users, Discover the collection of datasets (e.g. image, Level 2 Products, Level 3 Products, SAF) Search for and order of specific instances of EUMETSAT archived datasets (see §6) and of Subscribe to EUMETSAT or external partners dissemination services; Subscribe to User Notification Services (UNS)."
"Access to service-related documentation, and appropriate links to information available on EUMETSAT internet."
"It also allows partner agencies to discover, search, order and subscribe to EUMETSAT data and dissemination services through their own portal."
It federates with a common interface the following operational services: EUMETSAT Data Centre Retrieval services including catalogue searching and ordering User Notification Services (UNS).
MTG Mission archived dataset and services shall be discoverable by users through the EUMETSAT Earth Observation Portal.
"Users shall be able to search, order, and retrieve MTG archived datasets through the EUMETSAT Earth Observation Portal."
Users shall be able to register to MTG services through the EUMETSAT Earth Observation Portal.
Users shall be able to retrieve all the information necessary to read and display archived datasets and disseminated datasets.
"This includes pseudo code where appropriate, documentation, user guides..."
"Information about the MTG programme, data, documentation, services and status; A subset of MTG sub sampled images."
A significant part of these services are available on-line (through the EO portal (see §7.2) and the internet web pages (§7.3)).
However some users may not have a proper internet access and thus an alternative way is provided here.
The response time of the Helpdesk Function depends on whether the user request involves a bespoke response or an off-the-shelf response (e.g. one which can be found on the EO portal).
Multiprogramme and Corporative wide Help desk capabilities shall be upgraded to extend its service and coverage to MTG.
"When delivering the services, the EUMETSAT [DATAPO] and the Sentinel-4 [DATAPO- S4] data policies are taken into account."
The MTG Level 1 Datasets generation and dissemination baseline is provided in [MTGDIS].
The following text lists definitions for all reserved terms used in this document.
"It is a subset of the ""MTG Conventions and Terms"" document."
The section numbers below are the original section numbers from this document.
The LI lightning spectral radiance is the lightning optical pulse radiance as measured by the LI instrument in orbit.
"Peak intensities of the three spectral lines according to the oscillator strengths specified in Table 1, where it shall be assumed that the relative emission strength of the lines depends linearly on the oscillator strength f (dimensionless number)."
More details about these emission lines are provided in Table 1.
E_i and E_k are the atomic oxygen energy levels from which the transition wavelengths are derived.
The two rightmost columns provide background information on the oxygen energy levels and spin states.
"Any imaging satellite of the series (MTG-I1, MTG-I2, MTG-I3 or MTG-I4)."
"Any sounding satellite of the series (MTG-S1, MTG-S2)."
It designates the terms defined in the Conventions and Terms document.
"A dataset is a logical grouping of data e.g. it can be a packet, a subset of image or interferogram (group of related spatial samples or lines, swath, segment, spectral sounding information), LI triggered events, LI group, meteorological products, DCP messages or DCP bulletins... or a collection of the above over time (e.g. for climate related dataset)."
Housekeeping telemetry (HKTM) is all the telemetry necessary to monitor the health and status of the satellite and transmitted through the S-band telemetry link.
All the data transmitted via the payload telemetry link.
After decryption and extraction of the packets from the frames the payload data is presented as: a copy of the housekeeping telemetry.
Extraction of the packets from the transfer frames includes any necessary re- ordering and consolidation.
Compression may apply according to the instrument design.
Platform auxiliary data is any auxiliary data derived from platform equipments that is not transmitted as part of the housekeeping telemetry.
"Raw data coming from the AOCS is classed as platform auxiliary data, since it cannot be transmitted as part of the HKTM on the S-band telemetry link due to its volume or any other appropriate reason."
"The science data is the observation data originating from the instrument(s)/sensors, it applies at any data level."
Earth location information is part of associated auxiliary data.
Instrument auxiliary data is auxiliary data recording the internal parameters of an instrument as necessary for instrument data processing.
"Auxiliary data is any data that is neither science data, Digitised DCP spectrum nor housekeeping telemetry, used in or generated by Instrument Data Processing or Application Ground Processing."
"See also instrument auxiliary data, platform auxiliary data, IDP auxiliary data, IQT auxiliary data, AGP auxiliary data..."
IDP auxiliary data is auxiliary data resulting from the instrument data processing.
AGP Auxiliary Data is auxiliary data resulting from the application ground processing.
"The Disseminated Dataset includes all the data disseminated in Near Real Time via the various dissemination mechanisms (e.g. EUMETCast, internet, GTS/RMDCN...)."
The Archived Datasets includes all the data stored in the Data Centre and retrievable by internal or external users.
The Level 1 dataset consists of the science data at level 1 and the IDP auxiliary data nominally collected during one repeat cycle or accumulation interval.
The Level 2 Products consists of the science data at level 2 and the AGP auxiliary data nominally collected during the product time span (e.g. one or several repeat cycles).
Messages sent by DCP platforms containing measured meteorological information.
"Two types of DCP messages exist, the self-timed messages: messages transmitted periodically within the allocated time-slots and the alert messages which are special messages transmitted when the values of one or more measured parameters exceed predefined thresholds."
DCP Bulletins are generated from one or more DCP Messages conforming to the WMO Manual on Codes depending on their contents and dissemination formats.
"The External Data are those necessary for the Level 1 and Level 2 (re-)processing (include forecast data, observation data, calibration data) or for relaying by EUMETCast (e.g. MDD)."
The IQT auxiliary data is the additional data produced by the IQT at the same time as the level 1 science data allowing the interpretation of the science data and providing the satellite and IQT model status.
This excludes the off-line IQT performance assessment data.
"The ratio of the datasets “received” and that meet the Quality threshold, with that scheduled to have been “sent” or ”made available"", for a given period (removing the part of the period corresponding to the scheduled outages and the external outages)."
The Scheduled outages have to be announced to the end-user through the weekly schedule message.
"Outages are defined as ""the state of an item of being unable to perform its required function or performances""."
"Outages can be scheduled outage, unscheduled outage or external outage."
"Satellite availability is defined as the percentage of the time during which the Satellite provides all the required payload data, with Quality threshold being met."
It has to include the allowance for response from the ground as defined in [SRD]/[OBRD].
The sources of outage to be considered are those at satellite level.
"The Quality threshold is met when the requirements on Completeness, Accuracy and Timeliness are fulfilled."
This implies that a short outage preventing a repeat cycle to be completed on time has to be considered as an outage of the whole repeat cycle.
"A dataset is complete if no data has been lost since its generation, unless a requirement in the product specification or service specification allows some losses (e.g. missing samples)."
The requirements on accuracy are dataset specific and provided in the product specification or service specification.
"The timeliness is the time difference between the foreseen end of acquisition of the last contributing data (e.g. from a sample, a dwell, a swath, granule, a segment, an image, a file) by EUMETSAT (at satellite level for Meteosat, Metop or at Ground Segment level for external data like FSD and SAF), and the end of reception of the corresponding data (possibly processed) by the users (i.e. before decryption and decompression)."
It excludes also the processing time outside EUMETSAT control (e.g. SAF processing time).
The scheduled outages are due to planned operations or predictable events.
At satellite level the specification limits these outages to 3% per year.
Other scheduled outages are mainly due to planned ground segment maintenance and should be less than 0.5%.
"Also, the quality of around 5% of the acquired datasets per year may be degraded for some channels during eclipse seasons."
The tentative list hereafter identifies the events leading to the outage or quality degradation and attempts to estimate their individual duration.
Satellite orbit manoeuvres (e.g. Station Keeping) leading to a disturbance of the satellite attitude.
"The frequency of the outages depends on several parameters such as orbital position, satellite collocation strategy, satellite design and manoeuvre strategy."
There can be up to a few tens of manoeuvres per year with the outage lasting up to three hours each time.
Satellite yaw-flip leading to re-orientation of the satellite attitude and consequently to an interruption of the mission.
This occurs twice a year and with the outage lasting up to half a day [TBC 1] each time.
"Instrument decontamination requires that the Infrared sensors are switched off, thus interrupting the imaging in these channels."
The decontamination may also require interrupting/degrading the other channels (due to distortions introduced by the IR decontamination).
"Outage is typically one day once or twice per year, influence on other channels will be re-assessed once the satellite supplier / design is known."
Frequency and duration will be refined once the platform supplier / design is known.
"Sun, satellite, ground station co-linearity effect."
"When the Sun enters the main lobe of the ground station antenna, this may prevent the proper reception of the Ka-Band link."
"The co- linearity occurs twice a year around the Equinox seasons for around 10 days, impacting a few repeat cycles per day."
The extend of the co-linearity effect will be re-assessed once the MDA sites and characteristics are known.
The swap of a mission from one satellite to another (e.g. after the completion of satellite commissioning when the operational missions are transferred to a new satellite) will result in an outage of a few hours.
"The temporary swap of the full disc scanning service (FDSS) from the prime to the secondary imaging satellite and vice versa would result in an outage of a few hours on the FCI-FDSS at each swap and an outage of the Rapid Scanning Service (FCI-RSS) for the whole duration of the swap (e.g. during prime satellite decontamination, yaw flip manoeuvre)."
Some ground segment maintenance may not be achievable without service interruption (e.g. to swap between a prime and redundant service).
These interruptions are sporadic over the year and their exact duration depends on the disseminated dataset and maintenance activity performed.
"During the eclipse season the dataset quality will be degraded for some channels and/or a part of the coverage, however no interruption of the dataset acquisition and dissemination is foreseen."
The quality degradation around the eclipse is primarily due to stray light and thermal effects.
The degradation occurs typically for a few hours around midnight.
"There are 2 eclipse seasons per year, each lasting 42 days."
"The exact influence of the stray light on the dataset will be characterised in orbit, although the period of affected data will be predicted from on-ground analysis."
"This des all the unscheduled outages, thus a precise list cannot be made."
"The most Ground segment reconfiguration may cause outages, however such maintenance activities are normally scheduled in advance."
Loss of communication links (e.g. between ground stations and headquarters).
"This term groups all the outages outside EUMETSAT control, thus a precise list cannot be made."
"The most common causes for the outages outside the control of EUMETSAT are: Networks outside EUMETSAT responsibility, which in this context are networks that are not managed by EUMETSAT or for which no Service Level Agreement (SLA) exists (for External data unavailability (e.g. Meteorological Data Dissemination (MDD), Foreign Satellite Data (FSD), incoming forecast data...)."
Effect of lack of redundancy of the space segment (i.e. only one satellite in orbit).
"Unavailability of DCP beacons and SAR beacons, or those working outside specification."
"Flight Acceptance Review (FAR) – S/C acceptance prior to shipment to launch pad or Duration of S/C Storage – to be defined on the basis of the MTG deployment sequence Begin of Life (BOL) = BOL Satellite Specified Lifetime, starting from Launch End Of Extended Life (EOEL) at the end of Satellite Lifetime extension First Satellite Commissioning for both MTG-I and MTG-S is expected to last 4 months."
Recurrent satellites are expected to last 2 months.
System Commissioning for both MTG-I and MTG-S is expected to last one year.
Recurrent satellites are expected to last 6 months.
The Satellite Specified Lifetime is defined as the time in orbit from separation from the launch vehicle to satellite re-orbiting as depicted in Figure 1.
The satellite nominal operational lifetime is defined as the time in orbit over which the performances have to be met with a given satellite availability and excluding the time necessary for the execution of LEOP and satellite commissioning (see Figure 1).
"The word Satellite is used within MTG system to define a complete self standing subset of the MTG space segment, including Platform and Payload (observational instruments), all Platform and Payload supporting functionalities, and the interfaces to the external environment."
"Two types of ‘satellite’ are foreseen in the MTG system, the MTG-I and the MTG-S."
"The ‘platform’ provides all the resources, functionalities and performances necessary to support the nominal and contingency operation of the payload."
The parts of the satellite used to acquire the data that will generate the mission products.
"For MTG the payload comprises FCI, IRS, LI, UVN, DCP and SAR when embarked on their respective satellites."
A satellite item that can be physically depleted after a given period of time.
Orbit determination of a spacecraft requires as input measurements that are related to the satellite's position and velocity.
The classical two-way radar ranging employs a ranging signal that is radiated from the ground station to the satellite.
A satellite transponder is required to receive the signal and to transmit it back to the ground station.
"The ground station receives the transponder ranging signal from the satellite and determines the signal travel time T. This is expressed as an equivalent range value R= cT, which is equal to the sum of the uplink and downlink distance."
"On the geostationary arc, with a longitude anywhere between 10°W and 10°E."
"The part of the MTG System that is on ground and encompasses all software and hardware resources (including communication) to enable operations of all in-orbit MTG satellites, interfacing with external entities (e.g. Launch provider, satellite manufacturer, ECMWF) and provision of the services to the end-users with high operational availability."
"It also encompasses additional resources enabling development, testing, verification and operational validation of software, hardware and configuration data, as well as operations preparation, training and performance analysis, in parallel to operations."
Instrument data processing (IDP) is the function that converts instrument data coming from the satellites into level 1 datasets.
Application Ground Processing is the combination of the central Level 2 Processing located at the EUMETSAT Headquarter and the decentralised Satellite Application Facilities (SAF).
Level 2 Processing (L2P) is the function that converts Level 1 Datasets into Level 2 Products.
"The Data Centre is a Multi-Mission Element (MME) composed of UMARF, Earth Observation Portal and GSICS server."
"Data Centre component that receives and archives datasets at level 0, level 1 and level 2 together with auxiliary data and other associated data for all EUMETSAT satellites in view of deferred retrievals."
"The archiving process is automated, and is carried out 24 hours a day, every day of the year."
Data Centre component that provides a comprehensive data retrieval service including On-line access (via internet) to the archived dataset catalogues and other information on the archive.
"The EUMETSAT EO Portal provides means to discover the archived dataset collections, navigate and query the MTG catalogue."
The retrieved archived datasets can be tailored (e.g. spectral and spatial sub-setting) prior to media / online dataset delivery.
"The service includes administration functions with end-user interface (User Management and licensing, Help-desk, information Service, ordering, subscription, etc."
The GSICS data and products server is a platform for the inter- calibration of operational satellite sensors.
The Global Space-based Inter-Calibration System (GSICS) is an international collaborative effort to examine and harmonize calibration data from operational weather satellites sensors to improve climate monitoring and weather forecasting.
EUMETSAT’s Broadcast System for Environmental Data is a Multi-Mission Element dissemination system based on standard Digital Video Broadcast (DVB) technology.
"It uses commercial telecommunication geostationary satellites to multicast files (e.g. Level 1 dataset, Level 2 products) to the user community."
Verification and validation activities conducted after the launch and before the entry in operational service either on the space elements only or on the overall system (including the ground elements).
Commissioning of the overall system terminating with the closure of the System Commissioning Results Review (SCRR).
Confirmation through the provision of objective evidence that specified requirements have been fulfilled.
"Confirmation, through the provision of objective evidence that the requirements for a specific intended use or application have been fulfilled."
"The centroid is the generalized mathematical expression for quantities used in science and engineering such as centre of gravity, centre of mass and barycentre."
The centroid of a function of N independent variables is the intersection of all hyperplanes that divide the function into two parts of equal moment.
For example the centroid of a function with two independent variables is given by the .
Data levels are used to describe the condition of the science data at various points in the ground processing cycle.
The WMO lists the following data levels on their web site: Level 0 - Raw data.
"Level 1 - Data extracted by instrument, at full instrument pixel resolution, with Earth- location and calibration information."
"Level 2 - Geophysical value (temperature, humidity, radiative flux…) at instrument pixel resolution."
Level 3 - Remapped (gridded) product based on geophysical value derived at instrument pixel resolution.
Level 4 - Composite product (multisource) or result of model analysis of lower level data.
"For MTG the basic sense of WMO data levels is maintained, without the concept that the science data has to be at instrument pixel resolution."
"Enhancements of the data level definitions are given in the definitions of level 0, level 1 data."
"Level 0 data is the science data at packet level, after restoration of the packet-wise chronological data sequence for a given instrument."
"Level 1 describes, for a given instrument, a variety of different data sub-levels that are related to Instrument Data Processing (IDP)."
At level 1b radiance samples are associated with a particular spatial sample.
The spatial samples may then be rectified to form pixels located at fixed positions in the reference grid giving the level 1c data.
"Level 1a data is level 0 science data in counts after removal from the packets, whilst maintaining the spatio-temporal sequencing of the data."
Level 1b data is level 1a science data radiometrically and spectrally calibrated.
Level 1c data is level 1b science data rectified to a reference grid.
"Level 2 relates to level 1b or level 1c science data converted to geophysical values (temperature, humidity, radiative flux…) during application ground processing."
The spatial sampling distance is the required spatial sample spacing and is used as a base unit against which geometric requirements are assessed.
All requirements expressed in spatial sampling distance are taken to apply at the sub-satellite point and can be translated to a spatial sampling angle used to evaluate the requirement at all other positions in the area of coverage.
The angle subtended by the spatial sampling distance at the Sub-Satellite Point as seen from the satellite.
The sub-satellite point (SSP) is the intersection by the line drawn from the satellite to the centre of the Earth with the surface of the <Earth’s Reference Ellipsoid>.
"The grid angles are defined, in terms of the Normalized Geostationary Projection, as ), where S2’ lies in the S1/S2 plane at an angle λ S from S2 about the S3 axis."
"The grid steps are equiangular both in λ S and ϕ S and equal to the spatial sampling angle of the considered channel, Figure 3."
The corresponding projected distance at the sub- satellite point is the spatial sampling distance.
For reference grids of differing resolutions the grids are aligned as given in Figure 4 i.e. the fine grid pixel centres are offset by half the smaller spatial sampling angle from the coarse grid pixel centres in both λ S and ϕ S. See Figure 5.
The Target Grid is the set of spatial samples defined by the scan strategy for an unperturbed spacecraft at a fixed geostationary position.
The points are defined using the same projection as the reference grid.
"The estimated grid is the set of spatial samples defined as an outcome of the image navigation process, i.e. each spatial sample's location in space as a result of the image navigation process."
The verification grid is the set of spatial samples used for image navigation verification in conjunction with the estimated grid.
"An image is defined as the set of radiance samples acquired in a repeat cycle, associated at level 1c: with all the points (pixels) of the reference grid that are included in the area of at level 1a and 1b: with all the points (spatial samples) of the actual grid that are included in the area of coverage."
Coverage is defined as the region over which science data is collected.
"Full Disc Coverage (FDC) is defined as the maximum area of coverage required from an instrument, particularly if this involves the complete coverage of the Earth disc."
Local Area Coverage (LAC) is defined as a sub-area of full disc coverage.
A LAC zone is defined as an area of coverage meeting the LAC requirements.
In cases where more than one LAC zone are in use the LAC zones should be numbered from south to north starting from 1; see Figure 6 and Figure 7.
A dwell is the time period and area over which the sounder gathers simultaneously a group of spectral soundings and has properties of dwell time and dwell coverage.
The dwells within a LAC zone are numbered in the order of acquisition starting from 1; see Figure 10.
Dwell coverage is the area covered by all spatial samples of the spectral soundings collected during the same acquisition time.
The dwell time is the time period required to collect an interferogram (from which are deduced all spectral samples).
A swath is defined as the area covered by the spatial samples collected during a single east to west or west to east scan of a scanning instrument.
The swaths are numbered from south to north staring from 1; see Figure 11.
A row is defined as a line of spatial samples or pixels running in a (nominal) East to West and West to East direction.
A column is defined a line of spatial samples or pixels running in a (nominal) South to North direction.
The columns are numbered from the west to east starting from 1.
"The term column can be applied to dwells, swaths or rectified images; see Figure 15, Figure 16 and Figure 17."
The repeat cycle is defined as the time elapsed between the start of two consecutive sets of images taken in all spectral channels covering the same defined coverage.
The repeat cycle is defined as the time elapsed between the start of the data acquisition for two consecutive LAC zones.
The repeat cycle is defined as the time elapsed between the start of the data acquisition for two consecutive LI background radiance images.
The repeat cycle is defined as the time elapsed between the start of two consecutive east-west scans.
"In above definition, consecutive should be interpreted as temporally consecutive."
"For data from other sources (e.g. LI triggered event or from satellite platform), an accumulation interval may be defined."
"A detector element is a single measurement device that, together with others with similar characteristics, makes up a detector array."
The detector element responds to incoming radiation to produce a signal that can be converted from an analogue to a digital format.
A detector array is a collection of detector elements.
"A lightning optical pulse is produced by an electric discharge within or below a cloud, where the optical radiation is emitted from the hot lightning channel."
The lightning pulse duration is on the order of 50 µs and the released photons are transported to the cloud surfaces by scattering.
"The resulting lightning optical signal to be observed at the cloud top has a pulse duration delayed and widened in time to about 600 µs, distributed over an enlarged area of a minimum of about 100 km2 up to a maximum area of about 10.000 km2 depending on the number of scattering processes involved."
The spectral and temporal characteristics are illustrated in Figure 18.
For the FCI: A radiance sample is deemed a missing sample if either no measurement has been returned or the difference between its radiometric error and the radiometric accuracy is more than N times the specified radiometric noise for a specific repeat cycle.
NEdLeff[k] is the noise equivalent delta radiance requirement i and j identify the spatial sample within a swath in terms of column and row N is the noise equivalent delta radiance multiplication factor as given in the requirement for missing samples.
"For the IRS: A spectral sounding is deemed a missing sounding if either no measurement has been returned or a fraction of the spectral channels greater than M, within the considered spectral band, have associated radiance samples where the difference between the radiometric error and the radiometric accuracy is more than N times the specified radiometric noise, for a specific repeat cycle."
The parameters M and N are given in the requirement for missing sounding.
"Wavenumber, ν, is defined as the reciprocal of the spectral wavelength."
"The spectral variable, ξ, is any quantity used to represent the frequency behaviour of a monochromatic wave."
"The spectral variable can be a spectral frequency, wavelength or wavenumber."
The term spectral variable will be used in all the statements that are applicable to any one of the above mentioned quantities.
The spectral range is defined as the complete spectral domain over which the instrument is able to produce calibrated measurements.
"The spectral domain may or may not be contiguous (continuous, with its parts in uninterrupted contact)."
A spectral band is a subset of the spectral range of an instrument that has associated common properties and is contiguous.
For example the IRS has two spectral bands MWIR and LWIR.
A spectral channel is the smallest spectral interval measured by an instrument.
A spectral band is formed by a set of contiguous spectral channels.
For the FCI: A spectral channel is characterised by a set of spectral response functions per spatial sample that comply with the spectral response template for that spectral channel.
For the IRS: A spectral channel is defined after spectral resampling of the measured spectral samples to a discrete spectral positions separated according to the spectral channel interval within the spectral band.
"The spectral channel, identified by the index k, has an associated spectral variable, ξ k, where this location corresponds to the position of its spectral response function centroid."
"A radiance sample is an effective radiance measured by the instrument at a specific spatial and spectral location, see Figure 19."
"The radiance sample has spatial properties of spatial location (xi,yj) and shape (point spread function)."
Together the spatial properties are referred to as the spatial sample or pixel depending on whether the radiance sample has been located on the estimated grid or the reference grid respectively.
Likewise the radiance sample has spectral properties of spectral location (ξ k) and shape (spectral response function).
Together the spectral properties are referred to as the spectral sample or spectral channel depending on whether the radiance sample is located according to a reference spectral location and spectral response function.
The point spread function and spectral response function are related to the instrument response function.
The spectral channel is fixed by the optical and detector element spectral filtering characteristics.
Thus for each spatial sample of a spectral channel a single radiance sample is measured.
"The spatial samples are rectified to the reference grid to form pixels, again each with their associated radiance sample."
For the IRS: A spectral sounding is taken at a location given by the spatial sample.
"Once the spectral sounding interferogram has been Fourier transformed to the spectral domain a series of spectral samples are obtained, each with its own radiance sample."
"For the LI: A single spectral channel is defined, thus each spatial sample has an associated radiance sample."
"In the case of the IRS the PSF of the spatial sample will vary with the spectral sample or spectral channel, although the nominal location will be the same across the spectral variable range."
For the IRS: Spectral samples are obtained by performing a discrete Fourier Transform of the sampled spectral sounding interferogram for a spatial sample.
"The spectral sample, identified by the index k, has an associated spectral variable, ξ k, where this location corresponds to the position of its spectral response function centroid."
As the IRS will perform a number of spectral soundings simultaneously there will be a scale change between the spectral spacing of the spectral samples for each spatial sample.
This is due to the change in maximum optical path difference caused by the position of a spatial sample in relation to the optical axis.
Thus each spatial sample will have spectral samples taken at a set of wavenumbers specific to that spatial sample.
The spectral sample surface is defined as the group of spectral samples with the same index number following the discrete Fourier transform of all the spectral sounding interferograms in an area of coverage.
"The wavenumbers of the individual spectral samples making up a spectral sample surface is illustrated in Figure 20, In this definition it is assumed that each spectral sounding consists of the same number of interferogram samples."
On performing a Fourier transform of the interferogram each spectral sounding has the same number of spectral samples.
"The plots of the spectral sampling surfaces are generates assuming a 4km spatial sampling distance, a 0.625 cm-1 spectral channel interval, a magnification ratio of one and are plotted for a dwell coverage of 640km x 640km."
The plots assume that the optical axis lies in the centre of the dwell coverage and that the Zero Optical Path Difference (ZOPD) for each interferogram within the dwell is in the same interferogram sample position.
The spectral channel interval is the spectral distance between adjacent spectral channels with in a spectral band.
The spectral width is used to specify the spectral extent of a spectral channel in terms of the normalised spectral response envelope.
"The specified spectral width, Δλ0 will be different from the actual spectral width, Δλs, of a spectral channel, where the actual spectral width has traditionally been defined as the Full Width Half Maximum value of the spectral response function, ignoring local oscillations in the passband."
"However, with the usage of effective radiance there is strictly speaking no longer a need to provide the actual spectral width, although in practice the spectral width will still be quoted for historical comparison and conceptual understanding reasons."
The central wavelength is used to specify the spectral location of a spectral channel in terms of the normalised spectral response envelope.
"The specified central wavelength, λ 0, will be different from the actual central wavelength, λ S, of a spectral channel, where the actual central wavelength has traditionally been defined as the centroid of the spectral response function."
"However, with the usage of Effective Radiance there is strictly speaking no longer a need to provide the actual central wavelength, although in practice the central wavelength will still be quoted for historical comparison and conceptual understanding reasons."
"For the IRS: Spectral calibration is the process of determining the position and shape of the spectral response function (SRF) of a spectral sample or group of spectral samples by the observation of a known, stable spectral scene."
"For the IRS: Spectral resampling is the process by which the spectral samples derived from a sampled interferogram are relocated to pre-determined wavenumber locations, thus forming spectral channels."
The positions of the spectral channels are those given by the spectral channel interval starting at the first wavenumber in the spectral band.
The normalised spectral response is equal to the spectral response function normalised by the maximum spectral response function over the spectral variable range of interest at the time of measurement.
"The Instrument Response Function (IRF) is defined as the output signal to input radiant intensity ratio, with the output signal being the effective radiance measured by the instrument when observing a monochromatic point source."
The IRF is specific to the selected spatial sample or pixel and spectral sample or spectral channel and is a function of the spatial position and the spectral variable of the source.
Another consequence of the definition is the fact that the integral of IRF along the spatial variables and spectral variable is unity.
In the definition of IRF the instruments are assumed to be linear.
"The Spectral Response Function (SRF) is defined as the output signal to input radiance ratio, with the output signal being the effective radiance measured by the instrument when observing a spatially uniform, monochromatic source."
The SRF is specific to the selected spatial sample or pixel and spectral sample or spectral channel and is a function of the spectral variable of the source.
Another consequence of the definition is the fact that the integral of SRF along the spectral variable is unity.
"Synonyms: instrument spectral response function, instrument line shape In the definition of SRF the instruments are assumed to be linear."
The spectral response function difference is given for two different conditions.
A Fourier Transform Spectrometer (FTS) is an interferometer concept that converts input spectral radiances into interferograms that contain spectral information within the bandpass of the interferometer.
A spectral sounding is defined as the complete set of spectral samples for any fixed spatial sample captured during a dwell of a sounder.
"Radiant energy is the energy emitted, transferred or received in the form of electromagnetic radiation."
"As all the radiometric quantities, irradiance can be integral or spectral."
The above definition is applicable to the integral irradiance (with Φ the radiant power over a generic spectral interval).
"Radiance is defined as the radiant power per unit projected area and unit solid angle, leaving a surface in a given direction."
"The effective radiance is the calibrated output of an instrument with finite spatial and spectral resolution, in units of spectral radiance."
It equates to spectral radiance of a spatially and spectrally flat scene that would produce the same output as that produced by the actual scene.
"The LI effective radiance is the calibrated output of the LI instrument with finite spatial and temporal resolution, in units of radiance."
It is equal to the radiance of a spatially homogeneous scene with a constant output in time that would produce the same output as that produced by the actual scene.
The radiometric measurement range is defined as the complete radiometric domain over which the instrument is able to produce calibrated measurements.
"For a given spectral value, reflectance is the ratio between the power per unit surface area emitted by a surface and the power per unit surface area (irradiance) incident on the surface."
"For a given spectral interval, albedo is the ratio between the power per unit surface area emitted by a surface and the power per unit surface area incident on the surface."
"In this definition the measured effective radiance is assumed to contain calibration related errors and radiometric noise contributions, whereas the reference effective radiance is derived using a perfectly characterised reference spectral response function viewing a scene, traceable to a radiometric standards (e.g. National Physical Laboratory (UK)), with zero radiometric noise contribution."
"The radiometric noise is the standard deviation of the radiometric error associated with a spectral sample surface or a spectral channel respectively, collected during one repeat cycle."
When expressed in this form the radiometric noise is given as noise equivalent delta radiance (NEdL).
"For the infrared (IR) spectral channels, the radiometric noise can be given in terms of noise equivalent delta temperature (NEdT) associated with a blackbody temperature at which the NEdT is computed."
"For the VIS/NIR spectral channels, the radiometric noise can be given in terms of signal to noise ratio (SNR) associated with a signal at which the SNR is computed."
"Radiometric noise applies to radiometrically calibrated spectra, meaning that the noise induced by radiometric calibration is included."
The radiometric scaling function is used to derive radiometric requirements for measurement conditions different from the reference case.
R(Tm) and R(Tr) are the radiometric requirements for the measured and reference position given by the wavenumber for the IRS.
SNRm and SNRr are the signal to noise ratios for the measured and reference conditions conditions respectively.
The radiometric resolution is the minimum radiometric quantization step of an instrument.
"The radiometric accuracy is the mean radiometric error associated with a spectral sample surface or a spectral channel, collected during a repeat cycle."
The above definition deviates from the ISO 5725:1998 usage of the term accuracy.
The radiometric stability is the absolute value of the difference between the radiometric accuracy of two different images.
For the FCI IR spectral channels the medium term radiometric stability is the radiometric stability between any two images lying in the interval between two calibration cycles.
For the FCI VIS/NIR spectral channels the medium term radiometric stability is the radiometric stability evaluated between any two images separated by less than or equal to radiometric stability evaluated between any two sounding LAC’s or FDC’s separated by less than or equal to 24 hours.
The long term radiometric stability is the radiometric stability evaluated between any two images separated by less than or equal to the satellite nominal operational lifetime.
A triggered event occurs when the energy registered by a detector element exceeds the LI trigger threshold.
"The trigger threshold is used, at detector element level to discriminate a lightning optical pulse from the background radiance."
The Background Radiance for each LI detector element in the LI detector array averaged over a given time interval.
A lightning event is defined as a LI triggered event caused by a lightning optical pulse.
The field of view (FOV) is the solid angle subtended by some portion of an instrument.
"The term can be applied to a detector element, a detector array, a focal plane containing Usage of the term field of view without a specific reference to the item under consideration is often confusing."
A spatial sample is a spatial location in the area of coverage at which an instrument returns a measurement.
"The spatial sample is associated with a single radiance sample per spectral sample in the case of a non-resampled spectra, a single radiance sample per spectral channel in the case of a resampled spectra and the mean radiance sample for all spectral samples in the case of an spectral sounding interferogram."
"The spatial sample, identified by the indices (i,j), is spatially located at (xi,yj), where this location corresponds to the position of its point spread function centroid."
"The Point Spread Function (PSF) is defined as the output signal to input spectral radiant intensity ratio, with the output signal being the effective radiance measured by the instrument when observing a spectrally uniform point source."
The PSF is specific to the selected spatial sample or pixel and spectral sample or spectral channel and is a function of the spatial position.
Another consequence of the definition is the fact that the integral of PSF along the spatial variables is unity.
In the definition of PSF the instruments are assumed to be linear.
Image rectification is the process creating a level 1c image from a level 1b image.
The level 1c image has the property that there is a well-defined and invariant relationship between image coordinates (rows and columns) and the Earth location (geodetic latitude and longitude).
In order to achieve this transformation the radiance samples associated with the level 1b spatial samples are interpolated from the estimated grid to the reference grid to give radiance samples for each level 1c pixel.
"Image navigation specifically refers to the knowledge of the relationship between a spatial sample in instrument coordinates and the corresponding point on the earth, given by latitude and longitude coordinates."
"In general, image navigation refers to the methods employed to obtain that knowledge, whereas image navigation accuracy is a measure of how well that relationship is known."
"Image navigation is used to derive the verification grid of past spatial sample positions, where means to derive this knowledge are available."
When used to derive the position of future spatial samples based on past information the estimated grid is generated.
Image registration is an indication as to how well image navigation knowledge is maintained and controlled between images separated over time or between different spectral channels or instruments.
A pixel is a precise location on the reference grid at which an instrument returns a measurement.
The pixel is constructed from a number of spatial samples that have been interpolated to the given reference grid location during the image rectification process.
"The pixel, identified by the indices (i,j), is spatially located at (xi,yj)."
"Like the spatial sample the pixel also possess a point spread function that may extend over a number of SSDs in all directions, i.e. it will not be same as a square of sides SSD in length."
The actual site (AS) of a spatial sample corresponds to the centroid of the true projection of the spatial sample point spread function on the Earth’s surface at the time of measurement.
The combined actual sites of an image give the actual grid.
The measured site (MS) of a spatial sample corresponds to the estimate of the spatial sample actual site as derived from the image navigation process and used in the image rectification process or delivered as IDP auxiliary data with the level 1b data.
The combined measured sites of an image give the estimated grid.
The reference site (RS) is the geographical location of a pixel and corresponds to one of the grid points of the reference grid.
The corrected site (CS) is the true geographical location of the centroid of the PSF associated with a pixel.
"Ideally a corrected site corresponding to each pixel is measureable, but in practice only geographic features such as coast lines, mountains and lakes will be available."
In practice the location of the geographic features will be to sub-SSD accuracy.
Coregistration is used to describe the relative position of the spatial samples or pixels between different spectral channels of an instrument or between instruments.
The term can be applied to the spatial or the temporal position of spatial samples or pixels.
RSPKE is only given for spectral channels of identical spatial sampling distance.
When the RPPKE between spectral channels with differing spatial sampling distance is A group of p2 of the finer resolution spectral channel pixels centred on a coarse resolution pixel is taken as a pixel group.
"Each fine resolution pixel group is identified by the indices (i,j) of the coarse resolution pixel."
The reference site for the fine resolution pixel group is the mean reference site of the fine resolution pixels.
Due to the properties of the reference grid this means that the fine resolution pixel group and coarse resolution pixel are located at the same position.
Likewise the corrected site for the fine resolution pixel group is the mean corrected site of the fine resolution pixels.
"Eclipse is defined as when the solar disk is occulted by the Earth or Moon, as viewed from the MTG satellite."
The eclipse start is the time at which the sun starts to be occulted by the Earth or moon.
The maximum depth of an eclipse occurs at the time when the sun centre crosses the plane containing the satellite and Earth (or moon) centre lying perpendicular to the sun’s direction of relative motion in satellite centred reference frame with the x axis pointing to the Earth (or moon) centre.
The solar restricted zones are applicable for the uneclipsed and partially eclipsed sun.
It is defined to allow graded relaxation of requirements for spatial samples and pixels located close to the sun.
"In ‘TNW’, T stands for tangential, N for normal, and W for the Greek omega (ω) denoting the axis of angular momentum."
The normalized geostationary projection describes the view from a virtual satellite to an idealized Earth.
"Herein, the virtual satellite is in a geostationary orbit, perfectly located in the Equator plane at the given longitude, λD."
The distance between spacecraft and centre of Earth is given by the geostationary radius and the idealized Earth by the Earth's reference ellipsoid.
In the following a short description of the theoretical background is provided: Two cartesian coordinate frames are introduced.
"Again (s3) points northwards, and (s1) directs to the centre of the earth."
The vector re points from the centre of the earth to a point P on the earth's surface.
"Thus, λe is the longitude and φe is the geocentric latitude describing the point P."
"Thus pixels at the western side of the Earth have a lower index and a φ is the N-S scanning angle and corresponds to the standard definition of elevation, for an observation from the instrument perspective."
"Note that the first row, column of the reference grid is indexed 1,1. x0 and y0 gives the angle from the origin of the projection (the direction s1) to the centre of the pixel in the first row and column of the reference grid."
All trigonometric functions assume angles in degree.
"The geostationary radius is the distance from the Earth’s centre to the satellite in geostationary orbit and can be calculated from the sum of the geostationary altitude and the equatorial Earth radius, in turn derived from the Earth's reference ellipsoid."
The geostationary altitude (35786.4 km) is the distance from the satellite in geostationary orbit to the sub-satellite point.
Geographical co-ordinates give a location on earth as determined by geographical longitude (lon) and geographical latitude (lat).
"The geographical longitude is counted eastwards positive, beginning at the Greenwich meridian."
The geographical latitude is counted from -90.0 (south pole) through 0.0 (equator) until +90.0 (north pole).
The geodetic coordinates of a point are defined with respect to a given reference surface of the Earth (Earth´s Reference Ellipsoid).
"The normal projection of a point onto the local horizontal plane defines the geodetic longitude λ, latitude ϕ and the height h (see figure below)."
"The geocentric latitude is defined, with reference to Figure 33, as the angle, ϕ', between the equatorial plane and the radius from the centre or the earth to a point on the surface."
"See also geographical coordinates, geodetic latitiude."
The following table lists definitions for all acronyms used in this document.
The potential use during routine operations depends on experience in orbit and recommendation of the OPS-WG.
The IRS shall cover the spectral domain from 680 - 2250 cm-1 characteristics provided in Table 7.
Since this time the following modifications have taken place: calibration the former being applicable at spacecraft level and spectral calibration process.
The IRS radiometric noise shall be as given in Table 9.
"The Lightning Imager (LI) full disc coverage shall include the Earth within a circle of 16º in diameter, shifted northward to cover high latitude regions."
The Lightning Imager (LI) coverage shall contain at least the states and at least 84% of the visible earth disc (taken as a satellite is within the nominal longitude range.
The LI triggered events shall consist in the measurements of the strongest lightning emission features within the cloud top near infrared.
The LI shall provide a spatial sampling distance less than or equal to 10km at 45oN for the sub-satellite longitude.
The list and periodicity of disseminated dataset transmitted as defined in [MTGDIS].
"The old table 14, defining the timeliness, is provided below."
The operational availability of Lightning dataset shall be as per Table 14.
"The list, characteristics and periodicity of disseminated Level Appendix B."
The Internet Dissemination Service shall only deliver to the registered DCP Operator its own dataset.
The operational availability of the datasets via the Internet EUMETCast.
Service messages shall provide information on the status and EUMETCast dissemination.
"Old Table 9 used by requirements IRS-04140 IRS-04160, IRS-04180 and IRS-04200."
"New Table 9 used by requirements IRS-04140 IRS-04160, IRS-04180 and IRS-04200."
"Delays outside EUMETSAT control have to be added (e.g. for FSD, MDD, SAF)."
"The specified timeliness only refers to the EUMETCast contribution, i.e. the dissemination of SAF products and does not include the time required to generate the products at the SAFs."
The latter is specified in the respective SAF Product Requirements Documents.
Modification affecting only s are not tracked in the statistics but still listed above for completeness.
Supplier license code changes regarding the Green Deal.
"Minister of State, DECC, to the Energy Retail Association, 8th June Financier Remittances."
Green Deal CC Database & Payment Remittance and Interface Data added if necessary.
Green Deal CC Database & Payment Remittance and Interface Data users both easily and at low cost.
Green Deal CC Database & Payment Remittance and Interface Data measures.
Represents the classification of the requirements within the requirements document.
The following classifications have been Provides unique identification.
Numbering is not necessarily sequential; gaps in the sequence leave room to add additional related requirements when they are discovered.
This section lists the functional characteristics that the GD CC db must support.
"It also identifies what the database does, what inputs should be transformed to what outputs, and what specific operations are required."
"The functional requirements are broken into subsections by general functions, data functions, and interface functions."
"The general functional requirements apply to the system as a whole, without respect to specific functions or processes."
The data requirements identify and describe the management of information to be acquired and disseminated.
The functional interface requirements describe the functional interfaces to the GD CC db from information providers and consumers.
"The requirements in this section specify static and dynamic capacity for the number of users, connections, and other performance related factors."
"The performance requirements are divided into subsections and are provided in the form of design constraints, quality requirements, and system performance requirements."
Design constraints apply existing rules or external conditions to the system.
Examples of design constraints are communication standards and requirements for standardised hardware or software.
These quality requirements pertain directly to maintaining a high level of service quality.
System performance requirements specify quantitatively what the system must do and in what timeframe.
"Organisational requirements deal with policies regarding external parties involved with the system, personnel roles, training, and security needs."
Green Deal CC Database & Payment Remittance and Interface Data PPM Reconciliation data is as per the table below.
"In order to enable reusability and commonality across the EAN.UCC Business Message Standards, a common library has been developed to support the technical implementation of the EAN.UCC standards into XML schemas resulting in standardized data types and field sizes."
Item is the second message in the trade process following the Party message.
Item elements are the mandatory attributes needed to align the item information between trading partners.
These attributes in combination ensure the uniqueness of the data set associated with a GTIN.
"The use, definition, and relevance of these attributes is the same for ALL EAN.UCC industries."
Following the Item attributes is an extension of cross industry.
These are data attributes that may be required in conducting commerce between partners for the trade of an item or service.
These attributes are relevant to more than one industry.
The definition of these attributes must be the same for all industries.
Item and the extension of the cross industry data processes include communicating the data elements necessary to support the core business requirements in the global trading environment.
"The Party and Item process are mandatory in the completion of the price, purchase order, invoice, etc."
The audience of the standards would be any participant in the global supply chain.
"This would include retailers, manufacturers, service providers and other third parties."
"Change Requests: 01-000009, 01-000010, 01-000064, 01-000065."
"Additionally, the existing Electronic Data Interchange messages in widespread use were mined for their business content."
Acknowledgement is also due to the work going on in the XML environment.
The buyer and seller must make contact and set up a business relationship before trade can proceed.
This initial contact can be made in many different ways.
"Following the establishment of the trading agreement the parties must exchange their basic business data such as trading partner names, addresses, locations, item attributes, price lists, contracts and trading partner agreements."
"Specifically, the Core Item message follows the Core Party message in the data alignment process."
This process creates a common understanding between the trading parties which can be used as a resource throughout the trading process.
"There is only one scenario in the Item data communication process as described in problem statement of section 1.1. communicating the core item and cross industry data elements following the establishment of a business relationship between suppier, buyer or third party."
The objective of this document is to elaborate the Data Synchronization Data Model for Trade Item (hereafter referred to as ‘Data Sync Trade Item’) business process in enough detail to support the construction of standards.
"It is assumed that the players, both seller and buyer, have established a business understanding of the trading partner relationship."
The challenge is to provide the core elements necessary to complete all supply chain processes without duplicates.
"The two general players in the Data Sync Trade Item business process are the ""seller"" and the ""buyer""."
"Depending on the specific nature of the relationship other players may have a role, such as a Third Party."
"The graphic flow below pictures the core sequence of messages, and is expanded to account for additional scenarios."
The Data Sync Trade Item business process begins when the parties decide to do business together.
The next step is for the buyer to communicate the Party organizational information to the seller.
The seller provides his Party organizational information to buyer.
Other data alignment follows such as item and price attributes.
The start-state of the Data Sync Trade Item business process begins during the initial discussions between the trading partners and the need to exchange item information.
"Once the Data Sync Trade Item business message has been accepted by both the seller and buyer, then data alignment has been achieved."
This process can be an ongoing process as item business information changes or new parties are added.
The process of trading goods and services can now occur.
The end-state of the Data Sync Trade Item business process occurs when the parties have achieved Party and Item data alignment.
Applies item data or notifies the seller of any errors in the data.
See the work completed by the data synchronization project team for a detailed view of data communication.
"The Data Sync Trade Item messages include the item’s unique identification, descriptions, and characteristics."
"To help with the implementation of this data model, several key definitions are listed below."
Master data is considered to be that set of data that describes the specifications and structure of each item and party involved in the supply chain processes.
The uniqueness of the data associated with a trade item is given only by the GTIN.
"This data is static, not dependent on a transaction."
"Transactional data is that set of data that can only be determined during a business transaction, i.e., plan, sell, buy, and deliver cycle."
Master Data Alignment is the process of timely distribution of accurate Master Data from one partner to others and the correct use of this data.
Such synchronization and use of Master Data leads to more accurate business transactions and therefore reinforces the efficiency of the supply chain operations.
"Successful Master Data Alignment is achieved via the use of EAN.UCC coding specifications throughout the supply chain, communication of all changes and new information between trading partners and use of the information exchanged in subsequent transactions."
"Unique Identification of Items, GTIN and Parties GLN."
An attribute whose definition is common across all Industries Core attributes are common across all geographies.
These attributes do not necessary need to be maintained by the Registry.
The conditions of extension attributes can vary by each industry.
"E.g. Mandatory/Optional, Global/Local, Trading Partner Neutral/Relationship Dependent, and Common to all Hierarchy levels."
"Industry user groups should be developed in concert with the EAN.UCC GSMP Process, to determine their relevant extension attributes and the conditions associated with those attributes."
Process user groups such as CPFR and local (target market) extensions.
Values for an attribute can vary depending on the relationship with the party receiving the data.
The Trading Partner Neutral/Trading Partner Dependent status indicates this rule.
The condition Trading Partner Neutral is applied to any attribute whose value is independent on a buyer and seller relationship.
"An attribute, which has the condition Trading Partner Neutral, can have only one set of values ."
The condition Trading Partner Dependent is applied to any attribute whose value is dependent on a buyer and seller relationship.
"An attribute, which has the condition Trading Partner Dependent, can have only one set of values per GLN of Party Receiving Data."
These are attributes whose value is dependent on a specific point-to-point agreement between a buyer and a seller.
This condition is used to indicate that multiple values can be submitted for a trade item.
"Where there is a need to express multiple measures, these are handled through indicating the attribute type as ‘Measurement’."
"Both the value and UOM can be repeated, and must be used together."
See section 4.6 on Unit of Measure in the implementation consideration and concerns.
"Where there is a need to express multiple language versions, these are handled through indicating the attribute type as ‘Text Description’."
See section 4.4 on Language in the implementation consideration and concerns.
A Market Group is used to identify a proprietary group of data recipients.
This group is used and developed by the information provider to control del publication of data to a specific group of customers.
The purpose of this field is to explain where a manufacturer is intending to sell its product(s) to a buyer.
It does not control where the buyer can resell the product (s) to the end consumer.
"It is the country, (the geopolitical area) where the product is to be sold and available for publication in an Item Catalog."
"Target Market Country Code in relationship to Master Data, can be Trading Partner Neutral only."
A Target Market Country Code is not used to control Distribution or Consumer Market Area geographies.
E.g. product available for shipment from a single Distribution Center.
The number of sub-country codes will vary by each country.
These will match with the legislation requirements of each country.
A sub-country code must be associated with a Target Market Country Code.
All attributes are impacted by their geo-political relevance.
This condition can be used by information providers as they build data models.
"With this information, they can limit the attributes communicated to those relevant for that geography."
"A global attribute indicates that the attribute is relevant for business cases around the world, and can only have a single value throughout the world."
"A global/local attribute indicates that the field is relevant for business cases around the world, that its definition is the same around the world, but may have a different value depending on the geography."
"A local attribute is only relevant in certain geographical areas, and the values may change based on where the product is offered for sale."
"How does the Global/Global-Local/Local condition, and Target Market value interact to affect attribute values?"
"Start availability date = January 1, Target Market can be repeated where the values for the attribute are the same g. start availability date is the same for the GTIN + GLN + TM combination data set."
Market that is valid for (except where there are multiple values allowed).
An attribute in this model is mandatory when its value is required.
An attribute in this model is Optional when its value is not required.
An attribute in this model is depended when its value is conditional on some other attribute’s value.
"A Trade Item is any product or service upon which there is a need to retrieve pre-defined information and that may be priced, ordered or invoiced at any point in any supply chain."
"The term “trade item” is not to be confused with the legacy term “traded item” (now referred to within the General EAN.UCC Specifications as ‘standard trade item group’ which can mean a specific product containment level, which is also called case."
"In addition, the supply chain is any point from the inception of the product through the final consumption and disposal/reuse/recycling/return of that trade item."
"Reference General EAN.UCC Specifications for definitions of the term ‘trade item’, ‘retail consumer trade item’, and ‘standard trade item grouping’."
"A Party (or) Location is any legal, functional or physical entity involved at any point in any supply chain and upon which there is a need to retrieve pre- defined information."
This condition is used to indicate at what level of the product hierarchy each attribute is relevant.
"For some attributes, business requirements are such that the attribute only needs to be provided at a specific level."
Example – “netContent” this field is only required at the consumer unit level.
"For most attributes, a value must be entered for all attribute levels."
Common value condition indicates when the value for the attribute is equal for all levels of a hierarchy.
Definition: This represents the Total quantity of next lower level trade items that this trade item contains.
"Business Rules: e.g. in a mixed module, with 2 x five different types of nail varnish, this number = 10."
Where this differs from “QuantityofNextLowerLevelTradeItem” is that this field is used in conjunction with each GTIN identified in the field ‘NextLowerLevelTradeItem’.
"E.g. in the example of 2 x five different types of nail varnish, this number = 2."
"If the item is not mixed, then this number will equal the value submitted for the “QuantityofNextLowerLevelTradeItem” field."
Definition: Value indicates the number of unique next lower level trade items contained in a complex trade item.
A complex trade item can contain at least 2 different GTINs.
Examples: Ready to sell display of cosmetics contains 2 bottles each of five different colors (each with their own GTIN) of blush.
See tables in Section 4.1 of the Implementation Considerations and Concerns.
The number of next lower level trade item that this trade item contains.
Item Name: tradeItemIdentificationOfNextLowerLevelTradeItem (cid:198) Represented as association of ChildTradeItem Class to TradeItemIdentification Class.
Definition: A reference to the GTIN of the next lower level of trade item that this trade item contains.
Business Rules: Allowed for more than 1 reference to lower levels to allow for the registration of Mixed Assortments.
The sequence of entering GTINs is important when a next lower level GTIN is to be linked.
"The next lower level GTIN must already exist, therefore the order of trade items to be entered should be from lowest to highest e.g. consumer, then intermediate, then traded, etc."
"While there can be multiple child trade items, there can only be one trade item identification per child item."
Definition: Indicates the trade item identification of an item that is being permanently replaced by this trade item.
The trade item identification that is being permanently replaced must already be in the home data pool in order to ensure data integrity.
The old trade item identification specified in this field should be discontinued.
Definition: Describes the hierarchical level of the trade item.
See implementation s for full definition and rules for each value.
Business Rules: See implementation s for complete description of each product hierarchy level.
Reference TradeItemUnitDescriptorList which is an enumeration list in the Trade Item Class Diagram.
"Definition: A particular Global trade item Number, a numerical value used to uniquely identify a trade item."
Please see PTRG directions for creating GTINs Business Rules: EAN.UCC numbering structures will be used for the identification of trade items.
All of them will be considered as 14-digit Global Trade Item Number (GTIN).
Must be present to enable data to be presented to trade item catalogue.
"Must be submitted by the owner of the data (who may be the original manufacturer, the importer, the broker or the agent of the original manufacturer) See to the EAN.UCC specifications."
This field is mandatory within the Global Data Synchronization work process.
Definition: Text name of the additional external classification agency whose schema is being provided in addition to the Global EAN.UCC schema.
Business Rules: Required if additional classification schema field are populated.
Definition: Category code based on alternate classification schema chosen in addition to EAN.UCC classification schema.
The description of the additional classification bundle (code/agency + description) can be repeated for each classification agency used.
Required if ClassificationCategoryCode field is populated.
Definition: Global EAN.UCC classification category code.
"The system will assign Bricks on a first-approved, first- served basis."
Definition: System generated explanation of Global EAN.UCC category.
The system generated text equivalent of the Global EAN.UCC classification category code.
Definition: Unique 8 digit code which identifies the Global EAN.UCC classification attribute.
"Business Rules: If used, the first attribute, which is the primary attribute, is mandatory."
The system generated text equivalent of the Global EAN.UCC classification attribute code.
"ClassificationAttributeTypeCode is populated, this field becomes mandatory."
Definition: System generated explanation of Global EAN.UCC attribute.
Definition: Unique 8 digit code which identifies the Global EAN.UCC classification attribute value.
Examples: See Implementation s for full illustration.
Business Rules: One valid value may be submitted per GTIN.
"Once an attribute code is selected, it is mandatory to submit an associated value code."
The system generated text equivalent of the Global EAN.UCC classification attribute value code.
Definition: Unique location number identifying the information owner.
"E.g. Distributor, broker, Manufacturer, Franchisee."
The purpose of this field is to identify the originator of the data.
The retailer could receive information from both sellers and this field declares the information owner.
Examples: Refer to the following websites for specific directions on how to construct global location numbers - www.uc-council.org or www.ean- Business Rules: Combination of this field (gln) + gtin + target market uniquely identifies a set of attributes for a trade item.
"The data owner is not necessarily the source of the data, but has the responsibility to provide and maintain the data in the catalogue."
Name of the information provider on the trade item.
"Examples: Names of suppliers, wholesalers, manufacturers, distributors, Business Rules: Mandatory when Information Provider is provided."
The target market code indicates the country level or higher geographical definition in which the information provider will make the GTIN available to buyers.
This Indicator does not in any way govern where the buyer may re-sell the GTIN to consumers.
Business Rules:ISO 3166-1 format 3 digit numerical; following AIDC guidelines.
"This information drives data synchronization rules linked to global/local, local status."
Combination of this field +GTIN+GLN uniquely identifies a set of attributes or a trade item.
This field is mandatory within the Global Data Synchronization process.
The name for the specific target market identified with the Target Market Country Code .
The description will be generated from the ISO 3166-1 code list.
Business Rules: This is the textual indication of the target market code.
See Section 4.4 of Implementation Considerations and Concerns for more details.
The Target Market Subdivision Code is the secondary code of the Target Market and must be a subdivision of a Target Market Country Code.
"The Target Market Subdivision Code describes the ""geo-political subdivision of a country"" where the trade item is available for sale, as determined by the information provider."
"For example, ""State"" in the US, ""Land"" in Germany, ""Region"" in France, or ""Province"" in Canada."
This code is represented by the three- character ISO 3166-2 code.
This Target Market Subdivision Code is a dependent attribute.
It is important to note that the lack of the Target Market Subdivision code implies that the trade item is available in the entire target market country.
Business Rules: ISO 3166-2 format 3 digit numerical/3 character alpha which represents country and subcountry code; following AIDC guidelines.
This optional field helps further define trade item availability.
The target market code consists of a country code and an optional subdivision code.
A subdivision code must be used in tandem with a corresponding higher level country code.
Definition: Additional variants necessary to communicate to the industry to help define the product.
Multiple variants can be established for each GTIN.
"This is a repeatable field, e.g. Style, Color, and Fragrance."
Business Rules: May be used for additional technical or commercial information.
"As a descriptive text field, this data element is repeatable for each language used and must be associated with a valid ISO language code from the attached table."
The recognizable name used by a brand owner to uniquely identify a line of trade item or services.
"Business Rules: Free form text field, but not necessarily tied to language."
"If a trade item does not have a brand, Use ‘unbranded’ in the description."
"If a trade item is changed from being ""Unbranded"" to a brand, this requires a new GTIN."
Definition: A free form short length description of the trade item that can be used to identify the trade item at point of sale.
"Business Rules: Free form text field, this data element is repeatable for each language used and must be associated with a valid ISO language code from the attached table."
See Section 4.4 of the Implementation Considerations and Concernsfor more details.
Definition: Describes use of the product or service by the consumer.
Should help clarify the product classification associated with the GTIN.
See Section 4.4 of the Implementation Considerations and Concerns for more details.
The concatenated product description of a product or service.
"Examples*: When a supplier sends all information in maximum size the For automatic use of this information, e.g. on a tag, a separator should be given between all elements."
"Free form text field, this data element is repeatable for each language used and must be associated with a valid ISO language code ."
"When implemented, these four attributes may be concatenated as appropriate."
Item description is part of the set of core data that will be stored in the Registry.
"The waist watcher product range includes salad dressings, receipt books, kitchen utensils, etc."
It is the primary differentiating factor that a brand owner wants to communicate to the consumer or buyer.
In this example Yummy- Cola is the brand and Classic is the subBrand.
"Used, for example, in pharmaceutical industry to indicate the formulation of the trade item."
Defines the form the trade item takes and is distinct from the form of the packaging.
Business Rules: Optional field that can be used to further describe a trade item's benefit delivery method.
Definition: A code assigned by the supplier or manufacturer to logically group trade item independently from the Global trade item Classification.
"Business Rules: If trade itemGroupIDCode is present, description must be present."
"A description text field, this data element is repeatable for each language used and linked to data element ""Description language""."
Definition: Free text field used to identify the variant of the product.
"Variants are the distinguishing characteristics that differentiate products with the same brand and size including such things as the particular flavor, fragrance, taste."
"Examples: Examples: Bananna, Strawberry, Lemon Scented."
Business Rules: This is different from the Global EAN.UCC product classification variant.
"Free form text field, this data element is repeatable for each language used and must be associated with a valid ISO language code from the attached table."
See Section 4.4 of the - Implementation Considerations and Concerns for more details.
"The type of bar code or codes, which are visible on a trade item."
Definition: A code that indicates that a trade item is in compliance with specific applicable government regulations.
Different municipalities require this on items shipped-to or sold-in the municipality.
"The country code (codes) in which the goods have been produced or manufactured, according to criteria established for the purposes of application of the value may or may not be presented on the trade item label."
Business Rules: This information is for customs purpose in case of importation or legal requirements regarding customer information for some categories of trade item (e.g. meats and fruits) Information can be repeated if multiple countries are valid.
"In this case, the buyer will only know the actual country of origin at the time of delivery."
Definition: Unique location number identifying the brand owner.
"May or may not be the same entity as the information provider, which actually enters and maintains data in data pools."
"The brand owner is the source of the data relating to the trade item, but is not necessarily responsible for providing and maintaining the data in the catalogue."
This is the responsibility of the information provider.
"While the class BrandOwnerOfTradeItem is optional, the party identification for the brand owner is required when a brand owner is present."
Definition: Name of the party who owns the brand of the trade item.
Examples: Manufacturer of branded trade item - Can also be distributor manufacturers.
Definition: Dangerous goods classification of the trade item.
"There are 9 danger classes, some classes are further subdivided into subclasses."
Examples: Class “4.2”: Substances liable to spontaneous combustion.
Business Rules: Information required when dangerousGoodsIndicator equals Y.
Subsidiary risks given by repeating attribute value.
"Hazardous attributes relate to supply chain handling (e.g., transport, storage, handling)."
"If they are possible, they must be indicated, whether they are used by the data supplier."
Business Rules: Information required when dangerousGoodsIndicator equals Y. Repeatable per dangerousGoodsRegulation code.
"Definition: Dangerous goods hazard ID number, which must be applied to the vehicle, when transporting this trade item (dangerous good) by road or rail, to inform the police, the fire brigade and others in case of an accident about the kind of danger caused by the cargo."
Business Rules: Information required when dangerousGoodsIndicator equals Y. Repeatable per dangerousGoodsRegulationcode.
Definition: Identifies the degree of risk these dangerous goods present during transport according to IATA/IMDG/ADR/RID regulations.
Examples: Group I : Great danger - Packaging meeting criteria to pack hazardous materials with great danger.
Definition: Shipping name of the trade item (dangerous goods).
"The recognized agencies (see dangerousGoodsRegulationsCodes), in their regulations, provide a list of all acceptable proper shipping names."
"Definition: Chemical term of the trade item, listed by name and allowed in the substance list of GGVS (Dangerous Goods Ordinance for Roads) or GGVE (Dangerous Goods Ordinance for Rail)."
The language for text is specified using the two-digit ISO 639 list.
"The technical names are listed in the order that they contribute to the danger (main hazard, not necessarily the highest concentration)."
The four-digit number assigned by the United Nations Committee of Experts on the Transport of Dangerous Goods to classify a substance or a particular groups of substances.
Definition: GLN identifying the manufacturer of a trade item.
"May or may not be the brand owner, could be a contract manufacturer."
GLN identifying manufacturer of a trade item: this is repeatable field.
"Business Rules: While the class ManufacturerOfTradeItem is optional, the party identification for the manufacturer is required when the manufacturer of trade item is populated."
Definition: Descriptive name of the manufacturer of the trade item.
This is not the name of a party that assembles trade item.
"It is an optional field, manually maintained, that can identify the company that manufactures the product."
"Definition: Name of the sales or marketing campaign, for which the textile trade item is intended."
Input of user-defined text in order to assign the item to a specific marketing campaign.
Examples: Home Fashion theme such as 'Alexandra' or an Apparel theme such as '501 Blue'.
The date suggested by the supplier for the campaign to start.
It indicates the beginning of a marketing campaign.
The date suggested by the supplier for the campaign to end.
Definition: This element identifies specific items for promotional or special tracking purposes.
For example Dynamic Assortment: Chia Pets are sold individually to the consumer and each different Chia Pet is marked with a unique GTIN.
"The items are ordered by the case, which has its own unique GTIN."
The case will contain a random assortment of Chia Pets.
There is no guarantee that the same ratio of child items will be in a case from order to order but the total quantity of items in the case will remain the same.
A collateral item is a trade item delivered from a manufacturer to the retail selling floor that is not considered inventory and has no retail value.
"A Gift with Purchase (GWP) is a trade item given to a consumer as part of a promotional event, contingent on the consumer making a purchase of another item or items."
A Gift with Purchase is considered inventory and has no retail value.
"A Purchase with Purchase (PWP) is a trade item sold to a consumer at a special price as part of a promotional event, contingent on the consumer purchasing another item or items."
A Purchase with Purchase is considered inventory and has a retail value.
"A Dynamic Assortment is when the quantity of the case remains fixed, however the mix of the lower level GTINs may vary from case to case."
If Next Lower Level Trade Item Information is specified the actual quantity of each child item may be different from pack to pack.
"The pack may even contain only one of the child items, however the pack will always totalQuantityOfNextLowerLevelTradeItem."
Business Rules: Dynamic Assortment may only be specified when the tradeItemUnitDescriptor specifies PREPACK.
Definition: Element for consumer facing marketing content to describe the key features or benefits of the style suitable for display purposes.
Definition: Marketing message associated to the Trade item.
Definition: This element indicates the product material code that gives the composition of the trade item's first main material up to six material short codes that can be given in descending order of their respective percentages.
This element may be used to specify agency code or country specific code used to indicate materials that the trade item consists of.
Examples: CO Cotton; PE Polyethylene; PA Polyamide.
"Business Rules: materialCode and materialAgencyCode are paired elements; if one is used, the other must be present."
These fields are used in conjunction with the percentage.
Definition: This element indicates the agency that is maintaining the Trade Item Material codes.
"Reference “DIN 60001, Part 4 - Textile Fibers Codes."
Business Rules: materialCode and materialAgencyCode are paired elements; if one is used the other must be present.
Definition: Net weight percentage of a product material of the first main material.
Example: CO Cotton 50%; PE Polyethylene 40%; PA Polyamide 10%.
Definition: This element is used to indicate the material composition.
This element is used in conjunction with materialPercentage.
"It describes the composition of each material (e.g., plastic, rubber) contained in the trade item."
Definition: Manufacturer's identification number for the material safety data sheet for a trade item.
Business Rules: This is an internal number which is distributed by the manufacturer.
This attribute is mandatory if the Material Safety Data Sheet attribute is “Y”.
Item Name: materialSafetyDataSheet-(cid:198)this boolean question is answered by the population of materialSafetyDataSheetNumber.
It is thus not represented in the model and the schemas.
Definition: Indicates whether there exists a material safety data sheet for the trade item.
"This is a data sheet with the most important characteristics, protected measures and regulations to be adhered to when handling this trade item."
Definition: A description of the variable size that is necessary to uniquely specify the size of the item in conjunction with the non-packaged size dimension.
The size group would be Petite and the size would be “8”.
Definition: This is the system that is being used to define the size.
It is used in conjunction with size group to completely define the size dimension.
"Example: A shoe that is 10 inches or 25.4 centimeters could be specified without using this attribute, however, the same 10 inch shoe is a men size Europe (no distinction between men and women), women size 25 in Japan, and size 6 in Mexico."
This will allow for the size dimensions to be specified in using different size systems.
The size type would be Back and the size would be 34”.
The numerical size measurement of the size dimension specified by the size type.
The size type would be Back and the size would be 34 inches.
"The size dimension is specified using a decimal value descriptiveSizeDimension must be present, but not both."
The textual representation of the size dimension specified by the size type.
The size type would be Sleeve and the size would be “32/33 inches”.
"Business Rules: Either sizeDimension or descriptiveSizeDimension must be present, but not both."
"The alternate Unit of Measure of how Trade Items are ordered by the Retailer under one Unit of Measure, but sold under another Unit of Measure."
Example: A Spool of wire ordered by the spool and sold by lineal foot; Lumber ordered by board footage and sold by piece.
Definition: Describes the measurement used for selling unit of the Trade Item to the end consumer.
"Example: Each, pair, case, roll, set box, by the foot, by the sheet."
The Retailers require this if the Item is marked as a Consumer Unit.
Only values from the enumerated list can be chosen from the UN/CEFACT.
Definition: A governing body that creates and maintain standards related to organic products./Brules: only registered values may be used.
See implementation section 4.8 for reference to code list.
Definition: Used to indicate the organic status of a trade item or of one or more of its components.
ThePackage- this boolean question is answered by the population of Bar Code Type.
Definition: Indication if the trade item is physically bar-coded with the primary trade item identification number.
This is a y/n (Boolean) where Y equals trade item is bar-coded.
Technical This Boolean question is answered by the application of class “Bar Code Type List”.
"If the Bar Code Type List class (telling which barcodes are on the package) exists, then there is a barcode on the package."
The attribute is derived from the Bar Code Type List and is not in the model.
This is a yes/no (Boolean) where yes equals package can be returned.
"Business Rules: Boolean Y/N; Y= marked returnable, N= not returnable."
Attribute applies to returnable packaging with or without deposit.
Definition: trade item packaging contains information pertaining to its ingredients.
This is a yes/no (Boolean) where yes equals marked with ingredients.
"Business Rules: Boolean Y/N where Y=marked with ingredients , N=not marked with ingredients."
List of ingredients can be legally required in some countries for limited trade item sectors.
Definition: Contains details of any on pack product offer (consumer or traded).
"Business Rules: If the physical dimensions of the product change as a result of the promotion, then a new GTIN must be allocated."
"If only a token is added to the product, then no need to change GTIN."
Definition: Indication of which dietary or allergen marks that are on the package.
Definition: Indication of which environmental marks (e.g. recycling schemes) that are on trade item package.
This attribute is an enumerated list and is optional.
Definition: Indication of which ethical trading marks that are on the package.
Definition: Indication of which free-from marks that are on the package.
This attribute is and enumerated list and is optional.
The package of this GTIN is marked to indicate under which scheme it is recyclable.
Applies to recyclable packaging with or without deposit.
Definition: First date that the deposit value is valid for the deposit code.
Definition: Last date that the deposit value in the currency is valid for the deposit code.
Currently a European Union table of code lists exists for this requirement.
The code list required to identify the packaging material of the trade item.
Business Rules: Can be repeated for multi-material packaging and linked to packaging weight.
The agency or agencies controlling the packaging code lists of each country.
"Can be weight, volume or surface, can vary by country."
Business Rules: Can be repeated for multi-material packaging and must be associated with a valid ISO language code from the attached table.
Implementation Considerations and Concerns for more details.
The system generated text description equivalent of the packaging material code.
"As a description text field, this data element is repeatable for each language used and must be associated with a valid ISO language code from the attached table."
"Definition: Indicates if the packaging given in the described packaging configuration is a rented, exchangeable, against deposit or one way/not reusable."
"Business Rules: List of authorized values based on EANCOM 7073, X12 DE102 and X12 DE399."
The monetary amount for the individual returnable package..
Definition: In some markets the deposit information is specified by a GTIN giving the type of returnable package on which a deposit is charged.
Each deposit code is associated with an amount specified elsewhere.
The code identifying the type of package used as a container of the trade item.
See code list for possible values (packagingTypeDescription).
Business Rules: List of authorized code values based on UN-ECE 21 Recommendations.
Code list can be found in Implementatio Section 4.8 Can be repeated.
Definition: System generated text description of the type of packaging used for the trade item.
Business Rules: List of authorized text description values based on UN- ECE 21 Recommendations - EANCOM 7065.
Definition: Used to indicate the peg hole numbers when more than one hole is present in the product or packaging.
Peg holes should be numbered from the upper left corner of the front of the package to the bottom right corner.
"The peg holes should be identified from left to right, top to bottom with left to right having precedence."
The number of peg holes and their measurements must be determined following the orientation of the product.
Product orientation is based upon the General EAN.UCC Specification.
Required if the trade item is displayed on a peg board.
Business Rules: Required if the item has a peg hole.
Definition: Used to indicate the horizontal distance from the edge of the trade item to the center of the hole into which the peg is inserted when the trade item is displayed on a pegboard.
Business Rules: Required if the trade item is displayed on a peg board.
Definition: Used to indicate the vertical distance from the edge of the trade item to the center of the hole into which the peg is inserted when the trade item is displayed on a pegboard.
The hole into which the peg is inserted when the trade item is displayed on a pegboard.
The measurement is always taken from the top edge of the trade item to the hole.
Item Name: priceOnPackIndicator-(cid:198)this boolean question is answered by populating retailPriceOnTradeItem.
Definition: Indication of whether there is a retail price physically on or attached to the trade item packaging of the trade item by the manufacturer or information provider.
This is a y/n (Boolean) where y equals pricing on the trade item.
The retail price as marked on the trade item package.
"This field is dependent on a value of ""yes"" for field priceOnPackIndicator."
"Business Rules: As monetary amount field, this data element must be associated with a valid unit of measure."
GTIN allocation rules state that price is not a relevant criteria for changing a GTIN except when the price is printed as a part of the trade item’s packaging.
"In this case, the priceOnPack becomes Global (can not vary per Target Market)."
See Section 4.5 of Implementation Considerations and Concerns for more details.
Item Name: isTradeItemInformationPrivate (cid:198)this boolean question is answered by populating partyReceivingPrivateData.
Definition: Indicator to qualify whether master data is publicly available to any inquirer or is restricted to specific private user.
"If yes, then must have associated PARTY ID for whom the information is intended."
"Display configuration B, which contains public consumer unit A, is marked non-public, as it was built for retailer C. Pallet GTIN D, which is made up of Display B, is also marked non-public, only available to retailer C. Business Rules: Trade item hierarchy level impact - if GTIN is marked non-public, all higher trade item hierarchy levels are non-public."
Lower trade item hierarchy levels can still be public.
This Boolean question is answered by application of class Private Information.
Item Name: partyReceivingPrivateData – represented by relationship to Party Identification.
Definition: Unique location number identifying the party who is allowed access to the information by the data owner.
This is handled through the zero to many TradingPartnerNeutralTradeItemInformation.
"While the class ManufacturerOfTradeItem is optional, the party identification for the brand owner is required when a manufacturer is present."
Definition: This element indicates the end date of the trade item's seasonal availability.
The availability is more like an intention of the supplier as to how long he wants to offer the product.
The dispatching time is more useful for the DC and the outlet warehousing.
Definition: This element indicates the start date of the trade item's seasonal availability.
The seasonal availability can be different from the ordering time and especially from the dispatching time.
"Definition: This element indicates the calendar year in which the trade item is seasonally available.This item is seasonally available in the year “2002""."
This element applies to cases where the supplier has items in many different seasons or if multiple calendar years were involved.
This attribute might be considered as an implementation attribute that could be done in different manners in the GDSN and in the one-to-one environment.
"Definition: Indication of the season, in which the trade item is available, e. assignment to one of the following collection periods: spring/summer, autumn/ winter or all year around."
"It is repeatable if more than one season is indicated: Spring, Summer, Autumn, Winter, and All year (available throughout the year)."
The seasonal parameter is more an information for the search of data.
Definition: This element defines the season applicable to the item.
"Example: Holiday, back to school, Summer, Winter, etc."
"Special advertising actions, Winter end-of-season sales (WSV) or summer end- of-season sales (SSV)."
"Not covered by collection as a collection can have multiple seasons or vice versa, a season can have multiple collections."
Definition: This is a code to indicate the type of EAS tag located on the Trade Item.
"Examples: Values include Acousto-Magnetic, Electro-Magnetic, Ink or dye, Microwave, Radio Frequency."
Definition: This is a code to indicate where the EAS tag is located on the Trade Item.
"Example: Values include On outside of Trade Item, Concealed inside Trade Item, Integrated Inside Trade Item."
Definition: Identifies the target consumer age range for which a trade item has been designed.
Definition: Identifies the target consumer gender for which a product has been designed.
"Example: male, female, unisex (suitable to both genders)."
"Business Rules: If color code is indicated, colorCodeListAgency is requires."
The code list required to identify the color of the trade item.
Each industry needs to determine which code agency is will use.
"Business Rules: If color code is indicated, colorCodeListAgency is required."
This is used by certain industries which maintain specific color code lists.
Definition: Free text description of the color of the trade item.
This data element is repeatable for each language used and must be associated with a valid ISO language code from the attached table.
Definition: A code assigned by the vendor to a single trade item or to families of consumer trade items that can be used by in store scanners in conjunction with a U.P.C.
Business Rules: It only applies to the consumer unit.
"Definition: Communicates cancelation of the launch of a trade item that was never and will never be manufactured, but may have been presented to buyers."
Allows the reuse of the GTIN 12 months after cancellation.
The first date/time that the buyer is allowed to sell the trade item to consumers.
Business Rules: Time is expressed in the time zone of the target market where the trade item is intended for resale to consumers.
Definition: Communicate the date on which the trade item is no longer to be manufactured.
"Allows the reuse of the GTIN after 48 months with the explicit exception of Apparel, being 30 months and the implicit exception for specialty products (e.g., steel beams)."
The date on which the information contents of the master data version are valid.
"This effective date can be used for initial trade item offering, or to mark a change in the information related to an existing trade item."
This date would mark when these changes take effect.
Business Rules: This date will be used for version management.
The effective date can be different from publication date.
"If a new user begins to synchronize data on this GTIN after the original effective date, the effective date = the publication date for the new user."
Time zone of the information provider may be d in future drafts of the GDD.
"The date from which the trade item is no longer available from the information provider, including seasonal or temporary trade item and services."
"Business Rules: If the trade item is public only one date is valid per GTIN, GLN, TM combination."
If Item is private there can be more than 1 value per TM.
"There is only one ""end availability date"" per GTIN/GLN/TM combination at any given time."
"In the case of seasonal trade items, only one start/end cycle can be in the data set version being synchronized."
"Therefore, a trade item cannot have multiple start/stop availability dates associated with it at any given time."
Field is optional since most trade items are offered in an open ended environment.
"Is trading partner neutral for public trade items, trading partner dependent for private trade items."
The end date for when the maximum buying quantity is no longer available to the trading partner.
The end date for when the minimum buying quantity is no longer available to the trading partner.
The Date & Time at which a product is no longer exclusive to that trading partner.
Definition: Indicates the earliest date that an order can be placed for the trade item.
Definition: Indicates the earliest date that the trade item can be shipped.
This is independent of any specific ship-from location.
Definition: Indicates the latest date that an order can be placed for the trade item.
Definition: Indicates the latest date that the trade item can be shipped.
Definition: A system generated value identifying the date and time a record was last updated.
"This field allows the data pool to control the trade item data version, and allows the information user to determine if DDTHH:MM:SS."
Business Rules: System generated by the home data pool.
Definition: A date on which all static data associated with the trade item becomes available for viewing and synchronization.
There is only one release date per GTIN/TM/GLN combination.
"If a private trade item, the date can be trading partner dependent, if public, it is a trading partner neutral field."
The date (CCYY-MM-DDTHH:MM:SS) from which the trade temporary trade item and services.
"Business Rules: If the trade item is public only one date (CCYY-MM- DDTHH:MM:SS) is valid per GTIN, GLN, TM combination."
"Needs to be earlier than ""end availability date"" This date indicates when the trade item can first be ordered by the buyer from the information provider."
This date can be trading partner dependent if the trade item or service is defined as private.
It is trading partner neutral if the trade item/service is public.
There is only one start availability date per DDTHH:MM:SS.
The start dateand time for when the maximum buying quantity is available to the trading partner.
The start date for when the minimum buying quantity is available to the trading partner.
Definition: Attribute which defines the outer surface/appearance of the product.
"Business Rules: Until approved in the standards, use of “color” Attribute to define finish is acceptable."
Would only need to be added on Consumer Unit Items.
Definition: Defines the information and processes needed to safely handle the trade item.
Handling instructions is composed of both text and a language code.
"The language for text is specified using the two digit ISO 639-1988 list, for example, English is EN and French is FR."
See Implementation Considerations and Concerns for more details.
"The period of days, guaranteed by the manufacturer, before the expiration date of the trade item, based on arrival to a mutually agreed to point in the buyers distribution system."
Business Rules: This field is indicative of the normal Minimum Shelf Life.
"It is recognized that this figure may vary slightly depending upon locations of DC or Stores, therefore it is repeatable."
Definition: A factor that determines the maximum stacking for the product.
Indicates the number of levels the product may be stacked.
Business Rules: Factor will indicate how many levels the particular product may be stacked in.
The counting of the levels will always commence at 1 not 0.
The maximum admissible weight that can be stacked on the trade item.
This uses a measurement consisting of a unit of measure and a value.
This will be used for transport or storage to allow user to know by weight how to stack different trade item one on top of the other.
Business Rules: Used in conjunction with unit of measure.
"The period of day, guaranteed by the manufacturer, before the expiration date of the product, based on the production."
Item Name: dangerousGoodsIndicator—This boolean question is answered by the application of the class and is thus not included in model or schema.
"Definition: Indication, whether the trade item and/or at least one of its packaging components because of its properties - according to the respective national or international legislation for transport by road, rail, river, sea or air (e.g. the European dangerous goods agreements (ADR/RID) for transport by road and rail) - must be classified as dangerous good, and thus is subject to the respective regulations."
Technical This Boolean question is answered by the application of class “TradeItemHazardousInformation”.
Definition: Code indicating the classification system(s) of dangerous goods and/or the Agency(ies) responsible for it.
"Examples: ""ADR"" European agreement on the international carriage of dangerous goods on roads."
The lowest temperature at which a substance gives off a sufficient vapor to support combustion.
This uses a measurement consisting of a unit of measure and value.
The number of layers of the base trade item found in a trade item.
"It indicates the number of layers that a pallet contains, according to supplier or retailer preferences."
Business Rules: Only used if the pallet has no GTIN.
In this case it applies to the highest level of the item hierarchy and only 1 pallet configuration can be provided.
It is highly recommended to use GTIN for Pallet identification.
The number of trade items contained in a complete layer of a higher packaging configuration.
Used in hierarchical packaging structure of a trade item.
It indicates the number of trade items placed on a pallet according to supplier or retailer preferences.
The number of trade items contained on a single layer of a pallet.
It indicates the number of trade items placed on a pallet layer according to supplier or retailer preferences.
In this case it recommended to use GTIN for Pallet identification.
Definition: Indicates the number of non-coded physical groupings (innerpacks) of next lower level trade items within the current GTIN level.
"Business Rules: An inner pack can only contain the same GTIN, and inner pack sizing must be constant."
Definition: This is a code to indicate the type of import classification for the Trade Item.
"INTRASTAT Code, Harmonized Tariff Schedule of the United States, INTRASTAT Combined Nomenclature, Tarif Intégré de la Communauté."
"Values include Netherlands Import Code, Harmonized Commodity Description and Coding System, Customs Tariff and INTRASTAT Code, Harmonized Nomenclature, Tarif Intégré de la Communauté."
"Definition: Indication whether the base trade item is batch or lot number requested by law, not batch or lot number requested by law but batch or lot number allocated, or not batch or lot number allocated."
A batch or lot number is a manufacturer assigned code used to identify a trade item's trade item on batch or lot.
Differs from Serial Number which is a manufacturer assigned code during the trade item on cycle to identify a unique trade item.
Business Rules: Local legal requirement (E.g. Austria).
Definition: Indicates that the buyer can return the articles that are not sold.
This is a y/n (Boolean) where y equals right of return.
"This is at least relevant to General Merchandise, Publishing industries and for some FMCG trade item."
"Business Rules: This attribute applies to certain industries, and applies to return of salable goods."
"This indicator identifies the general rule, and is not transaction based."
"Definition: Trade item has a recyclable indication marked on it, This may be a symbol from one of many regional agencies."
"Examples: Battery recycling logo placed on the battery, Refrigerators, Heat Pumps and Air Conditioners symbol, Paper marked as recyclable symbol, Plastic types marked as recyclable symbols."
Business Rules: This is a yes/no (Boolean) where yes equals trade item marked with ISO markings.
The measured weight of the material expressed in ounces per square yard or grams per square meter.
For example: 20 OZ Denim would be specified as 20 UOM = ON.
"The fabrics range from gossamer fine to bulky and are described with the following terms: light, medium, medium-heavy, and heavy."
They include applications such as crisp café curtains and a number of sheer window coverings.
Medium weight fabrics generally weigh from 6 oz./sq.
They hang well in drapes and are the common choice for slipcovers.
"They comprise most upholstery fabrics, many drapery materials, and the most substantial terry toweling."
The very heaviest consumer textiles are various types of carpet and other floor coverings.
Business Rules: Acceptable Units of Measure for fabric weight are: ON – Ounces per square yard (oz/yd2)GM - Grams per square meter (g/m²).
Definition: This element is used to specify the quality of material (fabric) of a trade item.
Business Rules: May be used for marketing purposes (both to buyer and end consumer).
The measurement from front to back of the trade item.
Business Rules: Measurements are relative to how the customer normally views the trade item.
Orientation guidelines to be determined by PTRG within CR 02-000102 by Needs to be associated with a valid UoM.
See Section 4.6 of the Implementation Considerations and Concerns for more detail on UoM.
The measurement of the diameter of the trade item at its largest point.
Business Rules: Has to be associated with valid UoM.
The weight of the trade item when drained of its liquid.
Business Rules: Applies to defined bricks of GCI Global trade item Classification - Mainly food trade item.
"Definition: Used, for pharmaceutical trade item to describe 1 or many generic ingredients within the trade item."
Business Rules: Sector specific and local extension.
"Definition: Used, for pharmaceutical trade item to define the strength of each generic ingredient in a trade item or unit volume of the trade item."
See Section 4.6 of the Implementation Considerations and Concerns for more details on UoM.
Definition: Used to identify the gross weight of the trade item.
The gross weight includes all packaging materials of the trade item.
At pallet level the trade itemGrossWeight includes the weight of the pallet itself.
"Examples: ""200 grm"", value - total pounds, total grams, etc."
Business Rules: Has to be associated with a valid UoM.
"The vertical dimension from the lowest extremity to the highest extremity, including packaging."
At a pallet level the trade itemHeight will include the height of the pallet itself.
Definition: Used for pharmaceutical trade item to define the strength of each ingredient in a trade item or unit volume of the trade item.
Business Rules: Sector specific extension pharmaceutical trade item.
Can be locally mandatory based on each country's laws.
"Definition: This field is used to facilitate local business rules where a declaration of a trade item's net content is not on the product label Business Rules: For a product without an on-pack net content declaration this field should be indicated as YES, weight should be communicated at the trade unit level."
"The amount of the trade item contained by a package, as Examples: Evian Water 750ml - net content = ""750 MLT"" ; 20 count pack Business Rules: In case of multi-pack, indicates the net content of the total trade item."
"For fixed value trade items use the value claimed on the package, to avoid variable fill rate issue that arises with some trade item which are sold by volume or weight, and whose actual content may vary slightly from batch to batch."
"In case of variable quantity trade items, indicates the average quantity."
Definition: Used to identify the net weight of the trade item.
Net weight excludes any packaging materials and applies to all levels but consumer unit level.
"Business Rules: For consumer unit, Net Content replaces Net Weight (can then be weight, size, volume)."
Applicable for concentrated products and products where the comparison price is calculated based on a measurement other than netContent.
Business Rules: This field is dependent on the population of priceComparisonContentType is used.
The number of child-items that are packaged beside each other in a trade unit (on the side facing the consumer).
"This information is used in the space process, especially when allocating whole Trade Units (intermediate) into the shelf."
The Space Manager always allocates Base Units in the shelf.
Usually there are no pictures of Trade Units available and for Hypermarkets/Big Supermarkets there is a need to allocate whole trade units into the shelves.
The measurement from left to right of the trade item.
The maximum quantity of the product available to the retailer.
Definition: Minimum buying quantity agreed between trading partners.
The earliest date at which the supplier can deliver the product to the trading partner.
"Definition: Time (in weeks, days, hours …) required between order entry and the earliest goods release (use for pick-up, not use for delivery)."
Definition: This element is an indicator that selected styles or trade items may or may not be re-ordered.
It does not imply any information on current availability.
"Example: Some Designer's Merchandise, T-shirts printed out for a special event (commemorative items)."
Definition: This is an indicator that an item may be at a different price point than other similar SKUs (GTIN's price within a Style may differ).
The normal delivery time measured from receipt of order by the seller until trade item is shipped by the seller.
Business Rules: Geographic distance from manufacturing/distribution point to delivery point may impact this value.
The maximum quantity of the trade item that can be ordered.
This value can represent the total number of units ordered over a set period of time with multiple orders.
Business Rules: Value can vary on Trading Partner dependent basis.
Quantity means number of this trade item level hierarchy.
"This field is relevant at any trade item hierarchy level, but does not need to be populated for all levels."
Definition: Represent an agreed to minimum quantity of the trade item that can be ordered.
Can be a fixed amount for all customers in a target market.
Business Rules: Value refers to the minimum order for this trade item hierarchy level.
The order quantity multiples in which the trade item may be ordered.
"If the Order Quantity Minimum is 100, and the Order Quantity Multiple is 20, then the trade item can only be ordered in quantities which are divisible by the Order Quantity Multiple of 20."
"Definition: A trade item specification other than gross, net weight, or cubic feet for a line trade item or a transaction, used for order sizing and pricing purposes."
"For example, factors may be used to cube a truck, reflecting different weights, and dimensions of trade item."
"Definition: Indicates whether the described dispatch unit is delivered on a pallet and on which type of pallet, or if it is non-palletized."
If the dispatch unit is delivered on a pallet the pallet type must be given here.
The range of the pallet types/codes is listed in code sets.
"Definition: Indicates if the pallet in the prescribed pallet configuration is rented, exchangeable, against deposit or one way (not reusable)."
Business Rules: Used in conjunction with a pallet GTIN.
"List of authorized values based on EANCOM 7073, X12 DE102 and X12 DE399."
"The gross price before application of any discounts, allowances, charges, taxes, etcetera."
Business Rules: CatalogPrice would reside within the Item master data.
The Core Price model would contain class and price along with the class price type.
These will be one of the numerated values for class price type in Core Price model.
Implementation This attribute is represented by UML role.
Definition: This is the effective start date of the price agreed to by the trading partners.
"This start date is mandatory and, if no end date is communicated, then implies that the price is effective until further notice."
Various types of dates may be pre-aligned between buyer and seller.
"For example, based upon a prior agreement between trading partners this date may relate to any of the following events, first order date, first ship date, and first arrival date."
"For example, based upon a prior agreement between trading partners this date may relate to any of the following events, last order date, last ship date, and last arrival date."
This is normally used to establish a proposed value for the trade item for marketing purposes.
May be used as a guideline by the retailer to establish their actual retail price.
"Business Rules: As monetary amount field, this data element must be associated with a valid unit of measures."
Changes in this value do not require a change in GTIN.
"When the suggestedRetailPrice is provided for information (and not on the package : priceOnPackIndicator = 'N') , it can be different per Target Considerations and Concerns for more details."
Definition: An alphanumeric size factor the brand owner wishes to communicate to the consumer.
Business Rules: A descriptive size other than net content as labeled on consumer unit.
Must be associated with a valid ISO language code from the attached table.
"Business Rules: If size code is indicated, sizeCodeListAgency is required."
The value from a industry specific code list required to identify the size of the trade item.
"Examples: Used in industries such as shoes, apparel, home linens."
Refer to Attribute code list in Implementation section.
Definition: Permitted maximum temperature of the trade item on transport to the distribution center.
"Business Rules: Temperature information is important for dairy trade temperature limits are necessary during transport or storage, for quality or safety reasons."
See Section 4.6 of the Implementation Considerations and Concerns for more details of UoM.
Definition: Permitted minimum temperature of the trade item on transport to the distribution center.
Definition: Permitted maximum temperature of the trade item during delivery to market.
Definition: Permitted minimum temperature of the trade item during delivery to market to market.
See Section 4.6 of theImplementation Considerations and Concerns for more details of UoM.
The maximum humidity in percentages that the goods should be stored in.
The minimum humidity in percentages that the goods should be stored in.
The maximum temperature at which the trade item can be stored.
"Business Rules: When no other information is provided (temperatures to market or/and distribution center), this value applies at any point of the supply chain."
"Temperature information is important for fresh trade item, dangerous goods and other trade items for which certain temperature limits are necessary for quality or safety reasons."
The minimum temperature at which the trade item can be stored.
Definition: An indicator identifying the trade item as the base unit level of the trade item hierarchy.
This is a (Boolean) where y indicates the trade item is a base unit.
Examples: A bundle pack of product is composed of packages without GTINs that cannot be sold individually.
Definition: An indicator identifying that the information provider considers the trade item as a dispatch (shipping) unit.
Definition: Identifies whether the current hierarchy level of a trade item is intended for a ultimate consumption.
"For retail, this trade item will be scanned at point of sale."
"At retail, this data is commonly used to select which GTINs should be used for shelf planning and for front end POS databases."
This value reflects the intention of the Information Provider which may not necessarily be the intention of the retailer.
Examples: A multi-pack of paper towels and the individual paper towels contained in the multi-pack are both identified as a consumer unit.
This is y/n (Boolean) where y indicates the trade item is a dispatch unit..
Definition: An indicator identifying that the information provider will include this trade item on their billing or invoice.
This may be Trading Partner dependent based on channel of trade or other point to point agreement.
This is y/n (Boolean) where y indicates the trade item is an invoicing unit.
Definition: An indicator identifying that the information provider considers this trade item to be at a hierarchy level where they will accept orders from customers.
This may be different from what the information provider identifies as a despatch unit.
This may be relationship dependent based on channel of trade or other point to point agreement.
"Definition: Indicates that an article is not a fixed quantity, but that the quantity is variable."
"The weight is about 25 kilograms, but it can be 24 kilogram or 27 kilogram."
"Applies to EAN.UCC bricks: Meat, Cheese, Fruits, Dairy trade item."
Definition: Indicator to show how a product is sold.
Definition: Indicator to show if a product is loose or pre-packed.
Definition: Identification of the type of duty or tax or fee applicable to the trade item.
Repeatable field inside each possible target market.
Definition: Automatically generated text description of tax type code.
The current tax or duty rate percentage applicable to the trade item.
The current tax or duty or fee amount applicable to the trade item.
"Business Rules: As monetary amount field, this data element is must be associated with a valid unit of measure."
Definition: Indicates if radiation has been applied to a trade item’s ingredient.
This requirement is handled through the FMCG Extension.
Should only be submitted if a claim is made on the trade item.
Definition: Indicates if radiation has been applied to a trade item’s raw material.
"This field is trade item specific, indicating that radium has been applied to the trade item."
Definition: Used to indicate whether trade item contains genetically modified contents.
Definition: Indicates if radiation has been applied to an trade item.
Definition: Specification of the degrees of original wort.
The beer degree for the allocation of different original wort proportions in different kinds of beer to the respective beer tax group and beer tax rate.
The amount of fat contained in the base product expressed in percentage.
Definition: Percentage of alcohol contained in the base unit trade item.
This section includes Best Practices and Examples explaining how to best use this data model.
It also includes implementation guides for a variety of the more complicated issues encountered when designing the standards outlined by this document.
It also provides an overal review of the basic precepts used when developing this data model.
This model was designed with the intent of providing all industries with a generic template with which to build their own data model.
EAN.UCC currently has identified 23 different industries which participate in its standards development and application processes.
"While it is recognized that each industry has different needs, this model attempts to provide a flexible data model framework, which covers what is common accross industries and upon which these industries can append their own unique needs."
"The data model assumes a base level of business transactions and agreements between buyer and seller, which then lead to an exchange of information deemed to be necessary for conducting normal business transactions."
This set of information is herein called a data dictionary.
Core – these attributes are absolutely necessary to facilitate the accurate sharing of data sets between parties of all industries.
The combination of these five attributes guarantees the uniqueness of that data set.
The definition and use of these attributes is common to all industries.
"In this data model, the five core attributes are: GTIN of the trade item, the GLN of the information provider, the target market in which this data set is valid, a EAN.UCC external classification value, and a system generated Product identification as a process is mandatory."
Extension – these attributes are shared among several industries.
The determination of whether these attributes are mandatory or optional is made based on the business need of each industry.
It is important to share the responsibility for maintenance of these attributes and to maintain a common definition across industries since the buyer receiving data may receive it from multiple industries.
"Where industries use an attribute in different ways, a new attribute must be developed."
Industry specific extension – these attributes are such that they are only relevant to one industry.
The definition of these values is determined by this industry.
The complete data model for an industry is made up of a combination of these three types of attributes.
"It is expected that attributes may be added or deleted from the model in the future.Also, as more industries become involved in the EAN.UCC GSMP process, it is expected that more industry specific extensions will be created."
"In most cases, the agreement reached by the two parties that will be communicating data will include only a portion of the data model."
This is because this model is designed to capture all possible business needs of the industry.
"In many cases, the buyer will only require a subset of these attributes in order to conduct business in the manner that they are accustomed."
"The entire set of data attributes assigned to a GTIN may vary depending on who provides the information, and in which target market the data is relevant."
"Within the global data synchronization environment, the combination of three key attributes, GLN of information provider, GTIN of the trade item, and the Target Market identifies a unique set of values for the trade items’ attributes."
This combination can also affect which attributes are communicated.
The values of attributes can vary for a GTIN when GLN of information provider or Target market are changed.
Example – “orderingLeadTime” may vary depending on target market.
All variation must be compliant with GTIN allocation rules per the General EAN.UCC Specifications.
Variations that do not comply will require a new GTIN.
"As stated above, in addition possible variations in values for the same attribute, the list of attributes communicated may change based on these three keys."
Changes in the information provider can change the list of attributes associated with a GTIN.
"Example – Information provider A chooses to provide values for 50 attributes for a GTIN, while information provider B chooses to provide values for 100, seeing this as a competitive advantage."
The relevant target market can also affect the selection of attributes.
"Certain target markets will have legal requirements for some attributes, while other target markets will not."
Example – “dangerous goods” attributes are currently required in certain countries.
Parties that do not operate in these countries will not be required to communicate these attributes to their customers.
"There has been a long running debate within the EAN.UCC item project team regarding the application of a principle which states that if information about a product hierarchy is to be communicated, it is required that a GTIN be allotted to that level and the information only be attached to that GTIN."
"At the time this document was being finalized, this debate was still taking place."
It is the intent of the Item group to present to the Align Data BRG a paper describing the current industry practices as they relate to hierarchy with the proper industry endorsement and representation .
This model is designed in conjunction with a widely accepted view of product containment hierarchy found in the commercial products industries.
Eight discreet “levels” of GTIN Hierarchy have been identified.
Implementation with any level of automation will require the programs to map discreetly from each of these GTIN hierarchy layers.
Each attribute has the potential for a different meaning depending on which layer it’s attached to.
Each attribute may also vary in cardinality or condition depending on the ‘product type name’ of the GTIN.
"The following guidelines have been created, debated, practiced, reviewed, and endorsed by the UCCnet community over the last 3 years."
"The Guidelines Task Group, represented by over 60 individuals and participating companies has endorsed these Guidelines."
"May have children (DS, CA, PK, EA) in multiple instances."
"May have children (DS, CA, PK, EA) in a single instance."
May have (CA or EA) children in multiple instances.
May contain children (PK or EA) in a single instance.
Orderable: True or False / Consumable: True or False.
This may be a consumable innerpack (i.e. Carton of Cigarettes) or it may be simply a logistical pack (i.e. Dozens of toothbrushes).
Multiple instances of (DS or CA) parents are allowed.
Orderable: true or False / ConsumerUnit: True or False.
The lowest level of the item hierarchy intended or labeled for individual retail sale.
"May have multiple instances of (PK, CA, DS, PL, or MX) parents."
"In addition, a separate, unique GTIN is assigned to each orderable prepack."
This GTIN is not scanned by the retailer at the Point-of-Sale.
"For example, the NRF size code for the orderable reserved for prepacks and setpacks."
"A valid NRF color code will be assigned to the GTIN when all trade items are of the same color in the prepack; otherwise, the NRF color code 999- assorted prepacks whether the prepack is assorted by size only, color only, or both size and color."
Different prepacks of trade items are quantity contents of the prepacks are different.
The individual trade item GTIN must be scannable at the Point-of-Sale and may or may not be orderable separately outside the setpack(s).
"For example, the NRF size code for the orderable setpack GTIN will be assigned in the 90001-91999 range, reserved for prepacks and setpacks."
"A valid NRF color code will be assigned to the setpack GTIN when all trade items are of the same color in the setpack, otherwise the NRF color code 999-assorted is assigned."
Different setpacks are assigned different GTINs when either the trade item or quantity contents are different.
A multipack is not intended to be broken apart and sold as individual trade items.
A multipack is assigned a GTIN that is different from the GTIN that may be assigned to the individual trade items.
Generally components of a multipack are not marked with individual trade item GTINs.
"Each different multipack of the same trade items (e.g., three-pack socks versus six-pack socks) must have a different GTIN assigned."
Each different multipack GTIN must also have its own trade item/color ID/size ID.
"The hierarchy levels Pre-pack/Assortment and Multipack are not included in the next table, as the discussions of hierarchy were not finalized."
Attributes in the data model are designed such that they can and are used to describe the same value for any product hierarchy level.
The next page shows a table which lists all the attributes contained in this data model and s at which product hierarchy level they are relevant.
Refer to Class Diagram for Trade Item in the UML section where item hierarchy is handled.
Item containment provides a method of identifying the contents of a GTIN that is a packaging hierarchy rather than a consumer unit.
This can occur multiple times depending upon the number of levels in the hierarchy.
All components of each potential level of packaging must already be defined in order to be used in Item Containment.
Each level has to be identified with a product identifier and each level defines the containment (GTIN) of the next level.
It is recommended that only GTINs be used in Item containment.
"The attribute structure for classification included in this document reflects the learnings from the work that the GCI Product Classification workgroup is conducting at this point in time and applies to the Food, Beverage and Tobacco (grocery) sector."
Potential modifications to the codification structure may result in the inclusion in the Data Sync Trade Item model of additional attributes coming from other industry sectors (e.g. General Merchandise).
These potential modifications will be considered after the EAN.UCC's final agreement on a global classification schema is announced.
These products have been treated or packaged in such a way as to extend their consumable life.
"Includes products that may be described as Nectar, Fruit Drink or Juice Drink and available in single flavors such as carrot, tomato, orange, apple etc or they may be blends of more than one such as orange & apricot, cranberry & raspberry etc."
B.: Only one possible attribute value per attribute type.
Change Request (CR) 02-000102 was submitted to the EAN.UCC GSMP process and relates to how to measure the physical dimension of a product.
"At the July 10, 2002 conference call of the Align BRG, this Change Request was reviewed and the BRG agreed to forward to the Physical Technical Requirements Group (PTRG) for the definition of the physical requirements."
"This work is being developed by a subgroup of PTRG and will go through ballot cycles, which are estimated to conclude sometime in the first quarter of impact of the output on the Item work."
"Product orientation principles developed by the PTRG will affect the following attributes: width, depth, and height."
EAN.UCC currently has the following classes related to Language.
"Description Class: it contains two attributes, one is language and the other is text."
Text Description Class: it contains one or more Description Classes.
"Long Description Class: it contains two attributes, one is language and the other is long text."
Long Text Description Class: it contains one or more Long Description Classes.
It allows for multiple combinations of language and longtext.
These classes allow users to fill in the language and the text.
The language for the text is identified using a two character code from the ISO 639 language code list.
EAN.UCC currently has two classes related to Monetary Amount.
Monetary Amount allows for multiple currencies and value or Amount.
These classes allow users to fill in the currency ISO Code and the value.
The currency for the value is identified using a code from the ISO4217 currency code list.
The following describes how unit of measure is handled in the data model.
EAN.UCC currently has two classes related to measurement.
One is 'Measurement class' and the other is 'Measurement Value'.
Measurement allows for multiple Measurement Values.
Measurement Value allows for one Measurement Value.
These classes allow the users to fill in the unit of measure and the float (allows decimal value).
Example: 100 degree Fahrenheit or 38 degree Celsius.
There was no need to create another attribute for unit of measure because it is fulfilled by the use of the Measurement class because the Measurement class is reused.
There is multiple and numerous possible unit of measures.
The EAN.UCC system refers to the UN/Cefact #20 list for the possible unit of measure.
"The unit of measure is not broken down into categories of UOM such as ""time UOM, Weight UOM, dimensional UOM, or net content UOM."
Product Description is one of the four attributes designated as being mandatory (within the Global Data Synchronization process) for uniquely identifying a set of data associated with a GTIN.
"The product description field which is considered core, “tradeItemDescription“ is automatically generated by the model from the four attributes listed below."
"If an attribute is left blank or not defined, the product description exists only of attributes populated."
"While two of the four attributes are designated as optional, since they may or may not exist, it is widely recognized that most information providers will seek to provide values for all of these attributes so as to provide a product description that is as accurate as possible."
The Product Description attributes replaces the Item Description Long and Medium found in the previous GCI model.
"For more accurate product description, several new attributes have been added to the model."
Fields were included with the recognition that the great majority of categories have not yet had classification schemas deployed at the time of this document’s publication.
This section presents the issues concerning code lists that users have identified in implementing the current EAN(cid:121)UCC Trade Item Data Synchronization Standards.
It would be better for all communities to adopt one set of code lists now.
"The analysis that resulted in these code list recommendations took into account all definitions, examples, and business rules contained in the Trade Item BRD."
"Code lists from EANCOM, UNCEFACT, ISO, ANSI X12, VICS EDI, and UCS/WINS were also examined."
The goal was to develop code lists that reflected the intent of the original developers of the Trade Item.
It is envisioned these code list will be added to as new requirements are introduced.
It is not an exclusive or all-inclusive list but this is a living list.
There are several code lists used within the EANUCC system that are maintained by agencies other than EANUCC.
The code lists that are reference in this section apply to several attributes within the trade item as well as other business message standards.
"The following ISO codes lists are used to represent languages (for text attributes), Country and Subdivision (for country of origin and target market), and currencies (for amounts), and the source for the code list."
See Code List Source Bibliography section of this document.
Maintain a code list based on an external code list.
Any code list EANUCC maintains will need to be accessible to the community and maintained in such a way as to be detached from the schema versioning.
The end result is the code lists will be managed outside of the schemas in such a way to remain easy to update and allow for the syntax checking of code values as is done with enumerated lists.
The Unit of Measure (UOM) code is used throughout the EANUCC System.
In order to provide the best value to the EANUCC community the UOM code list will be maintained by EANUCC for its community.
It is anticipated additional code values will be required.
When the business requirements are defined additional code values can be added.
The table below lists all of the attributes whose values are contained in code lists.
The Item team created a subgroup to handle the code lists.
"The subgroup’s objective was to keep the lists as short as possible, removing inconsistent, repeated, unclear or too generic values and also removing information handled through other data elements (E.g., Hazardous related information is handled by specific Des)."
The issue of governance and maintenance of these code lists is still being developed.
Several of the code lists are maintained by outside agencies such as ISO.
"Other code lists are unique to this data model, and will need to be maintained by an EAN.UCC entity."
The table enclosed in the following page represents the work of the group at the time this document was released for Align BRG’s approval.
A separate and more complete Addendum may need to be added at a later time.
The Data Sync Trade Item model was built keeping in mind the design of the data synchronization process being developed by the Data Sync Project Team under the Align Data BRG.
"The key principle that is carried over from that work is the assumption that when a trade item’s information is transmitted from an information provider to a data pool, and data pool to data pool (in network data synchronization) that the entire product hiearchy is transmitted."
"In the grocery industry, that product hiearchy will normally include item, case and pallet, and may also include other levels."
A message detailing information about a trade item must include at least one consumable and one orderable unit.
"Included in this product hiearchy, it is understood that each link connecting the various levels is also considered to be a part of the message."
The following four Appendixes were incorporated for informational purposes.
"Shows how do attributes vary (by Target Market, by Relationship) or how can attributes be repeated (Multiple Values Allowed)."
APPENDIX B – Attribute Association by Trade Item Hierarchy Level for Data Sync Synchronization.
It is recognized that the attributes listed in this data model may be used for a ‘one-to-many’ global data synchronization process.
"In light of this use, the table in Appendix 3 lists which attributes are mandatory within this process."
"Please , this does not mean that only mandatory attributes are communicated via data sync."
"All other attributes, marked as optional here, can also be included in messages."
"Based on the Trade Item Implementation feedback presentation on July 7, 2004, the following modifications will be made to the Trade Item."
These four attributes are in the Trade Item appendix 1 class diagram.
Conversion of Mandatory Boolean attributes into code list solution.
The Boolean attribute should be replaced by a code list.
Below is the current model for the FMCGTradeItemMarking class and revised solution.
"The Florida Courts Technology Commission (“FCTC”), upon motion of its Trial Court Integrated Management Solution (“TIMS”) Committee, adopts this Functional Requirements Document (‘FRD’) to provide specifications for Court Application Processing Systems (“CAPS”) to coordinate the use of information technology and electronic case files, in court and in chambers, by trial court judges and staff."
"In addition to the functional requirements set forth in this document, systems must comply with applicable Rules of Judicial Administration, and other technical and functional standards established by the Court that may apply to CAPS."
"CAPS in this section must be certified under section 2 below before being deployed, renewed, or substantially modified."
Each circuit determines which certified system best meets its needs.
The chief judge’s approval shall be required prior to the purchasing or upgrading of any system.
Systems built and maintained by clerks of court and limited to their historical functions are excluded from this definition.
"Specifically, general purpose files, indexes, or document viewers made available by the clerk to users other than the judiciary and in-court participants are not subject to the functional requirements of this document, although they remain subject to all other FCTC policies and requirements, including but not limited to the Integration and Operability standards and all other requirements set forth by the Supreme Court."
This standard does require the clerks of court to make their official court files available to the CAPS in read-only fashion in real time or from a replication delayed no more than five minutes from real time.
The CAPS shall accept and display case information from the clerk’s case maintenance system (“CMS”) in form and function consistent with these functional requirements.
The system’s design must provide redundancy to eliminate a single point of hardware failure from interrupting CAPS availability to the Court users.
"It must use, to the extent feasible, industry standard document formats and transmission protocols, and avoid all use of proprietary formats, data structures, or protocols."
"In particular, the additional data elements for specific divisions of court as adopted by the FCTC."
"The system must be usable by judges, and also by judicial assistants, clerks, and case managers as the judge may direct."
"It must be able to retrieve basic case information, any scheduling or calendaring information the clerk may maintain, the clerk’s progress docket, and the set of electronic documents that constitute the official court file."
"When a document is being displayed, the court shall have the option to print one or more pages at once."
"It must be designed to minimize risk of data loss, including but not limited to secure, regular, and redundant data backup."
It must permit the court to specify the capacity of any multiple case docket and displays must be able to show the portion of capacity remaining.
It must also prevent booking a multiple case docket in excess of its capacity unless the user deliberately overrides the capacity.
It must also be able to call up a list of cases based on defined criteria and schedule or reschedule all of the cases simultaneously into a new time block.
The displayable fields shall be at least: hearing type; case attorneys; location (court and hearing rooms) and case age.
There shall also be a control that opens the progress docket (§5.5).
"Basic case information includes division of court); type of case; date opened; current status; identities, roles, and contact information of parties and attorneys."
It is the most common entry point for display of the contents of the court file.
The court application must display the docket sequence number for each docket entry in the progress docket.
It must contain a direct means for accessing legal research providers including but not limited to Westlaw and Lexis-Nexis.
The CAPS shall permit editing of the proposed order and file the signed order in PDF/A format.
Neither the court nor any county may be prevented from building or customizing their own form banks.
"This document has been prepared at the request of Mark Stobbs and is a statement of business and functional requirements for a replacement of the existing ‘Section 29 Database’, which is used to support the Professional Standard Authority’s (PSA) processes related to the review of fitness to practice decisions made by the nine health regulators."
"It is envisaged the system will replace the current SharePoint-based system, for which support ends in July 2019."
Help the PSA determine the most appropriate route forward.
Provide the foundation for the selection of an appropriate technology and vendor.
Provide the basis for the selected vendor to make a firm pricing proposal.
Reduce the risk of unforeseen additional requirements extending the development phase.
"Provide the platform for a rapid, high quality implementation of the system."
These requirements have been built on information gathered through interviews conducted in January and February 2018.
The PSA currently use a system that’s been developed in SharePoint 2010 to support its work in relation to scrutinising the fitness to practice decisions of the nine health regulators.
The PSA plan to replace the system well in advance of support expiring next year.
The principle users of the current system are the Scrutiny and Quality team.
"While the current system meets the team’s needs, there is scope to further streamline and automate the PSA’s processes."
The new system will replace the current SharePoint-based system and the data held there will be migrated across to the new platform.
It is envisaged that the new system will replace a number of the data sources and tools that are currently also used to support the Scrutiny and Quality Team’s processes.
It isn’t currently anticipated data will be migrated from these four sources.
"The system that was used prior to the implementation of the current S29 database is still used to provide staff with access to old cases, as the data wasn’t migrated to the current system."
"It is envisaged that this data will also be migrated to the new system, and that this legacy system will be decommissioned in due course."
The core system will be used by around 15 internal staff.
"The PSA has an office in London, but staff will need to access the system from home and when travelling."
"In addition, around 5 external researchers will need controlled access to the system."
"Regulators will be able to upload documents to the system via a portal, and legal firms will also be able to access specified cases and documents through a portal."
The following section describe how processes are currently supported by the system and how it’s envisaged that the new database will support them moving forward.
The final design of the system will be based on the capabilities of the selected technology.
All fitness to practice decisions are communicated to the PSA by the health regulator that undertook them.
The decision is added to the system as a case for review by the team.
The decision is also added to a spreadsheet which is used to report on the cases received.
Cases where the maximum available sentence has been imposed by the regulator are closed by the administrator.
The initial review is appended as a document to the case.
"At the end of the review the team member may recommend no further action is taken, identify a potential learning point that should be fed back to the regulator, request further information, or request a second opinion by a director."
A sample of cases that are closed at this stage are reviewed by a director.
"To facilitate this review, each week the administrator exports data from the system into an Access database from which a report is run detailing cases that should be considered for review."
"If further information is requested from a regulator, the regulator uploads the documents into a portal."
The tracking of requests for further information is currently managed in the cases spreadsheet.
"When the requested further information is received, a detailed case review is undertaken by the PSA’s internal solicitors and appended to the case as a document."
"If the solicitor determines that the decision of the regulator is insufficient, a case meeting is convened."
The case meeting spreadsheet is used to manage the activities associated with the set- up of and output from the case review meeting.
Additional legal advice may be sought from external solicitors and barristers.
"To facilitate this, case papers are loaded onto Kahootz which is an online file sharing service."
"Depending on the outcome of the case review, the decision may be appealed at court."
The administrator creates a draft case in the database and logs the case in the cases spreadsheet.
The administrator monitors receipt of the full details.
The administrator saves the determination to the S Drive.
"If the case is already a draft case, it is made a full case."
"If it relates to an existing case, it is added as a review case from that case, otherwise it is added as a new case."
The email from the regulator is forwarded to the database.
The system will calculate and update the number of working days available to appeal.
"The administrator moves the case to the ‘Initial determination review’ stage, and adds comment to say the harshest sanction has already been imposed."
The case is moved to the ‘Case closed’ stage.Cases for review are split into two lists based on their outcome.
The list one cases are available to the team coordinators and senior scrutiny officer as a view in the system.
The list two cases are passed to the senior solicitors for review on an Excel spreadsheet that’s created by the administrator each week.
They set the stage as ‘initial determination review’.
"They fill out the initial template review document, and add it as an attachment to the case.If there is a learning point, a case comment will be added with a category of ‘Draft learning point’, and the ‘Learning point recommended’ field is ticked."
"If the reviewer requires a second opinion before the case is closed, the ‘Second check requested’ field is ticked."
The stage will be set to ‘Determination director review’.
Case workers may also identify process issues which may be relevant to a performance review by ticking a ‘PR issues’ field.
"A list of cases where second checks have been created, or learning points identified, is created each week by the administrator for the director."
A list is also created for the director for random second checks.
"If the director agrees with the decision, the stage is set to ‘Case closed’ or ‘Send determination learning point’."
Alternatively they may add their own final learning point.
"If they disagree with the decision, they change the stage to ‘Request further info’."
The administrator closes cases that haven’t been checked with a to say no second check has been carried out.
The administrator records the outcome of the case in the cases spreadsheet.
The administrator will request further information.
The email request and any response from the regulator is saved to the database.
The date of the request is recorded on the cases spreadsheet.
The case details are copied to the transcripts page of the spreadsheet.
Due dates and dates followed up are tracked in the spreadsheet.
The regulator uploads the documents into the portal (though sometimes the NMC will use Kahootz).
"The stage is updated to either ‘Transcripts received’, ‘Exhibits received’, or ‘All requested info received’."
The transcripts sheet on the cases spreadsheet is updated with the receipt of the documents.
"When all information is received, the ‘All information received’ box is ticked in the regulator portal."
The legal team are notified we have all the documents and number of days remaining to the deadline.
The person undertaking the DCR adds their name as the caseworker and changes the stage to ‘Detailed case review’.
"Once the review has been drafted, it’s added as a document to the case and also saved to the S Drive."
The Status is changed to ‘Detailed director case review’.
The director sets the stage to either ‘Case closed – post detailed case review’ or ‘Send learning point – post detailed case review’.
The closure of the case is recorded on the cases spreadsheet by the administrator.
"The reviewer changes the stage to ‘Section 29 case meeting’, or, if it’s a GMC case, to ‘GMC appeal – s40b’."
"The administrator updates the cases spreadsheet with the DCR outcome, and the details of the case meeting are updated in the case meeting spreadsheet as known."
The s29 meeting date field is updated in the system.
The letter of instruction and related emails are saved to the database.
The administrator shares case papers with the relevant chambers/firm by uploading to the Kahootz online file sharing service.
The administrator drafts a letter to the regulator inviting comments.
The letter is saved to the S Drive and the system.Refer to court?Case closedNoA letter is sent to the regulator and registrant informing of non-referral.
The cases spreadsheet and case meetings spreadsheet are updated.
"The Stage on the system is changed to ‘Case closed – post case meeting’ or ‘Send case meeting learning point’, or ‘GMC appeal – PSA not joining as a party’."
Case meeting s are saved to the S Drive and the case in the system.
"Copies of the with any learning points are emailed to the regulator, and the email and any response is saved to the system."
"To avoid maintaining data in multiple places, the cases and case meetings spreadsheets will no longer be used."
The additional data tracked by these spreadsheets will now be managed in the system.
The Stage on the system is changed to ‘Refer to court’ or ‘GMC appeal – PSA joining as a party’.
Letters are sent to the regulator and registrant and scanned to the S Drive and saved to the system.
The senior solicitor or team coordinator change the Stage on the system is changed to ‘Appeal lodged’.
"The Outcome, Order, and Date fields are filled out on the system."
"The Stage will be either set to ‘Appeal settled – case closed’, or ‘Appeal upheld – case closed’."
The case meeting is shared with the regulator and published to the website.
The ‘List Two’ cases which will initially be reviewed by the internal senior solicitors will be available as a list in the system and won’t require the administrator to prepare a list each week.
Kahootz will no longer be used for file sharing with external lawyers.
"The user will identify that a case should be shared and who with, and the case and associated documents will be available to the lawyers by logging into a portal, using a user name and password, without the PSA needing to upload the documents."
The administrator creates a draft case in the database.
"If it relates to an existing case, it is added as a review case from that case, otherwise it’s added as a new case."
Reviewers will see the cases as lists within the system.
"They fill out the initial review fields in the system.If there is a learning point, a learning point record will be added to the case with a status of ‘Draft learning point’."
"Case workers may also identify procedural issues, which may be relevant to a performance review, by adding a procedural issues record to a case."
"A list of cases where second checks have been created, or learning points identified, will be available in the system."
A report will be created within the system for the director for random second checks.
The regulator will be automatically emailed with the request.
Any response from the regulator is saved to the database.
"The date of the request, and the person requesting further information, is updated in the system."
The regulator uploads the documents into the portal.
The date transcripts and exhibits are received is updated in the system.
The legal team are automatically notified the document have been received and the number of days remaining to the deadline.
"Once the review has been drafted, it’s added as a document to the case and saved to the S Drive."
The administrator shares case papers with the relevant chambers/firm by giving them access to the case through a portal.
The following table describes some of the key entities in the system.
This entity tracks information about the FTP cases that the PSA is This entity tracks information about learning points that are This entity tracks information about procedural issues that are This entity tracks financial data related to a case populated from This entity will track the activities related to a case.
The following section describes the key entities and the information they will track.
The fields described are not intended to be definitive and it is envisaged these will be finalised as part of the design process.
The contact entity will track information about current and former registrants.
The system will track information about the FTP cases the PSA reviews.
"From a case record it will be possible to see associated learning point, procedural issue, invoice, and activity records, including tasks, emails, phone calls and meetings."
"Where a case is a review of an existing case, it should be possible to create the review case from the parent substantive case."
"There will be a link between the two records, so it should be possible to see the associated parent case from the review case, and any review cases from the parent case."
"When a review case is created from the parent case the following fields should be automatically populated based on the values in the parent case: Regulator, Type of Hearing, Registrant Name, Gender, Registrant Number, Practitioner Type, and Charge Summary."
It will be possible to easily link a case to another case or another contact record and specify the relationship type.
"For example, link two cases that are for the same or similar issues but have been raised by different regulators."
It should also be possible to unlink cases if required.
It should be possible to attach a document to a case.
Documents may be a range of different types including PDF’s and Word documents.
"Ideally it should be possible to ‘preview’ a document without opening it, and mark a file as read."
"When a case is added, the deadline date for the PSA to appeal a decision should be automatically populated."
"This is currently 67 working days if the registrant has the right to appeal the sanction, and deadline will be managed within the system’s settings and will be held against the sanction outcome for each regulator."
"The settings of the system should track public holidays, so that these are not included in the working day computation."
The final day should no fall on a weekend or public holiday.
The Time Remaining field should be updated by the system daily so that users are aware how close the deadline is for appealing a case.
The values in the Practitioner Type field will be limited to those that are related to the selected value in the Regulator field.
"For example, limited to ‘Doctor’ if the GMC was selected as the regulator."
Within the settings of the system it should be possible to specify for any given stage on a case which options are available to the user when they change the stage value.
"It should be possible to stop a user moving from one stage to another if defined fields haven’t been filled out, or specific documents uploaded."
It should be possible to easily specify and save multiple ‘views’ of case data.
"For example, all cases that at a Stage of ‘further information requested’, or all cases where I undertook the original case review which have gone to appeal."
"It should be possible to update multiple case records at the same time, for example update the Stage field."
The system should track an audit trail of changes to a case record including original values and who made any changes.
The system should track an audit trail of any comments added and documents uploaded or deleted.
The system should generate a report of the number of cases that need a random second check for each sanction type.
The report should ideally randomly select the cases to be reviewed by the director.
Either 10% or 20% of cases need to be checked based the type of sanction.
"In order to make the number of fields on the case entity manageable, the system should ideally allow unused sections of data to be hidden on the entity form if they aren’t populated."
A ‘Total Invoiced to date’ field will be automatically calculated based on the total invoice value of associated invoice records for a case.
"It should not be possible to save a case with a ‘Stage’ field value of ‘Send learning point’, if there is no learning point linked to the case."
The learning point entity will track information about learning points identified during a case review.
The procedural issue entity will track information about procedural issues identified during a case review.
It is envisaged that the system will track invoices relating to a case.
This data will be primarily populated through a one-way integration with the PSA’s financial software which is currently Sage Line 50.
"The system will track activities such as emails, phone conversations, and meetings."
The system will allow the definition and assignment of activities.
"The activity types will include emails, meetings, phone calls, and to-do’s."
These activities may be scheduled for specific times and dates.
There should be the option to assign alarms and alerts to highlight important activities.
"Assigned activities should be visible against case and contact records, as well as in a list view, and in a diary view."
It should be possible to filter the list view for a specific date range.
Open and closed activities for all cases should be rolled up and visible at the contact record level.
It should be possible to apply filters to open and closed activities to help find the required information.
"Filters should include by activity type, date range, and user."
Incoming emails and attachments may be stored against a case.
"It should be possible for scheduled activities, such as a case meeting, within the CRM system to be synchronised with the Outlook diary."
It should be possible for activities scheduled in the Outlook diary to be synchronised with the diary within the CRM system.
"It should be possible for a change made to an activity in Outlook to be synchronized with the CRM diary, and a change to an activity within the CRM system to be synchronized with Outlook."
When the Stage field on a case is set to ‘Further information requested’ an email will be automatically sent to the relevant regulator requesting they upload the case transcripts into a portal.
"When the regulator accesses the portal, they will be presented with the cases where they have been requested to provide further information, but where that upload has yet to be completed."
Two folders will be available for the regulator to upload transcripts and exhibits.
"A regulator will only see their own cases, and not the cases of other regulators."
"The regulator should be able to upload multiple documents to the folder at the same time, and there should be no restrictions on the type or size of the file (users are currently limited to 29mb)."
The regulator should be able to see and open the files they have uploaded.
"The regulator should be able to delete files if, for example, they have uploaded a file by mistake."
The regulator should ideally be able to see a status bar to guide them on the progress of uploads.
The PSA administrator should receive an automated email notification when files have been uploaded to the portal.
Files uploaded to the portal will automatically be appended to the relevant case record.
Once the PSA administrator indicates all documents have been received by changing the stage to ‘All information received’ the case folder will no longer be visible to the regulator.
"When the PSA decide that they wish to share a case and its related documents with an external legal firm, they will be able to opt to share a case and all details of the case and associated documents will become visible to the designated lawyer when they log into the portal."
The PSA will be able to ‘unshare’ a case at which point it will no longer be visible to the legal firm.
The legal firm should be able to download appended documents to cases shared with them.
"They should also be able to upload documents within the portal and these will, in turn, be appended to the case."
There should be a simple means to search on key fields such as contact name and email address.
These simple search criteria should include ‘starting with’ and ‘contains’ searches.
It should be possible to make all fields searchable.
"It should be possible to perform key word searches, to bring back records that contain identified key words."
It should be possible to search for documents in the system.
Ideally a key word search would be able to identify documents that contain defined search terms within the document.
The system should facilitate complex searches which allow the combination of any field within the database including those that have been added through configuration or customization of the system.
A complex search should include the ability to perform ‘and’ ‘or’ searches.
Search functionality should be user friendly and should not require reliance on technical resources.
It should be possible to save groups of records that meet a specified search as a list within the system.
It should be possible to define a group as static or dynamic.
"A static list will remain unchanged over time, a dynamic list would be updated according to which records currently meet the defined criteria."
It should be possible to export a group of records to Excel.
Access to this function should be controlled through system security.
It will be possible to make any data entry field mandatory or recommended.
"When a new contact or case record is added, the system will prompt the user with any potential duplicate records."
"Provide duplicate identification whereby all, or a group of, records may be searched to identify potential duplicate records."
"This search for duplicates should be based on one, or a combination of selectable fields, for example company name and city for organisations, and last name and email for contacts."
Provide sophisticated data import tools that allow potential duplicates to be identified and merged as part of the data import process.
"Allow the merging of duplicate records, such that the administrator can select which data to keep from each record, rather than make one entirely subservient to another."
It is envisaged that users will utilise the system to help generate correspondence to prospects and clients.
Will allow a document to be merged to a single contact or a group of contacts.
Will allow a mail-merge template to be defined in either Microsoft Word or Outlook email.
"The template should be able to use any field within the database, including both standard fields and those added through the configuration and customization process."
It should be possible to save templates for future use.
"There should be both personal mail-merge templates that a user has created for their own use, and public mail-merge templates that are accessible by a wider community of users."
It should be possible to manage through the administration function which templates an individual has access to.
It should be possible for a user to preview a mail-merge document before printing or emailing and edit the merged document if required.
"When a mail-merge is completed, the user should have the ability to save details of the mail-merge to contact history."
This should include the option to attach a copy of the document sent to the record.
The creation of mail-merge templates should be a user activity and should not need the input of a technical resource.
The system should allow the users to attach files to case records in the system.
"It should be possible to give each file added to a record a description, and the user and time and date that the document was appended should be automatically recorded."
It should also be possible to categorise appended documents.
There should be no limitation on the number of files appended to a case or the individual or total file size.
It should be possible to have multiple folders of records appended to a case record.
"It should be possible to search for documents from a case based on criteria such as date uploaded, file type, file name, file category, file size, or who uploaded the record."
"The system should provide workflow management capabilities, such that a change in the system can trigger an action or a sequence of actions."
"Actions should include the generation of activity records, and the automatic creation of emails."
All data from the current SharePoint based system will be migrated.
"This will include the following record types: contacts, cases, and documents."
"There are estimated to be around 20,000 case records on the current system."
"There are estimated to be around 20,000 case records on this system."
The system will be integrated with the Sage Line 50 financial system.
This will be a one-way integration from Sage to CRM.
Invoice and accrual data held in Sage will be visible for each case in the CRM system.
Dashboard capabilities that allow users and managers to view key metrics from a single data view.
It will be possible for different users to have different dashboard views and to be able to create custom dashboards.
Export to Excel capabilities which allow users to make use of Excel’s graphing capabilities.
"Provide the ability to create customised reports, without the need to use an external supplier, including the ability to depict data graphically."
Provide security such that the ability to export data to Excel or have access to individual customised reports can be controlled by user.
The system will require a user name and password in order for a user to access it.
The system should have the ability to enforce a password change at a definable interval.
The system will provide the ability to restrict access to the system from a specific machine or IP address.
"The ability to specify by user, or group of users, which record types they have visibility of."
"For those records a user has visibility of, to be able to define which fields they can see, and if they can see the field, whether they can update or edit it."
It will be possible to limit a user’s visibility of records to a specific group of records.
"The ability to restrict functionality by user or group of users, in particular the ability to restrict the export of data."
The ability to restrict access to management reports within the system.
It should be possible to create audit trails for selected fields within the system.
"These will time and date stamp amendments, identify the user making the change, and the old and new values."
It should be possible to restrict a user’s ability to delete records from the system.
The PSA will allow a small number of external researchers access to the system.
"These users should only have read access to data and specifically be restricted from being able to add, edit, or delete records, or export data."
It should be possible to define different forms for each entity for different users and teams.
"For example, the fields that one team may wish to see on a case record may be different from those seen by other teams."
It is important that the system is flexible enough to meet emerging requirements.
Ability to relate entities on a one to many or a many to many basis.
"Ability to define fields against entities of varying types including, but not limited to, text, numeric, money, picklist, lookup and date/time."
Ability to add automation to forms such that actions can be triggered based on the value entered in a field.
"Ability to add logical workflow that can be triggered on the creation, amendment or deletion of records."
Ability to read or write data via standard web service functionality.
Ability to extend functionality through the creation of custom written plugins.
The change log describes the modifications in each version of the document.
This document describes the background and the business requirements of the Seamless Travel project.
"It is designed to help business people and decision makers from airports and airlines to understand how communication with other airports, airlines and partners via the Seamless Travel interface can improve their own business and the various possibilities for new and innovative ideas."
"This section introduces the guideline document and describes its purpose, the scope, the environment and the conditions."
This section describes the general background why ACRIS started this initiative and the global context.
This section explains the use cases defined in the project’s scope.
This section describes the logic of the data model that is used throughout the project.
"ACRIS is an acronym for “Aviation Community Recommended Information Services”, and is one of the working groups under ACI World."
"Members of the working group are airports, airlines and vendors."
The purpose of this working group is to define standard data models and web interfaces for exchanging operational and passenger related data between the partners in a standardized way.
Two working group face-to-face meetings are being held each year and additional meetings or conference calls are scheduled as required by the projects and topics.
"The working group is open for airports, airlines and partners from the aviation industry; participation is on voluntary base."
All contribution on meetings or projects is done on the own expense of the participants.
For more information on ACI ACRIS working group visit the homepage (http://groups.aci.aero/home) or have a look at the ACI ACRIS information video (https://www.youtube.com/watch?v=Fj7xcAauCSo).
Further details on ACI World can be found at http://www.aci.aero/.
The ACRIS Semantic Model is a collection of knowledge-driven models organized to support meaningful communication for business collaboration.
"The following chapters are giving a brief overview on the ACRIS Semantic Model, for more information see http://groups.aci.aero/home."
"As the participation on ACI ACRIS projects is on a voluntary base, some airlines, airports and partners were working in the project continuously, others supported the project in different phases according to their capacity or special knowledge."
As many players in the aviation industry are interested in efficient and high quality services for their customers – including passengers – it make sense to define common standards for information exchange and data models.
There are well known organizations for the different areas within the aviation industry representing their members but it is also important to think outside the box.
IATA has started the “Simplify the Business” (STB) initiative which shares under the roof of the “Travel Communication” project a lot of the goals with ACRIS Seamless Travel.
IATA participated in the ACRIS Seamless Travel project from the beginning and the aim is to create an industry wide common standard that is approved and actively used by airport as well as airline representatives.
"This document is designed for business people and decision makers of airports, airlines, aviation related vendors and service providers to understand the background, meaning and powerful possibilities of the ACI ACRIS Seamless Travel data model and Web services."
Data interchange in the aviation industry is a big challenge and strategic factor.
"And that not only means to exchange some data, but to ensure that there is a common understanding of the content, independently which data is exchanged and how many partners are using that content."
How do the ACI ACRIS Seamless Travel data model and web services fit to these objectives?
Why should this standard be chosen over implementing proprietary interfaces for your Open Data initiative?
"Many aviation related companies use the term “Seamless Travel” and of course, there are many different meanings of this term."
The purpose of this chapter is to explain why Seamless Travel is a topic for ACI ACRIS and what exactly the meaning of Seamless Travel in this context is.
The Seamless Travel topic was introduced to the ACI ACRIS working group in 2013 by Munich Airport.
The idea behind it is to provide passengers as well as visitors with all relevant information and give them the possibility to book services of companies from the whole aviation industry ecosystem.
"This includes not only airlines and airports, but also ground transportation providers and commercial tenants."
"One of the industry observations, namely that people don’t want to download a large number of mobile applications to their smartphone in order to get all necessary information and service possibilities for a single trip was the crucial factor to start a project."
Currently business travelers are required to have 30 or more apps from different airports and airlines installed on their phones which does not only result in a bad usability experience but also drives heavy users to third-party applications with less trustworthy data sources.
Another fact is that airlines and airports want to offer different information and services to passengers during their journey.
This starts with simple information about upcoming flights or places at the airport but also includes bookable services like paid lounge access.
An important goal is to give the passenger reliable and trusted information during the whole journey.
The challenge is to find new ways for airports and airlines to approach the customer and to give them the possibility to distribute high quality information - including services - via many distribution channels.
"To face this challenge, different approaches are conceivable."
"One is to have a single common app for the whole aviation industry, which is a utopian idea and only feasible for a modest number of companies."
The other one is to define a common data model and according interfaces to exchange data.
This standard would allow the embedding of trusted information (including services) from all partners in other applications.
One example scenario is a passenger travelling from Munich via Frankfurt to New York.
"This passenger should not be forced to download the Lufthansa, Munich airport, Frankfurt airport, and JFK airport applications in order to get all travel details."
Each of these apps is capable of displaying reliable information on a particular flight segment and interesting services at a specific location.
"The Munich airport app could be enabled to show transfer information for the next segment (Frankfurt to New York), to book a lounge at Frankfurt Airport, or find a location and the fastest way from the baggage belt to a specific restaurant in New York."
"For the airports and airline involved in this trip, Seamless Travel is a great chance to provide better information and sell more services, independent of which app the passenger downloaded."
All this and much more information is available in the IT systems of the partners.
The ACI ACRIS Seamless Travel data model and Web service interface will make it possible to exchange these pieces of information between all partners in a common and standardizes way.
"Munich airport has started working on this topic some years in advance, so some of the definitions were used as base for the ACI ACRIS standard definition."
The project management was also done by Munich airport.
The standard describes the different entities with all attributes and properties.
The semantic model represents the airport community common knowledge.
It comprises of ideas (business concepts) and connections between the ideas and is a collection of terms in the form of diagrams made by aviation industry professionals.
The standard describes all interfaces to handle transactions and exchange information corresponding the defined entities.
The standard does not define which kind of services can be offered via the Seamless Travel interface.
The defined interfaces can be used for direct connection between partners as well as there can be one or many platform providers / data integrators as a central connection point where the partners interlink.
"In real world scenarios partners will need to have regulations or contractual agreements for their legal relationship and data exchange (e.g. SLA, privacy issues)."
"Because these details differ for each relationship, they are not defined in this project’s context."
One of the first tasks for the project group was to define relevant B2B and B2C use cases.
"As there are different perspectives regarding airport, airline, provider and passenger, the use cases where clustered as shown in the diagram below."
As described in 3.4 Sparxsystems Enterprise Architect is used for specifying the ACRIS Semantic Model including use cases.
This whole chapter is the Enterprise Architect representation of the use cases.
The Seamless Travel use cases have been collected and categorised according to their area of interest.
These areas are intended to align with the ACI Semantic Model concepts.
The following diagram illustrates the actors involved in the Seamless Travel Use Cases.
"The Account package contains those use cases that concern the identification, characteristics and preferences of the user."
The user either manually selects a different than his default airport or it is automatically selected based on the user's location.
The application detects that the user is at an Seamless Travel enabled airport that is not his default airport nor the one currently selected.
The application then automatically switches to the airport the user is currently at.
The user has selected the change password page of the seamless travel platform.
He enters his current credentials and the new password.
"After the system has checked the password policy, the new password is stored for the account."
The user wants to change the password for the Seamless Travel platform.
The application validates the new password against the password policy of the Seamless travel platform.
The user creates an account for the Seamless Travel Platform.
"The application validates the entered data, if not valid: jumps to (1) and shows error message, otherwise creates an user account and stores the data entered."
The user fills out the input fields (at least the compulsory ones)3.
The user deletes an account from the Seamless Travel Platform.
"The user selects """"delete account"""" from the account overview screen within the app."
The user confirms the wish to irrecoverably delete the account.
The user has selected the login page for login to the seamless travel platform.
The user wants to login into the Seamless Travel platform to access information and services.
The application validates the user login data and give access to the application site.
The application logs in the user and shows next screen()1.
"The user can discard the information or react to it, where applicable (e.g. open a link, jump into a specific function)1."
The user allows booking agent to send new trip itinerary to app.
User wants to import new trip itinerary into the app rather than keying in the data herself.
The user enters the airline and booking number into the application.
The application retrieves the entire itinerary from the airline and loads it error-free into the application for the user.
The user forwards an email to the Seamless Travel application which scans the email for trip itinerary and confirms with the user.
The user selects his default airport from a list of airports.
The user select one of the Airports as his default Airport()3.
The service-provider/Airport/Airline wants to load user information.
The application send the information to the requester.
"The user changes settings or profile details (e.g. email address, phone number) that are stored on the servers of the Seamless Travel Platform."
The user wants to update it’s personal preferences()2.
The Airline package contains those use cases that concern the airline and passenger bag information.
The user wants to know what the status and where the checked-in baggage currently is.
The user selects a piece of baggage by tapping/clicking on it()1.
"Receive information about baggage from partner (airline, airport or ground handler)."
Airport or Airline or Ground-Handler provides information about baggage-status.
"A partner requests information about a baggage status, where the piece of luggage is identified by a unique identifier."
"StartA partner requests information about a baggage status, where the piece of luggage is identified by a unique identifier."
"Receive aircraft information (types, seat maps, …) from airport or airline."
The airport offers information about aircraft-types used at the airport.
The airline provides information about their fleet (aircraft-types).
The airport or airline replies with a list of aircraft types and their flight plan.
"Receive airlines information (e.g. services, facilities, PRM options, contact details)."
"The airline offers information about the airline’s service, facilities or PRM options etc."
A partner requests information about airlines at an airport.
The airport replies with a list of airlines and their details.
StartA partner requests information about airlines at an airport.
Display Airline information like service phone number.
The user wants to get information about airlines at a specific airport.
The user has an account for the seamless travel platform.
The application selects all airline-details from the database.
The system has to merge the local airline-info for the airport and the global airline-info for all airports.
The application displays a screen with all airline information.
"If the user hasn’t selected a default or current airport, the first step is that the application asks the user which Airport should be used."
"StartAlternate1If the user hasn’t selected a default or current airport, the first step is that the application asks the user which Airport should be used."
"Airport: AirportUser: User1.If the user hasn’t selected a default or current airport, the first step is that the application asks the user which Airport should be used."
The user selects the airport’s airline overview()4.
E.g. If there is a local Information Phone-number but no local email of the airl5.
E.g. If there is a local Information Phone-number but no local email of the airl2.
The application selects all airlines having scheduled flight to or from the selected airport()1.
The user selects the airport’s airline overview()6.
The application asks the user if he wants to fill the form electronically instead of seeing an agent at the lost and found counter.
"The user enters (at least all mandatory) input fields and presses """"submit""""."
The application saves the fields and transmits them to a partner.
"The user enters (at least all mandatory) input fields and presses """"submit"""".1."
The application notifies that user's baggage did not arrive as expected()2.
"The Airport package contains those use cases that concern the airport specific information, and that which relates to obtaining information that is of interest to the passenger experience within the airport."
The application shows list with all services provided via the app or web site he uses.
The user wants to see a list with all services he can use.
The application provides the user with a list of all services which can be used.
The airline and airport provide information on the availability of automated border control.
The airline and airport provide information on security fast track.
The airline and airport provide information about bag tag and bag drop options before passenger transits to the airport.
Airline and airport provide information about baggage options.
Airline: AirlineAirport: AirportUser: User2.End-user receives information.
The airline and the airport provide information on gate number.
The screening authority provides information on restricted/prohibited items and divest information.
The airport provides information about security waiting times.
A partner requests information about security waiting times information.
End-user will be offered an option to buy security fast track (if not yet included).
StartA partner requests information about security waiting times information.
To make it easy to find a service the user can search via a single search field.
The user wants to search services by entering some search criteria.
The application tries to generate a result-list which should be ordered by calculated relevance of the result-items.
Therefore different service fields have different importance for calculating the relevance.
E.g. the title is more important than the description.
"Fetch airport-specific information, e.g. facilities, maps, terminal processes, current events/issues, travel options to/from airport, services provided in/near/by airport, PRM options, local weather, contacts."
The airport provides information about the airport.
A partner requests information about airport-specific information.
StartA partner requests information about airport-specific information.
Weather Information Service Provider provides weather information at airports.
The information is provided by the weather information service provider.
Display Airport information like location of service desk or service phone number.
The user wants to view a list with information about the Airport.
The application provides the user with information about the Airport.
"If the user hasn’t selected a home airport, the first step is that the application asks the user which Airport should be used."
"StartAlternate1If the user hasn’t selected a home airport, the first step is that the application asks the user which Airport should be used."
"Airport: AirportUser: User1.If the user hasn’t selected a home airport, the first step is that the application asks the user which Airport should be used."
The application selects all Airport information from the database()3.
The Application displays Airport information -> ADD LOWER LEVEL (SUB) USE CASES (e.g. static / dynamic content)1.
"The Flight package contains those use cases that concern the flight specific information, and that which relates to obtaining information on flights that is of interest to the passenger."
The application add the flight to the user’s favorite flights in the user profile()3.
The application enables sending push-messages for updates of the flight to the user’s device)1.
The airline and the airport provide information on flight cancellation.
The airline provides information on flight cancellation.
The airline and the airport provide information on flight delays.
The user wants to remove a flight from the bookmarked flights.
"The user selects the """"unbookmark"""" button next to a flight."
The application removes the bookmark symbol and stores the updated bookmark list.
The user wants to search one or more flights by entering some search criteria.
The application selects all matching flights and displays a list on the screen.
"If the user hasn’t selected a home airport, the first step is that the application asks the user which Airport should be used for searching flights."
"StartAlternate1If the user hasn’t selected a home airport, the first step is that the application asks the user which Airport should be used for searching flights."
The User presses the “Search flight” Button on the application.
"Application: ApplicationAirport: AirportUser: User1.If the user hasn’t selected a home airport, the first step is that the application asks the user which Airport should be used for searching flights."
The application selects all matching flights from the database()5.
The application displays a list with all matching flights()3.
The airport provides flight information about arrival and departures.
The airline provides flight-information about their operated flights in cluding core-share information.
The airline provides passenger numbers to the airport and partners to forecast FTE requirements and manage passenger flows.
Airport and partner requests information about passenger numbers.
Airport and partner make use of the passenger numbers to forecast FTE requirements and manage passenger flows.
StartAirport and partner requests information about passenger numbers.
Airport: AirportAirline: Airline1.Airport and partner requests information about passenger numbers.
The user wants to see the list of flights of the current day at an Airport.
The application selects all flights of the current day and displays a list on the screen.
All arrival and departure flights of the day are included.
The application displays the filterable list with all flights.
"If the user hasn’t selected a default airport, the first step is that the application asks the user which Airport should be displayed."
"StartAlternate1If the user hasn’t selected a default airport, the first step is that the application asks the user which Airport should be displayed."
"Airport: AirportUser: User1.If the user hasn’t selected a default airport, the first step is that the application asks the user which Airport should be displayed."
"The Location package contains those use cases that concern the location specific information, and that which relates to obtaining information that is of interest to the passenger experience within the airport."
The airport provides passenger location to the airline/ground handling agent in order for the airline to decide whether to wait or to off-load the passenger.
Airport provides passenger location to the airline/groundhandler.
StartAirport provides passenger location to the airline/groundhandler.
Airport: AirportAirline: AirlineUser: User4.End-user is notified of flight re-booking()2.
The airline takes the decision to wait or offload the passenger()3.End-user is notified to go to the gate or that he was offloaded()1.Airport provides passenger location to the airline/groundhandler.
The application centers on the user's current position (with the correct level)2.
"The Services package contains those use cases that concern the service specific information, and that which relates to obtaining service information that is of interest to the passenger within the airport."
The booking process and an optional payment have to be done.
At the end the user has booked a service and got a receipt.
The user wants to book a service from a service provider.
The service provider wants to get a definite booking of a service and also the payment for it.
The payment provider has the goal to provide a secure payment.
"The application loads the first form-page from the service provider, who offers the service, extends this form with already known data and asks the user to check the filled and fill out the missing fields."
The user checks and fills out the form and presses next step.
The application pre-validates the form and sends it to the service-provider to receive the next booking-step Number 2.
The user process the payment-process without any communication with the system.
PCI compliance and privacy requirements are dealt with.
Payment provider may be interchangeable (linked to service).
"The application pre-validates the form and sends it to the service-provider to receive the next booking-stepRepeat steps 2, 3 and 4 until the last form is sent.."
The application request a fixed booking from the service-provider()10.
The application pre-validates the form and sends it to the service-provider to receive the next booking-step()11.
The application sends the confirmation to the user and displays it()7.
The application shows a booking summary to be checked by the user()12.
The application wants to change a service reservation.
The service-provider receives a change of a service reservation.
Partner A requests the change of a service information.
"Partner B receives the requests and checks, if this change is possible."
"If possible, B confirms the change to A, otherwise a human understandable error message is sent."
The application add the service to the user’s favorite services in the user profile()1.
Therefore a need an overview over all his booking actions to verfy or rebook them .
The user can view a list with all services he has booked.
This use case does not include the real booking transaction.
It only configures the service and reserves it for a configurable amount of time.
There is no contract between service provider and user at the end of this use case.
The application wants to prepare a service reservation.
The service-provider receives a service reservation.
The user starts the booking process for the selected service.
The server will reserve the service for a configurable amount of time (e.g. make it unbookable for others if resources are limited).
"Receive providers, query by e.g. date/time/location (when/where needed)."
The airport provides a catalogue of services offered at the airport.
The airline provides a catalogue of services with information of local availability.
The application wants to receive a list of booked services for a specific user.
The service-provider send a list of all bookings associated with the user.
Partner A requests the list of services booked by a single user identified by a unique ID Partner B replies with the list of services.
"The user selects the """"unbookmark"""" button next to a service."
The user selects a service to view the service’s details.
"To get the maximum of flexibility the description is assembled of mandatory date like Title, short-description etc."
The user wants to get detailed information about an offered service.
The service provider’s goal is to give a user detailed information about a service.
The Trip package contains those use cases that concern the specific information that relates to trips that a passenger wishes to take.
He clicks/taps a button to add this item to a trip.
The application shows a list of all of the user's trips.
The application adds the item to the trip and stores the updated trip.
Therefore the application has to save a new Trip-Wrapper and guide the user to complete the trip information.
The user clicks/taps on an visual element (e.g. button) to create a new trip.
The application saves this information and shows the new trip in a list.
The user clicks/taps on an visual element (e.g. button) to create a new trip.2.
The user has the trip details view open showing all flights/services/… for that particular trip.
The application removes the item from the trip and stores the updated trip.
There for different service fields have different importance for calculating the relevance.
The result is requested with a length (number of items) and offset (position of the first item to be transferred) to reduce traffic.
"The application shows a search bar, up to three recommended services and a list of all categories."
There has to be a view to show all the information about the Trip the application has collected during the interaction with the user.
The user clicks/taps on the trip from the list showing all trips.
"The application shows a list of all elements (flights, booked services, …) for that trip."
The following diagrams illustrate the list of terms extracted from the Use Cases.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to Party Role.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to the State of an element.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to Service Offering.
For example a Flight Service is a kind of Service Offering.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to the Location of an element.
For example a Delivery Address is a kind of Location.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to the Movement of an element.
For example a Surface Movement is a kind of Aircraft Movement which is a kind of Movement.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to Time Period.
For example Scheduled Time is a kind of Time Period.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to Transport.
For example an Aircraft is a kind of Transport Vehicle.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to Facility.
For example a Departure Gate is a kind of Facility.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to System.
The following diagram classifies the various terms from the content of the Seamless Travel use cases into those that relate to Item.
"The following diagram shows the concepts involved in Seamless Travel, and how they relate to each other."
"The relationships are termed ‘facts’, and these should be verifiable by a business user."
"For example, a passenger (Party) creates a service bookmark (Information Content)."
The following diagram shows the logical model derived from the Concept Map.
This illustrates the information items with the appropriate attributes.
This is used to generate the physical interface model.
"As these three files build on one another, they are not to be updated without reflecting these changes in the others."
Any change in the implementation guidelines for example would need to be reflected in the supporting files as well.
Version 1.0 was approved by the ACI World Airport IT Standing Committee (WAITSC).
"If show-stopping bugs, discrepancies, misspellings, etc."
These changes need to be brought up to the ACRIS group for approval.
"If the group agrees to adopt these changes a new minor release can be created that keeps its draft status, but is released for implementation."
"New features, major renaming or other changes that affect the standard and its implementers are supposed to be developed within a working group and to be submitted to the WAITSC for approval."
Unapproved changes from prior minor changes should be merged into these versions.
"The goal of future changes should be on adding optional fields / interfaces that do not interfere with the existing version, especially the rolled-out instances."
"From a technical standpoint, versioning either within the calls or as part of the URL would make sense to allow clients to distinguish between different versions."
"Additionally, the server should include the version number of the response currently delivered as well as other (newer) versions available."
This standard was developed within the ACI ACRIS Seamless Travel Working Group.
Regarding technical questions there currently is no formal support of any kind.
"Since Munich Airport was heavily involved in the development of this standard and has a running instance of Seamless Travel in production, feel free to send your inquiries to the Munich team – however there is no guarantee to receive quick response (as in commercial support)."
"The purpose of this document is to provide information to the FDP Executive Committee sufficient to allow their endorsement of the development, maintenance, hosting, and use of an on-line FDP Expanded Clearinghouse system [see http://sites.nationalacademies.org/PGA/fdp/PGA_171520]."
"This document explains the high-level technical and functional requirements, and provides information about the roles and responsibilities needed to support such a system, including the obligations of FDP and the obligations of other parties."
The document also includes a cost estimate for developing and maintaining this type of system for FDP members.
"It does not include details about expanding access to the system to non- FDP members, though the system will be designed in such a way to permit such an expansion."
"This Functional and Technical Requirements Document outlines the functional, performance, security and other system requirements identified by the FDP Expanded Clearinghouse System Development Working Group (EC-SDWG) as the proposed information system solution for the Expanded Clearinghouse."
The content of on-line profiles is expected to mirror the content currently found in the Expanded Clearinghouse pilot profiles found at: http://sites.nationalacademies.org/PGA/fdp/PGA_171219.
"The scope of this work includes the initial development of the web based system, based on information and feedback gathered during the Phase 1 Pilot."
References to future development considerations are included in this proposal for information purposes only.
Points of Contact relevant to this project are listed on the first page of this proposal.
"Once the project has received Executive Committee approval, this document will serve as a formal MOU detailing the agreed upon responsibilities and requirements."
A representative from each organization will be asked to sign the document documenting their organization’s acceptance of its roles and responsibilities.
This working group will be responsible for the administrative oversight and operations of the Clearinghouse system as detailed in the next section.
UW will serve as part of the system development group and provide back-up development and technical support should it be needed.
"The FDP will serve as the ultimate oversight, in the form of the FDP Executive Committee to ensure appropriate review, support and approval is provided throughout Phase 2."
All other information must be reviewed at least annually.
No subscriber will be suspended without having first had an opportunity to cure.
"There is currently no single, on-line electronic database containing all information needed for pass-through entities to perform risk assessments and to do ongoing monitoring of static or annualized data related to subrecipient monitoring."
"Select data are instead housed in certain federal government systems, such as the System for Award Management (SAM) or the Federal Audit Clearinghouse (FAC) with the remainder retained by the individual entities themselves."
"Certain data expected under the Uniform Guidance to be used for this purpose are as yet unavailable nationally to pass-through entities, including copies of A- creating data collection documents used with each other at time of subaward issuance or updating."
The plethora of forms coupled with most institutions collecting data on a per-subaward basis rather than on a per-entity basis has led to significant administrative burden without commensurate benefit from a risk management perspective.
The FDP Expanded Clearinghouse Phase 1 Pilot created a process whereby each pilot entity could provide a standard set of data and answers to questions in the form of an Entity Profile.
These Entity Profiles are currently maintained in excel and converted to pdf for to a centralized web site repository.
Data relative to administrative burden relief is being captured and will be reported quarterly beginning Fall 2016; early data suggest the relief will be meaningful.
"The profiles themselves generally require updating at least twice per year, resulting in significant ongoing burden."
"In addition, download of data for use in local systems is not available."
"These results, along with the remarkable success of the original FDP Financial Conflict of Interest Clearinghouse that was eventually opened to non-FDP members and now includes more than 1000 entities, signified a need to change to a more automated and electronically robust process for the longer term."
This proposal reflects the FDP’s efforts to build that electronically robust system.
"At designated intervals (at least monthly), the system sends an email reminding entities to update their System will also be able to send reminders on certain data elements when the data has become out of date (SAM expiration date, Audit date, etc) A list of these data elements will be developed by the ECWG and provided to the ECSDWG."
System provides designated FDP administrators with additional rights.
"FDP Administrators create new entities and approve new profiles FDP Administrators can create, edit, and disable user accounts."
The FDP Expanded Clearinghouse Web-based system will require an initial team of developers and testers.
These roles will be filled by the EC-SDWG on a volunteer basis.
"The project will require administrative, project management, and training duties that will be performed by the ECWG."
"Any financial management needs of this project will be coordinated through David Wright, Mark Sweet and Pamela Webb with the FDP Executive Committee."
To support the ongoing needs of this system the FDP will require an oversight committee to oversee and manage the system and the community’s data to ensure ongoing reliability and integrity of the system (ECWG).
"It is expected that once built, this system will exist on an ongoing basis with at least an annual review process build in to determine effectiveness, needs for updating or changes, potential need for termination, or other circumstances."
"Entities will have access to their data and reporting, but publication of community-wide data will be authorized by the FDP Executive Committee."
In anticipation that the web-based FDP Expanded Clearinghouse will eventually replace the various data collection components currently maintained by or through FDP we expect the long-term overall impact to FDP to streamline the type of data currently being housed on the FDP webpage.
Users will interact with the system in real-time via the web.
FDP members will be expected to acquire and maintain a secure and reliable internet connection adequate to facilitate data entry by their staff.
"Questions on the system in general, data entry, reporting and use will be facilitated by the FDP Expanded Clearinghouse Working Group."
"FDP pilot institutions are required to alter their current subrecipient entity forms and internal processes to accommodate the expected data collection and data entry, including timeliness."
"All user information, guidance and FAQ’s will be developed by the ECWG and EC-SDWG and maintained on the FDP webpage."
"All Pilot entities will have access to instructions and training materials to access to the system, including FAQ’s regarding the system."
"The FDP Expanded Clearinghouse will be maintained in the current Excel spreadsheet / PDF repository fashion until such time as a web-based system has been developed, testing and fully adopted."
Pilot entities will be required to assist in the transition between methods/systems.
"Basic data logic warnings (e.g., Gender: Male with Pregnancy status: Y) Manual review and validation of new draft entity profiles by a designated FDP administrator, prior to profiles being added to the system."
"The system is intended to be available online 24 hours per day, 365 days per year with the exception of scheduled and pre- notified system maintenance downtimes, if needed."
"Data will become immediately available for use, except for new profiles, which will be pending in queue for validation by an FDP administrator."
The ECSDWG will ensure that system resources are adequate for timely response times and overall software functionality.
The ECSDWG will review ISP/hosting provider options and once the initial development is complete will move the clearinghouse over to this for hosting the system.
The system will be built and tested on Vanderbilt hardware and software and then transferred over based on agreement of ECSDWG.
"The cost an ISP/hosting provider is estimated to be approximately $1,200 annually."
"Temporary inaccessibility, even up to several days, will not create a substantial burden on any user."
The host site for the system will be chosen so as to include data backup capabilities and protocols.
"VUMC will maintain a copy of the code on Vanderbilt’s network, which has daily backup protocols."
"Additionally, should the ECSDWG believe it to be prudent, a copy could be kept at University of Washington or another backup site."
It is expected that with the use of an IPS/hosting provider that downtime will be minimal or non-existent.
"The proposed FDP Expanded Clearinghouse system will consist of a web-based, centralized database Entity Profile and reporting to be utilized in the support of ongoing subrecipient entity monitoring activities and responsibilities by the Entities."
"Generally, all users will provide direct input into the system and outputs (reports) will also be generated directly from the system."
"However, to ensure growth ability, flexibility is also required for both input and output modes."
"Participating Pilot Entities will provide input (i.e., entity level data) and the ECSDWG, as an agent of the FDP, will provide system administration and support for report generation."
"The system is planned to be originally developed principally by staff at Vanderbilt University Medical Center, in close consult with the ECSDWG."
"As feasible and agreed upon, David Wright and Jason Myers might also assist in components of the development."
An additional desired functionality of the system is to integrate with other external systems.
The FDP Expanded Clearinghouse system will be desired to have the capacity to import and export data without ongoing support by the ECSDWG.
"To this end, the system will expose a RESTful API via HTTP to provide data in JSON format for external consumer access."
The clearinghouse system will also include the functionality to interface with the federal System for Award Management (SAM) web services to access certain data elements as defined in the functional requirements.
In addition exploration of utilizing the bulk download capabilities currently available in the Federal Audit Clearinghouse will be explored to allow for the possibility of utilizing that data for uploading entity profile data elements as well.
The desirability for the ECSDWG to continually update and improve the system is a given.
"However, the FDP will also require that the system be flexible and customizable to suit their needs."
The complexity of the system will limit the customizations available via the administrative interface at the FDP level.
"However, the code should be structured to make customizations a reasonably accessible task for a PHP programmer, and the FDP will have access to the code repository to make such changes as desired."
"Any tools that will be utilized, outside of those discussed in this proposal will be discussed an agreed upon among the ECSDWG prior to use."
No closed source or proprietary tools will to be used.
The system will be developed under the leadership of Vanderbilt University Medical Center using industry standard web development tools and practices.
"VUMC commits to develop the initial application as described in this document, and to provide additional support and development services up to 5 hours per month on an ongoing basis, without charge to FDP."
Either party may pursue a transfer of maintenance responsibilities at any time.
The ECSDWG will perform at least an annual review of how the system is working and whether responsibilities need to be shifted or changed in any way.
"VUMC may, at its discretion, or as contracted by FDP in exchange for appropriate remuneration, provide additional support or development services beyond this commitment."
"The FDP and ECSDWG will have access to the source code for the software and may work with other parties to extend, enhance, or edit the system in collaboration with VUMC provided the changes and enhancements are committed to the GitHub repository."
Source code will be stored on GitHub or in another mutually agreed repository.
There is no anticipated need for an end-user guide as system will include an intuitive user interface.
"VUMC will provide such documentation as necessary or as requested by the ECSDWG or FDP Executive Committee for technical requirements, including but not necessarily limited to documentation of the system-to-system API."
Any end-user help documentation will be developed by the ECWG.
"VUMC, as the primary developer, shall retain all right and ownership in the software product including but not limited to source code, including right to license the product (but not the data) to any third party."
"VUMC will grant to FDP a perpetual, worldwide, royalty-free, non-exclusive, non-transferable license to the software product and derivative works, without the right to sub-license, for FDP and its agent(s) to use the software product for its own purposes."
"This shall include no more than one production instance at any time, with unlimited backup, development and test copies permitted to maintain, improve and test the software as necessary."
FDP shall retain all right and ownership in its data.
"VUMC shall receive a perpetual, royalty-free license to the data strictly for the purposes of maintaining, improving and supporting FDP’s installation of the software product."
The ECSDWG will work together to determine where the system may need to be configurable and ensure that all parties are in agreement and parameters are appropriately documented.
"Under the leadership of VUMC, the initial system will be developed in iterations."
"As the developers complete portions of the application, they will make the updates available to ECSDWG for review."
"These reviews are intended to keep the application development on course, addressing any miscommunications early and providing the ECSDWG with a clear understanding of how the work is progressing."
The ECSDWG will review the submitted product and provide a notice of acceptance or s on changes that need to be made in a timely manner.
This iterative process will repeat until ECSDWG is satisfied with the software product.
"Once the parties agree that the software product is in a “Beta”, or near-final state, ECWG members be enlisted for private live testing, including entering new entity profiles, to flesh out remaining bugs and process issues to be fixed before go-live."
"Once the initial system is complete, the ECSDWG will submit the software product to ECWG for final review and approval."
"Additional timelines and documentation related to the go-live process will be developed, as needed including potential review and approval process by the FDP Executive Committee."
"The ECSDWG will be responsible for utilizing currently existing equipment either at VUMC or the FDP, or for contracting with a web hosting service for server space."
No additional equipment is anticipated at this time.
"The clearinghouse application will be built with PHP version 7, an open-source web scripting language."
"Data will be stored in a MySQL database, also open source."
"The user interface will be developed in HTML5, CSS3, and JavaScript."
VUMC will be employing components from standard and commonly accepted libraries such as PHP Symfony and jQuery for Javascript.
PHP dependencies will be managed via the Composer package manager.
The application will be able to run on any web server that supports PHP 7 and has a MySQL database.
The ECSDWG will be responsible for securing the necessary server space.
"The application code will use Git version control, and all commits will be archived in a designated repository which can be made available to other ECSDWG members."
Source code will be stored on a mutually agreed platform.
"If FDP so desires, Vanderbilt will provide server space for hosting the application."
"If FDP decides to have the application hosted on a third-party’s servers, Vanderbilt will work with the hosting provide to assure that it meets the needs of the application developers."
This domain will be configured to point to the web servers used for this project.
We anticipate this will be a minimal time commitment (less than 1 hour per week).
The bidder must indicate its compliance / non-compliance to the requirements and should substantiate its response in the space provided below.
"If more space is required to justify compliance, please ensure that the substantiation is clearly cross-referenced to the relevant requirement."
Describe the level of integration and solutions supported.
The solution must normalize common event fields (i.e. network.
The solution must provide near-real-time analysis as well as functionality.
The solution must provide the ability to correlate information across potentially disparate devices.
The solution must provide the ability to transmit alerts using solutions.
The solution must limit the presentation of multiple similar alerts.
The solution must support the ability to correlate against 3rd vulnerability scan results.
These 3rd party data feeds should be updated automatically by the solution.
The solution must provide bi-directional integration with 3rd operations staff may use to guide their work?
The solution must support multiple display points in different SOC.
"Providers are accountable for the overall project and shall ensure that all personnel, subcontractors and consultants are managed and comply with all requirements."
Human Resources and Training now combined in new Section 12.
Duplication in risk management requirements between former Section 2 and 7 removed.
Appendix 4 added giving Guidance on Competency Assessment.
The purpose of this document is to provide details for NERS Providers (Providers) of the requirements they need to meet for accreditation under the National Electricity Registration Scheme (NERS).
"The document details the assessment criteria against which Providers will be measured in respect of key legislation, safety, quality, environmental, competency and technical issues covering the various scopes of registration established by the Scheme Advisory Panel."
The aim of NERS is to facilitate competition in the provision of new infrastructure connections in the electricity utility sector.
The Registration scheme assessment process seeks appropriate evidence that Providers wishing to perform the activities for which they seek accreditation understand and comply with all the necessary technical and legislative requirements to satisfy the electricity distribution industry criteria for adoption of the installed assets.
Provider compliance is demonstrated by means of a thorough assessment of Provider’s procedures and processes prior to work commencing and a technical audit of work in progress.
An essential feature of the accreditation process is to provide assurance that the practices and procedures against which accreditation is awarded are consistently applied and maintained.
Hence work being carried out and supporting procedures are regularly checked throughout the accreditation period.
In addition to specifying the technical requirements this document outlines (in Appendix 1) the process for accrediting Providers under the scheme and details what needs to be done to maintain accreditation.
In NERS there is a 2nd tier National Electricity Registration Scheme specifically for civil contractors who are supervised by NERS accredited Providers awarded the contestable work.
This scheme has limited bounds of responsibility and scopes of work which are detailed in Appendix 2 of this document.
Accreditation – see Appendix 1 for details of the accreditation process and the arrangements covering the granting of ‘Partial’ and ‘Full’ accreditation.
Accreditation Body – an organisation which undertakes the assessment of the competence of Providers in accordance with the Scheme and has been approved for doing so by the Scheme Advisory Panel.
Accreditation Certificate – a certificate awarded to a Provider by the Accreditation Body for a scope(s) of work assessed under the Scheme.
Accreditation Period – ‘Partial’ accreditation validity is for a term of 1 year and ‘Full’ accreditation validity is for a term of 3 years.
Accredited NERS Provider – any organisation which has been assessed as competent in accordance with the scheme and has been issued with a valid and current Accreditation Certificate.
Adopting Utility – the Company which will be adopting the constructed asset.
Assessing Officer – A person appointed by the Provider to assess the competency of individuals nominated for appointment as competent persons and for recommending them for authorisation by the Authorising Officer.
Assessment – objective and detailed evaluation of the Provider to determine their capability in accordance with the Scheme criteria.
The person appointed by the Provider as responsible for formally assigning competencies based upon the recommendations of the Assessing Officer.
"Certificate of Competence - is a formal Provider recognisable document, dated with a 3 year certification period confirmed by the signature of the Provider Assessing and Authorising officers, which states that an individual has been assessed as competent to perform specified work activities, within the accredited scopes of the Provider."
This certificate of competence shall be issued to persons whose work includes that undertaken by a craftsperson and/or a craftsperson’s mate and is in addition to the requirement of a NERS Passport and any certificates / authorisations required by an adopting utility.
"Competency – a combination of qualifications, training, knowledge, experience, aptitude and fitness for the job."
Craftsperson – a person who has been trained to undertake specific tasks associated with the installation and/or construction of electrical plant or equipment.
"For scheme purposes these include cable jointers, overhead electrical linespersons, electrical fitters and mates to those skills."
Deficiency – the identified absence of or a failure to implement or maintain one or more of the specified criteria.
"These may be characterised as major, minor or observations as defined within Section 1.3."
Energy and Utility Skills Register (EUSR) – is a proposed web accessible database register of competencies.
NERS Provider (Provider) – a company meeting the requirements for accreditation and which has been assessed as competent in accordance with the scheme requirements.
"Passport (NERS Passport) – is a document that is issued by a Provider to an individual, before any work commences, to authenticate the identification of that individual and give a general record of that individuals training, competence, inductions, reviews, audits and work histories."
Procedure – a specified way of carrying out a process or activity.
"Where specified procedures shall be documented, they shall be version controlled with the approver/authoriser of each document identifiable."
"Qualified Supervisor – a competent person appointed by the Provider who has specific and direct responsibility, for the safety, quality and technical standard of work performed by all staff under their supervision."
"Safety Management System – the systems, processes and procedures, forming the Provider ‘s safe system of work, that ensure all aspects of the Health and Safety at Work Act 1974 and all appropriate legislation and regulations relating to the work covered under the Scheme are complied with."
"Second Tier Registration Scheme – a scope for civil contractors who are supervised by NERS accredited Providers and limits their work to cable laying, excavation and backfill."
This scheme has limited bounds of responsibility and scopes of work which are detailed in Appendix 2.
The general requirements of NERS as defined in this document.
Scheme Advisory Panel – Governing Body for the scheme-known as NERSAP (NERS Advisory Panel).
Technical Advisor – A person appointed by the Provider who has the appropriate level of qualification and operational experience (subject to the relevant scopes of work undertaken/to be undertaken) to advise the Provider on the fundamentals of the industry and the scheme.
The Technical Advisor may be an employee of the provider or employed on a consultancy basis.
In this document the following terms have the stated meanings.
The licensed company responsible for the electrical distribution network in a franchised area designated under the Electricity Act.
The licensed company responsible for an electrical distribution network embedded within one the franchise areas designated under the Electricity Act.
"Accreditation is a demonstration that the procedures, processes and competencies have been established by a Provider to ensure consistent delivery of the accredited scopes of work to the NERS scheme requirements in accordance with industry good practice and the adopting utility requirements."
An essential feature of the approval process is the assurance that procedures and practices against which approval has been awarded is consistently applied and maintained by the Provider.
"This is verified through an ongoing surveillance audit programme which checks, over the period of accreditation, work carried out and supporting procedures."
Providers should establish a risk management process which evaluates ongoing risk to their accreditation status.
Subcontracted aspects of their accredited scopes of work should be incorporated into this process.
Accreditation can be gained in any of the scopes detailed in this section.
Providers shall only do work within the specified parameters of their accreditation scope(s).
"This means that they shall observe any capacity, size or geographical limitations along with any other constraints that apply to their accreditation."
Where scope limitations preclude a Provider from providing a ‘complete solution’ to their (developer) client they must not have any involvement in controlling the work that falls outside the accreditation they hold.
"Instead a suitably accredited Provider, or the host utility, shall separately undertake all work elements that are outside the authorised scope of the ‘original’ Provider and the adopting utility shall be notified of the arrangements that have been put into place."
Where construction activities are being project managed the ‘project management’ Provider shall ensure that the work being done is within the scope of the ‘construction’ Provider.
All work specification design not done by the adopting utility shall be done by a Provider holding design accreditation.
"However where the new infrastructure adoption agreement issued by the adopting utility company is with a ‘construction’ or ‘project management’ Provider who does not hold design accreditation that Provider may act as the primary interface between the (developer) client, the adopting utility and the design Provider."
Providers shall ensure that in performing work for which accreditation has been granted they strictly adhere to the competency requirements detailed in Section 4.
"Providers wishing to operate in specific and/or all DNO geographical areas shall demonstrate through their systems and procedures their ability to mobilise effectively, efficiently and safely in accordance with relevant legislation, scheme requirements, relevant DNO standards and specifications including G81 documents."
"Providers that hold accreditation in any of the construction categories are not, also, required to hold project management accreditation, in those scopes, but where Providers also/do operate as a project manager, in them, they shall adhere to the requirements specified for the project management scope."
Project Management of design scopes are not available.
This is because the criteria set for such a scope would require the Provider to meet the overall requirements of a full design scope thus the Provider would be capable of undertaking that scope in their own right.
Accredited Providers not holding Design scope may therefore use Providers who do providing the design work is relevant to that Provider’s design accreditation.
"Adopting Utility Policies, Procedures, Specifications and Codes of Practice."
"These accreditation scopes apply both to Providers who either do not themselves carry out construction activities but who manage this work by subcontracting such activities to appropriately accredited Providers or to Providers holding a construction scope who wish to subcontract out activities, in other construction scopes that they don’t have the accreditation for, to other appropriately accredited Providers."
"Under NERS, Project Management is not a blanket scope that covers all areas of construction activities, but is categorised in accordance with the construction activities available."
"Therefore for each project management scope category, Providers are required to have documented procedures, processes and technical competencies in place to effectively manage the subcontract relationship and the quality of the work performed."
The processes and procedures shall define responsibilities for the listed aspects throughout the project life cycle.
Providers shall ensure that their quality control and supervisory arrangements are sufficient to ensure that the work is constructed to the required quality standards and that all adopting utility requirements are satisfied.
The adequacy of these arrangements should be checked through a risk based evaluation.
In case of civil and cable laying activities Providers holding Project Management of those scopes could also sub contract work in those areas to 2nd tier accredited Providers.
Network Connection is the classification of works associated with the connection of new networks to the adopting utility’s existing network and is broken down into Connections and Operations Activities.
Each activity has a number of scopes against which accreditation is required.
"Prior to applying for these scopes the Provider should discuss with the relevant adopting utility companies and determine their implementation plan phasing, their respective interface arrangements and any pre-requisite requirement for operational scopes."
"However, Providers already holding Live LV jointing do not automatically hold any Network Connection scopes."
Network Connection scopes are a separate entity from Live LV Jointing and as such require additional evaluation and accreditation.
Some DNO’s may require Providers to hold Live LV Jointing as a pre requisite before entering into relevant Network Connection pilot agreements.
Providers should check relevant DNO’s position on this point.
"The Switching of Apparatus under central or field control to facilitate a new connection, and or any associated diversion and reinforcements to an existing DNO or IDNO’s System."
"Apparatus Any item of electrical machinery or equipment in which Conductors are used, or supported, or of which they form part."
"The operation of circuit breakers, isolators, disconnectors, fuses or other methods of making or breaking an electrical circuit and/or the application and removal of Circuit Main Earths."
Some DNOs have put restrictions on the implementation of these scopes.
"Similarly work which does not fit comfortably into one of the above scopes will be allocated, at the discretion of the accreditation body, to an appropriate scope."
"This scope is applicable to connection work on services to underground cable, un- metered, single phase 230 volt points of supply with loads of 25 amps or less."
"The transfer, permanent or temporary disconnection, reconnection, or extension, of a service to such a point of supply."
"The installation of a new service to such a point of supply, excluding the joint onto an existing main."
"Live jointing associated with this process is restricted to the underground service cables and the Provider shall have in place an adequate decision making process to ensure safe operations where the above work may, or may be suspected to be, in the vicinity of a main."
Any other live work involving main cable shall be carried out by the adopting utility.
This scope also includes the connection to a dedicated single phase meter pillar.
"Network Connection (un-metered OHL) – overhead line connection of single phase un-metered services to existing overhead lines (live LV connections are included in the scope, however, the Provider shall have in place adequate live working decision making and approved live working procedures)."
"Providers shall ensure that personnel responsible for design, project management, construction, testing and commissioning and auditing activities carried out under this scheme are competent to do so and meet both the general and role competency specific requirements."
These competency reviews shall be documented and recorded.
Best practice is demonstrated when role specific competency requirements are built up from job descriptions which are broken down into job related tasks against which personnel can be assessed.
Role specific competencies are best summarised in a matrix detailing the minimum requirements for each grade and showing the actual level of competence for each role holder.
"Such a matrix should be supported with evidence confirming qualifications, training, experience, aptitude and fitness."
The production of a competency matrix is recommended in particular for those Providers with Network Connection construction scopes to facilitate skills development.
Persons engaged on the design of electrical networks or self-determination of POC shall be able to provide evidence of technical competence as well as knowledge and understanding of the design phase.
This may be achieved through a combination of education training and practical experience relating to the design activity undertaken.
"In determining a designer’s competence, the National Skills Academy for Power guidance document – ‘Governance of Network Design Competence’ is seen as good practice."
"All designs / POC shall be reviewed and approved by a person assigned to that duty, with that review and approval recorded."
Design engineers shall be required to demonstrate competence in the category of design accreditation they hold.
The Provider shall have and maintain a competency assessment procedure that indicates how the competency of design engineers is assessed.
This procedure shall include a competency matrix that defines the minimum competencies for each grade of technical staff and the actual competencies of named staff within each grade.
Those involved in delivering works as project managers shall have the technical competency to manage the subcontract relationship and interface with the adopting utility company to ensure that the works constructed are to specification for adoption in line with the adopting utility and industry standards.
Project management Providers shall appoint a suitably qualified Technical Advisor to oversee the process.
They shall demonstrate a level of technical competence relevant to the construction activities to be project managed.
If employed on a contract basis then their responsibilities shall be clearly defined within the contract of employment.
The Technical Advisor shall be responsible for overseeing the role competency process.
Records shall be kept of all competency assessments together with the supporting evidence obtained during the competency interview and these should be reviewed and updated at least annually.
For this scope Providers shall appoint Qualified Supervisors to oversee the scopes of work for which project management registration is required.
Qualified Supervisor should be appropriately experienced in the scope of work being undertaken or alternatively have more than 5 years performing that role in another related sector.
"Until such time as Qualified Supervisors have been assessed as competent to perform the role unsupervised by the Technical Advisor, and the decision documented, their technical audit function shall be overseen by the Technical Advisor, or someone assessed as being competent by the Technical Advisor."
"A person nominated and appointed as Qualified Supervisor shall be a Competent Person with the appointment reflecting the area of supervision in relation to that individual’s experience, training and qualification."
Evidence of current and ongoing competence of all operatives shall be demonstrated by the adoption of a competency record scheme as described in Section 13.
DNO Safety Distribution Safety Rules and shall have an understanding of the scheme and its associated Safety Management System.
"Names and designations of authorising officers including any changes shall be notified to Lloyd’s Register in writing and relevant information on the successor, as described above submitted, for review."
Qualifications of the Authorising Officer are at the discretion of the Provider.
"However any evidence of the Authorising Officers academic qualifications, background and experience should be available."
Where the Provider uses more than one assessing officer any one of those officer(s) can be nominated and appointed to manage the passport scheme.
The Assessing Officer can be an employee of the Provider or a consultant employed for this specific role.
"Additional competencies shall be documented by the Assessing Officer, following satisfactory test and assessment, and be added to the relevant person’s competency record (passport) and if necessary by the reissue of a certificate of competence."
"Assessing Officers must be suitably qualified with appropriate knowledge and experience of the operational aspects, safe working practices, Provider safety procedures, legislations, and technical reference documents that are relevant to the scopes of work they are to assess in."
They shall have a minimum of 3 years’ experience in a role that gave responsibility for controlling and/or supervising the type of work carried out by those individuals they are to assess.
"Where Assessing Officers are to assess the competence of persons to perform operations associated with the installation of electrical plant or equipment, then in addition to the above, they shall have knowledge of the electricity distribution networks, the Model Distribution Safety Rules, relevant adopting utility codes of practice, relevant areas of the Electricity, Safety, Quality & Continuity and the Electricity at Work Regulations."
To assess candidates for work / operations in the Network Connection construction scopes the Assessing Officer shall be able to demonstrate sufficient knowledge and understanding of the Distribution Safety Rules (DSR) and Operational Procedures of the adopting utility and / or Provider depending on the interface arrangements that each DNO has in place.
"The qualifications, experience and other evidence of the suitability of the proposed persons for positions as Assessing Officers shall be documented and provided to the accreditation body."
"The accreditation body shall indicate, via their assessor, approval at assessment or, to cater for additions or changes via letter /email interchange."
"Changes of Assessing Officer shall be notified to Lloyd’s Register in writing and relevant information on the successor, as described above submitted, for review."
"Qualified Supervisors shall have direct responsibility, for the safety, quality and technical standard of work performed by all staff under their supervision."
"Qualified Supervisors shall have the appropriate knowledge, qualifications and experience to satisfy the Authorising Officer that they are competent and suitable to supervise the scope(s) of work they are appointed to oversee (Typical evidence of this competence may be demonstrated by Qualified Supervisors holding a DNO Authorisation/Competency Certificate for a minimum of five years for the type(s) of work they supervise)."
The appointment shall reflect what areas of work the individual is to supervise.
"Where the scope of work is of a specialist nature, e.g. 66kV/132kV jointing, then trained engineer status may be accepted as an alternative to the above requirement."
In this instance the experience of the proposed qualifying supervisors shall be documented and made available to the accreditation body as evidence of the suitability of the proposed person.
"Where a scope of registration is not directly related to electrical activities, such as civil engineering works, then the qualified supervisor shall be able to demonstrate competence within their discipline equivalent to that defined above e.g. through holding a NRSWA Supervisors qualification etc."
"Staff carrying out work and / or operations in the Network Connection construction scopes shall be required to gain authorisation under the Provider’s procedures and, additionally, shall be required to gain authorisation as Competent, Authorised or Senior Authorised Person, as appropriate, against the adopting utility DSR."
"Where the Provider’s authorisation is accepted by the adopting utility, the adopting utility may wish to document their acceptance of the Person’s authorisation."
All new or returning to the industry craftspersons (cable jointers: fitters; linespersons) will be required to complete or undertake courses and tests relevant to the role and scope activities they are to undertake –ideally with such leading to an NVQ level 2 Qualification or equivalent .
"However, craftspersons that are currently appropriately trained and/or hold valid adopting utility authorisations and have evidence of relevant employment during the immediate past three years do not have to fulfil the above criteria."
Courses and associated tests for competence to perform craft skills shall be provided by an industry recognised training facility.
In all cases- before a craftsperson and or craftsperson’s mate is allowed to perform work their competence to carry out tasks associated with that work shall be assessed by the Assessing Officer and given authority by the authorising officer.
A craftsperson’s understanding of the written and spoken word should be considered with regard to the safety of the individual and others when the individual is carrying out general work or operations under this scheme.
"Operatives, working for a Provider who is registered for civil works, performing the role of Team Leader shall be considered competent, based upon an appropriate current Street Works Qualification Registration and documented competencies in risk assessment and manual handling."
An operative’s understanding of the written and spoken word should be considered in regard to the safety of the individual and others when the individual is carrying out general work or operations under this scheme.
Qualified supervisors shall be appointed for the scopes of work for which project management registration is required.
The qualified supervisor should be appropriately experienced in the scope of work or alternatively have more than 5 years’ experience performing an equivalent role in another related sector.
"In the latter circumstance, the Technical Advisor or Assessing Officer shall oversee the supervisor’s technical audit function until such times as the Technical Advisor or Assessing Officer considers the supervisor competent to perform the role unsupervised."
"Although formal qualifications are not generally required for administrative posts, measures of performance should be in place which ensure that the quality of the administration service is satisfactory and complies with the requirements specified for the work being done."
An administration system shall be in place to record and control issued certificates of competence and passports.
Paper records should be protected against risk of possible destruction.
"Records should include, training data, copy training certificates, assessment and authority details together with review dates."
Access to the records should be limited to defined staff.
"Within the context of this scheme the holders of the defined roles of Authorising Officers, Assessing Officer and Qualified Supervisor shall have been appointed in writing and shall, in the cases of Assessing Officers and Authorising Officers have been accepted in writing (except where the senior executive of the Provider is the Authorising Officer)."
The appointment of individuals to these roles should avoid introducing conflict of interest issues and should avoid undermining safety management.
For the avoidance of doubt; in the case of giving authority to the competence of an individual the Assessing Officer and Authorising Officer shall not be the same person.
The table below offers a guide to minimum training requirements for the different competency levels.
The subject area content should be tailored to be relevant to the individual designation.
Such training shall include assessments to determine that an acceptable level of understanding has been achieved.
Providers shall have documented procedures specifying the control and use of subcontract staff in respect of their accreditation.
In the case of specialist subcontractors it is not necessary to issue them with NERS passports.
"If this sub contracted work involves subcontractor individuals undertaking craftsperson and/or craftsperson mate tasks and activities then, in addition to the passport requirement, those individuals shall also possess a certificate of competence issued and signed by the subcontractors (carrying out the work) Assessing and Authorising Officers."
"The Provider subcontracting out the work should then satisfy themselves of the competence of such persons through their own procedures, and if necessary carry out their own assessments."
If the subcontractor’s accredited scopes are not relevant then sub-contractors individuals shall be subject to the competency and authority procedures of the Provider sub-contracting out the work.
"Providers shall maintain authenticated records of the ‘labour only’ contractor’s competencies and authorisations to support all competency claims, as documented in the ‘labour only’ subcontract staff NERS passports issued by the Provider."
Provider should confirm whether individual ‘labour only’ subcontractors already hold a passport that satisfies scheme requirements.
"Where they do, the Provider now employing them need not issue another passport but shall update and review the information within the passport in accordance with scheme requirements and shall, as with new passport issue, maintain records of competencies and authority’s to authenticate passport content."
In the event that calibrated tools and equipment are sourced from a hire company then the order shall be placed with a hire company on the Provider’s approved supplier list.
"Ground workers are contractors, who work directly on-site for developers and who may have a basic level of competence to excavate trenches, lay ducts and backfill."
The Accredited Provider may agree with a developer to install new infrastructure in trenches or ducts excavated and re-instated/installed by ground workers.
The operation and requirements of the 2nd Tier National Electricity Registration Scheme are described in Appendix 2 to this document.
Work undertaken shall be to the standards and specification required by the adopting utility and in accordance with the working methods described in any method statements and work instructions.
For the scopes of work undertaken Provider shall have documented method statements / work procedures detailing how the work is to be undertaken to the standards set by the adopting utility.
"Except where adopting utility Codes of Practice are used these shall provide a full description of how the work is to be undertaken, the standards to which the installation will comply, the material specification and how these criteria will be measured on site."
"Providers with Network Connection– Operational Activity scopes shall have documented operational procedures, or arrangements for working to the adopting utility’s procedures, in place."
Providers with design accreditation shall establish a documented method statement/procedure that identifies the design process from receipt of enquiry/information from the client to handover of installation information (construction pack) to the constructor.
This shall also provide for appropriate design support through the construction stage and shall be maintained and recorded.
The output from such a process shall be a plan with accompanying documentation that fully specifies the work to be constructed.
Providers with project management scopes shall ensure that the method statements of the contractors they employ deliver work to the scheme requirements.
"This may be achieved either by benchmarking against internal documentation or by documented, formal review of the contractors method statements by the Technical Advisor."
Providers with project management scopes shall also have a method statement/procedure specifying the project management role and which assigns responsibilities throughout the project life cycle from inception to adoption.
Providers shall have adequate procedures for assessing risk covering all key operations.
"These shall identify associated risks, preventative measures, procedures and processes and methods of communication."
Providers shall complete generic and/or project specific and site specific risk assessments as appropriate and these should be communicated to all relevant staff in advance of the work commencing.
Providers shall establish procedures which ensure compliance with technical specifications and requirements for notices and communication specific to the adopting utility areas in which they operate.
"For those Providers with Network Connection construction scopes, the adopting utility’s interface arrangements may also require reporting from site to the adopting utility’s control when staff arrives and when work is completed."
"Providers shall, where the adopting utility requires an adoption agreement or contract to be set- up before the work commences, ensure that such documentation is in place and completed by all the required signatories before any work is commenced."
Providers should also know how to access the sector specific requirements of those adopting utility companies who operate in areas where the Provider is not currently active.
"Documented procedures and processes should be established to control the technical elements of Tendering, Planning, and Construction elements of work carried out under this scheme."
"These shall include processes for contract variation pre and post contract letting (including delegations of authority) and, where appropriate, feedback into the design process."
Providers shall have a process in place for the issue of documented work instructions.
A process shall be in place for work scheduling which shall ensure that adequate numbers of experienced / trained staff are allocated to effectively schedule work.
Providers shall ensure that suitably trained and experienced resources are available to meet the work schedule programme and the effectiveness of the work scheduling process should be reviewed.
Where required by the adopting utility Providers shall notify the Accreditation Body of work they are scheduling.
The issue of work shall be a formal arrangement which shall include procedures for the handover of work from any design/planning functions to the construction function.
Site supervision and the supervision of operatives and sub-contractors shall be at a level to ensure compliance with safety and technical requirements.
Providers shall have documented procedures which detail how variations to the work are to be managed.
"These shall detail levels of empowerment and specify, in a format appropriate for operatives, which types of variation need to be referred back to the designer."
Providers shall have procedures for the formal handover of assets for adoption by the adopting utility.
"These procedures shall recognise staged completion and provide all the information required by the adopting utility including as-laid drawings, test certificates, Construction (Design and Management) Regulations (CDM) files and records of connected properties."
Provider shall hold or have ready access to sufficient equipment to enable the timely and satisfactory completion of works under this scheme.
"Materials, goods and services shall only be procured from suppliers / subcontractors which the Provider has approved."
The level of assessment / audit should be determined by the criticality of the supplier / sub-contractor as determined by a risk framework process.
"Providers shall establish and maintain procedures to ensure that all materials, goods and services are procured and delivered to the correct specifications/requirements of the adopting utility."
Goods receipt processes shall ensure received goods comply with purchase requisition technical specifications and that any non-conforming product is quarantined and not accepted into stock.
Providers should regularly undertake audit checks of activities which form a scheme requirement.
These include activities performed either directly by the Provider or which the Provider has delegated to others.
Providers shall have a documented audit procedure and a risk based rationale regarding the levels of audit for particular work activities.
"The review period should be shorter for newly authorised staff and/or those found to have an area of weakness (i.e. knowledge / skill) as identified from routine monitoring (supervision), site safety audits, or operational incident."
Providers with project management accreditation shall have a technical audit regime independent to that used by their contractors.
"As part of an overall risk based audit programme Providers shall carry out site based Health, Safety, Quality and Environmental Audits."
"Providers shall establish and maintain procedures for the identification, maintenance and disposal of records."
"These records should be legible, identifiable and traceable to the activities involved."
The records should be readily retrievable and protected from loss or damage.
"Providers shall have access to appropriate legislation, technical standards, and appropriate guidance documents."
All requirements of all relevant legislation shall be met.
"Providers should ensure that reference libraries, for paper copies and electronic/on-line referencing, are kept up to date and that all information is current."
Providers shall demonstrate that they have an appropriate Quality Management System which covers the requirements of their accreditation.
Through their Quality Management Systems the Provider shall demonstrate that they have a good understanding of the requirements for constructing new utility infrastructure in accordance with the scheme.
The accreditation body will take credence of any accredited quality management systems where these systems fully cover the scheme activities.
Providers shall maintain a schedule of customer complaints and make this available to the accreditation body along with all investigations and details of action taken following such complaints.
"Providers shall demonstrate appropriate Health, Safety, Quality and Environmental provision that provide clear direction for the organisation to follow."
Adequate procedures shall be in place to ensure compliance with the CDM Regulations both when the Provider has significant duty holder responsibilities under the Regulations or where the Provider is operating on a site controlled by others.
Provider operatives and sub-contractors co-operate with those holding significant duties under the Regulations.
Providers shall establish adequate procedures to ensure compliance with COSHH Regulations.
The Provider may choose to standardise on the highest standards across the areas in which they operate.
"Providers shall establish a procedure for providing routine and ad hoc H,S&E briefings to operatives."
"Records of briefings, including subject matter and attendees, should be maintained."
Providers shall have a documented procedure in place for the investigation and reporting of accidents and incidents.
"Providers with Network Connection construction scopes shall demonstrate that they have procedures for investigating and reporting accidents, incidents and system emergencies which are consistent with the requirements of adopting utility’s interface arrangements."
"Providers shall have HR procedures detailing recruitment, selection, interview and appointment criteria."
Job descriptions shall be available for all personnel where the post holder’s activities can materially affect work activities carried out under this scheme.
"As required for the accreditation scope this includes Designers, Project Managers, Technical Advisors, 1st line Managers (Supervisors), Team Leaders and Assistants etc."
Where advisors are appointed on a contract basis to support activities their role and the activities they perform should be documented and details of the terms and duration of their contract shall be provided to the Accreditation Body.
The receipt of personal supervision should be recorded in training records.
This section covers the documenting of individual training and competency records that are additional to the certificated assessment (certificate of competence) and authority that is required for persons who carry out craftsperson and/or craftsperson mate tasks and activities as defined section 1.1.
"The training and competence records of craftspersons and other operatives, shall be recorded in a document by Provider with detail of aspects of qualifications, knowledge, training, experience with, as appropriate, validity dates."
"This document, commonly known as the NERS Passport, shall be issued by the Provider employing the person and shall be reviewed and relevantly updated, annually by the Provider and will held by Provider’s staff at all times (except for when being updated)."
"All persons, issued with a passport, shall be made aware of its purpose and of the need to present it on site, when required."
The Provider’s Assessing Officer shall be responsible for managing the passport scheme including keeping the passport annually reviewed and up to date and shall signify reaffirmation of a specific competency by endorsing and dating the particular page/series of pages that relate to the competency under review.
"Where the Provider uses more than one Assessing Officer, any of those officers can be nominated and appointed to manage the passport scheme."
"However direct Assessing Officer input to the passport (i.e. sign off entry/annual update of training records and review of passport) shall be relevant to the scope(s) of work undertaken, the competence area and designation of the individual passport holder and the levels of competence the Assessing Officer is appointed to assess."
"The Provider shall be responsible for the issue of NERS passports to ‘labour only’ subcontractors, the only exemption shall be temporary unskilled labour employed on a site for 5 days or less."
Should the craftsperson or other operative gain employment with a different Service Provider then the individual would retain the passport and the responsibility for updating the passport would transfer to the new employer.
"Because craftsperson’s and operatives may already hold a NERS passport (issued by a former employer who was an accredited Provider) then, when inducting new employees/’labour only’ sub-contractors, Providers shall check if they already have a passport that satisfies them and the scheme requirements."
"If an individual already holds such a passport then the Provider need not issue a new one but shall, through their Assessing Officer, review and update information within them relevant to their new employment."
Replacement passports should only be issued where the old one has been lost or has no space for the information it must contain.
"When the passport is renewed the current employer shall be required to sign off the old passport, as would be required if a change of employment were to take place."
The old passport shall be returned to the operative / craftsperson in order that an ongoing record of employment competency is held.
Provider shall hold at least £5 million of public liability insurance covering all work under this scheme.
Insurance cover to meet contractual requirements and guarantee liabilities will vary depending upon extent of work and adopting utility involved.
Compliance with the requirements specified in this document will enable Provider to gain and maintain scheme accreditation.
This section provides guidance on how scheme accreditation operates and the actions that will be taken in the event of non-compliance with the scheme requirements.
The actual contractual terms and conditions will be those issued by the Accreditation Body when a formal quotation is sent to the Provider.
Once a Provider has been assessed as satisfactorily performing the activities for which approval is sought a certificate of accreditation will be awarded which details the scope of approved activities.
"At this stage the name of the Provider, along with the scope of works for which they are approved, will be added to the list on the accreditation body website."
"Once they achieve Full accreditation, the Provider will be able to display the quality mark associated with the scheme."
"To assist Providers preparing for assessment, especially those who are new to scheme accreditation in any utility sector, a desktop review or gap analysis is usually undertaken."
Having gained Full accreditation the work and processes of the Provider are monitored by means of regular surveillance visits.
"For Partial Accreditation the procedures, processes and documentation of the Provider are assessed for completeness and compliance with the requirements of the scheme."
"Where such procedures and documentation are already in place, their implementation will be assessed."
Subject to the outcome of this assessment Partial Accreditation may be awarded entitling the Provider to tender and obtain work which can then be used to demonstrate site activities during an assessment for Full Accreditation.
Where a Provider has yet to recruit staff at the Partial accreditation stage they shall demonstrate that their recruitment strategy will ensure that competent personnel are in place before any work is commenced.
"For the assessment Providers should ensure that the Accreditation Body’s representatives have access to those parties responsible for direct delivery of the work within the company and those who support the activity together with related processes, documentation and equipment."
"The extent of assessment will be determined by the Accreditation Body having regard to the range, scale and geographical spread of work for which accreditation is sought."
Following an assessment Providers will be given a month to provide whatever evidence is needed to close- out any identified deficiencies.
After this period the Accreditation Body will issue a report concluding the evaluation and summarising the findings.
At this stage the need for any further evaluation time to review deficiency close-out will be identified.
Partial accreditation remains valid for 1 year by which time it should be upgraded to full accreditation by means of an on-site assessment.
"Providers will be subject to a surveillance visit to establish that the required procedures, processes and competencies remain in place."
If these requirements are not demonstrated the Partial accreditation will lapse.
Providers with Partial accreditation shall inform the accreditation body as soon as any work which requires accreditation is obtained so that an assessment for Full Accreditation can be arranged.
Where the Accreditation Body identifies that a Provider with Partial Accreditation has been carrying out work without notifying the Accreditation Body their accreditation will be terminated.
When a Provider demonstrates that they meet the requirements for Partial accreditation the Accreditation Body will issue a Certificate of Partial Accreditation; such certificates will remain the property of the Accreditation Body and shall be returned to them on their request.
Major deficiencies identified at the Full evaluation stage can lead to the accreditation body terminating the Partial accreditation of the Provider.
The Full Accreditation of the Provider is dependent on the satisfactory technical assessments of activities for which accreditation are sought.
To achieve Full Accreditation for any particular element of the requested scope then those elements shall be carried out by the Provider (or managed by the Provider if appropriate to the Provider’s scope) and witnessed and assessed by the accreditation body.
"In order to progress from Partial Accreditation to Full Accreditation, Providers shall make each activity available for assessment at the first possible opportunity."
Where work covering the full range of the scope requested is not witnessed the Accreditation Body will restrict any accreditation to the scope of work reviewed.
"Award of Full Accreditation requires that procedures and processes assessed for Partial Accreditation, but previously untried, are fully implemented and are operating effectively."
"Providers shall also demonstrate a full understanding of the specific adopting utility requirements, specification details and contact arrangements."
"The Providers shall be fully prepared for the assessment by the Accreditation Body’s representative, and shall ensure the availability of appropriate personnel, documentation and site activities."
Facilities and access to sites shall be arranged by the Provider in order that the Accreditation Body can witness all appropriate work activities.
Subject to satisfactory performance throughout the accreditation process Full Accreditation will remain valid for 3 years after which time a reassessment will be carried out.
"Following completion of the assessment, and on acceptance of the ongoing surveillance program, the Accreditation Body will issue an Accreditation Certificate which will be valid for the term of the accreditation."
The certificate will remain the property of the Accreditation Body and shall be returned to them on their request.
Providers will receive a quotation in the form of a Request for Services (RFS) for scopes applied for.
"This RFS must be agreed, and signed, by the Provider, prior to the assessment process commencing."
"Following completion of the appropriate evaluation stage, Providers will be invoiced accordingly and shall be required to pay such charges promptly in accordance with the requirements as outlined in the Terms and Conditions in the RFS."
"Where any payments become overdue, the Accreditation Body will be unable to commit to further services."
"Dependent on status the Provider may, in some cases, be required to pre-pay all or a portion of the agreed RFS before the evaluation commences."
Having gained accreditation the work and adherence to process of Providers will be monitored through routine surveillance visits.
The accreditation body will also respond to any reports of non-compliance.
Surveillance visits and any extra visits needed to investigate substantiated reports of non-compliance will be chargeable to the Provider.
"The Accreditation Body shall verify through surveillance visits and periodic reassessment that the Provider has established, implemented and maintained procedures processes and competencies which provide for a consistent quality of the delivered product/service and which conform both in terms of quality and safety to industry good practice."
Individual competence is achieved and maintained to levels defined in Section 4.
Appropriate equipment is safely operated by trained and competent operatives.
Interfaces with all stakeholders (especially developers and adopting utility companies) are managed in accordance with the scheme requirements.
"For those Providers with Network Connection construction scopes, the Accreditation Body shall endeavor to carry out unannounced surveillance visits as part of the surveillance programme, where this is practical taking into consideration the type of work being undertaken, the project duration, the notice requirements of the adopting utility’s interface arrangements and the liaison arrangements in place between the Accreditation Body and the adopting utility."
Each approved activity scope and the Provider’s management system shall be subject to surveillance audit at least once during the three year accreditation period with the first surveillance visit held within a 6 months (maximum) of accreditation being awarded.
"The surveillance programme is subject to a minimum of 6 visits throughout the accreditation period for construction activities, project management and/or control and management of constructions activities."
In the case of Providers who only hold design scopes that minimum is 4 visits.
The number of visits will increase above the minimum dependent on the number and type of scopes held.
"The Accreditation Body may, at its discretion and subject to reasonable notice, vary the interval between surveillance visits, based upon the results of Provider/Adopting Utility/Accreditation Body audits."
Findings of Surveillance visits shall be documented and any deficiencies recorded shall be highlighted to the Provider.
Appropriate timescale for the close out of deficiencies should be agreed.
"For those Providers with Network Connection construction scopes- if any major deficiencies are identified whilst the work is being undertaken then the Accreditation Body will report the matter, immediately, to the adopting utility and Provider."
The Provider’s Network Connections scope accreditation may be suspended depending on the circumstances and may be subject to investigation.
"If the Provider’s staff are not in the location notified to the adopting utility the Accreditation Body may, in the absence of a reasonable explanation, suspend the Provider’s accreditation."
The Accreditation Body may also charge for an aborted visit if the surveillance visit has to be re-scheduled.
Arrangements for routine surveillance visits will be agreed between the accreditation body and the Provider in accordance with the surveillance schedule specified at the time of accreditation.
This arrangement will take account of the number of scopes of accreditation and subject to A.1.3.5 the scopes of work they are in.
"Should the volume of the Provider’s work, or scope of the Provider accreditation, change during the accreditation period then the surveillance visit programme shall be revised accordingly."
Where concerns about the compliance of a Provider are made to the accreditation body by adopting utilities or others additional investigation surveillance visits will be immediately arranged.
If the non- compliance issue investigated is confirmed the Provider will be required to cover the cost of the investigation.
The accreditation body will routinely advise Provider of the surveillance visit schedule (covering site and office activities).
Providers shall arrange with the Accreditation Body for surveillance visits to be undertaken no later than a month after the month specified in the schedule.
In order that work activities can be assessed Providers shall make reasonable provision for contestable work to be available for surveillance.
Where it is necessary to change pre-arranged visits Providers should give a minimum of 5 working days’ notice to the accreditation body.
Where a surveillance visit is cancelled within the notice period an abortive visit charge based on the charge for a surveillance visit will be made.
Where the planned activities are not being carried out at the time of the visit the Accreditation Body will make a charge for a further visit to assess the activities.
At least annually whilst undertaking surveillance visits the Accreditation Body expects to meet with the appointed assessing officer (relevant to the scope of work under surveillance) to ensure that they are taking active responsibility for the duties which are assigned to their roles.
During the accreditation period the Accreditation Body expects to see all the accredited scopes being demonstrated.
"Where scopes of work may be infrequently carried out by the Provider, the Accreditation Body may, taking into account the general compliance of the Provider relax the frequency they expect to view such work."
This arrangement will take account of the types of work the Provider normally focuses on and their surveillance programme and will only be allowed when the Provider agrees to notify the Accreditation Body every time work on the ‘infrequently’ performed scope(s) is being done.
Categories of work carried out infrequently may include the overhead line and higher voltage scopes (e.g.
Other than for scopes of work which are done infrequently (see Section A1.3.3) in the event that the Provider’s programme of work does not incorporate any work meeting the requirements for a surveillance visit for a period which extends beyond one month of the surveillance visit due date then the accreditation status of the Provider shall be downgraded to Partial.
"Under these circumstances the surveillance visit programme shall be suspended and annual (on the anniversary of the last surveillance visit) visits arranged to ensure that competency and procedures/processes, against which the initial accreditation was awarded, are maintained."
As required for all holders of partial accreditation Providers who have had their accreditation status downgraded must notify the Accreditation Body of their intention to start any work relating to their accreditation so that a surveillance visit can be arranged.
"Subject to the surveillance visit confirming that work is being done in accordance with the scheme requirements, and that the required procedures and processes are in place, then full accreditation shall be reinstated and a programme of surveillance visits re- established."
If a Provider considers that their ongoing workload is less than that used to determine the surveillance visit programme they should notify the Accreditation Body and ask for the programme to be re-assessed.
"However, as a minimum, to retain full accreditation Provider shall maintain their surveillance programme presenting each scope (unless infrequently carried out- see a.1.3.3) of their fully accredited activities and relevant management system for surveillance audit over the accreditation period."
Providers will be charged for surveillance visits carried out in accordance with the agreed programme or any which are subsequently arranged to close-out major deficiencies or the suspension/removal of accreditation.
Where any payments to the Accreditation Body become overdue the Accreditation Body is unable to commit to doing further visits.
Is found to have made false claims within the application for accreditation which are considered to impact on the integrity of the Provider.
Fails to complete within the agreed timescales and to the satisfaction of the accreditation body required remedial action(s) identified during routine surveillance or any other investigation.
Implementation of corrective action is subsequently found to have been inadequate to prevent a reoccurrence at any location of recently identified deficiencies.
Is found to continually fail to maintain safe systems of working and has working practices which result in the workforce or members of the public being exposed to danger or serious risk of injury through the use of faulty workmanship/working practice and faulty materials or materials not conforming to recognised standards.
Claims to have been approved for work not included at the time in the scope of their approval.
Commits a breach of any of the obligations imposed by the adopting utility.
Fails to incorporate into their procedures and working practices any changes made to the scheme by the Scheme Advisory Panel within an agreed time period.
Notifies the accreditation body that they no longer wish to be accredited for scopes of work.
"Where the accreditation body is notified that unsatisfactory work or non-compliance with the scheme requirements has occurred and the matter is disputed by the Provider, the accreditation body shall carry out an investigation."
Under certain circumstances an interested party or Provider may wish to escalate an issue to the accreditation body for further investigation.
The Provider and/or interested party shall also provide all relevant documentation relating to the work and shall ensure that the qualified supervisor responsible for the work is available.
"Where the investigation is to be carried out following a complaint made by the adopting network operator or other party, the Provider shall allow the complainant to be represented during the investigation."
"Where the investigation is to be carried out following a complaint made by the Provider, the interested party shall allow the complainant to be represented during the investigation."
"Where, as a result of inspections, the work is shown to not to comply with the scheme requirements the Provider shall, at its own expense, take the required remedial action to remedy the work with the timescale specified by the accreditation body."
The process and timescales for investigations is shown at the end of this section.
"The accreditation body shall notify the Provider in writing of the intention to cancel certification, fully detailing such reasons for its action."
"Normally, unless the nature of the non-conformance merits immediate action or is a reoccurrence of a recently closed deficiency, this will be in 2 stages."
Firstly the Provider will be notified that their accreditation is being suspended and given a limited time to address the non-conformances giving rise to the suspension.
If the non-conformances are not satisfactorily addressed during the allotted time period and steps are not taken to prevent a reoccurrence the accreditation will be cancelled.
Once accreditation has been cancelled then re-accreditation will be subject to a full re-assessment of the Provider.
"If the Provider wishes to object to action taken, including withdrawal of accreditation, by the accreditation body they shall, within twenty-one days of the issue of the notification to them, give notice in writing to the accreditation body of their objections setting out clearly the grounds for an appeal."
"Any such appeal will be assessed by a panel within the accreditation body, independent of those members of the Accreditation Body associated with the original withdrawal action."
"The results of the review will be communicated to the Provider in writing, detailing clearly the basis for the decision."
If the decision is not to the satisfaction of the Provider then they can appeal to the Scheme Advisory Panel which will be furnished with the basis for the original accreditation withdrawal and the findings of the appeals review.
The Scheme Advisory Panel shall be the final arbiter of all such appeals.
"The Provider and accreditation body shall bear their own costs associated with any appeal, regardless of the outcome."
"Re-instatement of accreditation will be effected under the conditions prescribed by the accreditation body’s review or that of the Scheme Advisory Panel, should the finding be that the accreditation withdrawal was not warranted."
"Alternatively, if the appeals process finds the accreditation withdrawal to be the correct course of action then re-instatement of the Provider would entail a full re-evaluation."
At the end of the 3 year full accreditation period a reassessment covering all required scopes of accreditation shall be undertaken.
The scale of this reassessment will take account of the performance of the Provider during the period of accreditation.
If the Provider has performed satisfactorily over the accreditation period their accreditation is likely to be reviewed with minimum examination.
"However if the work carried out by the Provider is limited, or if a number of audit reports identify major deficiencies or a growing trend of minor deficiencies, an appropriately more in depth level of re-assessment will be required."
The extent of the renewal assessment will take account of recently witnessed work with any scopes not seen during the previous 12 month period required to be seen during the re-assessment process.
"Where this cannot be arranged the level of accreditation, subject to satisfactory verification of procedures and processes, will reduce to ‘Partial’."
"However, where one of the scopes being re-assessed covers work that may be infrequently carried out (see Section A.1.3.3) then, provided the Provider has agreed this with the accreditation body and has notified all instances of the work being done, the accreditation body will take account of surveillance visits over the 3 year certification period."
In such the accreditation body may re- certify at the ‘Full’ level without witnessing work being done.
The Accreditation Body shall give each Provider 3 months’ notice of the expiry of their accreditation.
"If the Provider does not put in place adequate accreditation renewal arrangements, or allow adequate time for the required renewal assessment to take place, the accreditation will be terminated."
The reaccreditation assessment will take account of scopes viewed over the preceding 12 months and also consider whether any infrequently performed scopes have been satisfactorily demonstrated during the accreditation period.
"Where scopes are not witnessed during the re-accreditation, or there is not adequate evidence to support the award of ‘Full’ accreditation, these scopes may only be awarded ‘Partial’ status."
After this period of time the Accreditation Body will issue a report concluding the accreditation.
Having being satisfactorily reassessed and a surveillance programme agreed the Provider will be accredited for a further 3 years.
It should be d that adopting utility companies have the right to insist on defective work being corrected and the right to refuse to adopt infrastructure if it is not fit for purpose even though the work may have been carried out by an accredited Provider.
"The accreditation body will notify all adopting utility companies when action is taken to amend, suspend or terminate the accreditation of a Provider."
Other information on accreditation status will be shown on the scheme specific website maintained by the accreditation body.
On gaining accreditation Providers will be issued with the NERS Scheme Registration Mark (which incorporates the LR Approval Mark).
"Guidance on the use of this Mark will be provided when it is issued and the Mark shall only be used in the as issued configuration and can be displayed by accredited Provider on their stationery, publicity material, company buildings, flags, vehicles, and so on."
Correct use of a NERS Mark is a contractual obligation and a NERS accreditation certificate can be withdrawn if a Provider misuses a NERS Scheme Mark and continues to do this after attention has been drawn to the misuse.
"Also, if NERS accreditation is withdrawn from a Provider they must stop using the NERS Scheme Mark and, where necessary, withdraw any material carrying the Mark."
The 2nd tier scheme is restricted in relation to the scopes that are available and is for civil contractors who wish to hold an accreditation but with limited responsibilities.
These limited but clearly defined bounds of responsibility in relation to the restricted scopes of work are detailed in this Appendix.
Providers holding 2nd Tier accreditation shall not be able to compete for contestable work in their own right and can only operate as a sub-contractor to a NERS accredited Provider.
Assessment for accreditation under the 2nd tier scheme only covers those areas relevant to the work being undertaken and takes into consideration the supervisory responsibilities of the NERS accredited Provider.
"An induction process which should ensure that all staff undergo training in electrical safety awareness, manual handling, COSHH, drawing appreciation, risk assessment and company procedures."
"A training database showing qualifications, competencies etc."
"Training files holding copies of qualifications, cards etc."
Issue their staff with appropriate work instructions unless a work instruction has been issued by the accredited Provider that clearly outlines the location and extent of work to be undertaken.
Issue generic risk assessments and method statements to all gangs.
Document the H&S responsibilities of all staff and ensure that all staff are familiar with these.
Make available appropriate COSHH and manual handling assessment.
Have an audit procedure that covers both H&S and quality issues.
This scope of accreditation does not allow Providers to procure cable or ducting.
These shall be supplied by the NERS accredited Provider.
However Providers may purchase and provide storage for sand and other backfill material.
"Providers shall have a procedure in place to ensure that all tools, equipment, lifting tackle etc is tested / calibrated as required."
Providers shall be required to operate a safety management system covering the civil activities undertaken.
"Appointment of Authorising and Assessing Officers, and Qualified Supervisors."
An output from the safety management system will be a Passport issued to the Operative (see section 13 Passport and Ongoing competence Records for details on Passport requirements and content etc).
The operative will need to have his ongoing competency reaffirmed on an annual basis by the Assessing Officer and his Passport updated.
The assessing body will visit a site to assess the Provider competence in carrying out the works.
The project management scope is for Providers who do not themselves carry out construction activities but who manage this work by subcontracting such activities to Providers with the required construction accreditation.
"The scopes are also available, and can apply, to Providers holding construction scope(s) but who wish to subcontract out activities, in other construction scopes that they don’t have the accreditation for, to other appropriately accredited Providers."
Many different types of project management company exist; ranging from those who simply introduce constructors to the client (developer or whoever) to those who have a detailed involvement in controlling construction activities.
Nevertheless there are minimum requirements expected of Providers with project management accreditation which need to be established and maintained throughout the accreditation period.
Whilst these are detailed throughout the main body of the scheme requirements this summary provides an overview of the project management scope requirements to aid companies in preparing for accreditation assessments and ongoing surveillance visits.
There is not normally a requirement for Providers who simply introduce contractors to the client and where the construction Provider does the entire liaison with the host utility and the on-site liaison with the client to be accredited as project managers.
Provider with the required construction accreditation rather than doing the work under their direct supervision) they must demonstrate compliance with the project management scope requirements.
"Although they employ an accredited Provider to undertake construction work, project management Providers need to get involved in many technical aspects of new infrastructure delivery."
Hence they need to be able to demonstrate utility sector specific technical understanding and competence alongside their project management capability.
Providers shall have in place a documented procedure for assessing the competence of individuals who are to carry out such work and for giving authority to those individuals to carry it out.
"Scheme Requirements) and, additionally, where work is associated with craftsperson activities as defined in section 1.1 of Scheme Requirements - a certificate of competence signed by the assessing and authorising officer."
"The Assessing Officer shall keep records of tests including, in the case of oral tests, oral responses given."
"An assessment file should be compiled for each candidate providing background supporting evidence towards the competence required (i.e. previous authorities held, employment history, training details, experience and skills tests undertaken)."
The Assessing Officer may accept documented assessments of practical skills tests provided they are/were undertaken by a recognised training institution/facility.
"For giving authority to an individual’s assessment of competence the Authorising Officer shall be provided the candidate’s assessment file, which shall include recommendation for the areas of work to be given authority."
"The Authorisation Officer must be satisfied that the candidate has the necessary skills and ability to work safely on, or near, the existing or proposed electrical networks and that the extent and limitation of the authority being given is unequivocal."
An auditable trail of the assessment process shall be maintained which when successful shall result in an entry in the craftsperson’s/operative’s passport to provide for ready site based evidence.
Certificates of competence shall be required for craftsperson* individuals (as defined below and in in section 1.1 of Scheme Requirements) –and are an additional requirement to passports for these roles.
There is no requirement for the issue of certificates of competence for civil and cable laying activities – however passports are also required for these roles.
The certificate shall be issued following an assessment of competence conducted by the Provider’s Assessing Officer.
"That assessment, if satisfactory, shall be given authority by the Provider’s Authorising Officer."
The certificate shall be duly signed and dated by the Provider’s Assessing and Authorising Officers.
The certificate shall include a declaration requiring signature that the holder understands and accepts the responsibilities associated with the duties detailed on it and is aware that a separate authority may be required where/before work is to be carried out on a 3rd party owned network.
"Has been assessed as competent in having sufficient practical and/or technical knowledge and/or experience to enable the avoidance of danger personally and/or to others, and has also been assessed as being competent to carry out the following craftsperson tasks on electrical plant or equipment."
"I am aware that a separate written authority will, or may, be required where and before work is carried out on a 3rd party owned site, system or network (this includes Distribution Network Operator and/or Independent Distribution Network I also understand that the authority indicated on the certificate, and any other authority associated with it, is only valid whilst I am employed on actual contract(s) operated by the company."
As the holder of this authority I understand and accept my responsibilities associated with the duties detailed above.
A procedure shall be in place for selecting and training individuals who the Provider feel may be able to undertake tasks associated with the installation/construction of electrical plant or equipment.
Ensure the scope and level of training is dependent on the level of competence to be given authority and the procedure shall lay out the minimum requirement.
Ensure candidates have their competency assessed in a structured way against a set of agreed criteria and trade skills.
"Ensure that where training under personal supervision is undertaken the minimum requirements in terms of duration, level of responsibility and limit of work activities are clearly defined."
The person providing the personal supervision shall have the necessary experience and be given authority in writing to undertake these duties.
"Ensure selection, training and assessment process is documented and records maintained for all individuals even if they are unsuccessful."
"Indicate responsibilities for identifying refresher training and initiating training when any changes in type of work, take place."
"Ensure that before an existing assessment of competence is considered for annual renewal and thus allowed ongoing authority, a check is made that during the review period, work has been undertaken across the competence scope(s) originally given."
"Include process and action where review finds that certain elements of work, across the competence scopes, have not been undertaken within the review period."
Under such circumstances it may be decided that it is necessary for the jointer to perform such a joint under supervision to retain or regain that element of competence).
Partial Accreditation is the first stage of accreditation.
"It demonstrates that a Provider has the required systems, processes and procedures in place to meet the NERS requirements."
Providers with partial accreditation can tender and obtain work for the scopes they hold.
Full Accreditation is granted to Providers who have successfully demonstrated that they have adequately met the schemes requirements with respect to the construction of adoptable assets.
In the case of Design Scopes the Provider has successfully demonstrated that their processes meet both the scheme and adopting company’s requirements.
If a Provider’s has Project Management for a construction scope PM will appear after the voltage in the scope description i.e. Jointing (HV-PM).
"Any restrictions, anomalies or additions associated with particular scopes are added to individual Provider s."
To access LR web-site s click on Show contact Details in the Provider box concerned.
Granted when the first site works have been witnessed successfully.
The primary NERS Provider does not need to hold Design Accreditation.
"They are allowed to sub-contract the design to, or use a design supplied by, a NERS Provider with the design scopes relevant to the works."
"Management or Construction category, to another NERS Provider with the relevant scope."
It is also applicable to NERS Providers who hold at least one construction scope and wish to sub-contract out work covered by other scopes that they do not have.
In this situation they must utilise an appropriately accredited NERS Providers.
Project Management scopes are not awarded for Design.
These companies are known as Second Tier Providers.
Live jointing only allows jointing onto the main installed by the NERS Provider.
Live LV jointing covers un-metered on a hierarchal basis.
"Applicable to connection work on underground, un-metered single phase, 230v services with loadings of 500 W or less."
"The permanent or temporary transfer, disconnection or extension of a service to a point of supply."
"Installation of a new service to such a point of supply, excluding joint onto an existing main."
"Network Connections – Jointing (LV Mains and Services, LV Terminations) To include: Jointing- LV Mains & Services and Jointing – LV Terminations LV Pole, link box, LV board and LV Pillar terminations will appear, as relevant, in the Provider’s s."
"Providers holding Live LV jointing do not automatically hold Networks Connections scopes which are separate entities from Live LV Jointing and which requires a separate, additional evaluation and accreditation."
Jointing LV Live is a pre-requisite for a NERS Provider wishing to obtain this scope.
The LV Terminations scope includes live and dead jointing.
This scope covers: - Jointing HV mains and Jointing HV Terminations (HV pole & HV switchgear terminations).
Cable jointing (live or dead) of single phase un-metered services to existing mains.
"The definitions are taken from the ENA Model Distribution Safety Rules in which Conductors are used, or supported, or of which they form part."
Apparatus are electrically connected to a common source of supply the operational scopes are still under development.
Substation Installation (voltage as relevant up to and including 132kV) Scope includes responsibility for all elements of substation installation.
Any restrictions however will appear in relevant Provider s.
Includes overseeing specialist civil contractors who are not NERS accredited.
"Jointing Scope at the appropriate voltage, the erection of the termination and associated steelwork, insulators, surge arrestors, jumpers etc."
Self Determination of Point of Connection (POC) (voltage as relevant up to and DNOs may operate pilot trials for this work which is limited to specific voltages or defined capacities.
Electrical Design of Distribution Networks covering (LV Cable Networks to This also covers the domestic properties on a hierarchal basis.
Lloyd’s Register and Lloyd’s Register EMEA are trading names of Lloyd’s Register Group Limited and its subsidiaries.
This section gives a scope description and overview of everything included in this SRS document.
"Also, the purpose for this document is described and a list of abbreviations and definitions is provided."
The purpose of this document is to give a detailed description of the requirements for the “Amazing Lunch Indicator” (ALI) software.
It will illustrate the purpose and complete declaration for the development of system.
"It will also explain system constraints, interface and interactions with other external applications."
This document is primarily intended to be proposed to a customer for its approval and a reference for developing the first version of the system for the development team.
"The “Amazing Lunch Indicator” is a GPS-based mobile application which helps people to find the closest restaurants based on the user’s current position and other specification like price, restaurant type, dish and more."
The application should be free to download from either a mobile phone application store or similar services.
Restaurant owners can provide their restaurant information using the web-portal.
This information will act as the bases for the search results displayed to the user.
An administrator also uses the web-portal in order to administer the system and keep the information accurate.
"The administrator can, for instance, verify restaurant owners and manage user information."
"Furthermore, the software needs both Internet and GPS connection to fetch and display results."
"All system information is maintained in a database, which is located on a web-server."
The software also interacts with the GPS-Navigator software which is required to be an already installed application on the user’s mobile phone.
"By using the GPS-Navigator, users can view desired restaurants on a map and be navigated to them."
The application also has the capability of representing both summary and detailed information about the restaurants.
Any person who has interaction with the system who is not a developer.
"Practice for Software Requirements Specifications”, October 20, 1998."
"Marketing”, New York, Dorset House Publishing, 2005."
The remainder of this document includes three chapters and appendixes.
The second one provides an overview of the system functionality and system interaction with other systems.
This chapter also introduces different types of stakeholders and their interaction with the system.
"Further, the chapter also mentions the system constraints and assumptions about the product."
The third chapter provides the requirements specification in detailed terms and a description of the different system interfaces.
Different specification techniques are used in order to specify the requirements more precisely for different audiences.
The fourth chapter deals with the prioritization of the requirements.
It includes a motivation for the chosen prioritization methods and discusses why other alternatives were not chosen.
The Appendixes in the end of the document include the all results of the requirement prioritization and a release plan based on them.
This section will give an overview of the whole system.
The system will be explained in its context to show how the system interacts with other systems and introduce the basic functionality of it.
It will also describe what type of stakeholders that will use the system and what functionality is available for each type.
"At last, the constraints and assumptions for the system will be presented."
This system will consist of two parts: one mobile application and one web portal.
The mobile application will be used to find restaurants and view information about them while the web portal will be used for system as a whole.
The GPS will provide the for the user to be able to use the functions in the application in a seamlessly manner.
"Both the the database, however in slightly different ways."
The mobile application will only use the database to get data while the database communication will go over the Internet.
To avoid problems with overloading the operating system the application is only allowed to use 20 megabytes of memory while running the application.
The maximum amount of hard drive space is also 20 megabytes.
"With the mobile application, the users will be able to search for restaurants."
The result will be based on the criteria the user inputs.
There are several search criteria and it will be possible for the administrator of the system to manage the options for those criteria that have that.
"The result of the search will be viewed either in a list view or in a map view, depending on what criteria included in the search."
The list view will have one list item for each restaurant matching the search criteria and show a small part of the restaurant information so the user can identify the restaurant.
"In both views the users will be able to either select a restaurant as target destination or get information how to get there, or view the information of a specific restaurant."
The web portal will provide functionality to manage the system and the restaurant information.
"It will also provide information about the system, for example show when there is a new update."
"There are three types of users that interact with the system: users of the mobile application, restaurant owners and administrators."
Each of these three types of users has different use of the system so each of them has their own requirements.
The mobile application users can only use the application to find a restaurant.
"This means that the user have to be able to search for restaurants, choose a restaurant from that search and then navigate to it."
In order for the users to get a relevant search result there are multiple criteria the users can specify and all results matches all of those.
The restaurant owners will not use the mobile application but the web portal instead.
"There they will manage the information about their restaurant, for example a description of the restaurant, contact information and their menu."
The administrators also only interact with the web portal.
They are managing the overall system so there is no incorrect information within it.
The administrator can manage the information for each restaurant as well as the options for both the mobile application users and the restaurant owners.
The mobile application is constrained by the system interface to the GPS navigation system within the mobile phone.
"Since there are multiple system and multiple GPS manufacturers, the interface will most likely not be the same for every one of them."
"Also, there may be a difference between what navigation features each of them provide."
The Internet connection is also a constraint for the application.
"Since the application fetches data from the database over the Internet, it is crucial that there is an Internet connection for the application to function."
Both the web portal and the mobile application will be constrained by the capacity of the database.
Since the database is shared between both application it may be forced to queue incoming requests and therefor increase the time it takes to fetch data.
One assumption about the product is that it will always be used on mobile phones that have enough performance.
"If the phone does not have enough hardware resources available for the application, for example the users might have allocated them with other applications, there may be scenarios where the application does not work as intended or even at all."
Another assumption is that the GPS components in all phones work in the same way.
"In the case that the project is delayed, there are some requirements that could be transferred to the next version of the application."
"Those requirements are to be developed in the third release, see Appendix IV."
This section contains all of the functional and quality requirements of the system.
It gives a detailed description of the system and all its features.
This section provides a detailed description of all inputs into and outputs from the system.
"It also gives a description of the hardware, software and communication interfaces and provides basic prototypes of the user interface."
"A first-time user of the mobile application should see the log-in page when he/she opens the application, see Figure 2."
"If the user has not registered, he/she should be able to do that on the log-in page."
"If the user is not a first-time user, he/she should be able to see the search page directly when the application is opened, see Figure 3."
Here the user chooses the type of search he/she wants to conduct.
"Every user should have a profile page where they can edit their e-mail address, phone number and password, see Figure 4."
"Also, the user can set the mobile application to his/her preferred language."
The “P” icon shows where the user can click to navigate to his/her profile page.
"In Figure 5, the list view for the results is shown."
"When a user searches by price, this view should be the default one."
"The sorting header allows the user to sort the results according to price, restaurant name, distance, restaurant type and specific dish."
"Each result item includes information about the restaurants, a link to the restaurant’s web-page and an information link, which provides a more detailed description of the restaurant."
"There is also a filtering option, where the user can choose to filter the results by increasing or decreasing the price or distance range, see Figure 7."
"In the map view each restaurant is represented by a pin, see Figure 6."
"Next to every pin there is an information link which provides a more detailed description of the restaurant, as mentioned for the list view."
"The same filtering option, as for the list view, is included in the map view."
"The restaurant owners and administrators interact with the system through a web-portal, see Figure 8."
A restaurant owner should be able to register on the web-portal in order to log in and manage the restaurant information.
An administrator should also be able to log in to the web-portal where he/she can administer the system by for instance editing restaurant or user information.
"Since neither the mobile application nor the web portal have any designated hardware, it does not have any direct hardware interfaces."
The physical GPS is managed by the GPS application in the mobile phone and the hardware connection to the database server is managed by the underlying operating system on the mobile phone and the web server.
"The communication between the database and the web portal consists of operation concerning both reading and modifying the data, while the communication between the database and the mobile application consists of only reading operations."
The communication between the different parts of the system is important since they depend on each other.
"However, in what way the communication is achieved is not important for the system and is therefore handled by the underlying operating systems for both the mobile application and the web portal."
This section includes the requirements that specify all the fundamental actions of the software system.
DESC: A user should be able to download the mobile application through either an application store or similar service on the mobile phone.
RAT: In order for a user to download the mobile application.
"DESC: When a new/updated version or release of the software is released, the user should check for these manually."
The download of the new release should be done through the mobile phone in the same way as downloading the mobile application.
RAT: In order for a user to download a new/updated release.
"DESC: Given that a user has downloaded the mobile application, then the user should be able to register through the mobile application."
"The user must provide user-name, password and e-mail address."
The user can choose to provide a regularly used phone number.
RAT: In order for a user to register on the mobile application.
"DESC: Given that a user has registered, then the user should be able to log in to the mobile application."
The log-in information will be stored on the phone and in the future the user should be logged in automatically.
"DESC: Given that a user has registered, then the user should be able to retrieve his/her password by e- mail."
RAT: In order for a user to retrieve his/her password.
"DESC: Given that a user is logged in to the mobile application, then the first page that is shown should be the search page."
"The user should be able to search for a restaurant, according to several search options."
"The search options are Price, Destination, Restaurant type and Specific dish."
A user should be able to select multiple search options in one search.
RAT: In order for a user to search for a restaurant.
A specific pin will represent a specific restaurant location.
Each element in the list represents a specific restaurant.
"Each element should include the restaurant name, telephone number, type of food, distance according to the user’s position, average price, a short two-line description, a link to the restaurant’s web-page and an information link."
The list view should include a header with different selectable sorting options.
DESC: A user should be able to select a pin on a map or an element on a list.
"When a selection is made, the location of the restaurant should be sent to the mobile phone’s GPS-navigation program."
The user should then be navigated to the destination.
"When the destination is reached, a user should be able to go back to the search page on the mobile application."
DESC: A user should be able to switch between a map view and a list view for all search options.
RAT: In order for a user to switch between result views.
"DESC: A user should be able to select the information link, which is included on all result items."
"The link will direct the user to an information page, which includes a picture of the restaurant, the restaurant name, address, phone number, e-mail address, type of food, average price, restaurant description and a menu with name, description and price of the different dishes."
RAT: In order to show information about the restaurants.
DESC: A user should be able to input a maximum and a minimum price range.
"DESC: A user should be able to input a maximum and a minimum distance, according to his/her position."
By default the minimum distance is set to 0 km and the maximum to 10 km.
The user should be able to input a higher or lower maximum distance and a higher minimum distance than set by default.
DESC: Integers should be accepted as input when a user searches by price or destination.
If the system receives an invalid input the user should be informed and prompted to insert an accepted input.
RAT: In order for a user to search with valid input.
DESC: A user should be able to select a restaurant type in a given list as input.
RAT: In order for a user to search by restaurant type.
DESC: A user should be able to select a specific dish in a given list as input.
RAT: In order for a user to search by specific dish.
"DESC: A user should be able to conduct a search by providing either restaurant name, restaurant description, restaurant address, restaurant type or restaurant menu in the free-text search field."
RAT: In order for a user to search through the free-text search.
DESC: If no match is found the user should be informed but kept on the search page in order to get the possibility to conduct a new search right away.
RAT: In order for user to conduct a new search if no match is found.
"DESC: When viewing the results in a list, a user should be able to sort the results according to price, distance, restaurant type, specific dish or restaurant name."
When sorting by price the results should be ordered from cheapest to most expensive.
"When the sort button for a specific search option is clicked, then the order should be reversed and ordered in a descending matter."
If the sort button is clicked again the order of the results should be reversed.
RAT: In order for a user to sort results in a list.
"When filtering the results, only the existing results shall be affected and a new search query should not be sent."
RAT: In order for a user to filter results in a list or a map.
"DESC: On the mobile application, a user should have a profile page."
"On the profile page a user can edit his/her information, which includes the password, e-mail address and phone number."
A user should also be able to choose what language the mobile application should be set to.
"The different language choices are Swedish, English, Spanish and French."
RAT: In order for a user to have a profile page on the mobile application.
The requirements in this section provide a detailed specification of the user interaction with the software and measurements placed on the system performance.
The search feature should be prominent and easy to find for the user.
RAT: In order to for a user to find the search feature easily.
"The different search options should be evident, simple and easy to understand."
RAT: In order to for a user to perform a search easily.
The results displayed in the list view should be user friendly and easy to understand.
Selecting an element in the result list should only take one click.
RAT: In order to for a user to use the list view easily.
The results displayed in the map view should be user friendly and easy to understand.
Selecting a pin on the map should only take one click.
RAT: In order to for a user to use the map view easily.
The information link should be prominent and it should be evident that it is a usable link.
Selecting the information link should only take one click.
RAT: In order to for a user to use the information link easily.
METER: Measurements obtained from 1000 searches during testing.
"SCALE: If the system loses the connection to the Internet or to the GPS device or the system gets some strange input, the user should be informed."
METER: Measurements obtained from 1000 hours of usage during testing.
This section includes the design constraints on the software caused by the hardware.
The amount of Operate System memory occupied by the application.
METER: Observations done from the performance log during testing MUST: No more than 20 MB.
The mobile Operate System which the application is running on.
"The requirements in this section specify the required reliability, availability, security and maintainability of the software system."
The reliability that the system gives the right result on a search.
The average system availability (not considering network failing).
The application should be connected to the Internet.
RAT: In order for the application to communicate with the database.
The application should be connected to the GPS device.
"RAT: In order for the application to get the users location, the map and to calculate the distance."
GIST: Security of the communication between the system and server.
"The messages should be encrypted for log-in communications, so others cannot get user-name and password from those messages."
METER: Attempts to get user-name and password through obtained messages on 1000 log-in session during testing.
MUST: 100% of the Communication Messages in the communication of a log-in session should be encrypted.
Communication Messages: Defined: Every exchanged of information between client and server.
SCALE: If a restaurant owner tries to log in to the web portal with a non-existing account then the restaurant owner should not be logged in.
The restaurant owner should be notified about log-in failure.
METER: 1000 attempts to log-in with a non-existing user account during testing.
SCALE: If an admin tries to log in to the web portal with a non-existing account then the admin should not be logged in.
SCALE: A restaurant owner and IP address should not be able to log-in for a certain time period after three times of failed log-in attempts.
METER: 1000 attempts to log-in during the lock period after user account has been locked because of failed log-in attempts of three times.
"The locking period should be half an hour, and during that period the log-in function is disabled."
SCALE: An admin and IP address should not be able to log-in to the web portal for a certain time period after three times of failed log-in attempts.
The security of creating account for users of the system.
"SCALE: If a user wants to create an account and the desired user name is occupied, the user should be asked to choose a different user name."
METER: Measurements obtained on 1000 hours of usage during testing.
The security of creating account for restaurant owners of the system.
"SCALE: If a restaurant owner wants to create an account and the desired user name is occupied, the restaurant owner should be asked to choose a different user name."
The code should be written in a way that it favors implementation of new functions.
RAT: In order for future functions to be implemented easily to the application.
DESC: Test environments should be built for the application to allow testing of the applications different functions.
The application should be portable with iOS and Android.
The adaptable platform for the application to run on.
"In order to get a view of how to divide the requirements into different releases and what requirements should be included in which release, a prioritization of the requirements is needed."
This section discusses the choice of prioritization methods and gives a suggestion of how the release plan for these requirements could look like.
When prioritizing the requirements the ten most important ones were picked out first.
"This was done with a simple “1 to 10” ranking method, with one being “not important” and ten “very important”."
"Based on the elicitation meetings, and the perceived ideas of what was important to the different stakeholders, a number was set for each requirement."
The numbers were then summed up for each requirement and the ten with the highest score were chosen to be prioritized with the cost value approach.
"The results, which are red-marked, can be seen in Appendix I and as shown, it turned out to be five functional requirements and five quality requirements."
These requirements were then prioritized according to the cost value approach and the results can be viewed under Appendix II.
The remaining requirements were prioritized according to the “Five-Way Priority Scheme” as shown in Appendix III.
This method was chosen since it gives the different stakeholders the same importance and has an enough wide range for determining which requirement is more important than the other [3].
"However, in this prioritization process, the development team was not included as a stakeholder since the different features were not considered to be as important to them as for the other stakeholders."
"Other methods for prioritization, such as the hundred-dollar test and the yes-no vote, were also considered."
"The hundred-dollar test is quite similar to the five-way priority scheme, since it also gives a wide range for ranking the requirements."
"However, it is more easily misused since someone could save all their money and put them on a requirement that they think is very important [3]."
Others might not agree that this requirement is important but it might still get the most votes since one person cared about it [3].
"The yes-no vote method might be fairly simple to carry out, however the range is too narrow."
"For instance, if two requirements are not very important it would be hard to determine which of those requirements that is more important than the other [3]."
"In conclusion, weighing the disadvantages and advantages of these methods against each other lead us to choose the five-way priority scheme."
The requirements were divided into three releases based on the prioritization and their dependencies.
The three different releases were assembled so that each would work as a fully functional application.
"In the first release the requirements that build up the foundation of the application were included, together with the most highly prioritized requirements and their dependencies."
The second release also includes important requirements.
"However, these requirements are not vital for a functional application."
They are more suited to act as additional features that can contribute to making the software product more attractive.
The third release includes the requirements that can be afforded to discard if the project gets delayed or overruns the budget.
"For further details about the release plan, see Appendix IV."
This document has been produced in the context of the MACC-II project (Monitoring Atmospheric Composition and Climate - Interim Implementation).
The research leading to these results has received funding from the European Community's Seventh Framework Programme (FP7 THEME [SPA.2011.1.5-02]) under grant agreement n° 283576.
"All information in this document is provided ""as is"" and no guarantee or warranty is given that the information is fit for any particular purpose."
The user thereof uses the information at its sole risk and liability.
"For the avoidance of all doubts, the European Commission has no liability in respect of this document, which is merely representing the authors view."
This document compiles a complete set of user requirements for the Copernicus Atmosphere Monitoring Service at the end of the MACC-III project.
"It contains as its main content in a tabulated form all initial requirements raised by the Implementation Group and additional requirements collected by MACC, MACC-II in its 2 periods and MACC-III through all means of user interaction (questionnaire, bi-lateral interaction, user workshops, user advisory board, analysis of relevant GEMS projects and further applicable documents from g. PASODOBLE and PROMOTE, online user queries tool)."
This update (v6.0) is compatible in its requirement numbering to the earlier version v5.0.
The document explores the key user requirements of both Copernicus downstream services and of the intermediate and end users of MACC core services.
Version 1.1 included the evaluation of 11 additional questionnaires received after iterating version 1.0 of the document.
Moreover feedback of users (e.g. the local urban user group) through circulation by the user advisory board has been implemented into the user requirements.
Version 2.0 (MACC) included the response to each of the user requirements by the MACC services and additional users with their requirements (e.g. downstream services ENDORSE and ObsAIRve).
Most requirements could be met (e.g. the request to cover Iceland and Turkey fully (both are EEA member states) by the MACC models has been raised by EEA) or was dealt with during MACC-II but some are at least partly out of scope for the MACC services.
The version 2.0 was submitted to user review and upgraded according to feedback.
Version 3.0 was based on the former version document according to the user feedback.
"In the next version 4.1 (at the end of period 1 of Implementation Group for the GMES Atmosphere Core Service, specifically in chapters parameters for air quality, climate forcing, O3/UV, renewable energies), 5.1 (Functionality) and Annex 3 (Detailed outputs), have been integrated into the documentation of User Requirements for MACC-II."
The final MACC-II issue (v5.0) achieved a re-structuring to put in the focus the tabulated list of user requirements (section 2.1) and integrated in these tables the Implementation Group requirements (extracted from the original text) and further additional requirements obtained during period 2 of MACC-II.
This version of the User Requirement Document contained for the first time a comprehensive and consistently structured collection of all user requirements underlying the MACC services.
Issues (v6.1 - 6.3) add additional requirements and feedback from the service providers obtained during the short period of MACC-III (focused on data access and user interaction towards the operational phase) and updates the responses from the MACC-III team analysed until 6/2015.
It thus includes the documentation of user requirements collected during the MACC series of projects.
To ease implementation in the various services a re- ordering of user requirements was conducted to group the requirements by service where appropriate; some erroneous categorization of requirements as data policy was corrected (maintaining the original numbering).
"User requirements were obtained by all means of user interaction (questionnaire, bi-lateral interaction, user workshops, user advisory board, analysis of relevant GEMS projects and further applicable documents from e.g. PASODOBLE and PROMOTE, online user feedback system)."
The initial formulation of user needs for the MACC project was initiated by the Implementation Group (IG) of the GMES Atmosphere Core Service (GACS).
Consequently the initially formulated needs and requirements as expressed in the final report of the GACS IG from April 2009 build the backbone of the MACC user requirements.
Consequently they are also included in the MACC User Requirements Document.
"Specifically the chapters parameters for air quality, climate forcing, O3/UV, renewable energies), 5.1 (Functionality) as well as Annex 3 (Detailed outputs) have been evaluated and integrated into the MACC user requirements."
Additional user requirements were collected during MACC and MACC-II and all user requirements were now numbered and tabulated to assure traceable responses to them.
Several further user requirements were obtained during the short period of MACC-III (more in the light of the transition to the operational phase and user involvement).
In this analysis the granularity of requirements is kept as they were raised from the originator (so often one requirement includes several sub elements) – this allows an easier matching to concrete services than splitting requirements to a very detailed level (which significantly increases their numbers).
"All together the user requirements document contains now 288 numbered requirements: 188 technical, 44 regarding data access, 6 concerned with data policy and 50 for the newly added category user involvement."
"The following lists of requirements separately listed for four sections (technical, data policy, data access, user involvement) serves as baseline to derive formalized service specifications and trace requirements back to the originating user (group)."
"It should be d that some requirements were erroneously categorized as “data policy” – these were now associated to their correct categories (“technical” or “data access”), but for the sake of traceability their original numbering was maintained, adding the new category tag in front, such as “T(DP)xxx”."
"The requirements for the domains of air quality (AQ), climate forcing (CF), actually need very similar data, e.g. chemical composition, emissions, deposition fluxes, but for different purposes."
Also the requirements for stratospheric ozone and UV services as well as solar radiation are overlapping with the former ones.
"So the requirements listed here for various parameters (e.g. reactive trace gases or aerosols, Tab."
The update of the URD to version v6.1 adds latest feedback from the sub projects and their users including an update of the last column in the requirements tables 8responses on the MACC-III team).
The requirements numbering obeys the following pattern in each group of requirements (Tab.
"Within each group the requirements are sorted related on their topic, not chronologically."
"For each user requirement the following tables (1, 6, 7, 8) contain the requirement description, the targeted service(s), the originator and the implementation status / comment from service providers."
It should be d that user requirements received lately (e.g. during the second user workshop in June 2014) are under investigation (to be continued in MACC- III as part of routine operations) and therefore no further response is yet stated in the last column for them.
For the origin of user requirements the following acronyms are used in the tables: Online user feedback system.
Good availability and connectivity (e.g. maintained.
MACC air quality forecasts and analyses will serve as boundary conditions for further nesting activities of local and urban scale models.
"Furthermore, an emission inventory for use in PASODOBLE will be provided by MACC as well as additional parameters that were derived within PROMOTE at European scale, like forecasts of UV or satellite based aerosol products."
"As learned from PROMOTE experience, it is important to keep a maximum of information in emission inventory species concentrations (e.g. components of PM2.5 rather than the bulk concentration)."
Moreover ECMWF fields (analysis and forecast) should be provided by MACC.
The PASODOBLE Airsheds have been re-defined at the IC_AIRSHEDS Splinter Meeting held along the PASODOBLE Kick-Off Meeting (21.-23.06.2010).
It is important that these areas are covered by MACC European services.
The following MACC data products are required by PASODOBLE during the development and delivery of the PASODOBLE services.
"A timely, adequate and routinely delivery for the defined products is required, preferably two times daily (00:00 and 12:00)."
"At least by one PASODOBLE partner (VITO), a ftp-push system would be preferred for data access."
"G-STEP will use EU/ESA GMES data and programmes, supplied from satellite, aerial and ground based observations along with data from the wider R&D base to advance business innovation and competitiveness."
"The following MACC data products are required by G-STEP for demonstrating applications of space data and for encouraging the supply of local forecast information to relevant groups (e.g. health organizations), and for supplying information to environmental consultants."
G-STEP relies on timely routine delivery of MACC core services with easy access to data for supporting operational delivery of public information.
ENDORSE as GMES downstream project for energy needs from MACC-II solar irradiance time series with best possible accuracy.
"It is important to represent the statistical distribution of irradiance values well, so that the assessment of solar energy applications is based on good coverage of background and extreme values."
Time series need to be based on long enough periods (10-20 years) to allow coverage of typical and extreme years.
Access to the time series at selected locations needs to be provided and needs to be facilitated by up-to-date technical interfaces (web services).
"For services of this kind to be helpful, they must be consistent with existent European policy structure (e.g. EU Clean Air For Europe (CAFE), Convention on Long-range Transboundary Air Pollution)."
"Through the research GEMS and PROMOTE projects, significant efforts have been laid down in making data from national environmental agencies and research networks available in a suitable format and timely delivered."
"The ambition has been to assimilate such surface observations into operational modeling systems in order to improve analysis and forecast of AQ, and to use NRT data for NRT evaluation of model performances."
"Up to now, the NRT AQ data are mainly used for verification of model output in the GEMS and PROMOTE projects."
"This page is showing partly the same information as the EEA ozone web, but there is data from different countries/regions in the two systems."
Best would be the systems would merge into one common environment holding all data.
"In MACC, NRT data is to be used not only for validation but for data assimilation, that is, to produce better air quality forecast and analysis over Europe and the globe."
Input in the aerosol forcing processing tool (developed by Met Office Hadley Centre and ICARE offers a comparison tool of MACC data to satellite data through a web interface.
Browse images made available to the public and data only to registered users.
"The use will relate to specify boundary conditions, to assimilate MACC 3D dust objective analysis based on MODIS data as well as to use MACC dust products for validating/inter-comparing regional forecasts."
Experimental dust assimilation in a regional model using daily MACC dust analysis done by a SDS-WAS partner indicates possible benefits.
"MACC products, with access to the largest set of variables possible."
Improvement of TNO/GEMS NOx inventory necessary with respect to overshooting NOx emissions in large cities.
"Switzerland at the northern border of the Po Valley, while good agreement was found north of the Alps."
This points to an underestimation of NOx sources in the Po Valley.
"Additionally, the data will serve as input for research projects."
Products (and results) need to be proven by peer reviewed articles.
Documentation on data and correction history is needed.
It is important that users can have access to the data that is used for PROMOTE or GEMS services.
This data can then be used by the user for user specific tasks (e.g. for nesting procedures).
As already mentioned during the evaluation of the PROMOTE services it should be interesting to produce daily validation graphs for the air quality forecasts for day-1 and the measurements from day-1 fo the representative measuring locations.
"A number of meetings (user workshops, user advisory board meetings, summer school) led to valuable interaction among users, user feedback and user requirements."
For each meeting a dedicated report is available together with the respective presentations.
"At the first MACC-II user workshop (held jointly with GMES-PURE project, which is analysing the long-term requirements of the atmosphere service and needed satellite input data) a lively dialogue with about 30 users was achieved."
Presentations of the service offering of MACC-II and of a wide range of example use cases (from scientific studies to downstream services and market introduction) demonstrated possible usage to new users (some are shown in brief in section 3) and triggered the discussion.
"Main items of the discussion ranked around the need and possible way forward to estimate and display uncertainties in an appropriate way to users (overall, simple, event-specific)."
"Furthermore, the future evolution (existing gaps and possible improvements) and the perimeter of the service scope (e.g. national specific plots) were questioned."
"One important finding was that there needs to be a borderline of MACC-II service scope to allow small industries to work on the focused (regional, topical) post-processing, while those small businesses are ready to adapt to the evolving service delivery of Copernicus Atmosphere as long as its long-term sustainability is assured."
Regarding data access the user workshop clearly supported a simple registration procedure but no further complicated agreement mechanism; it was suggested that the access rules should be harmonized across all Copernicus services.
"Also service change / outage notifications were recommended, which were implemented afterwards."
A wish for further information on current users and their usage was expressed (e.g. this report provides such a collection).
"An evolution of data access technology (INSPIRE, WIS) was recommended (as implemented by MACC-II in 2014)."
"Dedicated working groups discussed in more detail the products and services for air quality, atmospheric composition, emissions, and solar energy."
"These working groups identified in each topic the added value provided by MACC-II, required new products / parameters (covered in the user requirements document update) and possible usage barriers (e.g. data access)."
"The second user workshop followed a similar format as the first one, but was held in a different member state."
"In addition an outlook to the operational Copernicus Atmosphere Monitoring Service (CAMS) until 2020 could be presented, since the Copernicus regulation had been approved recently."
A dedicated set of questions (focusing on the needs related to operations) was brought to the attention of the ~25 users.
"Questions raised targeted the evolution of input data and modelling technology, data access rules and the governance of Copernicus with its user involvement."
A focus was placed on the best interaction between Copernicus and national actors who may wish to build their services on input from Copernicus (e.g. air quality modelling chain).
"Representatives of national authorities expressed the required constraints for using MACC-II services: stability, continuity and sustainability of the service; if there are changes to the service then these must be very clearly documented to remove the possibility of non-existent trends being identified when in fact the ‘trend’ is due to a model upgrade for example."
Several clear needs were expressed for further evolution of the service offering (e.g. consistency between daily products and long-term re-analysis and clear documentation of service changes); those requirements were again included into the recent User Requirements Document update.
"A first dedicated policy user workshop was held in at the premises of the European Research Executive Agency, where MACC-II explained its policy-related services and products and exposed them to discussion and feedback to a group of national and regional policy actors."
"Those authorities named as their needed Copernicus policy services consultancy, scenarios / sensitivity studies and support in reviews; in many cases this would require on demand support possibly based on underlying routine processing of European data / models."
"Required services include source apportionment, future scenarios along regulatory scenarios."
MACC-II policy toolboxes should allow users to define online their scenarios.
"Continued cooperation with European policy actors (EEA, DG-ENV, JRC) and related international activities (WMO, WHO, UNEP) was recommended."
It was required to improve the robustness of services and documentation of uncertainties.
The representativeness of MACC-II datasets for regional / local observations was discussed.
"The MACC-II European air quality assessment reports were discussed and it was recommended to assess and document the consistency with the report (using the same name) published by EEA; furthermore the need for an advanced assessment report using only non-validated ground-based data was expressed, so that the annual MACC-II report comes timely for its utilization in the national reporting obligations."
Requirements expressed during this workshop were also analysed in the User Requirements Document update.
"Based on discussions at the 2nd MACC-II user workshop preceding the UAB meeting, members of the UAB made took some of those discussion items to concrete recommendations."
A major discussion point was how the MACC-II regional ensemble forecasts can be of best use to national / regional downstream services so that duplicated efforts for global / European modelling can be reduced.
A working group shall be initiated to iterate this issue between national representatives and the MACC-II ENS service and recommend a practical solution based on proven common needs of various users and documented impact of proposed output extensions.
"In addition, tools as they have been recently implemented for selection of parts of the service output (e.g. within OGC web services) can be helpful."
The UAB discussed in how far metadata on service quality / degradation (e.g. a missing particular satellite) can be introduced.
"However, it became clear that further development work and discussion is needed (e.g. on the granularity and severity of such degradation points for well documented major impact) before this is mature for introduction into the service."
The UAB regarded good communication on service updates and relevant meetings (e.g. user workshops) as important and recommended to re-initiate (as in MACC) issuing newsletters with general information; these newsletter should be published on a case-driven basis (a first one was published shortly after the UAB meeting).
Regarding training the UAB recognized the need for a general introduction to new users on the MACC-II website (e.g. in the form of a practical guide how to access the MACC-II products).
"At the end of its first formal MACC-II meeting the user Advisory Board discussed the governance for the future Copernicus Atmosphere Monitoring Service and recommended that the Service should continue to involve its own (topic-focused) User Advisory Board but at the same time the Commission should take care of a good communication between Service-internal user consultation, the Copernicus overall User Forum and the national user communities / formal representation for Copernicus."
"During the MACC-II summer school in June 2013 the 62 participants contributed to user feedback within several dedicated working groups who analysed different parts of the MACC-II website, detected several errors and weaknesses and made recommendations to improve the information."
Overarching the need for a section with frequently asked questions (FAQ) was raised in order to support new users’ entry to accessing the products and services of AMCC-II.
Acknowledging the constraint of easy maintainability those FAQ could be linked from the catalogue selections when a user has chosen the relevant service / product or they could be accessed via a general “cloud of clickable key words”.
"These FAQ could cover topics such as general atmospheric science background, general MACC-II services overview, technical information (methods used, input and output data, validation overview."
These recommendations and further detailed findings of the summer school working groups shall be analysed and a FAQ concept for implementation in the operational Copernicus Atmosphere Monitoring Service worked out during the MACC-III project (8/2014 – 3/2015).
"The second meeting of the User Advisory Board (UAB) was held by telephone conference, hosted by ECMWF on 25 November 2014."
The UAB expressed the request for an uninterrupted service continuity and for informative communication to users about any changes occurring.
The UAB was informed on preparations of a workshop (to be held 7 January 2015) to explore the best response to the user need for more complete chemical suite of species as output from the ensemble service.
"Finally, the UAB discussed the set of user documentation available from MACC-II (and to be updated in MACC-III): user requirements document, user queries summary, user feedback summary, metadata and technical web service interface descriptions."
"The UAB requested better accessibility to the user requirements documentation (including feedback on implementation response status) and to the user feedback summary (including use cases), either online or by better positioning on the website."
"Furthermore, the UAB suggested converting the user questionnaire available at the MACC website into an online tool for easier access."
"Finally, the UAB discussed the future process for prioritizing user requirements during the operational Copernicus Atmosphere Monitoring Service phase."
The UAB can provide valuable consultation in this process within the service.
At the current stage the consideration was raised whether for each requirement a number of users making this request should be added to guide prioritizing.
"However, it was also stated, that requirements by “power users” (e.g. EC directorates or large commercial entities) who request large data amounts or provide their downstream services to large audiences could be prioritized as well."
"The MACC-III Policy User workshop took place in Vienna on 3-4 March 2015 and gathered 29 product providers, users and potential users from 13 European countries."
The workshop focused on downstream users who make use of MACC-III data for policy support.
"Most participants had already gained some experience in using MACC-III products, such as the TNO-MACC emission data, the MACC global model or regional ensemble output for chemical boundary conditions, and the air pollution forecasts (in particular during episodes)."
"These products are used in support of policy decisions, for alerting, and to get a better understanding of the origins of pollution."
"During the workshop, use cases were presented, and news about policy-relevant products of MACC-III were provided."
The second day of the workshop was dedicated entirely to user-provider interaction.
During a series of training sessions the audience received a more detailed introduction about where to find MACC-III products and how to use and interpret the data and graphs.
The different roundtable discussions of the final session gave all participants the opportunity to provide their feedback and to make suggestions for MACC-III product refinements as well as new products.
"During and after the workshop the product providers of MACC-III received very useful comments from representatives from nine different countries, users that will be able to set the path for the information which their national policy officers will require."
"Among the main requests from the users were the timeliness of the products, the tailoring of products to specific regions and to simplify access to products and/or make them easier to find and to download on the MACC website."
"In terms of documentation, more metadata in air pollution data files was requested."
"The MACC-III User Workshop was held on 11 May 2015 in Rome, co-organized by ISPRA, Italy."
"The workshop provided an overview of MACC-III services and user support, a number of user case studies demonstrating the use of MACC-III products outside Italy and presentations on potential use cases in Italy with their associated needs."
A focus topic of the user workshop was the use of MACC-III boundary conditions.
"The interaction during the workshop has large potential to stimulate extended use of MACC-III products in Italy, but requires further coordination of different actors in this country."
The smaller number of attendees from other countries could also benefit from the interaction between users; the model of co-organizing the user workshop with a national Copernicus forum was considered very promising by other national representatives.
The final UAB telecon in MACC-III was held on 22 May 2015.
UAB members discussed best possible means of assuring to obtain user feedback.
Suggestions were made to clean up annually the user lists by requesting a renewal of user registrations combined with an obligatory answering of a small feedback questionnaire.
Such a renewal would require repeated prior notice by e-mail to avoid user frustration.
"Furthermore, different user types (occasional science users, high frequency operational users)) need to be treated differently."
As a second item the UAB discussed the future role of an UAB in the CAMS service.
All members agreed that a UAB allows more detailed discussions of critical items than possible in a larger user workshop.
It was also stated that the Copernicus User Forum based on national representation is too remote from the individual services.
For both reasons it was concluded that a UAB within the CAMS service would be worthwhile also in the future.
PASODBLE is an FP7 GMES atmosphere downstream project closely related to MACC.
"Its goal is to develop and demonstrate user-driven downstream information services for the regional and local air quality sector by combining space-based data, in-situ data and models - health community support for people at risk, hospitals, pharmacies and doctors - public forecasting and assessment support for agencies, tourist industries and sport event - compliance monitoring support on particulate matter for regional environmental agencies - local forecast model evaluation support for local authorities and city bodies Europe: air quality (forecasts and reanalyses), aerosol (SAT), UV, emissions."
G-STEP is a University of Leicester based knowledge-exchange hub.
"The aim of G-STEP is to support the exploitation of Earth Observation data and information in order to assist business, research and public sector organisations."
"G-Step will use European Union and European Space Agency (GMES) data and programmes, supplied from satellite, aerial and ground based observations."
One primary goal of G-STEP is to exploit these GMES technologies and the wider R&D base to advance business innovation and competitiveness.
The project ENDORSE aims at a user-driven development of downstream services in renewable energies by exploiting the GMES Core Services together with other EO/in-situ data and modelling.
"It addresses regional services promoting the energy use from sun, wind, and biomass, electricity grid management and building engineering through daylighting in buildings."
"Further downstream service projects are emerging or have already started: EVOSS (European Volcano Obervarory Space Service), Carbones, ObsAIRve (local air quality information distribution), EURO4M (FP7 2nd space call) and later ones may be added from the FP 7 3rd space call."
Their requirements will be assessed once they become available.
"MACC continues some of the PROMOTE services, thus MACC users have partly also been PROMOTE users."
"For the services which originate from PROMOTE, the user requirements of PROMOTE Stage II (2006 – 2009) apply also to the respective MACC services and are referenced here as PROMOTE origin."
"LANUV is a state authority, directly downstream of the Ministerium für Umwelt und Naturschutz, Landwirtschaft und Verbraucherschutz (Ministry for Environment and Environmental Protection, Agriculture and Consumer Protection) of the German federal state North Rhine Westphalia."
Among many other tasks LANUV is responsible for the assessment of the air quality throughout the territory of NRW and at hot spots of air pollution to meet the national immission protection law (BImSchG) and international obligations (directives of the European Union).
The European Environment Agency (EEA) is an agency of the European Union.
"Our task is to provide sound, independent information on the environment."
"We are a major information source for those involved in developing, adopting, implementing and evaluating environmental policy, and also the general public."
"The German Federal Environment Agency (Umweltbundesamt, UBA) was founded in 1974."
"Its key statutory mandates are to provide scientific support to the Federal Government, to implement environmental laws, and to inform the public about environmental protection."
"UBA acts as partner and Germany’s contact point for many international organisations, including the WHO."
"The mandate of UBA’s department Air Quality – as far as it might be related to MACC products – includes: Operation of the observational network for monitoring long-range and transboundary air pollution in Germany and for observations in international frameworks (UN-ECE, HelCom, OsPar, GAW)."
"The department evaluates air quality observations of its own observational network and the networks of the Federal Länder as well as the situation and development of air quality in Germany, reports on air quality both to the public and to international bodies, and acts as EEA’s NRC Air Quality."
"UBA Air Quality coordinates air quality research as well as standardization, harmonization and quality control of air quality modelling as a base for the development of national air quality strategies and for the evaluation of air quality strategies of the Federal Länder and the municipalities."
UBA Air Quality participates in air quality related bodies and working groups of UN-ECE CLRTAP and the EU.
"As independent and customer-oriented research organisation, VITO provides innovative technological solutions as well as scientifically based advice and support in order to stimulate sustainable development and reinforce the economic and social fabric of Flanders."
"The Deutscher Wetterdienst (DWD), which was founded in 1952, is as National Meteorological Service of the Federal Republic of Germany responsible for providing services for the protection of life and property in the form of weather and climate information."
This is the core task of the DWD and includes the meteorological safeguarding of aviation and marine shipping and the warning of meteorological events that could endanger public safety and order.
"The DWD coordinates the meteorological interests of Germany on a national level in close agreement with the Federal Government and represents the Government in intergovernmental and international organisations as, for example the World Meteorological Organization (WMO)."
Used PROMOTE hourly global forecasts of total column O3.
"Company providing support for the planning, operation and management of solar energy systems."
"GeoModel runs solar radiation model and provides additional data, spatial analyses and simulation tools aimed to specific user groups."
Data and simulation tools can be accessed throughout online interactive system http://solargis.info.
More information about Used GEMS Global aerosol service.
"Within the frame of public policies defined by the French government, ADEME’s mission is to stimulate, animate, coordinate, facilitate and perform operations aiming at the environment protection and energy management."
"Used PROMOTE and GEMS Services are PROMOTE Air Quality, GEMS Global Reactive Gases and GEMS Regional Air Quality."
NIES works with GOSAT - project information is available at www.gosat.nies.go.jp NIES plans to try using MACC aerosol product for research on bias correction in the remote sensing CO2 and CH4 products.
"As part of the Earth Observation Group at the University of Leicester, UK, my main area of current research is retrieving carbon dioxide and methane total column dry air mole fractions from the Greenhouse gases observing satellite (GOSAT) which is the first dedicated greenhouse gas satellite launched in Jan 2009."
"Using the MACC aerosol and cirrus optical depth and mixing ratio information for forecasted, near real time, dates allows for simultaneous retrievals of trace gases and aerosols/cirrus and has the potential for constraining our retrieval precision and quantification of aerosols/cirrus globally."
Used GEMS NRT and forecast Global Aerosol and Global Greenhouse Gases services.
Use of MACC products in risk forecasts for patients suffering from Chronic Obstructive Pulmonary Disease (COPD) and for aerosol forcing monitoring (done by Hadley Centre).
Use of MACC products for scientific analysis surveying on energy consumption that deteriorate environment.
"Laboratoire de Physique et Chimie de l'Environnement, Centre national de la recherche Use of MACC products for mesoscale modeling of atmospheric chemistry in the troposphere and lower stratosphere and for comparison with the model outputs."
The Belgian Interregionale Environment Agency (IRCEL-CELINE) is responsible for the forecasting of episodes with enhanced air pollution on behalf of the three Belgian Regions.
"In our forecasting procedures we use neural-nework as well as deterministic air quality models (CHIMERE, AURORA)."
Besides this own used models we also use information provided by foreign models (e.g. for instance the results on the gems.ecmwf.int website).
We were also a PROMOTE end user and are now participation in the PASADOBLE project.
"ICARE processes and provides online archive of satellite data to study the atmosphere (aerosols, clouds, radiation and water cycle)."
Any MACC products (observations or model forecast) relevant to these fields are of potential interest.
CENSE – Center for environmental and sustainability research.
MACC products could be helpful on the air quality forecast at local/mesoscale level.
Empa operates the Swiss national air quality network and is strongly involved in worldwide measurements of reactive as well as persistent atmospheric trace gases and particulates for example in the framework of GAW.
"Additionally, it employs several modeling systems for the assessment of source-receptor relationships and impact studies."
Those modeling efforts can greatly benefit from the use of MACC emissions and boundary condition data.
"Research laboratory, mesoscale modeling of atmospheric chemistry in the troposphere and lower stratosphere, Use of MACC products to compare with the model output."
The European Topic Centre on Air and Climate Change (ETC/ACC) assists the EEA in its support to EU policy in the field of air pollution and climate change.
"The ETC/ACC reports on the progress of EU enviromental policy on air quality, air emission and climate change issues."
"It participates in assessments and supports the European Environmental Outlook reports of the EEA, it collects data concerning the current state of the environment on air and climate change, and it is involved in further harmonising European monitoring networks and reporting obligations."
"MACC products could serve as reference material next to currently used data collection, but also as integrated part of our data collection, our state and outlook assessment activities."
"As such, we are seeking for synergies, connectivities, compatibilites and integrations / merges of our activities and products with (future) MACC activities and products."
"Please note that the answers in this questionnaire do not reflect the opinion of the ETC as a whole, but of PBL as a partner within the ETC; focusing on a specific part of the ETC/ACC work for EEA."
The Portuguese Meteorological Institute is the Portuguese national authority for meteorology and a member of ECMWF.
It provides national weather forecasts including ultraviolet index and total ozone column on a daily basis.
This section contains the questionnaire sent out to possible and confirmed users of MACC services and continuing to be available in the MACC web portal (O-INT sub project web site).
It has also been distributed within the local urban user group.
"Kindly provide some information on your organization and major tasks, where MACC products could be of help."
Which PROMOTE or GEMS service(s) have you used (if any)?
Which MACC service(s) do you use or consider using (see http://www.gmes- atmosphere.eu)?
Have you any specific lessons learnt from PROMOTE or GEMS (improvements due to user involvement)?
What are your requirements with regard to access mode?
What are your general expectations for the service(s); what will be the benefits?
How will the service(s) be used in your every day work?
CR 196 - Limited set of changes primarily to change loss of crew value and verification in 3.2.1.1 such that it measures the design applicable document that have been approved since CR 164 and design guideline errors found in appendices.
"CR 0164 -Limited set of changes to capture selected standards updates, clarifications identified through iCap and CPC contracts and JPRCB direction to implement the full pressurized Cargo IRD."
CR 0119 – Changes clarified and stabilized 1130 requirements; enabled more accurate proposals from the Commercial Partners; and incorporated changes required by ISS for post-landing operations.
Corrected omissions of previously approved changes and added export control notation in footer.
Verification and Requirement Updates per CCP CR0035.
"Under the guidance of processes provided by Crew Transportation Plan (CCT-PLN-1100), this document with its sister documents, Crew Transportation Technical Management Processes (CCT- PLN-1120), Crew Transportation Technical Standards and Design Evaluation Criteria (CCT-STD- Station (ISS) to Commercial Orbital Transportation Services Interface Requirements Document (SSP for services to the ISS for the Commercial Provider."
"When NASA Crew Transportation System (CTS) certification is achieved for ISS transportation, the Commercial Provider will be eligible to provide services to and from the ISS during the services phase of the NASA Commercial Crew Program (CCP)."
The CTS has two top-level objectives in support of the NASA mission of providing services to the ISS.
"The primary objectives are to provide for crew rotation capability for four NASA or NASA-sponsored crewmembers, henceforth called NASA crew, and to provide for an emergency crew return capability for these crewmembers at any time while the commercial spacecraft is docked to the ISS."
"Secondary objectives include transporting a limited amount of ISS Program-specified pressurized cargo to the ISS, returning pressurized cargo from the ISS, and providing for a crew safe haven capability when the spacecraft is docked to the ISS."
The Design Reference Mission (DRM) for ISS can also be found in CCT-DRM-1110.
The spacecraft will be capable of transporting NASA crew to the ISS and docking 24 hours after launch.
Mission launch opportunities must be accomplished within NASA-specified timeframes to accommodate ongoing ISS science operations and to minimize ISS traffic model impacts associated with other visiting vehicles.
"Prior to launch, the CTS supports a NASA-provided pre-launch health stabilization program for NASA crew."
The CTS also assures comparable health stabilization for any other crewmembers.
"Within a few hours of launch, NASA completes their crew medical assessments and baseline data collection process in NASA-provided facilities and hands the crew over to the CTS provider for transportation to the launch site."
The NASA flight surgeons will serve as the physicians for the NASA crew during all phases of flight.
Lift-off occurs when the launch site passes through the ISS’s orbital plane.
"Daily launch opportunities then depend on the resulting phasing; an everyday launch opportunity is desirable, but not required."
Launch and ascent into the 51.6 degree inclination must meet Range Safety constraints associated with the launch site.
"Following ascent, an orbital insertion maneuver is executed and becomes the first of several orbital rendezvous maneuvers to be performed."
These maneuvers bring the spacecraft closer towards the ISS.
ISS standard communications are used when the spacecraft closes to within tens of kilometers to the ISS and ship-to-ship voice communications are established.
Relative navigation is performed by the spacecraft using available cooperative and non-cooperative assets on the ISS.
"Communication and telemetry monitoring will be shared between the Commercial Vehicle Control Center (CVCC) and the ISS mission control facilities, Mission Control Center - Houston (MCC-H)."
"MCC-H Mission Authority will be established to ensure ISS, spacecraft, and crew safety."
"When in close proximity to the ISS, after receiving approval from both the spacecraft and MCC-H, the spacecraft begins a final approach to a NASA-specified docking port on the ISS."
"After docking, the vestibule between the ISS and the spacecraft is pressurized and verified not to be leaking."
"The spacecraft hatches are opened and the crew transfers into the ISS, placing the newly arrived spacecraft in a quiescent state."
"If the nominal docking attempt is not successful, or if an anomaly occurs near docking which would prevent docking at the nominal opportunity, the spacecraft backs out to a short safe distance and performs necessary reconfigurations, followed by a second approach and docking attempt."
"If that docking is also unsuccessful, the spacecraft will separate from the ISS vicinity on a collision-free safe trajectory and the spacecraft will prepare for a final re-rendezvous and docking attempt on the following crew day."
"If this final docking attempt is unsuccessful, the mission will be terminated, and the crew will return to Earth."
"Because of the short time duration from launch to docking, internal maintenance of the spacecraft should not be necessary, nor should the crew require certain complex habitability items for food and waste management that can be found on longer duration vehicles, like the Space Shuttle or the ISS."
Extravehicular Activity (EVA) will not occur because the complexity of preparing for and executing an EVA is precluded due to the short time in the spacecraft early in the mission.
"Similarly, EVA will not be performed during the short free-flight duration from undocking to landing."
"The spacecraft will be designed to be attached to the ISS for 210 days, although nominal crew rotations will occur at approximately 180-day intervals."
The spacecraft remains quiescent and requires minimal maintenance during docked operations.
"The CVCC will provide routine, periodic support for these docked operations, in association with MCC-H."
The ISS will provide power and environmental resources to the spacecraft in order to maintain the vehicle in a return-to-Earth ready state.
"Due to limitations in the number of docking ports on the ISS, the spacecraft may need to be relocated from one docking port to another during ISS increment operations to provide operational flexibility."
"To accomplish this relocation, the spacecraft’s full crew complement will ingress the spacecraft, close the hatch, and the spacecraft will be relocated from one port to the other port."
The crew needs to be in the spacecraft to protect from the potential failure to re-mate with a docking port and preserve assured return for the crew.
"When docked to the ISS, the spacecraft also provides a contingency “safe haven” capability allowing the crew to retreat to the spacecraft, close the hatch, and remain in a safe environment for up to 24 hours."
"If necessary, the spacecraft atmosphere will be purged during this activity."
The ISS will provide attitude control during this 24-hour period.
"After the ISS returns to a habitable environment state, the crew will open the hatch and re-enter the ISS."
"If the ISS cannot achieve a habitable state during this period, the crew will return to Earth."
"While docked to the ISS, the spacecraft will also serve as an emergency return vehicle for contingencies requiring the return of the crew brought to the ISS."
"Emergencies could result from ISS system failures, an uninhabitable crew environment, or a medical event requiring the return of the crewmembers."
The crew will return to Earth within 24 hours of a declaration of an intention to return early.
"The crew will be fully trained to execute these contingency return-to-Earth operations, landing at a location where rescue is likely to be most expedient."
"Due to the limited size and power available, the spacecraft is expected to have basic first aid and life support capability to respond to immediate medical conditions in the free-flight mode."
"If the Commercial Provider has received NASA approval to fly non-NASA crew to the ISS, the spacecraft will need to provide food, water, clothing, Environmental Control and Life Support System (ECLSS) consumables, and other logistics for these crewmembers for the docked timeframe, since NASA does not generally pre-position these supplies on the ISS."
"After handover is complete, the current increment crew will return in the spacecraft."
"They will enter the spacecraft, perform a vehicle health check, close hatches, depress the vestibule, perform a hatch leak check to verify seal integrity, and depart from the ISS."
"When available consumables permit, the spacecraft will potentially circumnavigate the ISS while in proximity to assess the external configuration of the ISS prior to final departure."
"During this circumnavigation, the crew will capture imagery to allow post-flight analysis of the ISS configuration."
The timeframe from undocking through landing is envisioned to be a short 4 to 8 hour free-flight duration.
Landing will occur on the continental United States (U.S.) land mass or waters directly extending from the coast for nominal landing.
"This reduces risk by minimizing rescue force assets, increasing proximity to U.S. medical facilities, increasing security, and ensuring a prepared landing site free of hazards."
"If the nominal deorbit maneuver is waived-off after separation from the ISS, a subsequent landing at an alternate landing site, with nearby recovery forces, will be possible."
The spacecraft may also perform orbital maneuvers in low Earth orbit (LEO) to better accommodate alternate landing sites.
"Returning crew will be deconditioned and potentially have impaired musculoskeletal, cardiopulmonary, and neurovestibular capabilities as a result of long duration exposure to the micro-gravity and space environment, resulting in degraded crewmember performance in the post- landing timeframe."
"Because of the deconditioned state of the crew, special considerations need to be provided for crew recovery, medical care, and other post-landing care activities."
"Upon arrival at the landing location, the NASA crew will be met with a recovery crew that will assist the astronauts in egress operations and removal of time-critical cargo."
NASA personnel will begin post- flight medical and science evaluations soon after egress is complete in a temporary facility at the landing location.
"Subsequently, the NASA flight crew, NASA support personnel, and time-critical cargo will be transported by a CTS element to a staging location where handover will be completed and the NASA crew and cargo will be flown back to Houston using NASA assets."
"After recovery operations are complete, the spacecraft will be safed and transported to a location for subsequent post-flight evaluation."
"The purpose of this document, hereafter referred to as CCT-REQ-1130, is to provide the requirements for development (design, manufacturing, testing, qualification, production, and operation) of commercial services to deliver NASA crew and limited cargo to and from the ISS."
"The intent of this document is that all CTS requirements are to be fulfilled by the Commercial Provider; however, it may be more practical for NASA to provide the consumables or hardware associated with a particular function."
This document clearly states when a function or hardware is the responsibility of NASA.
These services and design requirements were developed by the CCP and the ISS Program for the crew transportation system.
This document is clearly divided into ISS destination services requirements in Section 3.1 and transportation certification requirements in Sections 3.2 through 3.11.
"The CTS refers to all assets and services required to meet the requirements of CCT-REQ-1130, including pre-flight planning, trajectory and abort analysis, ground processing and manufacturing, ground operations, mission control, training, launch control, post-landing recovery operations, safety and mission assurance, and all other functions required for safe and successful human space flight missions."
"Other key definitions include integrated space vehicle, which will be used when discussing the launch vehicle and spacecraft."
"The spacecraft is also known as the “crewed element” and serves as the crew rescue or crew transfer vehicle, while the “launch vehicle” is the element that provides the propulsion systems necessary to transport the spacecraft to the desired insertion orbit."
"Another term that is utilized throughout this document is NASA crew, which consists of all crewmembers sponsored by NASA, including both International Partners (IP) and NASA astronauts."
"In the event of a conflict between the text of this document and references cited herein (listed in Section , the text of this document takes precedence."
"The exception to this statement is for SSP 50808, which takes precedence during ISS integrated operations."
Nothing in this document supersedes applicable laws and regulations unless a specific exemption has been obtained.
"In the event of conflict between this document and any spreadsheet exports of the NASA requirements database, the contents of this document take precedence."
This document was jointly prepared by and will be jointly managed by the CCP and the ISS Program.
The Joint Program Requirements Control Board (JPRCB) is the authority for baselining and approving changes to this document.
CCT-REQ-1130 will be maintained in accordance with standards for the CCP documentation.
"The CCP is responsible for assuring the definition, control, implementation, and verification of the requirements identified in this document."
Coordination with the ISS Program for verification and eventual certification of the requirements identified as ISS driven requirements will be performed through the CCP.
"When used within the context of a requirement under a contract, statements in this document containing shall are used for binding requirements that must be verified and have an accompanying method of verification; will is used as a statement of fact, declaration of purpose, or expected occurrence; and should des an attribute or best practice which must be addressed by the system design."
"When used within the context of a reference document under an agreement, the verbs shall, will, and should are only intended as informational and are not binding."
"In some cases, the values of quantities included in this document have not been confirmed and are designated as: “To Be Confirmed” (TBC) - still under evaluation, and “To Be Determined” (TBD) or “To Be Supplied” (TBS) - known, but not yet available."
"A ""To Be Resolved"" (TBR) is used when there is a disagreement on the requirement between technical teams."
"When a change in a d characteristic is deemed appropriate, notification of the change shall be sent to the appropriate review and change control authority."
Each requirement in CCT-REQ-1130 is annotated by its section number.
At the end of each requirement text is a requirement ID of the format R.CTS.
It can be used to cross reference requirements in this document to spreadsheet exports of the database.
See Section 1.3 in the event of conflict between this document and spreadsheet exports.
"The following design, manufacturing, testing, and quality control standards apply to all space flight hardware and software, including the launch vehicle, all portions of the spacecraft, and any launch abort system."
"There are also specific standards for ground support equipment (GSE), along with software standards for ground software that are needed to perform a primary mission objective, have direct interaction with human space flight systems, or have a direct impact on the health and safety of the crew."
They are identified by the words “meet” within the corresponding sections of this document.
Within the Applicable Documents list below these standards will be shown as fully applicable.
Verification language for these technical standards that must be met can be found in Section 4.0 of this document.
Any Applicable Document listed within these “meet” documents are considered to be “meet the intent of” documents and alternative standards can be proposed.
These contain requirements that can be met explicitly by following the standard or by proposing alternate standards that meet or are consistent with the requirement levied in the NASA Standard.
It should be understood that the applicable documents called out by “meet the intent of” standards from CCT-REQ-1130 are also considered “meet the intent of” standards.
"Within the Applicable Documents list below these standards will be shown as “Alternative Allowed.” Because these standards are unique, CCT-STD-1140 was developed to define some specific criteria utilized by NASA to evaluate and approve alternative standards."
The process and product defined in the respective sections of CCT-STD-1140 define the details of how any proposed alternative standards will be evaluated along with the key aspects of items proposed as part of the verification.
The Requirements Applicability Matrix in Section 2.1 of CCT-STD- alternative is allowed.
The specific verification language for each of these alternative standards will be partnered with NASA after an agreement is reached on the alternative standard.
Verification language for these technical standards that must be met or complied with can be found in Section 4.0 of this document.
"Similar to Engineering Standards, Human System Integration Design Requirements are listed in Appendix Q and are invoked by the “meet the intent” requirement 3.10.1."
Alternatives to the children requirements in Appendix Q can be proposed.
These are the third type of NASA standard and many of these documents can be found in the reference documents in Section 2.2.
These technical standards are reference and will have no verification language attached.
"CCT-STD-1150 was developed to define specific criteria for operations spanning the interval from integrated vehicle assembly, test, and integration at the launch site through recovery of NASA crew and cargo at the landing site(s)."
The products and processes defined in the respective sections of CCT-STD-1150 discuss in detail how operational standards will be evaluated.
"This section will provide a list of documents and technical and manufacturing standards that can be used as a reference during the launch vehicle, spacecraft, and ground system design activities."
Additional reference documents for a variety of technical disciplines can be found in CCT-STD-1140.
"Development of Acceleration Exposure Limits for Advanced Escape Systems (Brinkley, J.W."
The Use of a Vehicle Acceleration Exposure Limit Model and a Finite Element Crash Test Dummy Model to Evaluate the Risk of Injuries During Orion Crew Module Landings.
"Lockheed Engineering and Sciences Company, Inc., 1989."
"The Role of the Vestibular Organs in the Exploration of Space,"" pp."
The CTS shall be capable of at least two crewed launches to the ISS per year.
"Rationale: A normal ISS increment is 180 days, requiring a new replacement crew to be launched approximately two times per year."
"The CTS shall simultaneously operate two spacecraft, to allow an ISS NASA crew handover."
"The launch of the next rotation mission may occur prior to the departure of the current increment crew working on the ISS, resulting in a direct crew handover period where two commercial spacecraft would be docked to the ISS for approximately 7 to 10 days."
"The communication infrastructure in the spacecraft, CVCC, network, and other required assets must be sized to accommodate two operational spacecraft (one docked and one in free-flight mode or both docked)."
Rationale: ISS crew time is reserved for science and other operations.
"The spacecraft design should not require commanding, active monitoring, and maintenance during quiescent docked operations to avoid impacts to the ISS crew science productivity."
"Additionally, this will reduce the overall burden on the ground infrastructure required to support this spacecraft while docked to the ISS."
Periodic vehicle maintenance with a maximum crew impact is defined in requirement 3.8.3.1.
"The CTS shall complete the mission without requiring an EVA for nominal operations, contingency operations, or to perform maintenance activity."
Rationale: EVA will not occur because of the short time in the spacecraft early in the mission when the complexity of preparing for and executing an EVA precludes that activity.
"EVAs during the docked timeframe impact ISS crew time, consumables, and on-going science activities."
"Finally, the timeframe at the end of the flight is envisioned to be a short free-flight duration from undocking to landing, which precludes EVA."
"Rationale: Unless specifically d in requirement 3.1.1.6 or SSP 50808, the CTS must provide all the supplies necessary for space flight to meet the functions described in CCT- REQ-1130."
"The spacecraft shall accommodate and utilize the NASA-provided supplies for NASA crew to include the following items: Environmental Health Kit, Food and Utensils, Contamination Cleanup Kit, Passive Radiation Area Monitors, Crew Personal Dosimeters, Medical Kit, ISS Medical Accessory Kit (IMAK), Crew Worn-On Items, and ISS Crew Provisions."
The spacecraft shall accommodate a total of 85 kg (187 lbs) of NASA-provided supplies.
"Rationale: NASA has determined that certain items, such as food, clothing, personal dosimeters, a medical kit, and an environmental kit, will be provided to the NASA crew since many of these items will be the same product that they will use on their 180 day stay on the ISS."
A notional list of NASA-provided supplies for NASA crew with mass and volumes can be found in Appendix J for reference.
Some items in the NASA-provided supplies are driven by the operational timelines and contingency days.
"The base value for food was chosen in accordance with the notional timeline in Appendix P. For mission durations greater than this, additional food would be required."
"It is easier for the crew to have the same individual item and familiarity and training with the common items (e.g., Medical Kit) during both the free-flight and docked portions of the mission."
"For these items, the spacecraft must provide the appropriate stowage and interfaces to properly store the equipment prior to use."
These items are not cargo or payload and are in addition to the 100 kg of cargo called out in requirement 3.1.3.1.
"The CTS shall provide habitable consumables, such as food, water, clothing, oxygen, nitrogen, CO2 removal, personal hygiene, and other required consumables, for non-NASA crew during the docked portion of the mission when the non-NASA crewmembers are on the ISS."
"Rationale: For any mission model that requires additional crew beyond the 4 NASA crew required for the ISS increment, the CTS will be responsible for carrying the required logistics in the spacecraft to support the additional crewmembers during docked timeframe."
"NASA will not have the ability to pre-position supplies on ISS via another cargo launch vehicle due to the required ISS logistics support via Cargo Resupply Contract (CRS), Progress, and Automated Transfer Vehicle (ATV)/H-II Transfer Vehicle (HTV) vehicles."
"Thus, the CTS will be responsible for providing food, water, clothing, and other logistics for non-NASA crew."
The nitrogen only needs to be provided if any equipment or operation to support the non-NASA crew is venting air overboard as part of its nominal operation.
"The CTS shall accommodate 1, 2, 3, and 4 NASA crewmembers during a single mission."
Rationale: Four NASA crew are required to be transported and returned to the ISS during a single mission to meet the United States Operations Segment (USOS) demand for crew time based on full utilization of the ISS to perform science and support the ISS National Laboratory Program.
"All docking and undocking operations are a significant impact to the completion of ISS science, resulting in the determination by the ISS Program that the most efficient crew rotations strategy is to launch and return 4 crewmembers on a single vehicle."
"Additionally, the CTS must be able to perform the mission with crew complements of 1, 2, 3, or 4 crewmembers in a single launch or landing to provide flexibility in the ISS crew rotation plan."
Rationale: NASA crew are required to be transported to the ISS to meet the United States Operations Segment (USOS) demand for crew time based on full utilization of the ISS to perform science and support the ISS National Laboratory Program.
Rationale: NASA crew are required to be returned from the ISS to meet the United States Operations Segment (USOS) demand for crew time based on full utilization of the ISS to perform science and support the ISS National Laboratory Program.
The ISS requires continuous presence of the spacecraft to support sustained operations.
The 210 days provides 30 days of contingency on the nominal 180 day turnaround.
The nominal crew rotation will occur at approximately 180 days based on the ISS human research program medical data collection needs.
It is possible for this rotation to be altered by one month (earlier or later) in order to accommodate other overall ISS Program requirements or anomaly resolution/response.
The CTS shall launch from a U.S. (or U. S. State Department approved) launch site(s).
"Rationale: Launching from a designated U.S. (or U.S. State Department approved) launch sites reduces risk by minimizing necessary abort recovery force assets, increasing proximity to U.S. medical facilities, increasing security, and ensuring a prepared launch and emergency landing site, which minimizes unknown hazards and potential security issues."
"Rationale: Returning to a designated continental U.S. landing site or waters directly extending from the coast reduces risk by minimizing necessary recovery force assets, increasing proximity to U.S. medical facilities, increasing security, and ensuring a prepared landing site free of hazards."
"Deconditioned crewmembers have impaired musculoskeletal, cardiopulmonary, and neurovestibular capabilities as a result of long duration exposure to the micro-gravity and space environment, resulting in degraded crewmember performance in the post-landing timeframe."
"Because of the deconditioned state of the crew, special considerations need to be provided for medical and other post-landing care."
"This cargo includes any NASA items (ISS maintenance hardware, powered payloads, etc."
These items required for crew sustenance and operations of the spacecraft will be provided by the CTS and will be allocated mass and volume in addition to cargo goals defined below.
The spacecraft shall accommodate 100 kg (220.5 lbm) of soft stowage cargo in the pressurized volume during a single mission.
The spacecraft shall provide a contiguous volume with the dimensions 0.468 m x 0.556 m x accommodate time critical cargo.
"The 100 kg, 0.227 cubic meter cargo requirement is sized to transport a small amount of ISS Program-specified cargo inside the spacecraft to be transferred to the ISS upon arrival."
The cargo will be contained in either a standard set of ISS soft stowage cargo to easily accommodate transfer by the crew onorbit.
The dimensions of 0.468 m x 0.556 m x equivalent to a double-middeck locker and was chosen such that it would be a candidate location for the hard mounted cargo swap required by requirement 3.1.3.5.
The cargo in this volume (whether hard mounted or soft stowage) must be accessible as time-critical cargo.
Maximum flexibility in configuring the cargo items is important since failures of hardware components on the ISS will be a factor in the cargo items manifested on a given CTS mission.
"The spacecraft shall accommodate an additional 100 kg (220.5 lbm) of soft stowage cargo in lieu of a NASA crewmember during a single mission per requirements in SSP 50833, Section 3.1.2, except for Triple CTB's in section 3.1.2.1 and all M-Bags in section 3.1.2.2."
"The transport of an additional 100 kg of soft stowage cargo in lieu of a NASA crewmember provides the capability to react to situations that dictate the timely delivery and return of ISS components, supplies, and science hardware due to operational needs of the ISS."
"Obviously, maximum flexibility in the size, volume, and mass is important to accommodate a wide range of potential cargo."
The concept proposed is that the seat would be removed to allow for a cargo pallet or other structure to be flown in its place in order to properly restrain the cargo.
"The spacecraft shall accommodate hard mounted time-critical cargo consisting of either two powered single middeck lockers or one powered double middeck locker in the pressurized volume during a single mission, and maintain cargo services per requirements in SSP 50833, Section 3.1.1 while installed."
The intent of this requirement is to allow for the transport of time-critical cargo in a powered middeck locker or lockers.
"ISS power necessary for the locker(s) will be provided from docking until payload transfer in addition to, not in lieu of, all other power allocations specified herein or within SSP 50808, such as requirement 3.4.2.5, ISS Safe Haven or SSP the locker(s) are required in addition to, not in lieu of or included within, all other mass and volume requirements specified herein, i.e., the 100kg (220.5 lb) of pressurized cargo defined in requirements 3.1.3.1 and 3.1.3.5."
The middeck locker(s) would be provided by the ISS Program either prior to launch or during onorbit operations to be transported to or from the ISS with a known quantity of science samples inside.
"When the need arises, operational flexibility is required to allow the ISS Program to fly additional passive cargo within the mass and volume of the powered lockers."
"The spacecraft shall accommodate additional time-critical hard mounted cargo consisting of either two powered single middeck lockers or one powered double middeck locker, during a single mission in lieu of the soft stowage cargo required by 3.1.3.1."
The intent of this requirement is to allow for the transport of scientific samples in a powered middeck locker or lockers.
"ISS power necessary for the locker(s) will be provided from docking until payload transfer in addition to, not in lieu of, all other power allocations specified herein or within SSP 50808, such as 3.4.2.5 ISS Safe Haven or SSP 50808, 3.2.2.4.1.3 Power Consumption."
The middeck locker(s) would be provided by ISS either prior to launch or during onorbit operations to be transported to or from ISS with a known quantity of science samples inside.
"The CTS shall maintain cargo services per SSP 50833, Sections 3.1.1 and install time-critical cargo within 24 hours of a scheduled launch."
"Rationale: Once time-critical cargo has been handed over from the ISS program, it is critical that cargo services be maintained to ensure the integrity of the cargo."
"Late cargo installation, within 24 hours of scheduled launch, is required to maintain the integrity of time-critical cargo."
"The CTS may select the specific integration window, as long as it is within 24 hours of scheduled launch."
This requirement addresses both soft stowage and hard mounted time-critical cargo.
The time-critical cargo installation may include an Integrated Verification Test (IVT) to verify the interface between the spacecraft and the payload and must be completed within the L-24 window of opportunity.
"Once installed, the CTS must maintain cargo services, if required, until the cargo is removed for transfer to the ISS."
"In the event that a launch is scrubbed or delayed and rescheduled, access to remove and re-install the time-critical cargo would need to be provided as well."
"The CTS shall remove ISS time-critical cargo from the spacecraft no later than 1 hour after crew egress, post-docking and post-landing at a supported landing site."
Rationale: Early cargo access after spacecraft docking and landing is required to maintain the integrity of time-critical cargo.
"On orbit, the ISS crew must perform post-docking procedures quickly such that the cargo transfer can also occur no later than one hour after crew egress from the spacecraft."
"The CTS will provide the capability to retrieve time-critical cargo within 1 hour upon completion of crew egress after post-landing and post-docking, while also providing continuous cargo services, per SSP 50833."
The ISS program requires the operational flexibility to best utilize crew time and manage the crew day.
Mission priorities may preclude cargo transfer immediately following docking or prior to undocking requiring the spacecraft to maintain the specified environment and services until cargo transfer can be completed.
"In these scenarios, the spacecraft will receive the necessary ISS resources, e.g. power and intermodule ventilation (IMV), to support this mode of operation."
"The CTS shall have a launch probability not less than 80% for each launch opportunity, exclusive of external launch constraints and abort zone weather, for the time interval beginning with tanking and ending with the launch window close for that attempt."
"The launch vehicle, spacecraft, and ground infrastructure must be designed to have a high launch probability once the vehicle is in the final stages of preparation for launch."
"Each point at which the ISS is within the planar and phasing capabilities of the system is considered a launch opportunity; therefore, probability must be calculated throughout the year for these daily opportunities."
"The timeframe begins with booster tanking on the launch day, which signals a commitment to launch on that day and ends when a launch is no longer possible due to performance limitations."
